[
  {
    "title": "在 Quartz v4 中嵌入本地 HTML 格式报告的解决方法",
    "summary": "事情是这样的：最近我注意到，Gemini App 在执行深度思考并生成报告之后，还能进一步基于这份报告产出一份交互式的 HTML 网页，前端审美非常棒。作为赛博仓鼠癖，我自然想：能不能把这个页面嵌入到我的 Quartz 4 笔记中展示呢？——反正 Quartz 4 和 Obsidian 本质上是一体的，Obsidian 能做的，Quartz 4 应该也能吧？……对吧？然后，我带着这个朴素的想法，和",
    "tags": [],
    "url": "/posts/TechnicalTutorials/quartz-html-embedding/",
    "date": "2025-06-16T00:00:00.000Z",
    "content": "事情是这样的：最近我注意到，Gemini App 在执行深度思考并生成报告之后，还能进一步基于这份报告产出一份交互式的 HTML 网页，前端审美非常棒。作为赛博仓鼠癖，我自然想：能不能把这个页面嵌入到我的 Quartz 4 笔记中展示呢？——反正 Quartz 4 和 Obsidian 本质上是一体的，Obsidian 能做的，Quartz 4 应该也能吧？……对吧？然后，我带着这个朴素的想法，和 o3、Gemini 2.5 Pro、GPT-4o & OpenAI深度思考、Roo code 等等 AI 模型和产品展开了长达七个小时的缠斗，最终得出一个明确结论：可以实现，而且稳定、可复用。下面是我总结出的解决方法。一、原理说明：Quartz 4 为什么不讲理？Quartz v4 本质上是一个基于 TypeScript 的静态站点生成器，它对 .md 和 .html 有着「各执一词」的态度：如果你把 HTML 文件放进 content/ 目录，它会当成一篇笔记处理，然后去掉扩展名输出，这就导致html文件没办法正常被渲染展示；如果你放进根目录的 static/，Quartz v4 根本不会管它（那个 static 是给主题内文件用的）；即便你配置了 Plugin.Static()，Quartz 也只会把 quartz/static/ 里的文件搬到 /static/ 路径下；你不能在 Plugin.Assets() 或 Plugin.ContentPage() 里“说服”它保留 .html 扩展名——因为这些插件压根不支持你想要的那种 override。总结一下：Quartz v4 在构建层面压根没考虑你想挂载 HTML 文件，因为它默认你不会做这种事。我们必须另辟蹊径，把 .html 报告的生命周期交给我们自己控制，Quartz 构建完之后我们再偷偷塞进去。二、操作步骤：绕过 Quartz第一步：把报告文件放进单独目录新建一个 reports/ 文件夹，所有要嵌入的 HTML 报告（比如 Gemini 生成的交互页面）都放进去，比如：your-project/\n└── reports/\n    └── 20250613-iran-vs-israel-overview.html第二步：在笔记中通过 iframe 引用在任意 .md 文件中写入：<iframe\n  src=\"/reports/20250613-iran-vs-israel-overview.html\"\n  style=\"width:100%;height:90vh;border:none;\"\n  loading=\"lazy\">\n</iframe>这样 Quartz 构建时会忽略它，后面我们再补进去。第三步：在构建后自动复制报告文件打开 package.json，在 scripts 中加入以下字段：\"scripts\": {\n  \"copy-reports\": \"mkdir -p public/reports && cp -r reports/* public/reports/\",\n  \"quartz-build-and-copy\": \"npx quartz build && npm run copy-reports\",\n  \"build\": \"npm run quartz-build-and-copy\"\n}这段逻辑做了两件事：先跑原始的 Quartz 构建；然后把你放在 reports/ 里的报告原样复制到最终 public/reports/ 路径下，不改名、不加 .html，不被 Quartz 干扰。第四步（关键）：显式告诉 Vercel 用这个脚本部署编辑 vercel.json，加入：{\n  \"buildCommand\": \"npm run build\",\n  \"trailingSlash\": false,\n  \"rewrites\": [\n    {\n      \"source\": \"/:path((?:[^/]+/)*[^./]+)\",\n      \"destination\": \"/:path.html\"\n    }\n  ]\n}否则 Vercel 默认只会跑 npx quartz build，根本不会执行你刚才写的复制逻辑。三、最终效果你可以访问这个链接来查看最终嵌入效果，我们可以看到<iframe> 成功在笔记中渲染完整内容，无需额外改路由。image.png"
  },
  {
    "title": "人设、站队与真相：从海棠与“妈妈岗”议题看后现代传媒特性 & 兼论新闻事实核查工具",
    "summary": "在过去两周，有两个非常有趣的议题先后登上舆论的舞台中央：其一是海棠女作家被抓，引发舆论对“创作自由”的愤怒和对女性写作者的声援；其二是“妈妈岗”突然成为热词，在知乎等平台掀起一波关于女性劳动、家庭角色与政策工具的激烈讨论。随着时间推进，这两场情绪风暴很快暴露出惊人的相似之处——事实被抹去，情绪被放大，公共话语空间迅速塌缩为“立场斗兽场”。海棠事件中，不少原本被塑造为“受害者”的写手，事后被曝出曾卷",
    "tags": [
      "人类研究"
    ],
    "url": "/posts/Essays/mom-job-haitang-posttruth/",
    "date": "2025-06-15T00:00:00.000Z",
    "content": "在过去两周，有两个非常有趣的议题先后登上舆论的舞台中央：其一是海棠女作家被抓，引发舆论对“创作自由”的愤怒和对女性写作者的声援；其二是“妈妈岗”突然成为热词，在知乎等平台掀起一波关于女性劳动、家庭角色与政策工具的激烈讨论。随着时间推进，这两场情绪风暴很快暴露出惊人的相似之处——事实被抹去，情绪被放大，公共话语空间迅速塌缩为“立场斗兽场”。海棠事件中，不少原本被塑造为“受害者”的写手，事后被曝出曾卷走粉丝的慈善款、组织虚假募捐，发布用来操控舆论的虚假小作文，用情绪编织道德高地，最终演变为一场人设坍塌与信任透支的闹剧。而另一边，在“妈妈岗”话题尚未厘清基本政策内容、实施范围乃至用工逻辑的前提下，一批男性KOL便迅速下场，借“妈妈岗”之名输出自己的社会批判宏论，称其为“现代阳谋推恩令”乃至“结构性性别分化工程”，却几乎没有人回头看一眼政策原文或调研实情。是的，这当然不是孤例，而是现代移动传媒世代舆论机制的结构性症候。我们正在进入一个以“立场驱动”而非“事实驱动”的公共讨论时代：言说的权力掌握在谁能最快塑造情绪、制造道德位置的人手中，真实的事件则往往被简化为某种象征载体，迅速卷入既有的叙事结构（女权对抗、男拳反扑、上层压迫、下层反弹等）。在这个意义上，“站队”优于查证，“情绪”压倒真相，而“议题”本身不过是输送流量的道具。本文试图以这两起事件为剖面，揭示后现代传媒结构下议题生成的诸多病灶：事实的可替代性、情绪的商品化、以及真相在算法逻辑中被边缘化的必然。 在算法导向、身份政治、平台偏好共同作用下，我们究竟还能不能进行一次扎实、诚实、理性的公共讨论？或者说，这种可能性是否已经彻底被“先赢为敬”的传播机制消解殆尽了？一、事件速览1.海棠诈捐| 时间            | 关键人物 / 行动      | 自述或网络说法                           | 目前可确认的反转 / 争议点                                                      |\n| ------------- | -------------- | --------------------------------- | ------------------------------------------------------------------- |\n| 2024 年（首轮抓捕后） | @西红柿怼番茄tt  | 长篇“小作文”称家境寒门、赔偿无力，呼吁捐款            | 后被爆料：① 小作文由代笔撰写，承诺 1 万元稿费未兑付；② 共募得约 40 万+，其本人拿钱首付买房；③ 舆论定性为“诈捐” |\n| 2025-06-01 前后 | “二次捕捞”援助众筹 | 律师团与作者社群发起众筹，标签“贫困作者”             | 募资去向不透明，粉丝开始要求公示账目                                                  |\n| 2025-06-12    | @冰冰棒棒      | 发长文自述：远行取证、贫困、重病、家暴等，已筹得 8 万+ | 网友扒证据指出多处情节系捏造；账号注销 → 被认定“卖惨骗捐”                                     |\n| 2025-06-13    | 裸检梗作者      | 称在看守所被要求脱光检查并能“实时写小作文”            | ① 程序上羁押期禁止携带手机，故事逻辑矛盾；② 作者数日后悄然改口，引发真实性质疑                           |\n| 反复出现          | “判十年”流言    | 多位博主宣称：写 R18 文即面临十年刑期             | 法条与判例显示：涉案作者多获缓刑或教育释放；“十年”说法被认为夸大                                   |\n| 伴随事件          | “兰州拉面抵制”   | 部分粉丝因兰州警方抓捕号召抵制兰州及其拉面             | 兰州拉面连锁主体多源自河南，被嘲“无辜躺枪”                                              |\n| 整体趋势          | 作者与粉丝          | “小作文”情绪叙事—> 快速募捐—> 缺乏审计—> 频繁塌房    | 舆论转向：呼吁理性捐助、追责信息不实传播                                                |\nimage.png\nimage.png第一次看到这图的时候真给我看乐了海棠作者，或者更广义地说，以R18耽美文学为代表的一类边缘创作群体，之所以在近十年间反复陷入塌房—声援—反转—崩塌的循环，其背后的结构性原因可以概括为以下几点：其一，是“红色骑士团”式治理传统与后现代欲望政治的根本冲突。在我国，社会治理始终坚持对“非生产性欲望”的高压监管，尤其对色情内容、吸毒、性别流动与认同等议题保持零容忍姿态。这种以劳保风气与主旋律审美为底色的意识形态传统，与Z世代年轻人日益多元化、边界感模糊的文化诉求之间，形成了持续而尖锐的张力。这里的“欲望诉求”，包括但不限于色情作品的表达自由、轻度毒品娱乐化倾向、性别认知与性权利的自由化平权化等。其二，很多作者与其支持者对国家权力的运作机制几乎一无所知。她们以为警察不会动真格、法律只打“真坏人”，把创作平台视作灰色庇护所，却从未真正理解“传播淫秽物品牟利罪”是如何被认定、如何执行、如何量刑的。她们是在祖国温室中成长起来的花朵，熟悉互联网叙事，却从未真正理解司法逻辑。直到一纸传唤、一趟长途列车和一张拘留通知书从天而降，才首次意识到：文字并不总是中性的，它在某些语境中就是犯罪工具本身。其三，是公众情绪动员能力远超事实审查机制。一篇篇“小作文”像是一张张情绪债券，靠贫困、疾病、原生家庭来构建“道德高地”，迅速调动粉丝的同情心，却在事后一再被证伪。在没有基本事实判断、缺乏核实机制的情况下，同情反而成了骗子的工具，善意变成了协助作恶的温床。2.知乎KOL关于“妈妈岗”的误读| 时间          | 政策-实践节点                               | 关键信息                                                     | 来源                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| ----------- | ------------------------------------- | -------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 2019 年  | 广东中山市几家制造企业率先为育儿期女工试设“妈妈岗”            | 缩短工时、允许请假、工资按计件                                          | (news.cn)                                                                                                                                                                                                                                                                                |\n| 2023-04 | 广东省人社厅发布《关于推行“妈妈岗”就业模式的实施意见（征求稿）》 | 明确对象：抚养 12 岁以下 子女的女性；鼓励用人单位提供弹性上下班 + 子女托管；给予社保补贴 | (new.qq.com)                                                                                                                                                                                                                                                                                                                        |\n| 2024-03 | 全国两会提案：把“妈妈岗”写进促进妇女再就业政策包         | 方向：在车间、社区、园区设置灵活工时岗位；建立政府补贴+企业落地双轨制                      | (news.cn)                                                                                                                                                                                                                                                                                          |\n| 2024-11 | 佛山南海首批 13 家企业入选省级“妈妈岗”名录          | 岗位以质检、客服、分拣为主，时薪＋绩效模式                                    | (new.qq.com)                                                                                                                                                                                                                                                                                                                        |\n| 2025-06 | 湖北、山东、北京等地集中宣传“妈妈岗”，热搜登顶              | 地方媒体将其包装成“女性就业暖政策”，并展示托管、交通补贴等配套                         | (news.cctv.com)                                                                                                                                                                                                                                                                                 |\n| 2025-06 | 舆论爆点：知乎 / 抖音                      | 大量 KOL未经实证即宣称 “妈妈岗＝学习日本庶务科”“现代推恩令”，引发“男拳 / 女拳”对骂         | (zhihu.com, zhihu.com, zhuanlan.zhihu.com) |知乎上大量高赞答主将“妈妈岗”称为顶级阳谋或新时代“推恩令”，意指管理层终于认识到“女性 ≠ 母亲”，并开始通过岗位设置引导女性角色的转化。但这些观点往往基于立场先行、叙事想象，对政策内容和实际落地情况缺乏基本查证。事实上，多数所谓“妈妈岗”，不过是临时工／计件工的马甲升级。在当前经济下行、企业利润紧缩的大背景下，本就难以维持非核心用工的企业，根本无意设立一个“专岗”来承担额外成本。现实中，许多企业甚至根本不知道自己被划入了‘妈妈岗’名录，只是为了完成指标，由街道或园区层层上报、强行贴签。换句话说，所谓“妈妈岗”，更多时候不过是地方层面为完成就业数字的硬包装。在用工荒与生育荒同时到来的结构性困境下，目前它既未真正解决托育支持，也未真正创造稳定就业，只是披着关怀外衣的临时工 2.0 而已。3.总结通过“海棠作者”和“妈妈岗”这两起事件，我们不难发现，事件本身的复杂性早已被一种更高优先级的传播逻辑所吞噬。 在移动互联网的移动场中，真正流通的是人设、情绪与叙事模板，而非查证与逻辑链的完备。那些被高频转发的小作文、观点、答主，之所以能占据注意力中心，往往并不是因为他们掌握了更多信息或进行过实地调查，而是因为他们更早完成了立场归位与情绪调动。哪怕对政策一无所知，也丝毫不妨碍他们将“妈妈岗”包装成一次新时代的意识形态战役；即便无法判断法律条文的适用逻辑，也可以轻松将“海棠事件”升华为“对女性写作者的系统性打压”。这正是我们所处的后现代舆论结构的典型症候——一个去真相化、重符号性、轻语境、强情绪绑定的传播环境。在这样一种环境中，议题不再源于事实，而源于可供投射的情绪壳子；公共表达不再追问真伪，而是竞争谁的情绪、姿态、归属感更具传播性。接下来，我们将尝试对这一舆论机制的几项核心特征进行系统性总结与剖析。二、后现代舆论机制的几个特点1.有趣 & 可传播 ＞ 事实在当前的舆论环境中，传播性已经全面碾压了真实性。算法机制天然偏好那些能够迅速激发点击、评论与转发的内容，哪怕这些内容与事实本身并无太多关系。对平台来说，“有趣”与“可被转述”远比“准确”更具经济价值；而对内容生产者而言，精确考证与语境厘清所需的成本高得可怕，却几乎没有回报。这种结构性诱因直接催生新的信息传播规律：情绪消费 ＞ 理性讨论愤怒、共情与嘲讽等“高能情绪”成为流量的硬通货；而理性讨论则因为“成本高、爽点少、节奏慢”而被边缘化。在这样的机制中，哪怕你提供再缜密的论证，都不如一句“抓少了”或“男宝女宝闹麻了”来得爽快有效。碎片化剪辑 ＞ 完整语境平台环境主动压缩内容，将其压缩为“三十秒可转述的爽点”、“十图打包的图文包”、“反复使用的对骂模板”。深度分析在此处不仅没有生存土壤，甚至会因为“信息密度过高”“表达不够直接”而被算法筛掉。最终，我们看到的是一个表面上观点激烈、情绪澎湃，实际上却高度同质化、缺乏深度的伪多元空间。在这种空间里，讨论不再是为了理解事件，而是为了获得即时的情绪红利与归属感确认，爽点总是先于查证抵达，而真相往往连开口的机会都没有。2.立场 ＞ 事件本体事件的意义不再取决于它的事实细节，而是它能否迅速嵌入某个现成的叙事结构。换句话说，公共表达的起点不再是“这件事发生了什么”，而是“这件事能为我已有的立场提供什么素材”。这就是我们常说的“先站队，后补证据”机制——而在很多情况下，补证据这一步甚至都不再被需要。人们并不关心“妈妈岗”的政策文本是什么、实际工资多少、企业端反馈如何，他们只关心它是否能被解读为“社会父权的新工具”。同样，人们也很少真的去研究“传播淫秽物品牟利罪”的法律构成、起诉门槛和量刑条件，他们只需要“海棠作者”符合某种“女性写作爱好者遭受打压”的既定形象，就足以迅速完成立场建构与身份情感投射。将事件符号化，确实让它更具传播效率，也更容易调动群体认同。但问题在于：这种被“叙事框架先验绑定”的讨论方式，极容易遮蔽事实的复杂性与多义性，最终形成的是一种“观点即正义”的平面舆论空间——人们不再探讨事件如何发生，只争论它该归属于哪一边。3.同温层算法 ＞ 异质对话平台算法的推荐机制本质上是以情绪偏好与观点趋同性为核心参数进行投喂的，这直接导致了当代舆论场呈现出一种高度封闭的“同温层结构”：你所能看到的观点，越来越趋近于你已经相信的那一套。这一逻辑在“妈妈岗”话题中表现得尤为明显——只要你点开过一两个批评“妈妈岗是结构性压迫”或者“妈妈岗是塔终于觉醒了的赢学论证“的视频或回答，平台就会自动推送更多相似内容；你所在的信息流迅速被建构成一个看似“众声喧哗”实则“高度同质”的回声室。观点的多样性被算法精准筛选，留下的是一个舒适但虚假的“群体共识”幻象。而这套机制也极大地塑造了用户的认知方式：KOL说了我支持的事，所以他是对的；点赞多的答案就是“事实”，不论它是否查证过政策、实地采访过企业；与持不同意见者的对话渠道被切断，要么被屏蔽，要么在评论区被“审判式”围攻。在这样一个封闭结构中，观点不是被质疑和打磨的对象，而是被点赞与转发强化的标识符；事实不再以其“是否真实”赢得讨论权，而是以其“是否悦耳”决定能否出现。讨论不再是讨论，而是一场由平台算法导演、由用户情绪演出的立场确认仪式。4.符号可替代 > 真相不可追在后现代舆论环境中，事件的真相从来不重要，重要的是它能否被包装成某种易于流通的“叙事符号”。而一旦这个符号不再奏效、或者被反转、被打脸，平台和用户也不会真正回溯事实、厘清细节——他们只会迅速寻找下一个“可替代符号”，继续完成叙事的迭代更新。你可以看到这样的机制如何无缝运作：当“海棠作者”从受害者变成诈捐者，平台与支持者并不会为此反思公共判断为何失灵，而是立即将注意力转移到下一个更容易共情的对象——比如“写手坐长途火车烧到40度仍坚持配合调查”的辛酸叙述，继续完成情绪循环；当“妈妈岗”被证实为许多企业根本不知道、只是硬凑指标的“临时工马甲”，并不妨碍它继续作为“女性劳动贬值的象征”在下一轮短视频中流传，哪怕表达者从未看过一行政策原文。这就是符号社会的基本特征：可传播性高于可证伪性，叙事的连续性高于事件的准确性。你甚至可以说，在某些极端场景下，真相本身是一种“多余的累赘”——因为它太复杂、太慢、太不合情绪节奏，而被自动从传播链中剔除。因此，事件不过是符号资源的素材池，立场永远比真相跑得快，逻辑永远追不上下一次更新的叙事模板。5.总结最后总结一下，我们当前乃至未来即将全面面对的，并不是一个“真实驱动”的公共讨论世代，而是一个以符号为核心、以立场为入口、以情绪为燃料的舆论结构。这是一个后真实（post-truth）时代的典型图景：它不依赖对事件本身的还原，而依赖事件能否迅速被接入某种情绪叙事；它不鼓励开放的多元讨论，而偏好算法生成的“共识泡沫”；它的参与者不再追求事实的拼图式构建，而是主动寻找能够确认自我立场、强化身份认同的情绪节点和内容模板。我们正活在一个基于符号构建的社会现实中，这些符号来自性别、阶级、意识形态、创作自由等早已建构完毕的“叙事母体”；它们依托平台算法，以最小的事实成本获得最大的传播路径；它们形塑出一代人对公共空间的理解方式——不再是“我们如何解决一个问题”，而是“这个问题属于谁、代表谁、能不能帮我赢一仗”。这意味着，未来的舆论冲突也许不再围绕“哪个事实是真的”，而是围绕“哪个版本的叙事更能让我的人设成立”。真相成了流量叙事的偶然副产品，而非逻辑终点。三、所以有办法吗？什么，你以为我写到这里会语重心长地呼吁大家“要理性发言、增强媒介素养、多查证、多思考”吗？或者来一段煽情的自我点灯式鸡汤，告诉你“如果没有光，那我就是光”？那你疑似有点太不了解我了，想什么呢，这些对于人类舆论场这个克苏鲁来说是没啥用的。这就是后现代叙事的常态：真实崩解、意义漂移、立场内嵌、情绪优先。它不是哪个人的错，也不是哪个平台能调头的技术问题。它是一整套社会—媒介—认知结构共同作用下的必然结果，是我们已经抵达的语境本身。你可以不喜欢，但这就是历史发展的方向。不要[[辉格史观]]式地期待理性一定胜利、真相总会到来——那是旧世界的叙事幻觉。新时代没有凯旋的真理，只有持续更新的情绪模板与更高效的符号操盘术。所以怎么办？没有办法。你唯一能做的，就是时刻记住你正在看的这场戏，本身就是一场被剪辑过、配乐过、选择过的叙事构造。别轻易入戏，别随便转发，别太快下判断。如果可以，哪怕只有一次，在下手之前，按住手指，问一句：“这个东西，它是真的还是假的？”你不会因此改变世界，但也许可以免于在下一个情绪幻象里，变成别人叙事的道具。附：我自己核查事实的一些方法论这篇文章里谈到了不少“事实退位”与“情绪先行”的结构性问题，但真正能对抗这些问题的，除了保持冷静之外，还有一件事——练习核查事实的能力。这不是什么神秘技能，但确实需要长期锻炼。以下是我个人在做一些争议性事件梳理时形成的几个经验，供参考。1. 一定  一定 要注重核查整件事的逻辑链别急着判断对错，先捋顺时间线和动因链条。这比你看多少截图都重要。比如某个R18作者说自己“被逼裸检后写了小作文”，那你应该立刻追问：她被关在哪？看守所能不能带手机？她有没有真实出庭？如果没有，裸检合规吗？这里的核心是：很多“事实”之所以会反转，并不是因为有什么新证据，而是因为它本来就逻辑不通。当然，这一条说起来简单，做起来很难，因为它和你的知识面、信息分辨力、甚至情商密切相关。你没看过判决书、不了解公安流程，当然很难凭空拼出完整逻辑；但也正因此，要持续补课，不断让自己对公共结构、制度运行更熟一点。2. 熟练使用溯源与核查工具以下是我自己在追踪事件、查证信息时常用的一些方法和工具，它们不复杂，但真正用熟了，胜过99%的情绪推送内容。搜索引擎的时间筛选（Google / 百度）这是我最常用的工具之一。看热搜、看突发事件时，务必切换为“按时间排序”。目的不是找最新，而是找到最早：第一条爆料来自谁？时间点是否合理？有没有早于传播时间的“伪造痕迹”？这一步可以帮你判断事件是“自然爆发”还是“有组织放大”。谷歌搜图 + 图像溯源对于各种截图、照片、海报等内容，我强烈建议用 Google 的“以图搜图”功能溯源，看看它最早出现在什么语境中。很多“新图”其实是旧闻二次使用，或者跨语境拼贴的产物。尤其涉及战争、灾难、抓捕类视觉内容时，这一步至关重要。多语种交叉检索（关键词＋语言切换）对于涉及国际背景、边疆民族、跨区执法、海外舆论等议题，不要只搜中文结果。我会同时用英语、日语甚至部分东南亚语言做关键词并行检索。不同语种的报道角度、时间线与主述立场往往有巨大差异，能帮助你确认哪些信息是一致的，哪些是话术加工的。Web Archive / Wayback Machine / CDT / 网民备份用于寻找已删网页、被404的文章、早期原始版本。很多争议事件，在发酵初期其实说得比后期更清楚，反而被删掉了。抓住初期版本，有时比等公关稿更接近真相。辅助工具：微博减词搜索、天眼查、贴吧旧帖检索等微博搜索“关键词 -过滤词”可以帮你清掉不相关噪音，比如“妈妈岗 -知乎 -B站”；天眼查、黑猫投诉可用于核查当事人或机构背景；知乎、豆瓣、贴吧的“老帖”检索有时会揭示事情早在几年就已经发生过，是“旧闻新炒”。越火的热搜，越可能是剪辑过、截取过、情绪化后才推上来的版本。别直接信，先问一句：“这个图，这句话，是谁最早发出来的？出现在什么上下文里？”这是溯源的起点，也是真相能否浮现的临界点。3. 涉及到钱财、捐款、众筹的，小心小心再小心情绪动员型众筹往往最危险。任何一句“她太惨了，请大家帮帮她”背后，都要追问三件事：她是谁？有没有实名？有没有独立证据？钱怎么收？谁打的卡？平台是公开还是私人？有没有善款公示？有没有公开对账机制？一旦发现模糊措辞（如“她是我们群里的朋友”）、转账给私人账户、重复使用小作文等现象，宁可信其有诈，也不要轻易掏钱。在海棠作者事件里，最讽刺的一幕就是：为了“支持创作自由”，结果把自己的血汗钱交给了编故事的骗子。最后，别被“怕错过”的焦虑感驱使每一次热搜都会试图告诉你：“你现在就得发声，不然你就冷血”。但请记住，你可以慢一点、稳一点、再说一点。真相不是即时消费品，它需要时间，需要结构性知识，也需要你偶尔关掉评论区、静下来查一份原始报告。判断力不是天赋，是训练。是你一次次拒绝快感、拒绝立刻下结论时，悄悄长出来的东西。"
  },
  {
    "title": "「Quartz 4 × Obsidian」：一键发布，构筑属于你的数字花园",
    "summary": "事情是这样的：虽然我已经拥有一个基于 Astro + Fuwari 搭建的静态博客，用来发布一些逻辑完备、结构完整的长篇述论文章，但在日常学习与阅读过程中，我也会积累许多零散的短文和未成形的想法。这些内容也许不够“正式”，却往往承载着即时的思考与潜在的价值。可惜的是，它们往往难以在原有博客中找到合适的容身之所，久而久之便淹没在本地笔记堆里。因为我日常的写作和学习笔记基本都集中在 Obsidian ",
    "tags": [],
    "url": "/posts/TechnicalTutorials/obsidian-quartz-4/",
    "date": "2025-06-13T00:00:00.000Z",
    "content": "事情是这样的：虽然我已经拥有一个基于 Astro + Fuwari 搭建的静态博客，用来发布一些逻辑完备、结构完整的长篇述论文章，但在日常学习与阅读过程中，我也会积累许多零散的短文和未成形的想法。这些内容也许不够“正式”，却往往承载着即时的思考与潜在的价值。可惜的是，它们往往难以在原有博客中找到合适的容身之所，久而久之便淹没在本地笔记堆里。因为我日常的写作和学习笔记基本都集中在 Obsidian 中进行，久而久之我就萌生了一个念头：有没有什么办法，能让我不折腾后端，无需花费精力去维护，就能把这些 Obsidian 笔记选一部分轻松发布到网上？说白了，我在寻找一个适合懒狗的数字花园解决方案：最好是纯前端的，无需服务器支持；能自动处理 Obsidian 的目录结构和双链语法；部署方式足够轻量，能直接托管在 GitHub Pages & Vercel 上；如果还能有点样式自定义的空间，那就更完美了。这两天，我发现了Quartz 4 ——一个专为 Obsidian 用户设计的静态Markdown框架。它几乎精准满足了我对“懒人发布系统”的全部幻想：不需要后端支持，直接部署在 GitHub Pages；原生支持 Obsidian 的链接语法与文件结构；只要把笔记文件丢进特定文件夹、提交到仓库，它就能自动构建一个美观、可导航、可全文搜索的个人知识库网站。更重要的是，它有完整的开源社区支持、结构清晰、样式也足够现代，甚至连 SEO 和 PWA 兼容都考虑到了，几乎开箱即用。这篇文章将记录我部署 Quartz 4 的全过程，分享我如何将它无缝接入现有工作流，并进行一系列个性化的魔改与优化。希望能为同样在寻找“低维护成本知识发布方案”的朋友提供一些参考。效果预览：效果预览一、基本部署流程1. 准备工作GitHub 仓库你可以直接 fork 官方模板仓库（jackyzha0/quartz），或者选择社区改良版本（例如 sosiristseng/template-quartz），后者已经预配置好 GitHub Pages 与 Actions，更适合快速部署和后期迁移。我直接fork了官方模板仓库，并结合自己的习惯魔改了之前的外刊GitHub Action工作流本地环境Node.js ≥ 20（官方推荐使用 22）＋ npm ≥ 10Git在终端中运行以下命令确认版本是否满足要求：node -v && npm -v若版本过低，可前往 Node 官网下载安装，或使用 nvm 进行升级。详细参考：Quartz 官方文档。2. 克隆与本地预览在终端中执行以下命令：git clone https://github.com/你的用户名/quartz.git my-site\ncd my-site\nnpm install          # 安装依赖\nnpx quartz build --serve  # 本地预览首次运行前，建议在 content 文件夹中新建一个 index.md 文件，作为首页。示例如下：---\ntitle: 时歌的数字花园   # 浏览器标题与页面 H1\ndescription: 记录金融·科技·随想   # 可选；用于 SEO 与摘要\n---\n\n# 欢迎 👋\n\n这里会分享我的公开笔记、研究摘录和碎片想法。预览地址默认为 http://localhost:8080，保存 Markdown 或配置文件后页面会自动热重载。3. 个性化配置编辑根目录下的 quartz.config.ts（或 quartz.config.mjs，取决于模板版本），主要字段如下：|字段|作用|\n|---|---|\n|siteMetadata → name, description|网站标题与简介|\n|baseUrl|设置未来绑定的自定义域名，如 https://notes.example.com/|\n|theme / plugins|控制颜色主题、Graph View、全文搜索等插件开关|\n|defaultPublishStatus|默认发布状态。设为 'draft' 可默认不公开，需在 front-matter 中手动控制是否发布|修改保存后，刷新本地页面即可查看效果。二、个性化与发布到公网1.使用Github Action来同步远程指定文件夹到本地在我之前的博客 《通过 GitHub Action 实现自动推送英文外刊到 Obsidian 中》 中，我介绍过自己的 Obsidian 笔记库是如何通过腾讯云 COS（兼容 S3 协议）进行同步的。换句话说，我的笔记总是以最新状态存在于一个远程对象存储空间中，理论上可以随时被抓取和发布。这就为构建自动化发布流程提供了一个天然的切入点：只要能定期从 COS 中拉取我想发布的部分笔记文件，并写入 Quartz 站点的 content/ 目录中，再通过 GitHub Pages & Vercel自动部署，我就可以实现无感知的远程发布。为此，我设计了一个简单的 GitHub Action 工作流：定时拉取：每 6 小时触发一次（也支持手动），用 coscli sync 将 COS 中的 0.数字花园/ 目录同步到仓库的 content/。自动提交：如果检测到文件变化，则履行 git add → commit → push，并打上时间戳备注。一键部署：定期触发 GitHub Pages 与 Vercel 工作流，Quartz 自动重建站点，实现无感知发布。有了这条流水线，我可以继续在本地 Obsidian 随心所欲地写作，不必刻意区分「写作笔记」和「发布笔记」——只凭一个文件夹路径约定与命名规则，GitHub Action 便会替我完成“拉→编→发”的全部脏活累活。工作流文件：name: 同步COS到Obsidian仓库\n\non:\n  # 每 6 小时自动同步一次（UTC 时间）\n  schedule:\n    - cron: '0 */6 * * *'\n  # 允许手动触发\n  workflow_dispatch:\n\njobs:\n  sync-from-cos:\n    runs-on: ubuntu-latest\n\n    steps:\n      # 1️⃣ 拉取代码\n      - name: 检出仓库\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 1     # 只拉取最新提交即可，速度更快\n\n      # 2️⃣ 安装并配置 coscli（官方 CLI，支持 sync）\n      - name: 安装并配置 coscli\n        uses: git9527/setup-coscli@v2\n        with:\n          region:      ${{ secrets.COS_REGION }}      # ap-shanghai 等\n          secret-id:   ${{ secrets.COS_SECRET_ID }}\n          secret-key:  ${{ secrets.COS_SECRET_KEY }}\n          bucket:      ${{ secrets.COS_BUCKET }}      # mybucket-1234567890\n          coscli-version: 'v0.12.0-beta'             # 指定具体版本号而非 latest\n\n      # 3️⃣ 从 COS 下载到本地 content/（保持完全一致，但保留 .gitkeep）\n      - name: 拉取 COS 文件到 content/\n        run: |\n          # 自定义的重要文件，需要备份和恢复\n          mkdir -p /tmp/content_backup\n          if [ -f \"content/.gitkeep\" ]; then\n            cp content/.gitkeep /tmp/content_backup/\n          fi\n          \n          # 清空并重新创建 content 目录\n          rm -rf content\n          mkdir -p content\n          \n          # 恢复重要文件\n          if [ -f \"/tmp/content_backup/.gitkeep\" ]; then\n            cp /tmp/content_backup/.gitkeep content/\n          else\n            # 如果不存在，创建一个空的 .gitkeep 文件\n            touch content/.gitkeep\n          fi\n          \n          # 执行同步，使用递归模式\n          coscli sync \\\n            --thread-num 8 \\\n            --recursive \\\n            cos://${{ secrets.COS_BUCKET }}/0.数字花园/ \\\n            content/ \\\n            -e cos.${{ secrets.COS_REGION }}.myqcloud.com\n            \n          # 确保 .gitkeep 在同步后仍然存在\n          if [ ! -f \"content/.gitkeep\" ]; then\n            touch content/.gitkeep\n          fi\n          \n          echo \"COS 同步完成 ✅\"\n\n      # 4️⃣ 若有变动就提交\n      - name: Commit & push if changed\n        env:\n          TZ: Asia/Shanghai\n        run: |\n          git config user.name  \"COS Sync Bot\"\n          git config user.email \"bot@users.noreply.github.com\"\n\n          if [[ -n $(git status --porcelain) ]]; then\n            git add -A\n            git commit -m \"chore: sync notes from COS $(date '+%Y-%m-%d %H:%M:%S')\"\n            git push\n            echo \"已检测到变动并推送 🚀\"\n          else\n            echo \"没有文件变化，跳过提交 ✔\"\n          fi\n具体环境变量如何配置，请参见我之前的博客 《通过 GitHub Action 实现自动推送英文外刊到 Obsidian 中》 中的 二、Github设置的 3.配置安全凭证 (GitHub Secrets)：保护你的 S3 访问密钥。2. 通过 Vercel 部署 Quartz 到公网虽然 Quartz 官方默认支持 GitHub Pages 部署，但考虑到我个人博客也托管在 Vercel 上，加之其后台管理简洁、构建速度快，我决定将 Quartz 4 的站点也一并部署到 Vercel 上。不过需要注意的是，Quartz 4（即 Obsidian/Quartz 静态站点生成器）是基于 Python 的框架，默认会生成形如 xxx.html 的文件，而不是 xxx/index.html 的目录结构。这在 Vercel 上会造成一个小问题：若直接访问不带 .html 后缀的路径，会返回 404。为了解决这个问题，我们需要在项目根目录下新增一个 vercel.json 文件，手动指定重写规则：{\n  \"rewrites\": [\n    { \"source\": \"/(.*)\", \"destination\": \"/$1.html\" }\n  ]\n}这样，访问 /about 就会被自动重写为 /about.html，从而避免 404 错误。部署步骤如下：登录 Vercel，点击 Add New → Project。选择刚才已经设置好的 Quartz 仓库。在“Build & Output Settings”中填写以下内容：|字段|值|\n|---|---|\n|Framework|Other|\n|Build Command|npx quartz build|点击 Deploy。Vercel 会自动拉取代码、执行构建，并将 public/ 文件夹作为静态资源目录进行托管。几分钟后，你就能获得一个形如 xxx.vercel.app 的访问链接。绑定自定义域名：进入 Vercel 项目页 → Settings → Domains，添加你的域名，并将 DNS 的 CNAME 记录指向 cname.vercel-dns.com。同时，别忘了将 quartz.config.ts 中的 baseUrl 字段改为你的正式域名，并提交更新。设置 Node 版本（如需）：若 Vercel 默认使用的 Node 版本较低，建议在项目设置 → Environment Variables 中添加一条环境变量：NODE_VERSION = 22至此，Quartz 的部署流程就完成了。之后每次 git push，Vercel 都会自动触发构建并发布，无需手动干预，真正实现了一键写作、自动上线的无感化写作体验。"
  },
  {
    "title": "哪哪都有鹅厂——梳理腾讯的游戏产业投资帝国",
    "summary": "2024年春，《绝地潜兵2》横空出世，在全球范围内迅速爆红，短短三个月内销量突破1200万份，成为近年来PlayStation平台增速最快的现象级游戏。2025年6月，随着“保卫超级地球”新版本任务的上线，一场中美玩家在“超级上海”并肩作战、成功守卫地球的战斗引发全球热议——不仅社交媒体刷屏，甚至连上海广播电视台也进行了报道，中国驻外大使馆更在X（原推特）平台转发了这条新闻。就在热度尚未褪去之际，",
    "tags": [
      "暗涌"
    ],
    "url": "/posts/Finance and Economics/tencent-game-invest/",
    "date": "2025-06-11T00:00:00.000Z",
    "content": "2024年春，《绝地潜兵2》横空出世，在全球范围内迅速爆红，短短三个月内销量突破1200万份，成为近年来PlayStation平台增速最快的现象级游戏。2025年6月，随着“保卫超级地球”新版本任务的上线，一场中美玩家在“超级上海”并肩作战、成功守卫地球的战斗引发全球热议——不仅社交媒体刷屏，甚至连上海广播电视台也进行了报道，中国驻外大使馆更在X（原推特）平台转发了这条新闻。就在热度尚未褪去之际，有消息披露：腾讯早在 2024 年 7 月便已悄然收购了该作开发商 Arrowhead Studios 约 16% 的股份，成为其第二大股东。说实话，这条消息并没有让我感到意外，反而有种熟悉的乐感——毕竟，“鹅厂”出现在任何一款现象级游戏背后都不奇怪，而这似乎已经成为某种产业规律。有人调侃：“哪里有爆款，哪里就有鹅厂。”而在更深一层的观察中，也有人开始重新审视腾讯在全球游戏产业链条中的渗透路径与影响力。从《英雄联盟》的缔造者 Riot Games，到《艾尔登法环》的开发商 FromSoftware，从芬兰的 Supercell 到法国的育碧，鹅厂几乎无处不在，以资本之手悄然编织出一张覆盖全球的游戏投资网络。它不像传统意义上的“买下就整合”，而更像是一个耐心的资本猎人：可以全资控股，也可以少量参股；可以扶持成长，也可以静默观望；既给资源，又不抢主导——只求在关键节点上拥有一席之地。鹅厂的布局不仅仅只有传统的国内市场和欧美，更延伸至日本、韩国、东南亚甚至大洋洲。以下内容基于 OpenAI o3 模型加持下的深度研究功能，系统梳理了截至2025年6月，腾讯在全球范围内通过直接、间接、子公司或基金形式所投资的全部游戏工作室。报告按照地域分布与投资形式分类整理，涵盖中国、北美、欧洲、日本、韩国等主要游戏市场，全面呈现每家被投公司的国别、首次投资时间、投资比例、代表作品等关键信息，力图构建出一幅清晰的“腾讯游戏投资帝国”全景图谱。当然，ai整理肯定会有遗漏和不足，但已经非常全了一、鹅厂的游戏投资帝国（不包含子工作室）🇨🇳 中国大陆地区（仅包含独立工作室）| 工作室名称 | 所在国家 | 首次投资时间 | 投资比例    | 代表作/项目        |\n| ----- | ---- | ------ | ------- | ------------- |\n| 网元圣唐  | 中国   | 2020   | 20%     | 《古剑奇谭》系列      |\n| 祖龙娱乐  | 中国   | 2017   | 17.51%  | 《龙族幻想》        |\n| 掌趣科技  | 中国   | 2017   | 2%      | 《全民奇迹》        |\n| 世纪华通  | 中国   | 2019   | 4.76%   | 《热血传奇》        |\n| 青瓷游戏  | 中国   | 2021   | 4.99%   | 《最强蜗牛》        |\n| 散爆网络  | 中国   | 2021   | 20%     | 《少女前线》        |\n| 游戏科学  | 中国   | 2021   | 5%      | 《黑神话：悟空》      |\n| 库洛游戏  | 中国   | 2023   | 51.4%   | 《鸣潮》《战双帕弥什》   |\n| 创梦天地  | 中国   | 2018   | 18.59%  | 《神庙逃亡2》（中国发行） |\n| 西山居   | 中国   | 2017   | 9.9%    | 《剑网3》         |\n| 乐动卓越  | 中国   | 2022 年 | 100% 控股 | 《我叫MT》系列      |🇺🇸 北美地区（美国/加拿大）|                     |      |        |         |                        |\n| ------------------- | ---- | ------ | ------- | ---------------------- |\n| 工作室名称               | 所在国家 | 首次投资时间 | 投资比例    | 代表作/项目                 |\n| Riot Games          | 美国   | 2011 年 | 100% 控股 | 《英雄联盟》《VALORANT》       |\n| Epic Games          | 美国   | 2012 年 | 约40% 股权 | 《堡垒之夜》、虚幻引擎            |\n| Turtle Rock Studios | 美国   | 2021 年 | 100% 控股 | 《求生之路》《Back 4 Blood》   |\n| Pocket Gems         | 美国   | 2015 年 | 38% 股权  | 《War Dragons》《Episode》 |\n| Klei Entertainment  | 加拿大  | 2021 年 | 多数股权    | 《饥荒》《缺氧》               |\n| Inflexion Games     | 加拿大  | 2022 年 | 100% 控股 | 《Nightingale》（开发中）     |\n| Digital Extremes    | 加拿大  | 2020 年 | 100% 控股 | 《星际战甲（Warframe）》       |\n| Offworld Industries | 加拿大  | 2022 年 | 少数股权    | 《Squad》                |🇪🇺 欧洲地区|                           |      |             |              |                         |\n| ------------------------- | ---- | ----------- | ------------ | ----------------------- |\n| 工作室名称                     | 所在国家 | 首次投资时间      | 投资比例         | 代表作/项目                  |\n| Supercell                 | 芬兰   | 2016 年      | 84% 控股       | 《部落冲突》《皇室战争》            |\n| Ubisoft                   | 法国   | 2018 年      | 11% 股权       | 《刺客信条》《彩虹六号》            |\n| Paradox Interactive       | 瑞典   | 2016 年      | 10% 股权       | 《钢铁雄心》《群星》《十字军之王》       |\n| Fatshark                  | 瑞典   | 2019 年      | 多数股权         | 《战锤：末世鼠疫》               |\n| Sharkmob                  | 瑞典   | 2019 年      | 100% 控股      | 《Bloodhunt》等            |\n| 10 Chambers               | 瑞典   | 2020 年      | 多数股权         | 《GTFO》                  |\n| Arrowhead Game Studios    | 瑞典   | 2024 年      | 15.75% 股权    | 《绝地潜兵 2》                |\n| Larian Studios            | 比利时  | 约2020 年     | 30% 股权（无投票权） | 《博德之门3》《神界：原罪》          |\n| Yager Development         | 德国   | 2020 年      | 多数股权         | 《Spec Ops: The Line》    |\n| Frontier Developments     | 英国   | 2017 年      | 9% 股权        | 《精英危险》《动物园之星》           |\n| Sumo Group                | 英国   | 2019/2022 年 | 100% 控股      | 《小小大冒险》等                |\n| Splash Damage             | 英国   | 2020 年      | 100% 控股      | 《Dirty Bomb》《战争机器：战术小队》 |\n| Playtonic Games           | 英国   | 2021 年      | 少数股权         | 《Yooka-Laylee》系列        |\n| Payload Studios           | 英国   | 2021 年      | 少数股权         | 《TerraTech》             |\n| Lockwood Publishing       | 英国   | 2020 年      | 少数股权         | 《Avakin Life》           |\n| Lucid Games               | 英国   | 2023 年      | 并入子公司        | 《画板赛车》原开发商，现隶属光子工作室群    |\n| Bohemia Interactive       | 捷克   | 2021 年      | 少数股权         | 《DayZ》《武装突袭》            |\n| 1C Entertainment（Fulqrum） | 波兰   | 2022 年      | 控股           | 《先祖遗产》《国王的恩赐》           |\n| Techland                  | 波兰   | 2023 年      | 控股           | 《消逝的光芒》系列               |\n| Bloober Team              | 波兰   | 2021 年      | 22% 股权       | 《层层恐惧》《媒介（The Medium）》  |\n| Remedy Entertainment      | 芬兰   | 2021/2024 年 | 14% 股权       | 《心灵杀手》《控制（Control）》     |\n| Funcom                    | 挪威   | 2020 年      | 100% 控股      | 《流放者柯南》《沙丘》IP           |\n| Miniclip                  | 瑞士   | 2015 年      | 多数股权         | 《8球台球》《Agar.io》等休闲游戏平台  |\n| Novarama                  | 西班牙  | 2022 年      | 少数股权         | 《Killsquad》             |\n| Tequila Works             | 西班牙  | 2022 年      | 控股（大股东）      | 《RiME》《努努之歌：英雄联盟外传》     |\n| Voodoo                    | 法国   | 2020 年      | 少数股权         | 超休闲手游《Helix Jump》等      |🇯🇵 日本地区|                      |      |        |           |                                 |\n| -------------------- | ---- | ------ | --------- | ------------------------------- |\n| 工作室名称                | 所在国家 | 首次投资时间 | 投资比例      | 代表作/项目                          |\n| FromSoftware         | 日本   | 2022 年 | 16.25% 股权 | 《黑暗之魂》《艾尔登法环》                   |\n| Visual Arts（Key 社）   | 日本   | 2023 年 | 多数股权      | 《CLANNAD》《Little Busters!》等视觉小说 |\n| 白金工作室（PlatinumGames） | 日本   | 2020 年 | 少数股权      | 《猎天使魔女》《尼尔：机械纪元》                |\n| Marvelous Inc.       | 日本   | 2020 年 | 20% 股权    | 《牧场物语》《符文工厂》系列                  |\n| Kadokawa Corporation | 日本   | 2021 年 | 6.86% 股权  | 角川集团（FromSoftware 母公司）          |🇰🇷 韩国地区|             |      |        |           |                                |\n| ----------- | ---- | ------ | --------- | ------------------------------ |\n| 工作室名称       | 所在国家 | 首次投资时间 | 投资比例      | 代表作/项目                         |\n| Netmarble   | 韩国   | 2018 年 | 17.66% 股权 | 《二之国：交错世界》《漫威未来之战》             |\n| Krafton（蓝洞） | 韩国   | 2017 年 | 13.9% 股权  | 《绝地求生（PUBG）》                   |\n| Kakao Games | 韩国   | 2012 年 | 13.54% 股权 | 《黑色沙漠》韩国代理、《PUBG》韩国发行          |\n| Shift Up    | 韩国   | 2022 年 | 35.03% 股权 | 《胜利女神：妮姬》《Stellar Blade》（主机游戏） |🌏 其他地区|   |   |   |   |   |\n|---|---|---|---|---|\n|工作室名称|所在国家|首次投资时间|投资比例|代表作/项目|\n|Sea Ltd（Garena）|新加坡|2010 年|18.7% 股权|《Free Fire》《传说对决》东南亚发行|\n|Grinding Gear Games|新西兰|2018 年|80% 控股|《流放之路（Path of Exile）》|\n|Digital Confectioners|新西兰|2022 年|少数股权|《恐惧饥饿（Dread Hunger）》|\n|Riffraff Games|新西兰|2022 年|少数股权|《Framed》解谜类手游|\n|Triternion|斯洛文尼亚|2022 年|少数股权|《Mordhau（雷霆一击）》|以上数据整合自公开财报、媒体披露及专业数据库，可能随进一步收购动态发生变更。二、暴论分析1.概念勘误：天使投资人并不是天使投资人大众舆论中经常将腾讯的投资活动称为“天使投资”，意为鹅厂只给钱不干涉管理不整那些爹味抽象活，这其实是一个很常见的概念误用。首先，从严格意义上讲，“天使投资”是风险投资中的早期阶段，指在项目尚未有明确商业模式或稳定收入时，由个人或机构提供启动资金，承担高风险、换取未来可能的高回报。而腾讯的多数投资对象——比如已经推出现象级产品的工作室、拥有成熟IP的中大型公司、甚至是正在全球发行大作的上市集团——显然早已脱离“天使”适用的范畴。鹅厂真正扮演的并不是在项目极早期给予启动资金的早期贵人，而是具有战略价值的少数股东。这类股东不要求控股，不参与日常管理，也不急于催收IPO回报；它更像是某种耐心资本的化身，埋伏在生态位上，等待流量变现、技术溢出、或未来政策缝隙带来的红利。当时Epic面对外界对于“腾讯是否干预业务”的质疑，Epic Store领导人Steven Allison也正面回复媒体：“腾讯不会插手我们的业务，他们不会就我们正在做的事和我们讨论，也不会告诉我们该怎么做”。2.连接而非吞噬如果说鹅厂的投资策略有什么核心思想，那我觉得可能的最贴切比喻是其核心产品——微信的逻辑：连接一切，但不拥有一切。和巨硬豪掷千金打了四五年官司终于收购动视暴雪，意图将所有IP收归 Game Pass 生态的“帝国式”扩张不同，腾讯的投资更像是在构建一个鹅厂朋友圈。在这个网络中，每个被投工作室都是一个相对独立的节点，腾讯通过股权这一“好友关系”将它们柔性连接，既不控制，也不干涉。能够代表腾讯早期投资成功的案例还有很多。比方在腾讯极为擅长的FPS领域上，早在2013年他们就曾对研发出“吃鸡玩法鼻祖”的《DayZ》开发者Dean Hall进行过小额投资，并鼓励他制作一些真正的生存游戏。这种策略的优势显而易见：风险分散，收益共享。游戏行业本就充满不确定性，爆款产品的诞生往往有很强的偶然性。腾讯通过广泛参股，将筹码押在全球最顶尖的一批创作者身上。无论下一款现象级产品诞生于瑞典（《绝地潜兵2》）、日本（《艾尔登法环》）还是比利时（《博德之门3》），只要投对了人，腾讯便能间接分得红利。对于高度依赖创意与文化张力的内容行业而言，过度整合反而会扼杀生命力。腾讯的“不打扰”策略，给予了被投公司极大的创作自由，保留了它们最核心的竞争力——独特的企业文化与创新机制。这也是为何像 Larian Studios （《博德之门3》开发商）这样的开发商，愿意接受腾讯的无投票权股权投资——腾讯提供的是支持与连接，而不是干预与同化。放到集团战略层面，这种软连接带来的远不止资本回报。它催生了技术共享、发行协同与生态主导等多维度的协同效应。在这个遍布全球的“鹅厂朋友圈”中，真正起到“底座”作用的，是腾讯早在 2012 年便重金入股的 Epic Games，以及其主导开发的——虚幻引擎（Unreal Engine）。幻引擎如今已不再只是传统意义上的游戏图形引擎，它正在演化为横跨游戏、影视、建筑、工业乃至AI交互的跨界引擎——更是在进入 5 代时代后，完成了从“图形工具”向“实时世界建构平台”的跃迁。你看到的《绝地潜兵2》、《黑神话：悟空》，你未来可能玩的 3A 级国产开放世界游戏，绝大多数都离不开虚幻引擎的支持。鹅厂对Epic高达40%的持股意味着不管未来市场走向如何，腾讯始终都会在游戏市场上游占据难以撼动的关键位置。每一个基于UE5开发的爆款游戏——哪怕腾讯未直接参投——都在放大Epic的引擎影响力，也在持续增值腾讯手中的那部分股权。这种“坐享其成”的生态主导权，不仅比收购几家公司来得更轻盈和高效，更是一种将基础设施变成战略资产的高明布局，是“连接逻辑”的最高体现。3.鹅厂还是太有钱了这标题听起来像句批话，但却是理解前两点（耐心资本与连接逻辑）的底层基石。前文提到的所有精妙策略，其能够成立、能够被长期执行的前提，正是腾讯无与伦比的资本体量与持续、强大的现金流造血能力。让我们看一组数据：2024年，腾讯仅网络游戏业务一项的收入就高达约273亿美元。旗下如《王者荣耀》、《和平精英》等“常青树”游戏，每年能稳定创造超过5.5亿美元的收入。而进入2025年，势头不减，仅第一季度，腾讯游戏总销售额就达到了惊人的250亿美元。其中，国际市场收入占比持续走高，Q1达到23亿美元，同比增长23%。然而，简单地将腾讯的成功归结为“有钱任性”是片面的。真正的壁垒在于，腾讯将“钱”转化为了三种难以复制的核心优势：战略耐心、风险豁免权和生态引力。首先是战略耐心。强大的现金流造血能力赋予了鹅厂其他玩家难以企及的战略自由度与高容错率。一般的风险投资基金（VC/PE）受限于基金存续期（LP 的出资周期，通常7-10年）和 IRR（内部收益率）考核压力，必须追求相对快速的退出和回报，因此难以真正做到“耐心”。它们必须干预，必须催熟，必须整合以求协同效应最大化或尽快IPO。而腾讯的投资资金主要来源于自身庞大的主营业务现金流，它没有传统基金的退出压力，可以进行超长周期的战略布局。入股 Epic 13 年（2012-2025），等待虚幻引擎从工具变成平台；全资控股 Riot 14 年（2011-2025），看着它从一款游戏变成多IP宇宙——这种“耐心”，本质上是巨额资本才能买到的“时间”。“不干预”本身，就是一种只有资本极度充裕者才玩得起的昂贵奢侈品。其次是风险豁免权。游戏行业是典型的高风险、高回报、爆款驱动的创意产业。“连接而非吞噬”的广撒网模式，是资本雄厚者对冲单一项目风险的最优解。腾讯不必 All in 某一家公司或某一个 IP，它投资的是整个“赛道”——全球范围内最有潜力的团队、技术和 IP 源头。在这份长长的名单中，必然会有项目失败、沉寂或不达预期，但对于腾讯的资本体量而言，这些损失完全可控。只要抓住少数几个像 Riot、Supercell、Epic、FromSoftware、Larian、Arrowhead 这样的超级爆款节点，其带来的战略价值和财务回报就足以覆盖所有成本。资本规模，让“广撒网”从赌博变成了概率学意义上的风险管理。最后，也是最关键的，是钱所构建的“生态引力”。腾讯提供的早已不止是资金。当一家初创工作室接受腾讯投资时，它得到的可能还包括：技术支持：来自Epic Games的虚幻引擎技术专家，或腾讯内部技术中台的协助。例如在2019年与瑞典工作室Stunlock Studios的合作中，腾讯不仅对其提供财务支持，还在除了研发之外的许多方面，给到Stunlock关于GaaS以及服务器方面的建议和支持再之后，除了资金之外，腾讯也开始给合作方提供一套免费的清单：这份清单上会有很多资源和技术。如果你想用，尽管拿去用；但如果你不想用，腾讯也不会强迫你，因为这只是用来帮助开发者的额外资源。据瑞典游戏工作室Stunlock Studios CEO Rickard Frisegård回忆，早在2016年的时候，当时团队上线了一款MOBA游戏，腾讯是唯一在游戏上线后24小时内联系他们并给出具体合作方案的公司，并称Stunlock是一家非常有潜力的团队。尽管当时Rickard没有选择接受外部帮助，但从此一直与腾讯保持联系，直到2019年，当他们的新游戏点子需要外部支持的时候，才主动联系腾讯。腾讯在2019年入股Stunlock，2021年完成收购，经过6年的接触，双方建立了十足的信任。2022年，Stunlock的第一款SOC游戏（生存+开放世界+建造）《V-Rising》上线，在Steam平台收获如潮好评。发行网络：通过腾讯的全球发行品牌Level Infinite，产品可以更便捷地触达全球市场，并获得本地化、市场营销等全方位的支持。隐性背书：“腾讯投资”本身已经成为一种行业信誉的标签，有助于被投公司吸引更多顶尖人才和后续融资。总结：作为连接器和基础设施的帝国，与卑劣的我们在全球游戏产业风起云涌的十余年中，腾讯作为后发者，并未像前辈那样选择建立一个以“控制”为核心的内容帝国，而是打造了一个以“连接”为核心的资本网络与技术底座。它不是索尼，不靠垄断主机生态来绑定内容；也不是微软，不靠收购整合来打造平台闭环。腾讯的战略更像一种数字时代的帝国形态：它不扩张疆土，而是铺设连接；它不主导一切，而是构筑底座。当一家公司既不强行干预你的创作，又能为你提供全世界最好的开发工具和最便捷的全球发行渠道时，它的吸引力便不再仅仅是“钱”，而是一种难以抗拒的“生态引力”。因此，回到最初的问题：“哪哪都有鹅厂？”我们所看到的，是一个极度现代、极度“互联网化”的资本实体，正在以一种无形却高效的方式重塑全球游戏生态。它放弃了笨重的控股整合，转而追求更加轻盈、高容错率的生态主导权。鹅厂不直接生产爆款（至少在海外它不追求亲手制作），但它投资于生产爆款的人，并为他们提供“水电煤”般的基础设施服务。这正是“日拱一卒”与“耐心资本”的力量所在。当13-19年，鹅厂在游戏界的名声尚且非常恶劣之时，人们对鹅厂的印象仍停留在“氪金手游大王”“抄袭鼻祖”“行业吸血鬼”，但彼时的鹅厂并未通过大规模的公关预算投入去洗白，去花费过多的力气。鹅厂的实际行动是在正确的位置上，投了正确的人，并愿意等待。于是，在2025年，我们可以看到另一种帝国的可能：它十分低调不宣称主权，却主导格局；它不需要统一战线，却拥有无数友军。它不是创作者，却推动创作；不是统治者，却无所不在。这或许也揭示了人类社会另一种有趣的现象：人们实际上只会共情胜利者——或者更准确地说，人们会因为自己心爱的作品，而选择性地原谅、甚至赞美其背后的支持者。当舆论还在争论腾讯是否“毁灭了中国游戏”，还在断言”中国五十年都做不出3A游戏“时，它早已通过对FromSoftware、Larian Studios的投资，与《艾尔登法环》、《博德之门3》这些游戏史上的不朽杰作绑定在了一起。玩家们对宫崎英高和Swen Vincke的崇敬，会自然而然地转化为对腾讯“有眼光”的认可。当全球玩家为“超级上海”的胜利而欢呼时，腾讯作为Arrowhead背后那位低调的股东，也一同分享了这份荣耀与好感。当然，还有《黑神话：悟空》和游戏科学。胜利，让连接变得合理，让潜伏变得高明，也让那些曾被轻视的策略，获得了应有的光芒。历史和我们永远都只会记得胜利者，而只有留在牌桌上才有机会成为胜利者。"
  },
  {
    "title": "嗵嗵：东北凛冽的寒冬与毛茸茸的通灵舞",
    "summary": "有些记忆是无法被线性叙事的。它们更像一块被瞬间封存的感官琥珀——无需起承转合，只需一束光照进来，所有驳杂的气味、温度、声响与情绪，便会在同一时刻悍然苏醒，毫无预兆，像一场突袭。于我而言，福禄寿的《嗵嗵》就是那束光。而那块琥珀，是沈阳无尽的冬天。那时候，我每天都在下沉。沉入城市的地下，搭乘那班准时发车的铁皮野兽。车厢的震颤是一种规律的催眠，窗外是永恒的虚空，哈气在人们的睫毛上结成薄霜。东北的冬天是有",
    "tags": [],
    "url": "/posts/Essays/tongtong/",
    "date": "2025-06-10T00:00:00.000Z",
    "content": "有些记忆是无法被线性叙事的。它们更像一块被瞬间封存的感官琥珀——无需起承转合，只需一束光照进来，所有驳杂的气味、温度、声响与情绪，便会在同一时刻悍然苏醒，毫无预兆，像一场突袭。于我而言，福禄寿的《嗵嗵》就是那束光。而那块琥珀，是沈阳无尽的冬天。那时候，我每天都在下沉。沉入城市的地下，搭乘那班准时发车的铁皮野兽。车厢的震颤是一种规律的催眠，窗外是永恒的虚空，哈气在人们的睫毛上结成薄霜。东北的冬天是有实体的：零下一二十度的严寒，是一种温柔不起来的暴力，它剥夺一切多余的颜色、情绪和言语，只留下近乎真空的肃杀。而我的耳机里，正进行着一场盛大的、献给凛冬的通灵仪式。我并未因此感到希望。希望太轻了，轻得会被这片土地的风吹碎。 我感受到的，是一种彻骨的、野性而清醒的共振。仿佛这首歌并非由谁谱写，而是从寒风与冻土之间自然蒸腾出的旋律，是东北冬天本身的灵魂，被灌录进了节拍与吟唱里。而这旋律的真身，第一次向我显形时，却并非我想象中的原始祭祀、荒漠或任何宏大的悲怆。它显现为……一群毛茸茸的、跳着舞的小动物。小动物？兔子？熊？或者……小芒狗？我的生活中可没有芒狗和小动物，只有一沓沓待批的习题册和课后反馈。在教室中，我和孩子们都在进行一种精准的、被量化的仪式。我把知识拆解成公式、步骤、得分点，灌输给他们；他们则用分数回应我。一切都清晰、理性、没有一丝一毫的含糊。我们都在一个巨大的、看不见的坐标系里，努力向上攀爬，拒绝“下坠”。可当夜晚来临，我把自己献祭给耳机，按下播放键。咒语开始——神明神明张开嘴\n\n让我知道我是谁\n\n它把我向天上推\n\n略过尘与灰\n\n不得不停歇不停歇\n\n黑夜在背上飞\n\n来狂欢吧狂欢吧\n\n永远不下坠\n\n太阳太阳请你告诉我\n\n为什么为什么\n\n遗憾那么多\n\n夜幕夜幕请你告诉我\n\n该怎么做怎么做\n\n灵魂才不会破\n\n嗵一声落下（壳中藏心惶惶）\n\n嗵一声开花（抬头见那天光）\n\n嗵一声落下（浮生空空荡荡）\n\n变回孩子了（风带着我流浪）\n\n（请）神明神明张开嘴让\n\n我知道我是谁\n\n它把我向天上推\n\n略过尘与灰\n\n不得不停歇不停歇\n\n黑夜在背上飞\n\n来狂欢吧狂欢吧\n\n（就安心吧安心吧）\n\n永远不下坠\n\nwu…\n\n飞过麦穗\n\n飞过霓虹光辉\n\n飞过墓碑\n\n飞过瓦砾堆那声音一出来，白天的坐标系就碎了。所有的理性和逻辑都被那凛冽的寒风吹得无影无踪。我的世界被劈成两半：一半是窗明几净、被公式和目标填满的教室；另一半，是这首“邪性”的歌所召唤出的、混沌不清的内心荒原。它不是在鼓励我，它是在瓦解我。它在嘲笑我白天那个为人师表、兜售确定性的自己。它用鼓点敲打着我的耳膜，说：看，这才是你。你不是那个在讲台上循循善诱的老师，你只是一个在零下二十度的寒夜里，靠着一段无法被定义的旋律，试图辨认自己魂魄的通勤者。我看那些小动物一遍遍抬手、旋转、跺脚。它们跳得认真得近乎哀伤，像在替全世界的过劳人跳一场忘却之舞。仿佛它们知道我快要熄了，于是专门编排了一段舞，试图把我从城市、寒冷、地铁、讲义、教案、疲惫的孩子和沉默的领导之间，拎起来。让我 “不下坠”。哪怕只有四分半钟。走下地铁，凛冽的空气瞬间灌满肺腑，疼得人一激灵。我把耳机摘下，音乐戛然而止。世界瞬间失去了声音，但感官却被另一种东西填满——寒冷。它不再是抽象的温度，而是有了形状、气味和质感。我能“看”到它像无形的冰屑，从我裸露的皮肤渗入，沿着血管爬行；我能“闻”到它带着一股铁锈和冻土混合的、干净到极致的腥气；我能“听”到寂静本身发出的、高频的嗡鸣。这就是东北的冬天独一无二的通感：它用极致的寒冷，打通你所有的知觉，强迫你与这片土地上最原始、最沉默的力量共鸣。我觉得自己像一个刚刚结束通灵仪式的萨满。神明已经离去，仪式长袍被剥下，换上普通人的外衣。耳机里喧嚣的鼓点和吟唱，最终都凝结成了我脚下那一声声坚实的、踩在积雪上的“咯吱”声。那声音在告诉我：仪式结束了。而你，必须面无表情地，走回那片需要你继续扮演“老师”的，无声雪原。"
  },
  {
    "title": "DeepSeek 模型25年下半年更新前瞻",
    "summary": "“本文内容基于公开信息与个人推理，仅供参考，非 DeepSeek 官方声明。”之所以动笔写这篇文章，源于一起 AI 圈经典的“出口转内销”闹剧。今年 4 月底，不知哪家海外媒体扒拉到国内炒股社区的一篇DeepSeek写的、预测DeepSeek r2更新的、内容离谱水平已经突破当前人类科技上限的ai文，结果不仅当了真，还当成“第一手爆料”大肆宣发。更讽刺的是，这条明显未经核实的内容很快又被国内 AI",
    "tags": [
      "模型考古学"
    ],
    "url": "/posts/AI and Deep Learning/Deepseek-2025-predict/",
    "date": "2025-06-05T00:00:00.000Z",
    "content": "“本文内容基于公开信息与个人推理，仅供参考，非 DeepSeek 官方声明。”之所以动笔写这篇文章，源于一起 AI 圈经典的“出口转内销”闹剧。今年 4 月底，不知哪家海外媒体扒拉到国内炒股社区的一篇DeepSeek写的、预测DeepSeek r2更新的、内容离谱水平已经突破当前人类科技上限的ai文，结果不仅当了真，还当成“第一手爆料”大肆宣发。更讽刺的是，这条明显未经核实的内容很快又被国内 AI 媒体当作“外媒报道”原路带回，实现了完美的信源闭环。Cache_-6ba51fda3cfd38f6.jpg6月2日，《南风窗》居然把这玩意当作“各方透露”的可靠信息，堂而皇之写进自己文章里——令人忍俊不禁。Pasted image 20250603045953.png6月5日最新消息：摩根士丹利也干了！10b3adabb02a7a4bd2a14bc29cd16b89.pnge5c518f554145e311d59daa7d2232f8c.pngWhat can i say？人类就是这么草台班子，假新闻转一圈大家相互转载相互印证就可以变成多方交叉核验的可靠信源。时无英雄，使竖子成名。现在我也来“预测”一次，尝试结合当前业内研发节奏与 DeepSeek 既有的发布规律，对其 2025 下半年模型进展做一份不严肃但尽量靠谱的前瞻。一、火鸡科学家：DeepSeek 模型的研发&发布节奏深度求索不愧为幻方旗下的究极理工科公司，在整个大模型行业里，他们可能是最讲节奏感的一家。大家可能已经感受到他们发新模型的频率非常稳定：差不多每两个月就得整点动静。而且不是光有动静，更新还真的有条不紊：两轮小版本热身，接着一个大版本换代，这个“2小1大”规律，从 2024 年年初一路沿用到现在。以下我们按时间线盘一下 DeepSeek 模型的主要发布节奏：2023.11.16：DeepSeek-LLM V1（7B / 67B）正式“出道”。全开源+MIT 许可证，一开始就对标 LLaMA，明确了开源路线的技术与社区策略。2024.05.06 / 05.16：DeepSeek-V2 & V2-Lite上线 236B MoE 架构大模型，激活参数压至 21B，性能更强、推理更快。10 天后补发轻量版 V2-Lite，适配边缘端、小场景。2024.06.14 / 07.24：DeepSeek-Coder V2 系列\n编码专项模型上线，128k 上下文+强编程理解，属于 DeepSeek 在 code 模型这条支线上的第一次发力。2024.09.05：DeepSeek-V2.5版本整合更新，把 V2-Chat 和 Coder-V2 融成一个通用模型。2024.11.20：DeepSeek-R1-Lite作为R1的前瞻性小模型，进行先期技术测试。2024.12.10：DeepSeek-V2.5-1210“V2 最后一跳”，增强对话与网页检索模块，为 V2 系列收尾。2024.12.26：DeepSeek-V3（671B MoE）正式跨代，37B 激活参数、推理速度翻倍、API 接口大改，称得上一次“架构级跨越”。2025.01.20：DeepSeek-R1（685B MoE Reasoner）推理专项模型上线，对标 OpenAI O1，数理、思维链、工具调用明显强化，甚至还开源权重&训练代码，直接刷爆 HuggingFace。2025.03.25：DeepSeek-V3-0324（小版本更新）聚焦工具链整合与写作能力，前端能力明显增强。2025.05.28：DeepSeek-R1-0528（小版本更新）提升对话稳定性、结构化输出（如 JSON / Function 调用）与文学输出质量，幻觉率进一步降低。从 V2 开始，DeepSeek 基本维持“两个月一大更”的节奏，每个主版本之间都穿插两轮小版本热身或专项模型补强（如 V2 Chat 的 0517 / 0628，Coder 的 0614 / 0724），2024 年 9 月正式实现 Chat / Code 路线融合，最终以 V2.5-1210 封顶，随后迅速过渡到 V3 与 R1 世代，迄今节奏仍旧如一。所以，我们可以先扮演一下火鸡科学家，纯从发布节奏角度推测一下 DeepSeek 后续的进展：首先，如果沿用“两个月一次大更 + 中间热身小版本”的节奏推理，那 2025 年 7 月，很可能会迎来 V3.5 的发布。而 V3.5 相比 V3，大概率将成为一次“结构优化 + 能力扩展”的过渡版本，最有可能引入的，是多模态能力：比如图文对话、网页截图理解，甚至代码可视化与图形化推理等特化能力——这正是目前所有主流模型发力的方向，如o3和Gemini 2.5 Pro故事，DeepSeek 若要维持竞争态势，必须在这条线上补全短板。接着，大概在 9 月份左右，应该会出现 DeepSeek 两条路线的同步升级——即：V4：作为通用模型主线的全面迭代，参数规模可能不再暴涨，而是强调推理性能、效率与 Agent 化能力的提升；R2：作为 Reasoner 专线的强化升级，对标 OpenAI的o3后续迭代模型和 Gemini 2.5 Pro 0605&正式版&未来的Gemini 3，进一步提升数理 + 工具链 + 多步推理表现。如果这个推演成立，那么我们有理由期待：2025.07：V3.5 多模态增强版2025.09/10：V4 通用模型 + R2 推理模型 双线发布二、目前大模型科研的方向浅析如果说 DeepSeek 自身的发布节奏是其未来计划的“内因”，那么整个行业的技术发展趋势，则是不可忽视的“外因”。当前大模型领域的科研方向，已经非常清晰地聚焦在如何让模型“更好用”、“更能干活”上。1. 以 o3 为代表的 Agentic 模型发力：大模型走向实用的必由之路“Agentic” 这个词，近一年来在 AI 圈的热度持续走高。简单来说，Agentic AI 指的是那些不仅仅能理解和生成内容，更能自主规划、执行复杂任务、并与环境动态交互的 AI 系统。它们具备一定程度的自我导向和决策能力，能够为了达成特定目标而主动调用工具、访问数据库、甚至与其他 AI 或人类协作。Agentic AI 之所以成为兵家必争之地，根本原因在于它是大模型真正落地到产业化、工程化应用的必经之路。OpenAI在2025年4月正式发布o3模型，被认为是 Agentic AI 的一个重要里程碑。o3 的核心特点在于其强大的 “工具使用”能力和“链式思考”能力。在执行任务时，o3可以主动分析任务需求，自主决定调用哪些工具（例如网络搜索、代码执行、图像生成等），并通过多步骤的推理来完成复杂任务。OpenAI 甚至提到，o3 可以在一次运行中执行超过 600 次工具调用来解决特别具有挑战性的任务。这种能力使得 o3 在处理需要多方面分析、答案并非显而易见的复杂查询时表现尤为出色。在国内，阿里巴巴的Qwen 3系列模型在其发布时就明确强调了其先进的 Agent 能力。Qwen3 能够精确地与外部工具进行交互，无论是在其“思考模式”（用于复杂逻辑推理、数学和编码）还是“非思考模式”（用于高效的通用对话）下，都能在复杂的 Agent 驱动任务中达到开源模型的领先水平。2. 以 Gemini 2.5 Pro 为代表的多模态推理模型：更接近人类的交互与理解如果说 Agentic AI 解决了模型“如何做事”的问题，那么多模态推理模型则着重于模型“如何理解世界”以及“如何与我们交互”的问题。Google 在 2025 年初发布的 Gemini 2.5 Pro，在多模态能力上展现了令人印象深刻的进展。它不仅仅能处理文本，还能原生理解和处理图像、音频、视频等多种信息模态。这意味着你可以直接向 Gemini 2.5 Pro 输入视频，并获得结构化的输出，而无需手动进行中间步骤或切换模型——这种跨模态的统一理解能力，使得 AI 更接近人类感知和交互的方式。目前Gemini 2.5 Pro也是社区公认的真全能模型，堪称高性价比六边形战士三、跳大神时间到！如果说前面两部分还算有板有眼、数据充分，那么接下来我们要进入的环节，就纯属信口开河 + 玄学推演 + 大胆假设，小心求证了。这部分就纯属是我参考 DeepSeek 过去的发布节奏、公开发言中的蛛丝马迹、行业竞品的演进趋势，再加上点人类写手的直觉 + 八卦 + 社区情绪嗅觉，试图“未卜先知”一下 2025 年底之前 DeepSeek 可能还会整出哪些幺蛾子。以下内容不保证正确，只保证离谱中带点合理，也欢迎大家看完之后自行打脸，或者半年后回来复读——就当是 AI 圈的星象占卜了。1.DeepSeek V3.5 的目标可能会实现多模态 & 全模态推理多模态很棒，因此值得一次中版本升级；单纯的多模态更新又似乎不值得以 AGI 为目标的 DeepSeek 单开一个大版本号——所以我悍跳：V3.5 很可能将作为一次“通向全模态理解”的关键跳板。在这个阶段，DeepSeek 有望首次引入原生的图像处理能力，支持图片输入、图文对话、表格识别等功能，逐步补齐与 GPT-4o、Gemini 2.5 Pro 等竞品在交互模态上的差距。除此之外，v3.5可能还会跟Qwen3那样支持自动&手动选择是否开启思考推理模式，支持调整推理预算。2. Agentic 能力增强：思维链内的模型调用，迈向“执行力强”的AI助手在 V3.5 或后续版本中，我猜测 DeepSeek 有可能开始显性增强 Agentic 能力，其关键点就在于——支持思维链（CoT, Tree-of-Thoughts）内部的动态模型调用与工具调度，提升整体任务完成速度与执行表现。换句话说，未来的 DeepSeek 模型很可能会不仅“自己思考”，而且“知道该什么时候调用谁来帮忙”。这种演进趋势在 o3 身上已经有了清晰体现：通过嵌套式的推理结构，模型可以在思考过程中动态决策是否中断当前流程、调用外部工具（如代码执行器、搜索引擎、函数库），再将结果引入当前上下文继续推理。3.超长上下文探索如果说多模态和 Agentic 能力是模型“能力广度”和“执行深度”的拓展，那么超长上下文技术则是支撑这一切的底层基础设施，更是未来构建更复杂、更智能 AI 系统的基石。 我在博客《浅谈ChatGPT的记忆实现机制 兼论工程端记忆设计》就已经解释过模型记忆机制和上下文管理的重要性，因此就不在这里赘述。我们已经看到，无论是 Google 的 Gemini 2.5 Pro 还是 OpenAI 的 GPT-4.1，都在不遗余力地扩展模型的上下文窗口。Gemini 2.5 Pro 已经支持高达 100 万 token 的上下文窗口，并计划很快扩展到 200 万；GPT-4.1 同样将上下文窗口提升到了 100 万 token。开源社区做了很大有益探索的还有我们的 Minimax-01 模型只有拥有了处理海量信息的能力，DeepSeek 的模型才能在更复杂的任务中游刃有余，真正成为能够理解世界、解决问题的智能体。当然，超长上下文也带来了新的技术挑战，例如如何保持模型在长序列中的注意力、如何有效降低计算成本和推理延迟等。但正如 DeepSeek 在其 R1 模型中展现出的创新能力（如通过强化学习激励推理能力），我们有理由相信，这家以技术见长的公司，有能力在超长上下文这个关键领域再次带来惊喜。4. 进一步“降本增效”：昇腾集群上的训练调优 + 小型 MoE 模型补位DeepSeek 作为目前最坚定拥抱昇腾集群的头部模型厂商之一，早在 R1 阶段就已经开始将核心模型推理管线部署到昇腾系统之上，形成异构算力环境下的高效推理流程。接下来，降本增效势必会成为其下一阶段优化重心之一。从目前趋势来看，昇腾的最大价值并不在于性能赶上黄卡，而是在于“足够好 + 足够便宜 + 足够多”。尤其在推理场景中，在美帝封锁已经到穷凶极恶，模型性能已趋稳定的前提下，华卡提供的算力完全可以胜任绝大多数商业级调用需求。换句话说，昇腾最大的意义在于让“客户侧推理”不再消耗珍贵的 NVIDIA 训练卡资源。过去，大模型厂商在应对海量推理请求时，往往不得不动用与训练共用的 GPU 集群，造成高昂的资源占用与调度冲突。而现在，通过将推理管线外包到昇腾集群，大模型公司得以 “集中力量办大事”：将 A100 / H100 等昂贵资源彻底回归训练主线，全面加速基础模型的进化节奏。在这种趋势下，我们有理由相信 DeepSeek 会：进一步压榨昇腾集群在推理侧的性价比极限，从编译器、调度器、模型剪枝、INT4/FP8 量化等层面优化调用效率；搭配推出小型 MoE 模型，为移动端、私有部署、插件系统等高频但轻量的场景提供超快响应能力，建立模型产品线的高低配分层。5.更长、更稳定且多线程的编程 Agent 框架研发（但大概率不会由 DeepSeek 亲自主导）其实这一块有点凑数的味了，毕竟从 DeepSeek 一贯的风格来看，他们并没有太大意愿去做复杂系统的工程封装，也鲜少在社区或发布会（如果官网发个通告也算的话）上强调 Agent 框架、插件生态、IDE 插件集成这些开发体验相关的内容。但这不代表 DeepSeek 会在这一赛道上彻底缺席。随着业界逐步从“能写代码”向“能写能改能跑”的多线程 AI 编程助手过渡，模型本身的结构和能力边界也需要配套升级。就目前趋势来看，DeepSeek 至少会在以下几个维度提供潜在支撑：延长上下文窗口，以支撑大型代码库的理解与调用路径分析；优化思维链结构，提升对复杂编程任务的“多步操作规划”能力；降低推理开销，使得 Agent 可以在多线程并发场景下稳定运行；增强结构化输出能力，便于与执行环境、编译器、终端接口进行更顺畅的通信。DeepSeek 可能不会亲自去造 IDE，但它会造出可以被 IDE 驱动的强模型；不会去做完整的 Agent 运行框架，但它会在底层提供更适合被封装成 Agent 的模型。在 Jules、Codex、Windsurf、Cursor 等产品把“AI 工程助手”这条路铺通之后，DeepSeek 未来如果希望其模型参与企业级应用，迟早也得提供一条通向“能用”的高速通道。四、最后再骂一嘴炒股社区炒股社区是我这辈子见过中老登最多、最傲慢、讨论质量最低的社区之一。你很难在别的地方看到这么多既缺乏基本事实判断能力、又习惯用“我看你这样就不懂”开口的中年人类，在大模型、芯片、算力、AI训练架构等完全不属于他们认知舒适区的领域里，侃侃而谈、信口开河，散播着一堆似是而非、但因为语气自信而极具误导性的观点。最讽刺的是，他们很多人其实根本不懂自己在说什么，但依旧能把谣言传成“共识”，还能顺带编出几条股价逻辑链自圆其说。你永远不知道一条“DeepSeek全面采用昇腾集群进行训练”、“xxx传要在美国要上市”的假新闻，会从哪个贴子冒出来，又会在多短时间内被转到什么公众号里变成“知情人士透露”。而当你追溯源头时，却发现整个链条的起点，是一篇用大模型写的预测贴。当然，他们也不会觉得有什么问题。对炒股社区而言，一切信息都只服务于一个目标：讲一个能让人抬轿的故事。至于那个故事本身是真是伪、有没有技术依据、有没有人真在干活，谁在乎呢？也正因如此，我觉得写这篇文章是有点意义的。在一个真假信息混杂、专家话语失效、热钱和短线情绪主导讨论的时代，哪怕只是稍微把节奏理清楚、逻辑讲明白，也不失为一种小小的抵抗。"
  },
  {
    "title": "信息洪流中的官僚体系：苏联央地关系与大部委制度反思",
    "summary": "当代社会信息爆炸所带来的挑战与变革已成为共识——从海量数据的生成到算法驱动的决策逻辑，信息处理能力正在成为衡量一个组织治理效能与制度韧性的核心标尺。历史往往是一面棱镜，能够折射出现实问题的深层结构。如果我们将视线投向20世纪的苏联，这个曾试图通过高度集权的官僚体制掌控国家机器各个环节的超级大国，其独特的央地关系与“大部委制”运作模式，为我们提供了一个关于信息如何在庞大层级结构中流动、扭曲乃至淤塞的",
    "tags": [
      "风自东方来"
    ],
    "url": "/posts/Finance and Economics/planning-vs-market-ussr/",
    "date": "2025-06-01T00:00:00.000Z",
    "content": "当代社会信息爆炸所带来的挑战与变革已成为共识——从海量数据的生成到算法驱动的决策逻辑，信息处理能力正在成为衡量一个组织治理效能与制度韧性的核心标尺。历史往往是一面棱镜，能够折射出现实问题的深层结构。如果我们将视线投向20世纪的苏联，这个曾试图通过高度集权的官僚体制掌控国家机器各个环节的超级大国，其独特的央地关系与“大部委制”运作模式，为我们提供了一个关于信息如何在庞大层级结构中流动、扭曲乃至淤塞的极具价值的制度样本。从“苏维埃+电气化”的理想图景到帝国解体的历史终章，信息处理能力的失灵与官僚体系的结构性僵化，无疑构成了其中始终存在的制度性症结。本文聚焦于苏联模式的两个核心支柱：其一是高度集权而缺乏弹性的央地关系，其二是支撑计划经济运作的 “条条块块”分明却又彼此掣肘的大部委体制。这些制度设计在理论上旨在实现国家对资源与发展路径的全面掌控，但在实际运行中，它们是如何面对、应对，抑或说，是如何被日益复杂的经济社会信息洪流所吞没？它们又是如何在结构性约束下，逐渐走向效率低下、创新停滞，最终触发系统性危机的？值得说明的是，笔者并不认同所谓“奥地利学派”或其他新自由主义理论对苏联经验的粗暴归因。本文的分析框架与判断立场，更多是立足于制度运行的实际逻辑与信息治理的基本机制，而非某种预设立场的工具性演绎。在当下的舆论语境中，批评公有制、唱空体制的言论往往可信度天然高人一等，为公有制辩护、解释政策的论证义务从头重上三分，这可不算什么“独立思考”。因此，我希望读者不要将本文视作某种“结论的权威”或“真理的引导”，而是将其作为一个分析样本，帮助你建立起自己的判断标准。你完全可以质疑、反驳，甚至推翻我的论点，只要你的反思是出于理性，建立在事实与逻辑之上。最终，每个人都应当思自己所思，言自己所言，以理性的方式主张自己的制度理解与经济权益。:::note\n我深知很多材料的可信度可能会受到各种信息传递上的自然扭曲（比如语言、不同的作者立场和不同时代的看法也不尽然相同），因此我会使用引用的格式来对某些争议信源进行特殊说明\n:::一、概念基础：科层制、信息与苏联体制运行机制要理解苏联的纯计划模式在信息洪流中的困境，我们首先需要厘清几个核心概念：科层制（Bureaucracy）的理想与现实，信息在组织行为中的角色，以及苏联体制自身独特的运作逻辑。这三者相互交织，共同构成了苏联信息治理失灵的制度背景。1.韦伯的科层制理论与“理性官僚”的制度理想所有现代官僚体系的研究都绕不开马克斯·韦伯（Max Weber）的经典论述。韦伯将科层制视为一种基于“法理型权威”的、最具效率和可预测性的组织形式。科层制具备明确的权力等级，专业分工明确，执行事务依据规章制度，且官员的选拔与晋升基于其专业能力与经验。在韦伯看来，一个理想的科层制组织，其成员如同精密机器上的齿轮，能够高效、精确地执行既定任务，实现组织目标。这种“理性官僚”是现代国家治理能力的基础。从表面上看，苏联建立的庞大国家机器，尤其是其中央政府各部委和地方苏维埃执行委员会，似乎高度符合韦伯科层制的某些外部特征：层级分明、部门林立、强调统一指令。例如，在勃列日涅夫时期，全联盟及联盟-共和国级的部委数量一度超过100个，每个部委内部又设有复杂的司、局、处层级，试图将国民经济的每一个毛细血管都纳入统一管理。然而，正如后续章节将深入分析的，苏联的“科层制”在实践中，其“理性”色彩逐渐被权力寻租、信息壁垒和意识形态僵化所侵蚀，距离韦伯的理想模型渐行渐远。2.信息与组织行为：从“信息作为资源”到“信息的政治”信息是任何组织进行决策、协调与控制的基础。在古典组织理论中，信息往往被视为一种客观的“资源”，如同人力、物力、财力一样，可以通过科学的管理方法进行有效的收集、传递与处理，以服务于组织目标。组织行为学先驱赫伯特·西蒙提出的“有限理性”概念，已经指出了决策者在信息获取与处理能力上的局限性。然而，信息在组织内部远非中立的“资源”。它更是一种权力，一种可以被用来巩固地位、规避责任、甚至打击对手的“政治资本”。掌握信息者往往掌握了议程设置与决策的主导权，而信息的选择性呈现或刻意扭曲，则直接服务于部门利益或个人目标。因此，组织内部的信息流动，并非简单的技术过程，而是一个充满博弈与策略的“信息政治”过程。在苏联体制下，信息高度集中于中央，尤其是国家计划委员会等核心部门。理论上，这些信息应服务于“科学”的计划制定与资源调配。但实际上，由于缺乏市场机制提供的价格信号和竞争压力，信息的真实性与时效性大打折扣。同时，由于权力高度集中且缺乏有效监督，信息的收集、上报与解读过程，不可避免地受到各级官僚的利益诉求与政治考量的深刻影响。3.苏联体制的运行逻辑：计划权、执行链与反馈滞后苏联模式的核心是高度集中的指令性计划经济。其基本运作逻辑可以概括为：强中央，弱地方：中央各工业部委直接管理其在全国范围内的下属企业，绕过了地方政府的许多权限。地方政府在经济管理上的自主权非常有限，更多是执行和监督中央计划的角色，安全（克格勃KGB）、内务（MVD）等强力部门也都是中央垂直领导；地方绝大部分财政收入上缴中央，再由中央根据计划进行再分配。地方缺乏独立的财源和财政自主性，严重依赖中央拨款。这使得中央可以通过财政手段有效控制地方。计划权高度集中：国家计划委员会负责制定国民经济的宏观与微观计划，从五年计划到年度计划，细致到规定成千上万种产品的产量、价格、分配和投资。在鼎盛时期，计划委员会需要平衡和协调的“物质平衡表”项目多达数万种，试图对全国主要商品的生产和分配进行全面控制。1980年代，由国家物价委员会直接定价的商品和服务项目超过20万种。注：赫鲁晓夫时期进行过一些权力下放的尝试（如设立国民经济委员会Sovnarkhoz，将部分经济管理权下放到区域），但效果不彰，很快又回归集权；戈尔巴乔夫时期推行“公开性”（Glasnost）和“改革”（Perestroika），试图下放权力和激活地方积极性。然而，这一过程失控，削弱了苏共的控制力，反而激发了各加盟共和国的民族主义和分离倾向，最终导致苏联解体。地方精英抓住了权力真空的机会，纷纷宣布独立。层层分解的执行链：中央的计划指令通过各专业部委（如重工业部、农业部、轻工业部等）下达到各加盟共和国、州、区，再到具体的工厂、农庄（集体农庄Kolkhoz、国营农场Sovkhoz）。这一“条条”（中央部委垂直管理）与“块块”（地方行政区域管理）结合的体系，构成了庞大而复杂的执行网络。自下而上的反馈机制（理论上）：企业和地方政府应定期向上级汇报计划执行情况、资源需求、生产数据等。这些数据理论上应成为下一轮计划制定的依据。然而，这一看似严密的体系存在一个致命缺陷：反馈滞后与失真。信息的上传下达需要经过漫长的层级，每一个层级都可能因为自身利益、理解偏差或能力所限而对信息进行加工、筛选乃至扭曲。当计划与现实脱节时（这在复杂经济中是常态），由于缺乏有效的横向协调机制和快速的反馈回路，调整往往缓慢而无效。正如匈牙利经济学家科尔奈·亚诺什（János Kornai）在其著作《短缺经济学》中所描述的，计划指令的僵硬性与信息传递的低效，是造成“常态化短缺”的重要原因。4.信息扭曲的三个基本机制：隐瞒、膨胀与层层过滤这实际上是全世界科层制的共同难题，在官僚制度内，为了规避责任、逃避惩罚，下级往往倾向于隐瞒坏消息、问题和困难。在斯大林时期的高压政治下，以及后续“稳定至上”的勃列日涅夫时代，未能完成计划指标或暴露管理缺陷，都可能带来严重的政治后果。因此，地方官员和企业管理者有强烈的动机将负面信息“内部消化”，或将其最小化处理。这里就不举例子了与隐瞒坏消息相对的是夸大好消息。为了获得奖励、晋升或仅仅是满足上级的期望，虚报产量、夸大成就（俄语中称之为 pripiski，意为“虚报浮夸”）成为普遍现象。企业管理者为了完成或超额完成看似不可能的计划指标，常常在统计数据上做手脚。著名的“乌兹别克棉花案”便是登峰造极的例子：在沙拉夫·拉希多夫（Sharaf Rashidov）主政乌兹别克斯坦期间（1959-1983），该共和国长期系统性地虚报棉花产量，骗取了中央政府数十亿卢布的补贴，这种大规模的数据造假持续了近20年。最后，信息在自下而上传递的过程中，每一级官僚机构都会根据自身的理解、偏好和政治需要对信息进行筛选和“润色”。原始数据中包含的复杂性、不确定性和地方特殊性，在层层上报中逐渐被简化、模糊化，甚至被扭曲成符合上级期望的“标准答案”。最终到达决策核心的信息，往往与真实情况相去甚远。这种过滤机制，使得中央决策者如同“雾里看花”，难以准确把握实际情况，制定的政策自然也容易脱离现实。这三大机制相互作用，共同编织了一张扭曲的信息网络，使得苏联的官僚体系在信息处理上陷入了结构性的困境。它不仅削弱了计划的科学性与有效性，也固化了体制的僵化与低效，为日后的危机埋下了深层伏笔。二、央地关系中的信息博弈：从“命令-响应”到“上下失真”1.中央集权的初衷：效率、统一与国家能力苏维埃政权建立之初，面对的是内战的破坏、经济的凋敝以及外部环境的敌视。在这种背景下，高度的中央集权是迅速整合资源、恢复秩序、提升国家能力的必要手段。列宁的“苏维埃政权+全国电气化”勾勒了通过集中力量实现国家现代化的蓝图。斯大林时期的工业化运动更是将这一逻辑推向极致。通过国家计划委员会（Gosplan）和各工业部委，中央政府试图对全国的经济活动进行精密计算和统一调度。第一个五年计划（1928-1932）期间，苏联的生铁产量从330万吨增长到620万吨，钢产量从430万吨增长到590万吨，煤炭产量从3550万吨增长到6440万吨。这些在当时被视为中央集权巨大动员能力的体现，为国家在短期内建立起相对完整的工业体系奠定了基础。这种集权模式的初衷，在于通过统一的计划和指令，消除地方主义的干扰，最大限度地集中力量办大事，实现国家战略目标。尤其是在战争或准战争状态下，这种模式在资源调配和动员方面展现出其“效率”的一面。在卫国战争期间，苏联能够迅速将西部工业设施大规模东迁，并调整生产以满足军事需求，这与中央对经济命脉的强力掌控密不可分。这也是所有对苏联的批判者都必须要承认的一点2.地方执行者的双重任务与“软约束”行为然而，地方执行者——从加盟共和国领导人到州、区党委书记，再到企业厂长——实际上承担着双重任务，他们既是中央政策的忠实执行者，又是本地区/本单位利益的代言人。这种双重身份使得他们在与中央的互动中，必然会采取复杂的博弈策略。匈牙利经济学家科尔奈·亚诺什提出的“软预算约束”理论则深刻揭示了计划经济体制下企业和地方政府的行为逻辑。由于企业亏损最终会由国家财政兜底，破产风险极低，地方和企业管理者缺乏严格的成本控制和效率提升的内在动力。相反，他们更倾向于：向上多报需求：为了获得更多资源（投资、原材料、劳动力指标），地方和企业会夸大生产潜力、项目前景和实际困难，争取更有利的计划指标和资源分配。向下隐藏能力：为了更容易完成计划，避免因超额完成而被“鞭打快牛”（即下一期计划指标大幅提高，被称为“棘轮效应”），他们往往会低报生产能力，隐瞒富余资源。囤积资源：由于物资供应的不确定性，企业和地方习惯性地囤积原材料、设备甚至劳动力，以备不时之需，这进一步加剧了整体经济的短缺。讨价还价：计划制定过程充满了中央与地方、部门与企业之间的讨价还价。例如，一个地区为了争取一个大型工业项目，可能会承诺不切实际的配套条件和产出；而企业为了降低生产指标，则会强调设备老化、原料不足等困难。这种“软约束”下的行为模式，使得中央从一开始就难以获得关于地方真实需求和能力的准确信息，而信息博弈与失真在苏联经济的各个领域都留下了深刻印记。其中最经典的就是粮食采购领域，也是苏联央地矛盾最为尖锐的领域之一。苏联中央政府为了保障城市供应和出口换汇，往往对农业地区下达极高的粮食征购指标。在20世纪30年代初的农业集体化时期，国家以极低的价格强制征购粮食，征购量常占到一些地区产量的30%-40%甚至更高。地方官员为了完成任务，不惜采取强制手段，而农民则以消极怠工、隐瞒产量甚至武装反抗作为回应。这种对抗导致了巨大的农业损失和人为的饥荒（如1932-1933年的乌克兰大饥荒，哈萨克斯坦等地也遭受重创）。即便在后斯大林时期，粮食问题依然困扰苏联。地方为了减轻压力，往往会在播种面积、预计产量等数据上做文章，向上汇报时或多或少地“调整”数据。苏联每年因储存、运输不善造成的粮食损失高达20%至25%，这背后既有技术问题，也有因信息不畅、权责不清导致的管理问题。英国《金融时报》援引苏联官方数据指出，仅“烘干、运输、储藏”三个环节造成的粮食浪费，就相当于当年苏联进口粮食总量（数千万吨）的一半左右；而苏联《经济问题》杂志则进一步估算，仅饲料用粮（饲料粮通常占全年粮食产量的相当比例）在处理不当情况下，损失可达20%–30%，约为3,500–4,000万吨。也就是说，单就这部分饲料粮而言，损失率就已经在20%–30%之间.农业部门只对地里的农畜产品数量负责，从集体农庄国营农场到各城市的国营商店，中间要经过运输、仓储、加工、包装、销售等漫长的产业链条和环节。按苏联经典学说，这部分不创造价值，故最不受重视。它导致苏联拥有巨大的账面食品产出，很大部分无法抵达消费端。对苏联农产品的损耗，各家说法不一，苏联农业权威尼科诺夫院士估计，苏联粮食损耗为40%。1988年，苏联农业部门统计土豆产量8700万吨，但进入市场的只有1740万吨，期间又损耗了60%，达到消费终端时，只剩下700万吨。除了前文提及的“乌兹别克棉花案”这一登峰造极的系统性造假外，各种形式的虚报浮夸在苏联经济中屡见不鲜。工业企业为了完成或超额完成月度、季度、年度计划，常常在产品数量、产值上“添油加醋”。建筑部门为了报告项目“提前竣工”，可能在工程质量上大打折扣。农业领域除了产量虚报，还有牲畜存栏数、牛奶产量等方面的虚报。例如勃列日涅夫时期，哈萨克斯坦的粮食产量也曾出现过严重的虚报问题，时任哈萨克共产党第一书记的库纳耶夫在其回忆录中也间接承认了这一点。这种虚报不仅导致中央决策失误，还造成了巨大的资源浪费，并败坏了社会风气。3.信息上行过程中的失真链条：激励缺失与机制扭曲信息从基层单位（工厂、农庄）到地方政府，再到共和国层面，最后汇总到莫斯科的中央部委和国家计委，每经过一个层级，都可能发生一次“处理”。但这种处理往往不是为了提高信息质量——而是服务于该层级官僚的特定利益。下级官员在向上级汇报时，会有选择地过滤掉那些可能引起上级不快或暴露自身问题的信息，同时将那些符合上级期望或能体现自身“政绩”的信息加以突出和“美化”。信息在层层传递中，棱角被磨平，复杂性被简化，最终到达中央决策层的信息，往往是经过精心“修饰”的版本。在某些情况下，上下级之间甚至会形成某种“共谋”。地方官员为了争取中央的投资或补贴，会与企业合谋夸大项目效益或困难程度。而中央某些部门的官员，为了显示本部门工作的重要性或管理范围的扩大，也可能默许甚至鼓励这种行为。这种自下而上的信息失真链条，使得中央即便拥有最先进的计算机和最庞杂的统计机构（如中央统计局，TsSU），也难以获得真实、全面的国民经济运行图景。1970年代末，苏联情报机构克格勃（KGB）甚至开始独立收集经济数据，因为他们发现官方统计数据越来越不可靠，这本身就是对官方信息系统失灵的讽刺性证明。这个说法的来源为斯科特·谢恩（Scott Shane）1994年出版的著作《 dismantling Utopia: How Information Ended the Soviet Union》。\n“对日益严重的危机的认识最初是在克格勃内部产生的，克格勃凭借其遍布各个地区和机构的告密者大军，掌握着国家的脉搏。此外，克格勃主席尤里·安德罗波夫在20世纪70年代在克格勃内部设立了一个秘密部门，专门从事经济分析。”尽管许多材料证实了苏联统计数据的不可靠性以及克格勃对经济问题和腐败的知晓 ，但很少有材料独立且明确地证实，在20世纪70年代末期，克格勃为应对此特定目的而设立了一个专门的宏观经济数据收集单位。现有材料中，克格勃官员如切尔卡申或卡卢金的回忆录，虽然讨论了克格勃的行动和内部政治，但在提供的摘录中并未具体提及这样一个单位或其经济数据产出。如果克格勃确实在形成自己更符合实际的经济评估，这将对理解冷战后期苏联的决策产生深远影响。它将表明，苏联国家内部至少有一个强大的机构，其对现实的看法可能比政府其他部门受到的扭曲要小。克格勃内部这种“更清晰的视角”可能影响了安德罗波夫就任总书记后的政策，并可能影响了向后续领导人（包括戈尔巴乔夫）就改革必要性提出的建议。4.“忠诚”优先于“真实”：政治文化对信息治理的影响这部分主要是勃列日涅夫时期，和自列宁开始的等级名录制比较凸出，但本文在此不做过多讲解。三、大部委体制与“条条块块”的组织悖论在前文探讨了央地关系中的信息博弈之后，我们进一步聚焦苏联体制的另一个核心支柱：庞大而高度专业化的大部委体制。这种体制在理论上旨在通过精细分工实现对国民经济各领域的有效管理，但在实践中，却催生了“条条”（中央垂直管理部门）与“块块”（地方行政区域）之间的深刻矛盾，以及部委内部和部委之间的信息壁垒，最终严重制约了体系的整体效能和应变能力。1. 大部委体制的缘起与制度意图：集中化 vs 专业化苏联的大部委体制（Министерство, Ministry）直接脱胎于早期苏维埃政权的人民委员部（Народный комиссариат, People's Commissariat, Narkomat）。其建立的初衷，一方面是实现国家对关键经济部门的高度集中控制，确保资源能够按照中央计划统一调配，服务于快速工业化和国防建设等战略目标。另一方面，则是试图通过专业化分工来提升管理效率。每一个部委负责一个特定的行业或领域，如重型机器制造业部、煤炭工业部、农业部等，理论上能够汇聚该领域的专家和技术力量，进行“科学”管理。斯大林时期，随着工业化全面铺开，部委数量迅速膨胀。到勃列日涅夫时代，全联盟级和联盟-共和国级的部委总数一度超过100个（例如，1970年代末期，约有60多个全联盟部委和近30个联盟-共和国部委）。每个部委都像一个独立的“工业王国”，下辖遍布全国的科研机构、设计院、工厂企业、乃至配套的教育和生活服务设施。例如，仅苏联航空工业部（Minaviaprom）就掌控着从飞机设计局（如图波列夫、伊留申、米高扬等）、发动机制造厂到总装厂的完整产业链条。这种体制试图将“计划”的触角延伸到经济的每一个细胞。2.“条条块块”矛盾：条线管理与属地管理的冲突苏联的行政管理体系呈现出典型的“条条块块”结构：“条条”（ведомственные линии, vedomstvennye linii - 部门条线）：指中央各部委对其下属单位（工厂、矿山、农场等）实行的垂直领导和管理。这些企业直接听命于莫斯科的部委指令，其生产计划、资源分配、产品调拨等均由中央部委决定。“块块”（территориальные единицы, territorial'nye edinitsy - 领土单位）：指地方苏维埃政府（从加盟共和国到州、市、区）对其行政辖区内的社会经济事务的管理。这种双重管理体制不可避免地导致了“条条”与“块块”之间的持续冲突和协调难题：资源争夺：中央部委下属的企业（“条条”单位）往往是地方上的用人大户、用地大户、能源消耗大户，但其产出和利润主要上缴中央，对地方财政贡献有限。地方政府（“块块”）则需要为这些企业提供基础设施（道路、水电、通讯）、社会服务（住房、医疗、教育），却往往缺乏足够的资源和权限。例如，一个大型中央直属工厂的扩建计划可能得到部委批准，但地方政府却要为新增工人的住房、子女入学等问题焦头烂额。政令不一与责任推诿：企业既要执行来自中央部委的生产指令，又要遵守地方政府的行政法规（如环保、劳动安全等）。当“条条”的要求与“块块”的规定发生冲突时，企业往往无所适从，或者选择性执行。信息在“条条”和“块块”之间流动不畅，甚至相互封锁，导致决策依据片面。地方发展失衡：中央部委倾向于从本部门利益最大化出发，在全国范围内布局生产力，可能导致某些地区产业结构单一（如专门的煤炭城市、钢铁城市），过度依赖某个“条条”的兴衰，缺乏综合发展能力和抗风险能力。地方政府对此往往无能为力。赫鲁晓夫时期曾试图通过设立“国民经济委员会”（Совнархоз, Sovnarkhoz）来打破“条条”的过度控制，将部分经济管理权下放到区域性的经济委员会，强化“块块”的统筹作用。这一改革在1957年至1965年间推行，最初旨在克服部门主义，促进区域综合发展。例如，最初设立了105个经济行政区。但由于触动了中央部委的既得利益，且未能根本解决计划经济的深层矛盾（如价格信号缺失、激励机制扭曲），反而造成了一定程度的经济混乱和地方本位主义抬头，最终在勃列日涅夫上台后被废除，重新回归了高度集中的部委管理体制。这一反复，本身就说明了“条条块块”矛盾的根深蒂固。3.部委之间和部委内部的信息壁垒与重复冗余如果说“条条块块”的矛盾是纵向权力与横向权力间的冲突，那么部委之间的“部门主义”（ведомственность, vedomstvennost'）则是横向权力单元之间的深刻隔阂。每个部委都追求自身体系的完整性和独立性，将信息和资源视为本部门的“私产”，不愿与其他部门共享，即信息孤岛现象：各部委都建立了自己的信息收集、处理和上报系统。由于缺乏有效的横向信息共享平台和激励机制，关键的技术数据、生产经验、市场需求（即便在计划经济下也存在隐性需求）等信息，往往被锁在各自的“保险柜”里。一个部委研发的新材料或新工艺，可能对其他部委的生产有重要价值，但这种跨部门的技术转移非常缓慢和困难。为了避免受制于其他部门，各部委倾向于建立“大而全”、“小而全”的配套体系。不同的工业部委可能都会投资建设自己的小型工具厂、维修厂、甚至科研机构，从事类似的研发和生产活动，造成了严重的重复投资和规模不经济。苏联国家计委（Gosplan）虽然名义上负责协调各部委的计划，但面对数量庞大、利益各异的部委，其协调能力往往力不从心。据估计，苏联时期各类科研机构多达数千家，但由于部门分割，许多研究成果无法有效转化和推广。由于信息不透明和部门本位，国家层面的计划制定，有时会演变成各部委争夺资源和指标的博弈场，出现 “为计划而计划” 。部委之间为了争取更有利的计划指标（如更多的投资、原材料配额，或更低的产出指标），可能会向上级（国家计委或更高层）提供经过“修饰”或片面的信息。这种信息壁垒和重复冗余，不仅极大地浪费了宝贵的国家资源，也使得跨部门的协同创新变得异常困难，严重制约了经济整体效率的提升和技术进步的速度。当然，不仅仅部委之间存在壁垒，在每个庞大的部委内部，由于高度集权和森严的等级制度，信息流动同样面临层层阻隔和扭曲。因为部委的主要决策权（人事、财务、生产计划、资源分配等）都集中在部长、副部长以及少数核心司局（Главк, Glavk - 总局）领导手中，所以部委条条之间的信息上行下效的汇报链条极为冗长：一个基层工厂的实际生产问题或创新建议，需要经过厂长、联合公司（如果有）、总局、主管副部长，最终才可能到达部长层面。每一个环节都可能因为官僚程序、负责人对问题的理解、个人利益考量等因素，对信息进行过滤、删减、甚至歪曲。这与前文所述的“隐瞒、膨胀与层层过滤”机制在部委内部同样适用。当外部环境变化或出现突发状况时（例如，国际市场某种原材料价格剧变影响进口，或某个关键设备发生故障），由于决策权高度集中且信息传递缓慢，部委系统往往难以做出快速有效的反应。企业想要调整生产计划、更换供应商或采用新技术，都需要漫长的审批流程，这种内部的等级化和信息梗阻，使得大部委这艘“巨轮”虽然体量庞大，但“船大难掉头”，反应速度和适应能力都大打折扣。4.体制刚性与应急失能：切尔诺贝利事件为例注意，我们在这里当然也绝对不能否认苏联红军指战员、消防员、矿工、科学家、医生、司机、建筑工人以及众多志愿者的非凡勇气和自我牺牲精神。他们是真正的英雄，在人类历史上最严重的技术灾难面前，用自己的血肉之躯筑起了减少灾难扩散的屏障。1986年4月26日发生的切尔诺贝利核事故，是苏联大部委体制在信息管理、部门协调和应急反应方面结构性缺陷的一次灾难性总爆发。切尔诺贝利核电站名义上由苏联能源和电气化部（Minenergo）负责运营和管理。然而，其反应堆（RBMK-1000型）的设计和关键核部件的供应则主要由中型机器制造部（Minsredmash）掌控，这是一个拥有极高保密级别和巨大权力的“超级部委”，长期主导苏联的核武器与核能计划。此外，国家核能安全监督委员会负责安全监管。这种多头管理和平行结构，使得权力分散，责任模糊。正如苏联著名核物理学家、参与事故处理的瓦列里·列加索夫院士（Valery Legasov）事后指出的，RBMK反应堆本身存在设计缺陷，且操作规程未能充分警示在低功率运行下的危险性。事故当晚进行的涡轮发电机惯性实验，本身就是在多项安全规程被绕过或被故意违反的情况下进行的，例如关闭了多个关键的应急保护系统。这种对规程的漠视，部分源于对完成实验任务的压力，部分也源于长期以来对“绝对安全”的迷信和对潜在风险的认知不足，而这种认知不足，恰恰是信息未能有效共享和警示机制失灵的结果。事故发生最初的数小时乃至数天内，信息的传递呈现出典型的“下情上达”困境和“保密优先”的官僚惯性。核电站管理层和普里皮亚季市地方官员在最初并未完全意识到灾难的真实规模。即便当消防员（许多人在未被告知辐射危险的情况下英勇扑救，如第一批到达现场的弗拉基米尔·普拉维克中尉和维克多·基别诺克中尉的消防队）出现严重辐射症状时，向上（基辅的乌克兰共和国领导层和莫斯科的能源部）汇报的信息仍然不完整、不及时，甚至存在淡化处理。据记录，莫斯科方面直到事故发生数小时后才陆续收到零散报告，且初期报告严重低估了辐射水平和反应堆损坏程度。由于缺乏准确、及时的信息，苏联最高决策层在最初几十个小时内无法做出有效判断。直到事故发生近36小时后，即4月27日下午，普里皮亚季市约5万居民的疏散才开始进行。而苏联官方首次向本国民众和国际社会公开承认发生核事故，则是在4月28日晚间，是在瑞典福什马克核电站等欧洲多国监测到异常高的辐射水平，并向苏联发出质询之后。这种“被动公开”本身就反映了体制在危机信息管理上的严重缺陷，即内部信息封锁和对外形象考量优先于公众知情权和生命安全。据米哈伊尔·戈尔巴乔夫后来回忆，政治局在最初几天获得的信息也是混乱和矛盾的。在处理阶段，虽然迅速成立了由部长会议副主席鲍里斯·谢尔比纳领导的政府委员会负责现场指挥，但各部委之间的协调依然困难重重。能源部、中型机器制造部、卫生部（负责医疗救助和辐射防护评估）、国防部（派遣军队、工程兵和飞行员参与救援、清理和修建“石棺”）、内务部（负责区域封锁和治安）、克格勃（负责情报收集和控制社会舆论）等，都有各自的利益、信息渠道和行动逻辑。正是这种体制性的信息不透明和应急准备不足，使得许多救援人员（后来被称为“清理人”，ликвидаторы）在对危险缺乏充分认知和足够防护的情况下投入工作。首批进入现场的消防员几乎是在毫无特殊防护的情况下与高强度放射性物质搏斗，导致他们在短时间内受到致命剂量照射而牺牲。随后调集的数万名军人，包括预备役人员，以及从全国各地征召的矿工（如图拉矿工在反应堆下方挖掘隧道以防止核心熔穿地下水）、建筑工人等，他们中的许多人也未能得到关于辐射风险的全面信息和足够的个人防护设备。先后有超过60万“清理人”参与了切尔诺贝利事故的善后工作，他们承受了不同程度的辐射，许多人因此留下了长期的健康问题，甚至过早离世。 在事故原因调查和善后措施的讨论中，部门利益和“政治正确”的考量也时常干扰科学决策。对RBMK反应堆设计缺陷的承认过程就充满了阻力，因为这涉及到对整个核工业部门乃至国家科技声誉的否定。瓦列里·列加索夫院士在国际原子能机构会议上相对坦诚地报告了事故原因（包括操作失误和设计问题），这在当时为苏联赢得了一些国际尊重，但在国内却承受了巨大压力。四、制度僵化与信息溃败：晚期苏联的治理逻辑危机如果说苏联体制在早期和中期尚能凭借其强大的动员能力和对“增长”的路径依赖维持运转，那么进入勃列日涅夫时期（1964-1982年）及其后，曾经的制度优势逐渐蜕变为难以撼动的结构性障碍。信息系统在此时不仅未能成为改革的催化剂，反而沦为掩盖矛盾、粉饰太平的工具，最终导致整个治理体系陷入“认知失调”与“行动失能”的恶性循环。这种僵化与信息溃败，是理解苏联解体前夜其治理逻辑危机的核心。1.稳定队伍的勃列日涅夫时代与\"停滞\"的代价勃列日涅夫上台后，吸取了赫鲁晓夫时期频繁改革引发政治动荡的教训，将“稳定干部队伍”（стабильность кадров）作为核心政策。这在短期内带来了政治上的平静，但也导致了官员队伍的严重老化和思想的僵化，形成了所谓的“格伦托克拉西”（老人政治）。高级官员平均年龄不断攀升，苏共中央政治局成员的平均年龄从1966年的58岁上升到1982年的70岁。这种人事上的凝滞，使得任何触及既得利益的改革都难以推动，整个官僚体系弥漫着不求有功但求无过的氛围。在这种背景下，信息系统的作用更多地转向了“维稳”而非“纠错”。负面信息被视为对“稳定”的潜在威胁，倾向于被过滤和压制。中央决策层听到的，越来越多的是经过精心包装的“好消息”和符合预期的“数据”。面对这种明显的放缓趋势，体制内部却缺乏有效的反思和调整机制，反而通过宣传和统计手段努力维持“持续发展”的表象。这种“稳定”的代价，便是日后被称为“停滞时代”（Эпоха застоя）的全面困境。当官方的、正式的计划经济体系越来越难以满足社会日益增长的需求和应对复杂的经济现实时，一个非官方的、基于“潜规则”和人际关系的“第二经济”（вторая экономика）或称“影子经济”（теневая экономика）便不可避免地发展壮大起来。这既是对僵化体制的一种“适应”，也是对其合法性的侵蚀。“布拉特”（блат）——一种依赖个人关系网获取稀缺商品和服务的非正式体系——成为苏联社会生活的常态。从购买紧俏家电、获得优质医疗服务到安排子女入学就业，几乎无事不可“布拉特”。这种现象的存在，本身就说明了正式信息渠道和资源分配体系的失灵。人们不再相信官方的承诺和计划，转而依赖非正式网络。“第二经济”的范围十分广泛，包括：私人农业生产：集体农庄成员和城市居民在自留地（приусадебные участки）上进行的生产，其产品往往通过非官方渠道销售，弥补了国营商店供应的不足。据估计，在1970年代末，自留地占用的耕地不足苏联总耕地的3%，却生产了全国约25-30%的农产品，尤其是肉、蛋、奶、蔬菜和水果。地下工厂与服务：未经官方许可的生产活动（如服装、鞋帽、家具）和各种有偿服务（如修理、建筑、运输、私人教学）。倒买倒卖与权力寻租：利用职务之便或信息不对称，将国家资源或紧俏商品进行倒卖以牟取暴利。这在商业、物资供应等领域尤为突出。虽然自留地土地仅占国营农场和集体农庄的极小的比例，但却生产出不相称的大量农副产品。1991年，自留地仅占全部农业生产土地的3%，但却生产出18%的粮食和28%的畜禽产品。据欧洲复兴和开发银行1991年发表的《价格政策和食物分配的调查报告》(Survey on Pricing Policy and Food Distribution)估计，苏联农民的自留地比国家经营的同类土地产出量要高出1.5—6倍(Schnitzer,1994：244)。人们意识到，土地私有化政策通过把农村土地转移到农民手中，意在把集体农庄庄员转化成新型现代农民(farmers)，为建立以家庭农场为主的市场化农业经济奠定基础。“现在的农民自留地只占全国可耕地面积的4%，但其产量却占苏联谷物总产量约25%。 ”莫里斯·博恩斯坦. (1988,P. 273)说。据西方经济学家格雷戈里·格罗斯曼（Gregory Grossman）等人的估算，到1970年代末至1980年代初，苏联“第二经济”的规模可能占到其国民生产总值（GNP）的10%-20%，甚至更高。这部分经济活动游离于国家计划和统计之外，中央对其规模、结构和影响几乎没有准确的信息。它的存在，一方面缓解了部分社会矛盾，满足了部分民生需求；另一方面，也加剧了腐败，扭曲了资源配置，并进一步削弱了中央计划的权威性和有效性。2.普遍的怠工与社会活力的丧失：“他们在假装付我们工资，我们则假装在工作”苏联晚期流传着一句广为人知的民间谚语：“Они делают вид, что платят нам, а мы делаем вид, что работаем（他们假装付我们工资，我们则假装在工作）”。这句话一语道破了当时社会普遍存在的劳动积极性低下，以及对“公家”事务的冷漠态度。在平均主义的薪酬体系和“铁饭碗”制度保障下，个体劳动的付出与回报之间缺乏敏感的联动机制。多劳并不意味着多得，少干也鲜少有风险。这种激励结构的缺陷，加之“棘轮效应”的普遍存在——即超额完成任务反而可能提高下一个周期的指标要求——使得进取精神反倒成了一种非理性选择。与此同时，苏联经济长期困扰于商品短缺与货币购买力的持续衰退。这进一步削弱了劳动者赖以维系的物质激励。即使名义工资上升，但面对空荡荡的货架和劣质高价的商品，货币的价值尺度与交换功能遭到严重削弱。人们即便手握现金，也常常陷入“有钱买不到东西”的困境，使得财富积累变得无意义，进而动摇了通过辛勤劳动改善生活的信念。在正式经济回报体系失效的背景下，许多劳动者将精力转向“第二经济”或依靠“布拉特”（关系网络）获取资源。他们更愿意投入到那些真正带来实利的活动中，而非官方分配的、回报微弱的本职工作。曾经作为意识形态核心的“国家主人翁”意识，也在高度集权、僵化低效的官僚体制中逐渐瓦解。普通劳动者在生产、管理乃至社会治理中缺乏实质性的参与感，感受到的更多是自上而下的命令与遥远的宏大叙事。他们很难在劳动与集体福祉之间建立真实的关联，也无法从中获得个人价值与成就感。缺乏主体感的结果是显而易见的：对“公家”财产的漠视、对工作质量的敷衍、对技术革新的冷淡，逐渐成为常态。当制度无法提供清晰的价值认同时，“为谁工作、为何工作”的困惑便无处不在，劳动的异化感也随之滋长。在这种氛围长期浸润下，消极怠工、“磨洋工”（тянуть время）乃至“顺手牵羊”（несуны）等行为，从个体的权宜之计逐步演变为社会的集体习惯。非官方的估计显示，工作时间中因“开小差”等原因造成的无效劳动，可能占到总工时的 20% 至 30%。而酗酒问题的普遍化，更进一步侵蚀了本已低迷的劳动生产率。这种消极情绪与行为模式，最终不仅拖累了经济效率，损害了产品质量，更深层次地侵蚀了整个社会的道德基础与创新精神。它如同慢性毒药，摧毁了制度自我修复与发展的内在动力，也为苏联治理逻辑的最终崩溃埋下了隐患。3.信息系统的彻底失灵在晚期苏联，官方信息系统日益从一个旨在辅助国家治理、反映客观现实的工具，蜕变为一个主要服务于政治宣传、竭力维护体制表面“光鲜”的庞大机器。其核心功能不再是提供决策依据，而是制造和传播符合意识形态期望的叙事。这种异化，使得整个官僚体系乃至最高决策层，逐渐陷入一种与现实脱节的“认知失调”状态。如前所述的“乌兹别克棉花案”等虚报浮夸现象，只是冰山一角。为了迎合上级、完成指标，各级部门和企业都有动机在数据上“做文章”。中央统计局（TsSU）虽然拥有庞大的数据收集网络，但其汇总的数据在多大程度上反映真实情况，连克格勃都表示怀疑。这种信息环境，导致了决策层在某种程度上“失去现实感”。安德罗波夫（1982-1984执政）上任后，曾试图通过克格勃等渠道了解国家真实状况，并发起了一系列反腐和整顿劳动纪律的运动。这本身就说明了他对官方信息系统的不信任。然而，其努力因其迅速去世而未能持续，且积弊已深，非短期运动所能扭转。当最高领导层都难以准确把握国家脉搏时，任何有效的改革都无从谈起。甚至可以说在安德罗波夫阶段唯二可以正常运作的苏联机构就是内务部和克格勃，令人忍俊不禁戈尔巴乔夫上台后（1985年），推行“公开性”（Гласность）和“改革”（Перестройка）。“公开性”在一定程度上打破了信息封锁，使得许多长期被掩盖的问题暴露出来，例如历史问题（斯大林时期的罪行）、经济困境的真实程度、民族矛盾、环境灾难（如切尔诺贝利事件的后续影响）等。然而，信息的释放并未自动带来治理能力的提升。反而，“公开性”所揭示的严峻现实，与长期以来官方宣传形成的“美好图景”之间的巨大反差，进一步冲击了民众对体制的信任，加剧了社会的分化和思想的混乱。同时，“改革”试图触动僵化的经济和政治结构，但遭遇了来自官僚体系内部的强大阻力。最终，信息的溃败与制度的僵化相互强化，形成了一个无法解开的死结。当“公开性”撕开了体制的重重黑箱，展现出的却是千疮百孔的现实和无力回天的治理困境。五、再论计划与市场：科层官僚制与信息过载1.经济计算大论战的历史回响与信息维度20世纪上半叶，围绕计划经济可行性的“经济计算大论战”在经济学界激烈展开。以路德维希·冯·米塞斯（Ludwig von Mises）和弗里德里希·哈耶克（Friedrich Hayek）为代表的奥地利学派学者提出，没有生产资料的私有制和市场竞争形成的价格信号，中央计划机构无法进行理性的经济计算，从而无法有效配置资源。哈耶克在其著名论文《知识在社会中的运用》（The Use of Knowledge in Society, 1945）中进一步强调，经济运行所需的知识是分散的、地方性的、甚至是默会（tacit）的，这些知识无法被集中收集和处理。尽管我们已在前言中表明，本文不完全认同奥地利学派对苏联经验的某些结论性批判，尤其是其往往忽略计划经济在特定历史时期（如早期工业化、战争动员）的特殊功能。但我们必须承认，这场论战的核心——信息问题——确实击中了计划经济的要害。苏联国家计划委员会（Gosplan）试图通过编制数以万计乃至百万计的“物质平衡表”来协调成千上万种产品的生产、分配和消费，这本身就是一项对信息处理能力的极致挑战。这种体系的运行，依赖于一个核心假设：中央计划者能够获取、处理并基于这些信息做出最优决策。然而，正如前文所揭示的，信息的隐瞒、膨胀、过滤以及官僚体系自身的“噪音”，使得这一假设在现实中难以成立。苏联的实践，在某种程度上成为了经济计算论战中批判方观点的复杂注脚。对于人类自有社会以来就形成的市场和市场经济，其核心机制之一是价格。价格并非仅仅是货币的数字表达，它是一种高度浓缩的信息载体，传递着关于稀缺性、供求关系、消费者偏好、技术可能性等复杂信息。分散的个体和企业基于价格信号做出独立的经济决策（生产什么、购买什么、投资什么），从而在“看不见的手”的引导下实现资源的相对有效配置。价格的波动也提供了即时的反馈，促使市场主体调整行为。相比之下，苏联的计划经济主要依靠行政指令（“指挥棒”）来调配资源和组织生产。价格在很大程度上是国家（如国家物价委员会）行政确定的，长期固定，无法真实反映供求变化和资源稀缺程度。当“指挥棒”取代了价格信号，信息传递就从一个横向、自发、多中心的过程，变成了一个纵向、指令性、单中心的过程。中央计划机构发出的指令，层层下达到企业，但这些指令本身就是基于不完整甚至失真的信息制定的。而企业执行情况的反馈，又如前述，经过层层“加工”。其结果是，整个经济系统缺乏一个有效的、自调节的反馈机制，错误决策的成本高昂且难以纠正。2.信息过载：科层制无法承受之重即便我们假设存在一个完美无私、技术精湛的中央计划团队，并且所有基层单位都如实上报信息，科层官僚制在面对现代经济的复杂性时，依然会遭遇“信息过载”的瓶颈。一个经济体中每时每刻都在发生无数的交易、创新和外部冲击。即使有最先进的计算机辅助（苏联在计算机应用方面相对滞后，早期主要用于军事和科研，大规模经济管理应用不足，如OGAS项目的受挫），全面收集、实时处理并精确协调如此庞大的信息流，对于任何单一的中央机构而言，都是一项几乎不可能完成的任务。苏联中央统计局（TsSU）虽然雇佣了大量人员，但其主要职能是收集数据并按固定格式上报，而非进行复杂的动态分析和预测。在决策上，科层制的等级结构决定了信息传递和决策的链条漫长。当一个工厂需要调整生产计划以应对原材料短缺或市场需求变化（即便在计划框架内也存在隐性的“用户需求”），报告需要层层上报，审批指令再层层下达，往往耗时良久，错失良机。这种“时滞”在快速变化的环境中是致命的。如第三章所述，大部委体制和央地分割导致了严重的信息壁垒。各部门、各地区往往只关心自身“一亩三分地”的指标和利益，缺乏横向信息共享和协同的动力与机制。国家计委虽试图统筹全局，但其面对的是一个个信息不透明、利益固化的“独立王国”，协调难度极大。这使得本已不堪重负的中央信息处理系统，还要额外承担大量的内部协调成本。对于现代国家最重要的科技创新领域，创新往往源于对市场细微变化的感知和对未知领域的大胆探索。在信息高度集权、风险厌恶的科层体制内，自下而上的创新建议难以得到重视和资源支持。计划指标的刚性也使得企业缺乏试错空间。信息的单向流动（自上而下的指令为主）而非双向互动，扼杀了基层的创造活力。苏联虽然在某些国家主导的尖端科技领域（如航天、军事）取得了巨大成就，但在民用技术创新和产品多样化方面则显著落后。这种信息过载的压力，使得苏联的计划体系越来越像一个庞大而笨拙的巨人，对外部环境变化反应迟钝，内部协调失灵。所谓的“计划”，在很多情况下，与其说是前瞻性的科学规划，不如说是对上一期计划的简单延续，或是对既成事实的滞后追认，以及各方利益博弈后的妥协产物。3.去中心化与弹性制度设计：对现代中国“放管服”改革的参考意义苏联官僚体系在信息处理上的结构性困境，尤其是面对信息过载时的僵化与失能，为我们理解现代国家治理，特别是中国正在持续深化的“放管服”（简政放权、放管结合、优化服务）改革，提供了深刻的历史参照。“放管服”改革的核心逻辑，在某种程度上，正是对高度集权科层制下信息处理瓶颈的一种回应，试图通过制度创新来提升治理体系的适应性与效率。“放”权：承认信息分散性，激活基层活力与苏联国家计委试图包揽一切的“全知全能”模式形成鲜明对比，“放管服”改革首先强调简政放权。理论基础为中央政府不可能掌握所有地方性、行业性的具体信息，也无法对瞬息万变的市场做出最快最优的反应。改革最主要的就是减少行政审批，释放市场主体信息处理能力：大量行政审批事项的取消和下放，例如企业投资项目核准范围的大幅缩减、工商登记便利化（如“多证合一”、“证照分离”改革），实质上是将原先由政府部门垄断的信息处理和决策权，部分交还给更贴近市场的企业和个人。企业基于自身对市场前景、技术可行性、成本收益等信息的判断进行投资和经营决策，这比层层上报、等待中央部委批复的模式，无疑更能适应市场节奏，也更能激发微观主体的创新创业活力。自2013年以来，中国国务院部门取消和下放的行政审批事项已达上千项，中央层面核准的企业投资项目削减90%以上。在央地关系方面，改革赋予地方更大自主权，利用地方性知识：向地方政府下放经济社会管理权限，鼓励地方因地制宜进行制度创新（如各地自贸试验区的探索），也是承认并试图利用“地方性知识”的体现。地方政府离具体问题更近，对本地的资源禀赋、社会需求、潜在风险等信息的掌握，往往比远在首都的中央部委更为直接和及时。赋予其相机决策的权力，有助于提升政策的针对性和有效性。“管”结合：从直接干预到规则治理与风险预警“放”并非“不管”，而是要转变管理方式，从过去的事前审批、直接干预，更多地转向事中事后监管，构建基于规则和信任的治理框架。这同样对信息提出了新的要求。现代信息技术的发展，为“放管结合”提供了有力工具。通过建立全国统一的信用信息共享平台、推广“双随机、一公开”监管等方式，政府可以利用大数据分析识别高风险领域和主体，进行精准监管，而非“一刀切”式的全面干预。这要求政府具备更强的数据整合、分析和预警能力，从处理“审批信息”转向处理“风险信息”和“行为信息”。对于政府而言，有效的“管”依赖于清晰、透明、可预期的规则。政府的角色更多地是制定行业标准、环保标准、安全标准等，并确保这些规则得到严格执行。这需要高质量的立法和公正的司法作为保障，其信息基础是对行业发展规律、潜在外部性以及国际通行规则的深刻理解。“服”优化：提升透明度，降低信息不对称优化服务是“放管服”改革的重要目标，其核心在于提升政府服务的效率、便捷性和透明度，降低企业和群众办事的制度性交易成本。各地推行的“一网通办”、“最多跑一次”等政务服务改革，通过整合信息系统、简化办事流程、公开服务标准和办理进度，极大地减少了企业和群众获取政府服务所需的时间成本和信息成本，这本身就是对传统科层制下信息壁垒和办事难问题的一种消解，企业开办时间从改革前的平均20多个工作日压缩到目前的几个工作日甚至更短。政府信息的公开透明，不仅是优化服务的要求，也是现代治理的内在需求。主动公开政策法规、规划计划、财政预决算、重大项目等信息，畅通公众咨询、投诉、建议渠道，有助于减少因信息不对称引发的猜疑和寻租，也能汇集更广泛的社会智慧，提升决策的科学性和民主性。苏联的教训清晰地表明，一个封闭、僵化、信息单向流动的官僚体系，在面对复杂性和不确定性时是何等脆弱。而现代中国“放管服”改革的实践，虽然仍在不断探索和完善之中，但其所体现的去中心化趋势、对市场机制和基层创造力的尊重、以及对信息技术赋能治理的积极拥抱，无疑是对苏联模式的一种深刻反思和超越。通过构建更具弹性、信息更畅通、反馈更及时的治理结构，才能有效避免陷入“信息过载”与“控制幻觉”的泥潭，提升国家治理体系和治理能力的现代化水平。结语：这就代表计划是错的吗？行文至此，我们通过对苏联央地关系与大部委制度的审视，深入探讨了信息在高度集权官僚体系中如何流动、扭曲乃至淤塞，以及这种信息治理的失灵如何最终导致制度僵化与治理危机。从“苏维埃+电气化”的雄心壮志到帝国解体的历史悲剧，信息处理能力的上限与官僚科层制的固有弊病，无疑是贯穿始终的隐痛。那么，这是否就简单地意味着“计划”本身是错误的？是否意味着任何形式的国家干预和顶层设计都注定失败？笔者认为，答案并非如此非黑即白。将苏联的经验简单粗暴地归结为“计划经济必然失败”，既不符合历史的复杂性，也无助于我们理解当下与未来。首先，我们必须区分“计划”的理念与苏联特定历史条件下的“计划模式”。 计划，作为一种预见未来、设定目标、配置资源、协调行动的理性行为，是人类社会进步不可或缺的工具。从个人的人生规划到企业的战略发展，从城市的基础设施建设到国家应对气候变化等全球性挑战，都离不开某种形式的计划。问题不在于“计划”本身，而在于计划的范围、深度、执行方式以及其所依赖的信息机制与制度环境。苏联模式的悲剧，并非源于“计划”这一概念，而是源于其试图通过一个无所不包、高度集权、排斥市场信号、压制地方与个体能动性的指令性计划体系，去全面掌控一个日益复杂和动态的现代经济社会。其核心症结在于中央计划机构试图扮演“全知全能”的上帝角色，但其获取和处理信息的手段却受制于漫长的官僚链条和各层级的利益博弈，导致决策基础与现实严重脱节；官僚系统缺乏市场价格信号这一最直接有效的反馈机制，同时行政反馈系统又因层层过滤和报喜不报忧而失真，使得错误难以被及时发现和纠正。其次，苏联的经验恰恰反衬出，一个有效的治理体系，无论其意识形态底色如何，都必须高度重视信息机制的建设，并寻求“计划”与“市场”、“集中”与“分散”、“控制”与“激励”之间的动态平衡。任何单一中心都无法完全掌握和处理现代社会运行所需的海量信息。因此，需要尊重市场在资源配置中的决定性作用，利用价格信号等市场机制来传递和处理分散的经济信息，在必要的宏观调控和战略规划下，赋予地方政府和市场主体更大的自主权和创新空间，鼓励自下而上的探索和试错。正如中国“放管服”改革所启示的，简政放权、优化服务，本身就是对信息处理机制的优化。大数据、人工智能等现代信息技术为提升治理能力提供了强大工具，可以帮助我们更好地收集、分析信息，进行预测和决策。但技术本身无法取代合理的制度设计和权力制约。苏联也曾有过如OGAS项目这样试图用计算机辅助计划经济的宏大构想，但最终因体制障碍而失败。最后，回到本文的初衷，反思苏联并非为了简单否定过去或唱衰某种体制，而是为了从历史的镜鉴中汲取智慧，帮助我们更好地理解当下信息洪流对所有组织形态提出的挑战。 无论是政府、企业还是其他社会组织，其治理效能都越来越取决于其信息处理能力、制度弹性和对环境变化的适应能力。在信息爆炸的时代，如何避免“信息茧房”，如何打破“部门壁垒”，如何激发个体智慧，如何让决策更贴近真实，是我们共同面临的课题。苏联的故事提醒我们，当官僚体系变得封闭僵化，当信息流动被人为阻断或扭曲，当“控制的幻觉”取代了对现实的敬畏，那么，无论其初衷多么宏伟，其最终的命运都已悄然注定。因此，问题的关键不在于要不要“计划”，而在于如何科学地“计划”，如何让“计划”建立在真实、充分的信息基础上，如何让“计划”与市场机制、民主参与、法治保障有效结合，从而真正服务于社会福祉和可持续发展。计划并没有错，错的是把它变成了神谕，把信息当作命令，把反馈当作威胁，把创新当作风险。真正理性的计划，不是要掌控一切，而是要承认自身的有限性，并与市场机制、地方知识、技术工具共同协作，构建一个多中心、可纠错、能适应的治理结构，这需要我们以更加开放的心态、更加理性的精神，持续探索和完善自身的制度体系。希望这篇博客能为你提供一个思考的起点，让你在纷繁的信息中，构建属于自己的判断。"
  },
  {
    "title": "儿童节专题｜她的身体，他的灵魂：男娘审美的生成机制",
    "summary": "上一篇《儿童节专题｜从裙子到雌激素：伪娘、药娘与性别拟象的进化论》中，我们探讨了当代青少年在性别表达与身体时间上的多重路径：从以服饰与妆容为媒介的“伪娘”表演，到借助激素进行身体再编程的“药娘”跃迁。这些探索可以被认为是对性别气质的主动调度和青少年在面对身份焦虑、性别规训与算法审美共同作用下的一种策略性回应。但，“扮演女性”或“成为女性”并不是这场文化剧的全部。在这一景观化的性别实践中，还有一个更",
    "tags": [
      "亚文化研究"
    ],
    "url": "/posts/HumanSciences/gender-femboy-sissy-evolution-2/",
    "date": "2025-05-31T00:00:00.000Z",
    "content": "上一篇《儿童节专题｜从裙子到雌激素：伪娘、药娘与性别拟象的进化论》中，我们探讨了当代青少年在性别表达与身体时间上的多重路径：从以服饰与妆容为媒介的“伪娘”表演，到借助激素进行身体再编程的“药娘”跃迁。这些探索可以被认为是对性别气质的主动调度和青少年在面对身份焦虑、性别规训与算法审美共同作用下的一种策略性回应。但，“扮演女性”或“成为女性”并不是这场文化剧的全部。在这一景观化的性别实践中，还有一个更有趣且具备代表性的奇观：越来越多普通男性，尤其是Z世代的年轻人，正在主动投射情感与欲望于一种被称为“男娘”的形象之上。他们不是女装大佬的同好，也未必是跨性别群体的盟友，而是那些在社交平台上刷到“又香又懂你”的男孩子后，心甘情愿地点赞、转发、留言“老婆”、“我可以”的“正常男生”。这引出一个值得追问的问题：为什么一个拥有女性化外表、但又保留男性身份和心理结构的形象，会成为如此多男性的理想审美对象？本文将试图揭示“男娘”形象背后的文化心理结构：她拥有她的身体，但说的是他的语言；她被性化、被凝视，却也成为“懂我”“陪我”的亲密他者。 她是一种幻想拼贴，一种自恋镜像，一种既逃避阳刚困境又重新安排欲望秩序的折中物。一、老调重弹：那个令人恐惧、不听话的新女性伴随着目前性别议题争论的愈演愈烈，我想我们必须要承认一个新的事实——在互联网平台，男女双方各自的视角下，对方性别有一定概率，甚至很大程度上是令人恐惧&厌恶的。男性在公共平台上谈恋爱、性、择偶、婚姻问题，很容易被贴上“物化女性”“直男癌”“郭楠”的标签；女性在表达自身情绪、身体经验与性别意识时，又常常被指责“小仙女”“女拳”“太矫情”甚至“上纲上线”。一种日益扩大的性别猜忌与怨怼，悄然成为网络舆论的默认氛围。尤其是在恋爱关系的建构想象上，“她”早已不是那个温柔顺从、体贴入微、把“你高兴就好”挂在嘴边的恋人形象。取而代之的是一个更具主体性、更敢表达不满与拒绝的女性形象：她可能要求你承担情绪价值，可能拒绝为你的性冲动买单，可能在你表达控制欲时明确划线，甚至在一段关系中不再默认“让着你”。所以我们可以在各种NGA的小剧场中看到太多太多的经典好女朋友与贤妻良母剧情：可能是我的女朋友给我装了电竞房并且cos了我最喜欢的角色；可能是我的老婆认为我太辛苦所以偷偷攒钱提了5090；可能是另一半哪怕看不懂也不理解小胡子和大胡子的爱恨情仇，但还是会耐着性子给足情绪价值听你讲二战史——这些旧世代的幻想投射了当前男同胞们的情感困境。什么 你问我为什么不说女同胞？因为我不逛豆瓣，参与的女性主义议题并不多，突兀的去描绘女性同胞对理想中的那个”男性“很容易干出来刻板印象这个“新女性”是独立的、边界感强的、不为欲望所驯的。她不是“理想情人”，她更像一个挑战者——挑战传统男性对亲密关系的支配幻想，挑战你作为男性的性别舒适区，挑战你对“理解与陪伴”的那套老剧本。于是，在相当一部分男性的经验中，异性不再是一种单纯的吸引和慰藉，而是一种混合了渴望、戒备甚至恐惧的复杂存在。“爱她”与“怕她”并存，“想接近”与“想撤退”交织。女性的自我意识觉醒与性别权力的重新协商，虽是社会进步的重要成果，却也在一定程度上摧毁了传统男性赖以构建情感满足与身份安全感的剧本模板。因此，这种女性的“不可预测性”与“高边界”，让一部分尚未在情感经验中建立稳固自我认同的男性，转而寻求更可控、更容易理解和掌握的替代品——一种能提供被爱幻想，同时又不对自己提出情绪负担的“理想他者”。这个他者，不再是女性。至少，不是那种现实中的、拥有独立意志与复杂情绪的女性。男娘，悄然填补了这个位置。二、全新的文化景观：可爱温驯的“带把女兄弟”在这个性别语境愈发紧张、亲密关系逐渐复杂的时代，一个“既温柔可爱、又毫无攻击性，同时还能和你一起打游戏、开黄腔、追番”的形象悄然成为Z世代男性心中理想型的替代者——他不是真正的“她”，也不是传统意义上的“他”，而是那个长着女生的脸、挂着男生的心、拥有理解力与无害感的“带把女兄弟”。这是一个高度视觉化与人格拟合的文化景观新物种。他存在于抖音、B站的变装视频中，存在于二次元Cos照与各种男娘tag的本子里，也存在于你深夜刷手机时点进的“伪娘推荐合集”中。他们常常面容清秀、声线娇软，皮肤光洁、笑容甜美，在服饰与妆容上呈现出比多数现实女性更符合“少女模板”的标准——可爱、顺从、易受控、愿意撒娇，但绝不会反抗、挑衅或宣称“我不属于你”。这种形象的爆火，绝非偶然。男娘所承载的，是Z世代男性在文化景观变迁中对情感连接的“替代性修复尝试”。现实中的亲密关系风险太高，复杂性太强，女性的主体性太难掌控；而男娘，则通过一套视觉+语言+行为的组合程式，提供了一种“既被性化、又能共情”的他者剧本。他是她——因为他足够好看、足够“可爱”、足够能唤起凝视与幻想。这让他可以承载情欲投射，成为一个“安全的、没有情绪成本的性对象”；他又是你——因为他懂梗、打游戏、听你讲骚话还能给你点赞，不会要求承诺，不会做出超出你掌控感的回应。他既能成为“她”，也仍然是“你”——是那个不让你害怕的、好看的你；是那个不会让你自卑的、被性化的她。这种情感拼贴的最终结果，是一个既能够唤起欲望，又不会反噬情绪的“低风险他者”。这不是恋爱，也不是纯粹的性欲满足，更像是一种以性别拟象为接口的情感平替机制。正是在这个意义上，我们必须承认：男娘之所以成为审美显学，绝不仅仅是因为他“好看”，而是因为他在这个性别张力高涨、亲密关系断裂、阳刚气质失效的时代背景下，恰好承接了一种极其微妙的心理需求——对“理想女性”的怀旧幻想，与对“理解自己”的同性投射，两者的融合。而更深层次的问题在于：这其实是视觉文化对“理想女性形象”的再编码与男性内部化。传统时代，“理想女性”是温顺贤淑的大和抚子，是小鸟依人的恋爱对象；到了ACG文化泛滥的后景观时代，“理想女性”变成了二次元老婆，是懂你、不多话、可攻略、永远不会反抗的角色。而现在，这个理想对象不再由真实女性扮演，也不再非要是虚拟角色，他可以是一个现实中的“男孩子”，只要他具备那套审美模版与行为范式。这意味着：“女性性化”已成为一种技术手段与文化接口，而非必然由女性来承载。男娘并不意味着性别革命，更像是男性将“可被凝视”“可被消费”这套机制转向了自己，但并没有放弃其原有的性别优势与共情主导权。结语：一副安全的可性化的躯体“男娘”之所以成为审美显学，归根结底，并非出于性别政治的觉醒，也未必来自对现实女性的敌意，而更像是对一种幻象的回应——对可爱、温柔、理解、自带滤镜与低风险亲密的集体想象。这一形象调和了多个矛盾要素：既被性化，又能共情；既有女性化的身体外观，又保留男性之间的默契与界面语言；既可爱顺从，又不具备现实女性的主权性与情绪强度。它是一种情感缝合的产物，是当代年轻男性在亲密关系焦虑、身份认同漂移与审美可视化环境中，为自己重新拼贴出来的“理想他者”。这一形象并不要求真实——甚至不必来自真实经验。它更像是一种文化机制下的心理接口，一种既能唤起欲望，又能回避复杂协商与现实抗拒的替代关系模板。如果说“伪娘”“药娘”指向的是身份的再造与身体的重写，那么男娘文化本身更多代表了想象的重组与关系的退化。它所承载的，或许不是性别表达的自由，而是某种亲密秩序瓦解之后，对“可被爱、可被理解”这一幻想角色的再次制造——只是，这一次，不再需要他者。"
  },
  {
    "title": "儿童节专题｜从裙子到雌激素：伪娘、药娘与性别拟象的进化论",
    "summary": "前言您有不认同我观点和反对的权利因为人类短期内的不可知是无限的，可知是有限且片面的，所以我始终认为这个世界上可以存在多种并行不悖的理论价值体系不要伤害自己，不要伤害他人这两天写个抽象和稍微偏向于地狱的，大家都知道这两年我国z世代的舆论场与审美观兴起了「男娘&伪娘」热，从B站、抖音到贴吧、QQ频道，不乏打扮得比女生还要精致的少年身影，面容柔顺，眼妆轻盈，穿着jk&洛丽塔然后被一群人追着喊「兄弟你好香",
    "tags": [
      "亚文化研究"
    ],
    "url": "/posts/HumanSciences/gender-femboy-sissy-evolution-1/",
    "date": "2025-05-30T00:00:00.000Z",
    "content": "前言您有不认同我观点和反对的权利因为人类短期内的不可知是无限的，可知是有限且片面的，所以我始终认为这个世界上可以存在多种并行不悖的理论价值体系不要伤害自己，不要伤害他人这两天写个抽象和稍微偏向于地狱的，大家都知道这两年我国z世代的舆论场与审美观兴起了「男娘&伪娘」热，从B站、抖音到贴吧、QQ频道，不乏打扮得比女生还要精致的少年身影，面容柔顺，眼妆轻盈，穿着jk&洛丽塔然后被一群人追着喊「兄弟你好香」和「老婆老婆」，成为网络社群中的视觉焦点与流量焦点。之所以将这一现象作为儿童节专题来谈，是因为近年来出现了一个值得社会学关注的趋势：越来越多年龄介于11到17岁之间的青少年主动选择以“伪娘”或“药娘”的方式进行性别气质的扮演甚至身体干预。更具体地说，至少在目前广泛流通的理解中，“伪娘”这一阶段的实践并不直接指向性别认同的彻底转变，而更像是一种针对“女性气质”的拟象策略——通过服饰、姿态、声线乃至情感表达，建构起一个高度表演化的“理想化女性形象”。而“药娘”则是在此基础上进一步迈入生理层面的自我干预：通过雌激素摄入、青春期延迟治疗、心理暗示甚至自我催眠等手段，试图模糊乃至重构“性别”的身体基础。本文倒无意做出什么道德审判，去惊呼「救救我们的孩子」之类的，只希望在这个儿童节，将目光从早已被资本主义景观文化腐蚀到没有值得关注的天真幻想中稍微移开一寸，看看另一群孩子——那些在性别与身体之间游移、尝试用拟象、技术与表演为自己“再造身份”的少年。这些群体并非，至少说并不完全是受困于网络哗众取宠的诱惑，更是在以一种极具时代特征的方式，回应当代青少年关于「成为谁」的深层焦虑。在这一文化现象的背后，是青春期性压抑的非出口化，是数字媒介下审美资本的流通逻辑，也是教育、家庭、性别话语体系共同塑造下的空白地带。伪娘&药娘热更像是当代性别政治、算法推荐机制与社群文化协同产出的结果——它既不等同于跨性别，也无法用“玩梗”一词加以全部归类。一、伪娘：以女性为镜的投射与传统男性职责的消解1.“女性”作为欲望、神秘与关注的综合体在许多青春期男性的经验世界中，“女性”常常被符号化为一个承载着多重意义的复杂综合体。\n首先是欲望的客体。 青春期的生理唤醒与性冲动，使得“女性”与吸引力、亲密关系乃至性幻想直接关联。然而，在现实的社交与情感教育普遍匮乏的环境下，这种欲望往往伴随着强烈的压抑与无措。\n其次是神秘的“他者”。 由于性别隔离的教育模式和社会交往的局限，女性对于许多青少年男性而言，是既向往又陌生的存在，她们的思维方式、情感表达、生活细节都充满了“未解之谜”，这种神秘感本身就构成了吸引力的一部分。\n最后，是关注的焦点。 不论是在家庭、学校还是大众传媒中，理想化的女性气质（如温柔、美丽、精致）往往更容易获得正向的关注和赞美，这对于渴望被看见的青少年而言，无疑具有强大的示范效应。中译中就是性压抑正是在这种背景下，一部分青少年开始探索好奇、模仿与性压抑的自我调和路径。当直接的异性交往受阻，或对自身男性魅力缺乏自信时，通过模仿“女性”的外部特征——服饰、妆容、姿态——成为一种间接满足好奇心、缓解性焦虑，并尝试理解“他者”的方式。这里出现了一个关键的心理转换：从“拥有女性”（即建立亲密关系）的渴望，部分转移或变形为“成为女性”（即模仿和扮演女性气质）的实践。 图：很经典的Q群男娘meme这种转变实践的深层驱动力之一，便可能涉及到一种隐秘的性倒错快感 (sexual inversion pleasure)。需要强调的是，这里的“性倒错”并非严格指向临床意义上的性偏好障碍或性取向的根本转变，而更侧重于在性别角色扮演中，个体将自身置于一个通常被认为是“被欲望”的客体位置，并从这种身份的代入和想象中获得满足。当他们精心打扮，凝视镜中那个被自己一手建构的、符合特定审美（往往是柔美、可爱）的“女性”形象时，可能会体验到一种对自身“女性化”形象的迷恋与自体性欲式的愉悦。这种凝视既是主体对客体的审视，也是客体化的自我对主体欲望的映照。更进一步，他们可能在想象中将自己投射为被他人（尤其是理想化的男性凝视者）欣赏、渴求的对象。这种“被看见”、“被欲望”的想象本身，即便缺乏真实的互动，也能带来一种强烈的心理满足感和兴奋感，这与传统男性气质中主动追求、占据主导的模式形成了有趣的倒置。这种快感往往与对性别规范的逾越感、对禁忌的触碰感交织在一起，使得每一次成功的扮演都充满了探索与自我肯定的刺激。但这种转换并非一定意味着性别认同的转变，尤其在“伪娘”阶段，更多时候，它是一种策略性的身份游戏，一种在现实压力下对“理想化关系”的替代性满足，以及对自我可能性边界的探索。通过扮演“理想女性”，他们似乎也暂时拥有了理想女性可能获得的关注与青睐——这对于很多正处青春期，世界观与价值观尚未完善，渴望他人认可与赞美的青少年来说是致命的吸引力。这种吸引力，部分源于对传统男性角色压力的逃避，部分也来自于这种“拟态”所带来的新奇体验与即时反馈。2.“伪娘”作为表演：想被看见，想被认可“伪娘”的实践，本质上是一种高度自觉的表演。这种表演的核心驱动力，是“想被看见，想被认可”的深层心理需求。注意，这里的表演不仅仅是指演给别人看，还有演给自己看的部分。首先，从“演给别人看”的维度来看， 对于许多在传统男性气概标准下感到边缘、压抑，或对自身男性魅力缺乏自信的青少年而言，“伪娘”身份提供了一个全新的舞台。通过精心修饰的妆容、柔美的服饰和刻意练习的姿态（当然在多数时候可能就是穿上丝袜和小裙子然后拍一拍腿），他们试图建构一个符合特定社群审美（通常是二次元文化或泛化的“可爱”“萌”系审美）的“女性”形象。我们可以认为这是一次自我性魅力的激活尝试——他们渴望通过这种非传统的性别呈现，去吸引目光、获得赞美，从而在社群中建立一种新的存在感与价值感。这种面向外部的表演，往往伴随着一种羞耻与快感共构的观看机制。一方面，扮演异性、挑战主流性别规范的行为，不可避免地会触动个体内心深处及社会文化层面对于“失范”的羞耻感和焦虑感——担心被误解、被嘲笑、被排斥。但另一方面，正是这种“禁忌”的跨越，以及由此带来的超乎寻常的关注、新奇的赞美（如“太可爱了，想太阳”等网络用语）甚至带有情欲色彩的凝视，又能产生强烈的兴奋与快感。观众的目光（无论是欣赏、惊奇还是猎奇）成为了确认其表演成功与否的关键，每一次“老婆”“女神”“兄弟你好香”的称呼，都是对其“女性魅力”的即时肯定，这种肯定能够极大地满足其被认可的欲望。在这场表演的观众席上，同样坐着表演者自己。“演给自己看”的维度，赋予了“伪娘”实践更复杂的内涵。 当他们穿上裙子，画上眼线，镜中的影像不仅仅是一个等待被外部世界评判的客体，更是一个自我探索和对话的媒介。通过扮演一个理想化的“女性”形象，他们可能在尝试触碰和体验自身性格中被压抑或未被发掘的柔软、细腻甚至脆弱的一面——这些特质在传统的男性角色脚本中往往不被鼓励。图：b站的搜索结果\n因此，这是一种另类的自我赋权与自我确证：在现实中或许难以获得的掌控感、对美的极致追求、以及对自身形象的塑造权，通过这种具身的扮演得以实现。当外界的男性身份让他们感到束缚或不适时，镜中那个经过精心建构的“她”，可能更符合他们此刻内心的某种期望或想象。此时的变装活动更像是在既定性别框架内，为自己开辟的一块可以自由呼吸和实验的“自治区”，一个可以短暂成为“理想自我”的避风港。他们从中获得的愉悦，不仅仅来自他人的赞赏，更来自这种自我构建和自我欣赏的过程本身。这种“成为理想形象”的体验，能够带来一种内在的满足感与平和感，暂时缓解青春期的身份焦虑。我在之前的博客从“捡到女高中生”到“萝莉妈妈”——看现代社会中男性的爱与性需求中曾经阐述过，在传统社会中，“成年男性”的身份建构与路径几乎是线性的：完成学业、进入职场、结婚生子、养家糊口，成为丈夫与父亲。在这一剧本中，男性获得的是明确的社会定位、权力结构与自我认同。但在进入现代化乃至后现代化社会后，这一剧本开始全面崩塌，特别是在日本、中国、韩国等东亚社会，以下几个趋势交织叠加：就业结构不稳定：非正规就业增加、阶层固化、内卷加剧，使得“通过劳动获得体面人生”的路径受阻；婚恋结构紧缩：婚姻率与生育率双降，结婚不再是男性身份的默认通道；父职功能的模糊：在女性觉醒与家庭结构变化中，父亲身份不再稳固、权威日益边缘化。这些变迁意味着：“成为一个合格男人”这件事，变得既不清晰，也越来越难达成。在这一背景下，许多男性面临一种深层的结构性焦虑：我该如何被需要？我该如何爱？我还能扮演什么样的角色？有些男同胞们选择去喜欢更商品化、简化和安全化后的女性景观，而有一部分男同胞们则选择了扮演——当个体将精力聚焦于外表的精致化、情感的细腻化（即使是表演性的），并在虚拟社群与自我审视中因此获得即时满足时，现实世界中对“男性”在学业、事业、家庭等方面的传统期望与压力，似乎被暂时悬置或选择性忽略了。他们通过成为一个被欲望、被呵护、被自我欣赏的“客体”（无论是被他人还是被自我所构建的理想形象所欲望和呵护），巧妙地回避或延缓了成为一个承担传统男性责任的“主体”所面临的挑战与焦虑。3.数字平台的助推在探讨数字平台如何助推伪娘化路径之前，我们有必要先简要回顾其文化源流。事实上，“伪娘”及其近义词“男娘”（男の娘，otokonoko）的概念并非移动互联网世代的创新，其起源可追溯至日本的ACG（动画、漫画、游戏）文化。在这些作品中，具有女性化外貌与特质的男性角色早已屡见不鲜，他们或为剧情增添喜剧色彩（如《乱马1/2》中的早乙女乱马的部分形态虽非典型伪娘，但已触及性别转换的趣味性），或探索性别表达的模糊地带（如《笨蛋、测验、召唤兽》中的木下秀吉，其性别甚至成为作品中的一个独立分类“秀吉”），或仅仅是满足特定“萌点”的审美偏好（如《Fate/Apocrypha》中的阿斯托尔福）。这些存在于虚构叙事中的形象，以其独特的魅力吸引了众多拥趸，为后来的实践者提供了最初的想象蓝本和模仿对象，也奠定了“伪娘”文化最初的审美范式和社群基础。图：早乙女乱马\n早乙女乱马\n图：阿斯托尔福\n阿福然而，在中国，真正将这一亚文化现象从小众圈层的特定爱好者群体推向更广泛公众视野，并赋予其全新实践形式和病毒式传播动力的，正是数字平台的崛起，也就是抖音、B站等平台。“好香”“老婆”等话语体系与点赞文化提供了即时正反馈，强化了表演动机。 在这些平台上，对“伪娘”作品的赞美往往直接而热烈。“兄弟你好香”、“我可以”、“脑婆脑婆”等评论，以及大量的点赞和转发，构成了强大的激励机制。这种即时、量化的肯定，极大地满足了青少年渴望被关注和认可的心理需求。每一次成功的“出片”，都能在社群中引发一阵小范围的狂欢，这种正向反馈循环不断巩固着他们进行“伪娘”实践的意愿和投入度。虚拟社群的“追捧”不仅赋予了这种表演以合法性，更使其成为一种能够迅速积累“社交资本”和“审美资本”的有效路径。二、从伪娘到药娘：拟象的生物政治跃迁1.药娘的出现：拟象不再只是装扮，而是激素调节当“伪娘”阶段通过外部装扮获得的关注与自我认同达到一定阈值，或遭遇瓶颈——比如，无论如何化妆，喉结、体毛、骨骼等男性生理特征依然顽固地提醒着扮演的“不彻底性”——一部分青少年可能会寻求更深层次的“女性化”路径。于是，“药娘”作为一种进阶形态应运而生。这里我们不考虑那些真正非常非常少数的，从出生下来就明确认为自己是真女性的生理男性这里的“药”，主要指雌激素（Estrogen）和抗雄激素（Anti-androgen）。通过口服、透皮吸收等方式摄入这些激素类药物，目的是抑制自身雄性激素的分泌和作用，同时模拟女性体内的雌激素环境，以期达到身体上的女性化效果，如皮肤细腻、体毛减少、脂肪分布改变（如胸部发育、臀部变宽）、声音变高等。对于更年幼、尚未完全经历男性青春期发育的个体，有时还会涉及到青春期阻断剂（Puberty Blockers） 的使用，以延缓或阻止第二性征的出现，为后续的“女性化”争取时间和空间。图：经典药娘神药鱼板\n这些技术路径，在互联网的匿名性和便捷性之下，往往以“教程”、“经验分享”的形式在特定社群中传播。获取药物的渠道也常常游离于正规医疗监管之外，充满了不确定性和风险。然而，驱动他们迈出这一步的，是一种对“更像女孩”的强烈幻想与执着实践。这种幻想源于对理想化女性气质的进一步内化，也可能混杂着对自身男性身份的焦虑、不满，甚至是对原生性别身体的某种排斥。他们不再满足于“看起来像”，而是渴望“感觉像”，甚至“生理上接近”。这种对“真实感”的追求，使得拟象的策略从外部的“画皮”转向了内部的“换血”。2.这还是游戏吗？当针剂和药片取代了化妆品和连衣裙，成为塑造“女性”形象的主要工具时，一个根本性的问题浮现了：这还仅仅是一场角色扮演的游戏吗？ 显然，技术对身体的直接干预，使得这场“游戏”的性质发生了质变。药物带来的生理变化，即便在某些情况下是可逆的，其过程也远比换下一套衣服复杂和深刻。这其中，自我暗示、自我认同与自我医疗形成了一个强有力的连环效应：自我医疗：在缺乏专业医疗指导的情况下，个体自行决定用药种类、剂量和周期。这本身就是一种对身体掌控权的极端宣告，但也伴随着极大的生理和心理风险。这种行为本身，强化了他们改造身体的决心和主动性。身体变化与自我暗示：微小的生理变化——比如皮肤手感的些微改变，或者胸部的一丝胀痛——都可能被放大解读为“正在变成女孩”的证据。这种积极的自我暗示，会进一步巩固他们继续用药的信念。身体的反馈，无论多么细微，都成为了驱动其继续实践的动力。身份认同的固化：随着身体在激素作用下逐渐显现出某些女性化特征，个体对“药娘”身份的认同也随之加深。身体的变化与身份的建构相互印证、相互强化。曾经可能只是模糊的性别探索或表演，在药物的催化下，逐渐凝固为一种更接近本质性的自我认知——“我正在成为/我就是这样的（女性化）存在”。谈及我国“药娘”现象的蔓延，我们必须正视一个在阴影中运作，却对青少年具有强大塑造力的因素：那些独特、甚至可以说是丑恶与险恶的“药娘”小圈子文化。这些圈子往往以线上社群为主要阵地，以一些“前辈药娘”或自称“导师”，“姐姐”的核心人物展开：ta们一方面以“认同你、支持你”为旗帜，对新进者进行过度的赞美与情感绑定——“你好可爱”“你本来就应该是女孩子”——这种无条件的接纳极易让内心孤独、渴望关注的青少年产生依附心理，仿佛自己终于找到了“真正懂我”的人。任何一丝对女性化特质的向往，任何一次试探性的变装，都可能被无限放大和拼命夸奖，营造出一种“你天生如此”“你本该如此”的虚假认同感。紧接着，这种赞美随后迅速转向对生理干预的推动：通过持续不断地灌输诸如“你就是一个女孩，只是困在了错误的身体里”、“勇敢做自己，药物可以帮你实现真正的自我”等观念。这些观念在封闭的同侪环境中被反复强化，质疑的声音被边缘化，而对药物效果的浪漫化想象和对潜在健康风险的刻意淡化，则成为主流叙事。在这种系统性的鼓励、怂恿乃至情感操控下，青少年对于“成为女性”的模糊渴望，逐渐被塑造成一种必须通过服用激素才能解决的“核心问题”，一种不容置疑的“内在真实”。这些尝试原本可能只是青春期探索的一段插曲，或者对“伪娘”阶段表演性满足的延伸，就这样在圈子文化的催化下，加速滑向了不可逆的生理干预的轨道，使得技术对身体的介入不再是审慎的选择，而更像是一种被精心策划和诱导的“必然”——但你被鼓励做出改变，却没有人真正为后果负责。3. 伪娘与药娘的差异与演进：从符号游戏到身体政治一般来说，伪娘更偏向于拟象的表层，具有可逆性。 “伪娘”的实践核心在于外部符号的堆砌与表演。其手段主要包括服饰（JK、洛丽塔、女仆装等）、妆容、假发、声音模仿、姿态学习等。这些改变是暂时性、可逆的，如同换上一套戏服，演出结束后即可卸下。身体本身，除了可能的脱毛或皮肤保养外，并未经历根本性的生理改变。其拟象策略更侧重于视觉和行为层面的“像”，是一种对女性气质符号的借用与扮演。此时的“女性化”更像是一种精心构建的皮肤或面具，其下的生理性别基础依然稳固。而药娘则是拟象的内化与身体重塑。 “药娘”则将拟象的战场从外部延伸至身体内部的生理层面。通过激素药物干预（雌激素、抗雄剂、青春期阻断剂），她们追求的是一种更持久、更深层的“女性化”，试图改变第二性征，如皮肤细腻化、体毛减少、脂肪重新分布（如胸部发育）、肌肉量减少等。这种改变不再是简单的“装扮”，而是对身体生物化学过程的直接介入，其影响往往是部分可逆或不可逆的。拟象不再仅仅是“看起来像”，而是试图在生理层面“趋近于”女性。身体不再仅仅是承载符号的画布，而成为被主动改造的生物政治对象。从伪娘到药娘的演进，通常源于前者实践中遭遇的 “拟象天花板” 以及对 “真实感”的进一步追求 。最初，通过伪娘装扮获得的关注、赞美和社群认同能带来强烈的满足感。然而，随着时间的推移，这种外部反馈的边际效应可能递减。同时，无论妆容如何精致，一些无法掩盖的男性生理特征（如喉结、骨骼轮廓、体毛的持续生长）会不断提醒扮演者其“伪”的本质，可能引发一种“不彻底”、“不够像”的焦虑。这种焦虑感，在追求极致拟象的个体身上尤为突出。此时，个体可能已经通过表演体验到了某种程度的性别疏离或对女性化自我的亲近感。当外部扮演不足以缓解这种内在感受，或反而强化了对“更真实”女性化身体的渴望时，药物便成为了一个看似能弥合“外在形象”与“内在期望”之间鸿沟的选项。他们不再满足于“扮演女性”，而是渴望“成为（更接近生理定义的）女性”。从社会角度，正如前文所述，特定的“药娘”社群文化，通过美化药物效果、淡化风险、并构建一种“追求真我”的叙事，会极大地推动这种演进。在这些圈子中，从“伪娘”走向“药娘”有时被视为一种“进步”、“勇敢”或“更彻底的自我实现”，形成了一种无形的“升级”压力或诱惑。三、文化社会机制：谁塑造了这种“想成为女性”的路径？在前两部分，我们探讨了“伪娘”的表演性实践和“药娘”向身体政治的跃迁。现在，我们需要将镜头拉远，审视那些更宏观的文化与社会机制。1.性教育的缺失与性别知识的匮乏首先，我们必须正视一个基础性的结构问题：我国性教育与性别认知教育的长期缺位。 这在家庭与学校两个最重要的青少年成长环境中，共同制造了一个关于“性与性别”的“沉默地带”。在家庭层面， 传统文化观念的束缚使得许多父母对性话题讳莫如深，甚至视之为洪水猛兽。他们或缺乏相关知识，或感到尴尬，或简单粗暴地将“性”等同于“危险”与“禁止”。对于孩子在性别气质、性倾向、身体发育等方面的困惑与好奇，往往采取回避、压制或简单归因（如“不要学坏”、“男孩子就该有男孩子的样”）的态度。这种回避，使得家庭未能成为青少年获取正确性别知识、疏导性困惑、建立健康性别认同的安全港。在学校层面， 尽管生理卫生课程有所涉及，但内容往往侧重于生理结构和生殖健康，对于性别多元化、性别认同、性别气质、性心理发展等更深层次的社会学与心理学议题，则普遍付之阙如。教育体系更倾向于强化传统二元性别刻板印象，而非鼓励对性别多样性的理解与尊重。老师们自身也可能缺乏相关培训，难以应对学生在这一领域提出的复杂问题。我知道传统思潮的朋友看到这块可能有点难以接受，那其实可以将至理解为——女生就应该柔弱等着被拯救，男生就应该刚强当一个绅士礼让女生，这样是不是就好理解了？这种家庭与学校的“共同失声”，直接导致了青少年性别知识的极度匮乏。 当他们进入青春期，生理和心理经历剧变，对“我是谁”、“我喜欢什么”、“我与他人有何不同”等问题产生强烈探究欲时，却得不到系统、科学、包容的引导。他们对“性别”的理解，可能还停留在最表浅的生理差异或社会赋予的刻板角色上。正是在这样的“真空地带”中，当一些青少年感受到自身气质与传统男性规范的格格不入，或对“女性”产生强烈的好奇与模仿欲时，他们缺乏足够的知识框架去理解这些感受的复杂性。他们可能不知道性别认同、性别表达与生理性别并非总是高度统一，也不知道除了“成为传统男性”或“模仿女性表象”之外，还存在更广阔的自我认知与表达空间。这种知识的贫瘠，使得他们更容易将对女性气质的向往，直接窄化为对“女性”身份的外部拟态，甚至进一步走向生理干预，因为这是他们在信息不对称的环境下，所能接触和理解的、最直接也最“彻底”的路径。2.数字文化中的女性形象：从ACG到“二次元老婆”还是我之前就在从“捡到女高中生”到“萝莉妈妈”——看现代社会中男性的爱与性需求中阐述过的，现代资本主义景观社会生产框架下的那些二次元老婆实际上都是经过美学和商业逻辑双重塑造的“理想女性形象”，具有高度的“可消费性”。温柔体贴、傲娇可爱、天然呆萌、坚强隐忍……各种“萌属性”被标签化并排列组合，满足了不同受众的情感投射与幻想需求。这些性格特质往往简化了真实女性的复杂性，使其更易于被“理解”和“喜爱”。用户可以通过购买周边、参与讨论、进行二次创作等方式，不断强化与这些虚拟角色的情感连接。这些形象也呈现出显著的“可模仿性”。其鲜明的视觉符号（如特定的发型、服装风格、妆容特点）和行为模式（如特定的口癖、姿态、表情），为那些渴望展现“女性气质”的青少年提供了具体的、可操作的模仿蓝本（Cosplay与二创）。图：笨蛋、测验、召唤兽中的木下秀吉\n当一个青少年在现实中对自身男性身份感到焦虑，或对“女性”充满向往时，这些数字幽灵般的“二次元老婆”便可能成为他们构建自我拟象的重要素材库。他们模仿的，并非现实中复杂多样的女性，而是这些被高度提纯和符号化的“理想型”。“成为她（们）”似乎提供了一条捷径，不仅能获得虚拟社群的关注与认可（如前文所述的“兄弟你好香”），更能在想象中体验到那种被呵护、被需要、被欲望的“理想女性”的主观感受。 这种模仿，是对“女性气质”的符号化挪用，也是在数字媒介环境下，个体试图通过消费和扮演特定形象，来重塑自我认同的一种尝试。3.算法与社群的放大效应现代数字平台，尤其是短视频、社交媒体和兴趣论坛，其核心运作逻辑之一便是算法推荐。当一个青少年开始对“伪娘”、“女装”、“可爱”等关键词或相关内容表现出兴趣时，算法会迅速捕捉到这些信号，并持续推送同类信息。这使得用户沉浸在一个由相似观点、审美和行为模式构成的信息茧房中。在这种回音室效应下，个体看到的、听到的都是对“伪娘”或“药娘”实践的肯定、赞美甚至是教程化的引导。质疑的声音、批判性的思考、关于风险的警示，或者其他性别表达的可能性，往往被算法过滤或被社群边缘化。这会造成一种 “幸存者偏差”式的认知：个体可能会误以为这种实践比现实中更为普遍、更为安全、更被广泛接受。算法无形中将零散的个体连接起来，形成看似庞大且活跃的线上“同温层”，强化了实践的合理性与吸引力。基于共同兴趣和实践（如女装、使用激素）形成的线上社群，为参与者提供了强大的身份归属感与认同感。这对于正处于青春期，渴望被理解、被接纳的青少年而言，具有难以抗拒的吸引力。共享的语言与符号系统：圈内黑话、特定的表情包、对特定服饰或妆容风格的偏好、对“理想女性形象”的共同想象，这些都构成了社群的独特文化，增强了内部凝聚力。即时的情感支持与价值肯定：在这些社群中，发布女装照片或分享用药体验，往往能迅速获得“姐妹”们的赞美、鼓励和“指导”。这种正向反馈，尤其是在现实生活中可能感到孤独或不被理解的情况下，会极大地满足个体的心理需求，使其对社群产生强烈的依赖。集体身份的构建与强化：社群通过不断复述“做真实的自己”、“勇敢追求美丽”、“我们是特殊而美好的存在”等叙事，为成员构建起一种超越个体层面的集体身份。这种身份认同，不仅赋予了其行为以“意义”，也可能使其在面对外部质疑时，更加坚定自己的选择，因为这不再仅仅是个人行为，而是“我们”共同的事业。规范的内化与行为的引导：正如第二部分所提及的，一些“药娘”社群中，“前辈”的经验分享和“指导”往往会潜移默化地影响新成员的决策，推动他们从“伪娘”向“药娘”的“进阶”。社群内部形成的规范和期望，会塑造个体对“理想状态”的认知，并引导其行为朝着社群认可的方向发展。算法与社群共同作用不仅放大了“伪娘”与“药娘”现象的可见度，更通过制造信息茧房和提供情感联结，深刻地塑造了参与者的认知、情感与行为模式，使其在“成为女性”的拟象道路上越走越深，也可能越来越窄。四、哲学与社会学视角：身体、性别与再制造的政治:::note\n这部分就是纯念经了，不想看的可以直接跳到结尾。\n:::1.身体作为被编程的对象：福柯式身体政治解读法国哲学家米歇尔·福柯在其权力理论中深刻揭示了现代社会权力如何渗透并作用于个体身体，将其塑造为“温驯的身体”（docile bodies）。权力不再仅仅是压制性的、否定的，更是一种生产性的力量，它通过一系列精细的规训技术（disciplines）——如监视、规范化、考试、训练——将个体纳入特定的知识/权力网络中，使其身体和行为符合社会期望。从这个角度看，“伪娘”与“药娘”的实践，无疑是身体政治的生动体现：“伪娘”的身体规训：在“伪娘”阶段，个体通过对外在符号的精心操演——服饰、妆容、姿态、声线——来“编程”自己的身体，使其符合特定社群（如二次元文化、特定审美圈）所认可的“女性化”标准。这个过程充满了自我监视（镜子、照片、视频）与他者监视（网络评论、社群反馈）。“好香”、“老婆”等赞美，以及对“不像”、“穿帮”的批评，都构成了无形的规训力量，不断校准和塑造着个体的表演。这里的身体，成为了一个被精雕细琢以符合特定审美脚本的表面。“药娘”的生命权力介入：“药娘”则将这种身体编程推向了更深的生物学层面，直接呼应了福柯晚期提出的“生命权力”（biopower）概念。生命权力关注的是对人口生命过程（出生、死亡、健康、繁衍）的管理与优化。在“药娘”的实践中，激素药物的使用，正是试图通过生物化学手段直接干预和“优化”身体的性别特征，使其更符合“理想女性”的生理表型。个体主动或在社群影响下进行的“自我医疗”，可以被视为一种极端的自我规训，将身体置于一套非官方但同样具有强制力的“医学”知识和技术体系之下。她们试图通过技术手段，“重写”身体的生理程序，以期达成一种“更真实”的女性化。在这两种实践中，身体不再是自然的、自在的，而是成为了一个可以被观察、被分析、被干预、被改造的对象。无论是通过外部符号的堆砌，还是内部生理的调整，其最终目的都是为了生产出一个符合特定“女性气质”规范的身体。这个“规范”本身，又往往是由大众文化、亚文化社群以及潜在的消费逻辑所共同塑造的。2.表演性别理论视角（Judith Butler）朱迪斯·巴特勒（Judith Butler）的表演性别理论（gender performativity）为我们理解“伪娘”与“药娘”现象提供了另一个关键视角。巴特勒认为，性别并非一种内在的本质或固定的身份（“所是”），而是一种持续的、重复的社会表演（“所做”）。我们通过日复一日地“扮演”符合社会规范的性别角色——通过姿态、言语、服饰等一系列风格化的身体行为——来建构和维系我们的性别认同。性别，是在这些重复的“述行”中被不断生产和再生产出来的。2.1 性别不是所是，而是所做“伪娘”的实践完美地诠释了“性别是所做”。他们通过有意识地采纳和表演社会文化中与“女性”相关联的符号和行为（穿裙子、化妆、模仿女性化的举止和声线），来建构一个临时的、情境化的“女性”身份。这种身份并非源于其生理性别或内在认同（至少在初始阶段不一定如此），而是纯粹通过“做”出来的。每一次成功的扮演，都是对“女性气质”的一次述行展演。“药娘”则将这种“做”的层面从外部行为延伸到了身体内部。她们通过服用激素来“做”出一个更符合其性别表达期望的身体。身体的变化（如皮肤变好、胸部发育）进一步巩固了其“女性化”的述行，并可能反过来强化其对女性身份的认同。这表明，身体本身也可以被视为性别述行的一部分，是可以被“做”出来的。2.2 “药娘”现象是否推动了性别规范的松动？这是一个复杂的问题，答案并非非黑即白。一方面，从积极的层面看，“伪娘”与“药娘”的实践，尤其是后者对生理性别的直接干预，确实挑战了传统二元性别体制的稳固性。它们揭示了生理性别、性别认同和性别表达之间的复杂关系，表明性别并非天生注定、不可更改。这种对身体可塑性的强调，以及对性别身份流动性的展现，具有潜在的颠覆力量，可能促使社会对性别多样性有更开放的认知，从而在一定程度上松动僵化的性别规范。它们的存在本身，就是对“男必须阳刚，女必须阴柔”这一刻板印象的冲击。但另一方面，也存在着强化甚至制造新规范的风险。 许多“伪娘”和“药娘”所追求和扮演的“女性气质”，往往是高度刻板化、甚至是被男性凝视所塑造的“理想女性”形象（如前文所述的“二次元老婆”）。她们可能模仿的是一种非常特定、甚至有些物化的“萌”、“可爱”、“柔弱”的女性特质，这反而可能巩固了对女性的某些狭隘定义，而不是真正挑战性别规范的内核。为了获得社群的认同，个体可能需要不断追求更极致的女性化外表和生理特征，这本身就构成了一种新的束缚。这种对“真实女性”标准的执着，可能使其从逃离一种性别规范（传统男性气概）陷入另一种（高度理想化的女性气质）的规范之中。3.是性别自由，还是新的顺从？从积极的角度看，选择成为“伪娘”或“药娘”，可以被视为个体在既有性别框架感到不适或不满时，寻求自我表达和身份认同的一种尝试。这体现了对传统男性角色和气质规范的一种偏离，一种对“成为不同于传统男性”的渴望。在这个意义上，它似乎提供了一种逃逸的路径，一种在性别表达上的“自由”。然而，这种“自由”可能并非纯粹的、无拘无束的。如前所述，青少年接触到的“理想女性形象”（尤其来自ACG、网络社群）往往是高度特定和简化的。他们“自由选择”的模仿对象，本身就是文化工业和社群偏好共同塑造的产物。这种选择，更像是在一个预设好的“女性气质菜单”中进行点选，而非完全原创性的自我发明。对于那些在传统男性气概标准下感到挫败、焦虑或被边缘化的青少年，转向“伪娘”或“药娘”的路径，可能并非完全出于对女性身份的积极向往，而更多是出于对“失败的男性身份”的消极逃避。当“成为一个成功的传统男性”的道路显得崎岖或缺乏吸引力时，“成为一个被关注的可爱伪娘/药娘”似乎提供了一个更易获得即时满足和社群认可的替代方案。一旦进入“伪娘”或“药娘”的实践，个体可能会发现自己需要不断投入精力、金钱甚至健康去维系这个新身份，以符合社群的期望和自我的设定。对“更像”、“更真”的追求，可能使其陷入一种新的身份焦虑和表演压力中，形成了另一种形式的“顺从”——顺从于“理想女性化”的标准，顺从于社群的目光，顺从于药物的逻辑。这也就是资本主义景观社会的强大之处。万物皆可被消费，万物皆可被观赏结语：谁的身体，谁的疆域？当裙摆落下，当药片吞下，当青春期的焦虑化作软化骨架的激素回路，我们终究要问出那个问题：谁拥有这个身体？谁在定义这个身体的意义？是算法？是虚拟社群？是父母、教育体制，还是资本幻景下那永远温柔、永远可被消费的“理想女性”？当一个个青少年在化妆镜前凝视自己——那已不再那么“男孩”、却也未曾真正“成为女孩”的脸，他们到底在试图逃离什么，又在向谁靠近？如果“伪娘&男娘”尚是一场策略性的审美游戏，是在传统男性规训之外争取喘息的表演实践，那么“药娘”则意味着这场游戏走向身体政治的深水区，走向“可逆”的终点。在这—跃迁中，身体从未是单纯的个体财产，而是不断被他者投射、规训、重塑的疆域。伪娘的裙摆可能属于自己，但它的形状、色彩、意义，往往由社群赞美决定；药娘的荷尔蒙通路可能由自己启动，但路径的引导却早已嵌入某种“更像女性”的社会剧本之中。而正是在这里，“自由”变得暧昧不清。我们是否真的在见证性别规范的松动？还是，只是从一个由阳刚气质主导的系统，悄然转向了另一个由“理想女性化”景观消费符号绑架的秩序？是否真的选择了“成为自己”？还是，只是被更隐秘的欲望、算法和审美规范所选择？“成为谁”，当然是个体的权利。但这个“谁”是否经过真正的思辨与体验？还是只是某个视觉模板的套版拷贝？“做自己”，当然值得尊重。但如果这个“自我”，只是由点赞算法构建，由封闭社群反复复制，又是否真的“属于自己”？“谁的身体，谁的疆域？”这不是一个能轻易回答的问题。但它必须被提出。尤其是在这个儿童节，当我们讨论那些用裙子、用激素、用表演去探索“成为谁”的少年时，我们不能只有赞美与恐慌，不能只有自由与规训的二元对立，我们更需要意识到：这不仅仅是孩子们自己的事情。它拷问着我们的教育体系是否提供了足够多元和包容的性别认知资源；拷问着我们的社会文化是否能容纳超越二元对立的性别表达；拷问着数字平台在追求流量的同时，应如何承担起对未成年人健康成长的责任。问题并非“他们为什么这样”，而是我们，是否真正给予过他们别的可能性。在拟象的狂欢与身体的政治之间，我们仍有太多需要追问与聆听。这些游移在性别与身体之间的少年，他们的故事，关乎的不仅是他们自己，更是我们共同的未来，以及我们希望为下一代塑造一个怎样的“身份疆域”。旅程至此，思绪纷飞，言犹未尽，感谢阅读。"
  },
  {
    "title": "浅谈ChatGPT的记忆实现机制 兼论工程端记忆设计",
    "summary": "要想研究ChatGPT这个产品的“记忆”功能实现机制，我们就必须要从大模型本身的“记忆”到底是个什么东西开始说起。在我们的传统的，人类视角的认知里，“记忆”意味着信息的持久储存和可随时调用，但这一常识在神经网络中往往并不成立。大语言模型（LLM）本身其实并不具备“记住某个具体事实”或“反复调用某段对话”的内建机制 。它们所谓的“记忆”，更多体现在参数记忆 的层面——即通过反复训练，将大量的语料信息",
    "tags": [
      "模型考古学"
    ],
    "url": "/posts/TechnicalTutorials/chatgpt-memory-system-breakdown/",
    "date": "2025-05-25T00:00:00.000Z",
    "content": "要想研究ChatGPT这个产品的“记忆”功能实现机制，我们就必须要从大模型本身的“记忆”到底是个什么东西开始说起。在我们的传统的，人类视角的认知里，“记忆”意味着信息的持久储存和可随时调用，但这一常识在神经网络中往往并不成立。大语言模型（LLM）本身其实并不具备“记住某个具体事实”或“反复调用某段对话”的内建机制 。它们所谓的“记忆”，更多体现在参数记忆 的层面——即通过反复训练，将大量的语料信息固化在数百亿甚至万亿级的参数中，从而形成一种对语言结构、事实知识乃至人类行为模式的“潜在记忆”。虽然这种参数记忆赋予了大模型前所未有的知识广度，但其本身的信息管理是静态的，只能反映训练阶段所接触到的信息，无法根据用户的即时输入动态调整，也无法在多轮对话之间保持状态。这也意味着，大模型在默认状态下是无记忆、无连续性的。为了让用户在使用中获得“ChatGPT 记得我说过什么”的体验，系统必须引入额外的机制来补全这种能力的缺失。最直接的方式，便是上下文管理（context management）。所谓上下文管理，是指在一次交互过程中，将用户与模型之间的多轮对话，打包成一个“对话上下文窗口”（context window）一并输入模型，从而模拟出“记得过去对话”的效果。这种机制并非模型主动“记住”了内容，而是每一次调用模型时都“重新喂给它过去发生的事情”。这也是为什么很多初次使用大模型api的用户会惊讶为啥每一轮对话所耗费的额度会呈现滚雪球式增长，因为如果你不限制上下文总窗口和轮数的话，系统需要在每一次请求中携带之前的全部对话内容，自然而然就会账单爆炸了。上下文管理是目前 LLM 实现短期记忆的核心方法，但它也存在明显的限制：窗口大小有限（目前主流模型支持的最大上下文为128k tokens），每次输入的上下文越长，推理成本也越高；同时它无法实现真正的“长期记忆”——例如跨会话的状态保留、用户偏好的追踪、个人资料的学习等。这就引出了 ChatGPT 的另一个核心设计：用户级的“记忆系统”。为了给用户更好的，更智能、温情的对话体验，这个系统试图实现的是对用户信息的持久存储与调取，补上“上下文窗口”无法承担的那部分“跨会话记忆”。但它不是模型本身的能力，而是产品层的一项“外挂功能”，通过在后端数据库中记录“用户告诉过模型的信息”，并在合适的时候动态注入这些内容到上下文中，从而模拟出模型“记得你”的效果。在下文中，我们将围绕 ChatGPT 的这一“类人记忆”系统展开分析，探讨其设计原则、实现逻辑与当前的能力边界。一、发展演进梳理我们可以通过下面这张表格来来一窥ChatGPT记忆系统的演进：| 日期/时期  | 功能/更新     | 核心功能               | 用户层级               | 关键用户控制方式                  |\n| ---------- | ------------- | ---------------------- | ---------------------- | ----------------------------- |\n| 2024年之前    | 仅上下文窗口        | 会话内回忆，受限于tokens数量      | 所有用户                   | 除提示工程外基本无                     |\n| 2024年早期    | 自定义指令         | 用户定义的持久性指南             | 所有用户                   | 管理自定义指令                       |\n| 2025年4月之前  | “已保存的记忆” (显式) | 用户明确告知的事实性信息存储         | Plus, Pro, 免费版 (仅限此功能) | 查看/删除已保存的记忆                   |\n| 2025年4月10日 | “聊天历史”参考 (隐式) | 自动从所有过去聊天中提取洞察以供回忆     | Plus, Pro              | 切换“已保存的记忆”/“聊天历史”开关，临时聊天，存档聊天 |\n| 2025年4月之后  | 双重记忆系统        | 结合显式用户指令和隐式AI学习的综合回忆机制 | Plus, Pro              | 同上，并可询问“你记得关于我的什么？”           |2025年4月10日，OpenAI宣布，ChatGPT现在可以参考用户所有的过去聊天记录，以提供更加个性化和相关的回应。官方通过@OpenAI和萨姆·阿尔特曼的推文发布了这一消息 ，并在FAQ文档中提供了更多细节 。萨姆·阿尔特曼称之为一项“出人意料的强大功能”，并指出它预示着“AI系统将在你的一生中了解你，并变得极其有用和个性化” 。这一变革使得ChatGPT从主要依赖显式指令或会话内上下文，转变为一个能够基于用户全部互动历史持续学习和自我定制的模型 。更新后，ChatGPT的记忆系统以双重方式运行：“已保存的记忆” (Saved Memories)：用户明确要求ChatGPT记住的细节（例如，“记住我是素食主义者”）。这可视为先前显式记忆系统的演进。“聊天历史”参考 (Chat History Reference)：ChatGPT从过去的对话中自动收集洞察，以改进未来的互动，即使这些信息未被明确保存。这是更新、更全面的记忆层。 OpenAI建议用户将关键信息通过“已保存的记忆”功能来固定，因为“聊天历史”并非逐字记录所有细节，而是综合提炼洞察。底层机制既然是 OpenAI 出品的功能，其实现方式自然不可能像早期开源项目那样简单粗暴——例如直接将上下文丢进向量数据库，待用时再暴力召回。相比之下，OpenAI 构建了一个由系统自动维护的动态用户画像机制，并在每次新对话开始时，将相关信息注入到系统提示中，以实现类人“长期记忆”的体验。Model Set Context (模型设定上下文)：包含用户明确“保存的记忆”，并附有时间戳。例如：“1. [2025-05-02]. 用户喜欢冰淇淋和饼干。”Assistant Response Preferences (助手回应偏好)：基于过去互动风格，指示ChatGPT应如何组织其回应。例如，用户可能偏好XML、JSON等结构化格式。此部分通常带有一个Confidence (置信度)标签 。Notable Past Conversation Topic Highlights (过往对话主题重点)：记录了以往对话中的高级别主题摘要，以保持未来讨论的连续性。例如，用户对AI漏洞或脚本编写的兴趣。此部分也包含Confidence标签 。Helpful User Insights (有用的用户洞察)：聚合了关于用户的具体事实信息，如姓名、职业、研究兴趣、博客地址等。Recent Conversation Content (近期对话内容)：存储数量有限（约40条）的近期聊天摘要，包含用户输入的消息，但不包括AI的回应，这可能是为了控制数据量和降低注入风险。时间戳的详细程度随对话的新近度而变化。User Interaction Metadata (用户互动元数据)：自动生成的账户使用信息，包括不同模型使用比例、账户年龄、设备类型、平均对话深度、常用意图标签（intent_tags）以及 UI 偏好等。ChatGPT 会在持续使用中逐步形成对用户的抽象性理解与偏好建模。当用户输入新的请求时，模型并不会“无脑加载”所有历史内容，而是通过一系列筛选和匹配算法，挑选与当前上下文最相关的信息注入提示中。对于用户保存的记忆条目，系统采用语义索引机制，在嵌入向量空间中计算相关性，通常会检索出最相关的 5 到 20 条数据，用于增强模型当前的应答能力。接下来，我将展示一份经过去敏处理的 ChatGPT 老用户档案（序号对不上是我删了那个条目），帮助大家直观了解这一用户画像系统究竟是如何“描绘”用户的。1.模型设定上下文与助手回应偏好{\n  \"Model Set Context\": {\n    \"1\": \"用户在论文写作中常用的统计学软件是Stata，编程语言是Python。\",\n    \"2\": \"在未来帮助用户调试代码时，需要指出具体需要修改的地方，而不是提供整个项目代码。\",\n    \"3\": \"用户有一个GitHub仓库的上游仓库是DIYgod/RSSHub。\",\n    \"4\": \"用户这周准备把谢林的近代哲学史看完。\",\n    \"5\": \"用户制作日语五十音Anki卡片，使用拼音表示假名发音。\",\n    \"6\": \"用户喜欢太空策略游戏《群星》。\",\n    \"7\": \"请记住，要用中文回复用户的问题。\",\n    \"9\": \"用户最近在看ARK Invest的《The Big Ideas》研报，对其中的区块链方面特别感兴趣。\",\n    \"11\": \"用户计划为自己的博客开设一个新系列，名为「暗涌」，主要侧重于创投领域的专业分析。\",\n    \"13\": \"用户现在居住在某城市。\",\n    \"14\": \"用户想写一篇关于「美联储政策工具与美国宏观经济指标解读」的博客。\",\n    \"15\": \"用户在加密货币市场主要关注超买和超卖指标。\",\n    \"17\": \"用户喜欢咖啡。\",\n    \"22\": \"用户希望博客的文章链接格式为  目录下，后缀形式类似于 ai-and-deep-learning/tech-review-openai-o3/，即分类+子分类+文章slug 的路径结构。\",\n  \"Assistant Response Preferences\": {\n    \"1\": \"用户倾向于结构化但具对话性的语气，常要求在金融、AI和经济主题上平衡清晰与深度。\",\n    \"2\": \"用户经常润色和迭代内容，尤其是在技术或报告写作时非常注重精准性。\",\n    \"3\": \"用户在探讨 AI 架构、金融建模等主题时喜欢深入技术细节，但在一般事实查询时更偏好简洁总结。\",\n    \"4\": \"用户在讨论理论时重视其实际应用，常追问其在市场、投资等情境下的运用。\",\n    \"5\": \"用户喜欢互动和迭代的交流，不偏好长篇独白，除非主题要求深入探索。\",\n    \"6\": \"用户有时喜欢轻松风格，但即使在非正式场合也期待有见地的回应。\",\n    \"7\": \"用户偏好实用、以研究为基础的视角，倾向质疑过于泛泛的说法。\",\n    \"8\": \"用户在处理技术文档、金融分析等密集内容时喜欢带有标题或编号的条理清晰的信息。\",\n    \"9\": \"用户在探讨 Web3、区块链等趋势时表现出怀疑，倾向质疑其真实影响力。\",\n    \"10\": \"在故障排查或自动化建议中，用户偏好直接执行路径，而不是抽象理论。\"\n  }\n}2.过往对话主题重点  \"Notable Past Conversation Topic Highlights\": \"略，为后续添加。\",\n\": {\n    \"1\": \"在2025年2月至3月的对话中，用户讨论并分析了大型语言模型，尤其是 DeepSeek V3 和 R1。他们特别关注如多Token预测（MTP）、多头潜在注意力（MLA）和专家混合（MoE）等技术。用户还探讨了FP8训练和混合注意力机制等优化方法，以提升长上下文处理能力。同时还分析了强化学习驱动的模型微调（如DS R1）以及监督微调（SFT）阶段与RL微调方法的区别。\",\n    \"2\": \"信息被隐去\",\n    \"3\": \"在2025年初，用户深入研究了RAG（Retrieval-Augmented Generation）技术，撰写了一篇详尽博客，解释其在提升LLM检索能力中的作用。他们探索了融合检索与生成的架构以提高准确率，包括微软的GraphRAG，并研究了知识检索管线与向量搜索优化。重点在于实际应用和处理长尾查询、保持事实准确性的效率提升。\",\n    \"4\": \"2025年2月至3月期间，用户研究了金融风险分析，尤其是VaR（在险价值）、历史模拟技术与组合层面的金融预测。他们将统计与机器学习模型应用于资产定价，并讨论了用于比特币价格预测的时间序列方法，还探讨了美联储政策工具如何影响宏观经济指标。\",\n    \"5\": \"用户对ARK Invest的《Big Ideas 2025》报告进行了深入分析，聚焦AI、自动物流、生物科技、机器人与能源转型等投资主题。他们详细讨论了AI驱动的自动化，包括AI代理、决策系统与云端基础设施，认为核能可能成为满足AI推理需求的可行能源解决方案。其评论聚焦于战略投资影响与宏观经济趋势。\"\n  }\n}3.有用的用户洞察  \"Helpful User Insights\": {\n    \"1\": \"用户的学校和职业（已隐去）\",\n    \"2\": \"用户最近的工作历程（已隐去）\",\n    \"3\": \"用户对金融市场、投资和宏观经济非常感兴趣。\",\n    \"4\": \"用户正在撰写一个系列博客，聚焦于金融与技术主题，尤其是投资策略、宏观经济趋势和AI应用。\",\n    \"5\": \"用户具备技术背景与AI应用实践经验，尤其是Python编程，曾开发投资相关自动化工具和区块链金融应用。\",\n    \"6\": \"内容已隐去\",\n    \"7\": \"用户积极研究先进AI模型与Transformer架构，尤其关注如RAG、MLA、MoE等优化技术，并撰写相关技术文档。\",\n    \"8\": \"用户熟练掌握多种编程语言，尤其是Python，并具备机器学习、数据库管理与API集成经验。\",\n    \"9\": \"用户对哲学，特别是形而上学与德国观念论（如莱布尼茨与斯宾诺莎）有浓厚兴趣。\",\n    \"10\": \"用户是资深游戏玩家，喜欢《原神》和《群星》等策略与幻想类游戏。（这里是因为我每次都喜欢问如何评价原神来测试模型的回复策略）\"\n  }\n}4.用户交互元数据  \"User Interaction Metadata\": {\n    \"1\": \"系统检测到用户当前所在地区为美国（可能因使用VPN不准确）\",\n    \"2\": \"在过去的对话中，有28%使用了gpt-4o，1%使用了gpt-4-5，21%使用了o3，43%使用了gpt4t_1_v4_mm_0116等其他模型。\",\n    \"3\": \"用户平均消息长度为1410.9个字符。\",\n    \"4\": \"在最近的742条消息中，18%为other_specific_info类话题（135条），14%为分析图像（104条），11%为文本编辑/润色请求（80条）；其中142条交互质量为高（19%），28条交互质量为低（4%）。\",\n    \"5\": \"用户目前为ChatGPT Plus订阅用户。\",\n    \"6\": \"用户目前通过安卓设备的ChatGPT原生App与模型交互。\",\n    \"7\": \"用户当前的User Agent为：ChatGPT/1.2025.126 (Android 15; 24129PN74C; build 2512605)。\",\n    \"8\": \"用户在过去1天内活跃1天，过去7天内活跃6天，过去30天内活跃17天。\",\n    \"9\": \"用户账户注册时间为52周。\",\n    \"10\": \"用户平均对话深度为3.0。\"\n  }\n}5.近期对话内容{\n  \"Model Set Context\": { ... },\n  \"Assistant Response Preferences\": { ... },\n  \"Notable Past Conversation Topic Highlights\": { ... },\n  \"Helpful User Insights\": { ... },\n  \"User Interaction Metadata\": { ... },\n  \"Recent Conversation Content\": {\n    \"1\": \"用户于2025年5月25日请求翻译并以 JSON 格式组织其 ChatGPT 用户档案结构，包括模型设定上下文与响应偏好等模块。\",\n    \"2\": \"用户在5月24日前后连续开展「内容已隐去」工作\",\n    \"3\": \"在5月21日前后，用户探讨了「内容已隐去」\",\n    \"4\": \"5月18日至20日之间，用户撰写多篇关于「内容已隐去」\",\n    \"5\": \"用户在5月17日开展多个技术类话题的问答，包括「内容已隐去」等。\",\n    \"6\": \"5月中旬，用户持续开发「内容已隐去」\",\n    \"7\": \"用户在5月初深入探讨了「内容已隐去」\",\n    \"8\": \"用户使用了图像输入功能，多次请求对枪械、药品包装等照片进行识别和背景分析。\",\n    \"9\": \"用户自5月以来显著提升互动深度，从设定请求延伸至脚本编写、数据可视化、技术部署流程全链条。\"\n  }\n}二、简单的设计机制总结在前面我们已经大致知道了 ChatGPT 的“记忆”到底是什么东西，它不是真的在记忆，而是一种系统层面的语义增强机制。那么，这套机制到底是怎么运行的？1.“记忆”不是模型本体的能力，而是外挂首先要明确一点：大语言模型本身是无记忆的。所谓的“记忆”，并不是模型内部参数的更新或状态的延续，而是通过系统层主动注入提示（prompt injection）来模拟一种“持续了解你”的效果。从架构上看，整个记忆系统被设计为模型调用流程的外围外挂（wrapper）模块，主要负责两件事：用户画像构建：后台系统持续从对话中提取信息，形成“你是谁、你关心什么、你喜欢什么”的多维度抽象。上下文注入：在你每次发起请求时，从这些画像中提取出与当前任务最相关的几条提示信息，合并进提示词中，然后统一交给模型处理。所以，ChatGPT 能“记得你喜欢咖啡”，不是因为它记住了这个事实，而是因为系统每次都在偷偷提醒它：“这位用户喜欢咖啡”。这也是为什么模型的行为会随着你关闭/开启记忆开关而发生显著变化——你改变的不是模型的记忆，而是系统是否允许插入这些提示。2.核心模块一览OpenAI 当前使用的是一种分层式的用户状态注入系统，这套系统目前大致由以下六种模块组成：| 模块名称 | 功能描述 | 是否用户可见 | 是否可编辑 |\n| --- | --- | --- | --- |\n| Model Set Context | 显式保存的个人事实（例如“我是xx工程师”） | ✅ 是 | ✅ 是 |\n| Assistant Response Preferences | 模型应采用的回应风格、技术细节控制（如偏好结构化输出） | ❌ 否 | ❌ 否 |\n| Notable Past Conversation Topic Highlights | 你经常聊的主题摘要（如“RAG”、“金融市场”） | ❌ 否 | ❌ 否 |\n| Helpful User Insights | 系统推导出的事实性描述（如“用户熟练掌握Python”） | ❌ 否 | ❌ 否 |\n| Recent Conversation Content | 最近的聊天摘要（40条以内） | ❌ 否 | ❌ 否 |\n| User Interaction Metadata | 账户行为数据（如设备、模型使用比例） | ❌ 否 | ❌ 否 |其中，只有最上面一项 Model Set Context 是真正对用户开放管理的，其余部分全部隐藏在系统层，由模型和后台服务自动维护与调用。用户每次和 ChatGPT 对话时，系统在背后会挑选出若干“你曾说过”、“你可能想要”、“你经常关注”的内容，然后偷偷塞进提示中。这个过程通常会提取 5～20 条信息片段，并在每一轮请求中动态调整，构成一种“临时记忆拼贴”。3.记忆不是简单储存，而是语义压缩与匹配与我们直觉上的“记忆 = 存信息”不同，ChatGPT 的记忆设计是一种语义压缩与动态召回机制，更类似于以下过程：用户长期对话内容进入嵌入向量空间；系统将这些内容抽象为低维语义向量（embedding）；当前请求被编码为新的向量后，与历史语义向量进行相似度计算；匹配到的“最相关历史内容”被提取、结构化并注入提示词中；最终模型获得一个“仿佛记住你”的输入结构。这比暴力查找更高效，也更灵活，因为它支持语义模糊匹配、上下文重构与用户偏好迁移（即使你换了说法，系统也能识别你在说同一个东西）。也正因如此，ChatGPT 的“记忆”并不总是准确复述，而是常常表现为“理解你的倾向”。它不是存档式记忆，而是“反应式记忆”。4.记忆并不全依赖你“说了什么”用户画像的形成不依赖你明确说了什么、写了什么，而是系统主动从语义层进行归纳。举个例子：你问：“帮我写一份针对区块链创业项目的投资人路演PPT”系统可能会自动得出：你从事或感兴趣的领域：加密市场 / 创投你具备一定技术与财务建模能力你倾向使用结构化、输出导向型语言这一条“Helpful Insight”就被加入到你的用户画像中，尽管你从没明确告诉过模型这些事。也就是说，ChatGPT 不是在等你喂信息，而是在暗中提取你每一句话的“上下文后设含义”。ChatGPT 的记忆系统其实不是在存你说过什么，而是在逐步构建一个与你高度重合的人格镜像（persona）：  它知道你怎么说话、说什么话题、用什么结构、在意哪些细节——然后在你发起下次对话时，加载一个“定制版的你”来与之对应。这意味着：每个用户看到的 ChatGPT，其实都是不同的“你版本”所触发的 ChatGPT。模型始终是同一个模型，但你和我眼中的 ChatGPT，很可能拥有完全不同的“人格面具”。三、实践中我们为什么需要模型记忆，及如何实现记忆从工程的角度，ChatGPT的记忆机制固然非常精妙，但我们也不应陷入某种误区：以为只有 OpenAI 那样的“高精度用户画像”才叫记忆。我们最终需要的应是一个权衡了系统复杂度、运行速度、成本三者之后的，可以工程落地的系统。在实践中，大模型“记忆”机制的设计目标，可以拆解为三个层次：1.最基本的：上下文维护这也是目前绝大多数chatbot应用场景中所使用的做法——依靠模型的 context window，把前几轮对话作为输入拼接进去。优点是简单直接、实现成本低，不涉及长期存储或用户画像系统；缺点也显而易见：上下文长度有限（尤其在不使用长上下文模型时）无法跨会话使用，关掉网页就“失忆”模型在响应中不会有“我记得你”的个性化表现这更像是一种假装有记忆，而非真正的“记忆机制”，当然，其实这种模式在目前绝大多数chatbot场景中都是够用的。2.中间形态：模糊语义记忆在这一级，系统开始主动做一些“用户偏好”或“历史行为”的抽象归纳，构建一个轻量、模糊、非结构化的长期记忆机制。典型实现方式包括：将用户对话摘要后存入向量数据库（如FAISS、Weaviate）维护标签系统（如“Python 用户”、“偏好 markdown 输出”）引入 session id 或 user id 作为索引，对当前请求语义进行 recall这类“记忆”是可扩展的、弱绑定的、具模糊召回能力的，尤其适合如AI客服，用户推荐系统，和那种轻量知识增强（如上下文补全型代码助手）等场景。在这个视角下，ai 并不试图准确记住你说过的每句话，而是尽可能提取你的行为特征，在你发起下一个请求时，用模糊而贴近的“印象”来提升模型的回应质量。3.高精度记忆：结构化+动态注入这也就是OpenAI目前所采用的模式。显式保存的用户设定（如模型设定上下文）隐式提取的行为洞察（如 topic highlights, insights）响应风格控制（Assistant Preferences）自动语义相似度计算与动态提示注入（Embedding-based Memory Routing）优点是：用户个性化程度高，响应质量贴近用户意图能长期积累用户资料并自我优化可拓展为插件调用、工作流调度、agent人格等更高阶能力但它也有代价：用户看不到的那部分“记忆”变成了不可控的灰盒结构需要配套一整套后台服务来做状态管理、embedding存储与匹配极大提高了系统工程复杂度与维护成本这类设计适合的，是构建长期陪伴型智能体、个人AI助手、或大规模用户多轮交互平台。未来各家的主流ai助手软件大概率都会走这条路。我自己也实现过一套“猴版”的长期记忆系统。整体思路是：每当对话进行到第十五轮，就调用一次 Gemini Flash，从当前对话中抽取潜在需要记住的信息，并为每条内容分配一个优先级权重，存入一个 JSON 文件中。这些记忆条目会根据优先级逐渐被“遗忘”或更新。每次新对话开始时，系统会从中选取 5 条——最近更新的、优先级最高的、并加入一定随机性——插入到上下文中，从而模拟出一种简易的长期记忆效果。这个方案不依赖任何 embedding 模型或向量数据库，纯靠 prompt 操作和权重管理维持运行。虽然很猴版，但实际使用体验也还算凑合，能在不少轻量场景下跑得起来。真的，我觉得大道至简，大家扪心自问一下其实绝大多数chatbot场景用哥们上面那套用法是完全可行的，效果也未必会输给那些无脑塞向量数据库的记忆方案，整体系统复杂度也低好修改"
  },
  {
    "title": "《债务危机》书评&笔记",
    "summary": "瑞·达利欧作为桥水基金的创始人，几十年来以宏观对冲策略闻名。为纪念2008年金融危机十周年，他系统整理了自己研究和应对债务危机的框架与案例，希望用“规律战胜恐慌”，帮助政策制定者与投资者更有条理地识别、化解下一场危机。达利欧认为，经济就像一台机器，虽然复杂，但其运行逻辑是可以被理解的。债务，作为这台机器中的一个关键齿轮，其累积和清算过程形成了周期性的波动，即债务周期。他区分了短期债务周期（通常称为",
    "tags": [
      "书评"
    ],
    "url": "/posts/Finance and Economics/review-ray-dalio-debt-crisis/",
    "date": "2025-05-24T00:00:00.000Z",
    "content": "瑞·达利欧作为桥水基金的创始人，几十年来以宏观对冲策略闻名。为纪念2008年金融危机十周年，他系统整理了自己研究和应对债务危机的框架与案例，希望用“规律战胜恐慌”，帮助政策制定者与投资者更有条理地识别、化解下一场危机。达利欧认为，经济就像一台机器，虽然复杂，但其运行逻辑是可以被理解的。债务，作为这台机器中的一个关键齿轮，其累积和清算过程形成了周期性的波动，即债务周期。他区分了短期债务周期（通常称为商业周期，持续约5-10年）和长期债务周期（持续约50-75年）。当长期债务周期达到顶点并逆转时，往往会爆发大规模的债务危机，对经济、社会乃至政治格局产生深远影响。本书的核心贡献在于：建立了一个“原型”或“模板” ：通过对48个历史案例的量化分析，达利欧发现不同国家、不同时期的债务危机尽管细节各异，但在宏观层面展现出惊人相似的演进模式和因果关系。这个模板帮助我们识别危机所处的阶段、关键的转折点以及可能发生的事件。区分了两种主要危机类型：通缩性萧条：通常发生在债务主要以本国货币计价，且该国拥有储备货币地位或强大经济实力的国家。决策者有能力通过“印钞”等货币政策来应对。通胀性萧条：通常发生在债务（尤其是外债）以外币计价，或本国货币不被信任的国家。决策者“印钞”只会加剧资本外流和货币贬值，导致恶性通胀。总结了应对危机的关键原则：基于历史经验，达利欧为政策制定者、投资者和普通人提供了在债务危机不同阶段应该如何行动的指导原则。他特别强调了“和谐的去杠杆化”的重要性，即通过政策组合拳（财政紧缩、债务重组、财富转移和货币创造）来平稳度过危机，避免极端通缩或恶性通胀。达利欧的研究方法是独特的：他不仅进行定性描述，更重要的是进行了大量的量化分析，追踪各种经济指标（债务水平、偿债比率、资产价格、利率、货币供应量、通胀率、经济增长率等）在危机前、中、后的动态变化，从而使他的结论更具说服力和可操作性。债务周期阶段一：周期早期——欣欣向荣与债务的良性增长特征：经济从上一次去杠杆化（或萧条）中复苏，信心逐步恢复。债务增长与收入增长大致同步，甚至略快于收入增长，但债务主要用于支持生产性投资，提高生产力。资产价格温和上涨，投资回报率良好。利率通常处于较低水平，信贷环境相对宽松但不过度。人们对未来的预期乐观，但尚未达到非理性亢奋的程度。驱动因素：生产力的提高是根本驱动力。信贷的合理扩张为经济活动提供了润滑剂。政策制定者通常采取支持性或中性的政策。举例：美国二战后的50年代和60年代初，经济快速增长，家庭和企业债务随之增加，但整体健康。中国加入WTO后的最初几年，出口和投资驱动经济高速增长，债务水平开始上升，但主要投向基础设施和制造业，带来了生产力的巨大提升。关键点：在这个阶段，债务是“好”的，因为它促进了经济增长和财富创造。问题在于，持续的繁荣容易让人忘记风险，为下一阶段的过度行为埋下伏笔。达利欧提醒，“不要让债务的增长速度快于收入的增长速度，也不要让收入的增长速度快于生产率的增长速度”，这是保持经济健康的关键。阶段二：泡沫时期——非理性繁荣与债务的恶性膨胀特征：债务增长远超收入增长：这是泡沫的最核心特征。人们借入越来越多的钱用于消费和投机，而不是生产性投资。资产价格急剧上涨，远超基本面：股票、房地产等资产价格被推至不可持续的高位，形成“庞氏融资”现象（即依赖资产价格持续上涨来偿还债务或再融资）。过度乐观和投机盛行：“这次不一样”、“只会涨不会跌”的论调充斥市场。新手投资者大量涌入，寻求快速致富。信贷标准显著放松：银行和金融机构为了追逐利润，降低贷款门槛，发明复杂的金融衍生品，进一步放大杠杆。经常账户赤字扩大（对于某些国家）：国内消费和投资需求旺盛，导致进口增加，可能依赖外国资本流入来弥补。央行开始收紧货币政策：为了抑制过热的经济和通胀压力，央行通常会提高利率或收紧信贷。这是泡沫走向破裂的关键催化剂。识别泡沫的信号（达利欧总结的七个典型特征）：资产价格相对于传统估值指标（如市盈率、租售比）处于高位。市场预期资产价格会继续快速上涨（普遍看涨情绪）。存在广泛的杠杆买入行为。买家提前购买（远期购买或囤积）以防价格上涨或避免错失机会。新买家（以前未参与市场的人）大量进入市场。刺激性的货币政策助长了泡沫（例如，低利率）。经济存在脆弱性，容易受到紧缩政策的冲击。举例：美国2000年代中期的房地产泡沫：低利率、宽松的信贷标准（如次级抵押贷款、NINJA贷款——无收入、无工作、无资产贷款）、金融创新（CDOs, MBS）共同催生了房价的非理性上涨。人们相信房价只会涨，大量借贷购买房产，甚至进行投机。日本1980年代末的资产泡沫：“广场协议”后日元大幅升值，日本央行维持低利率，导致过剩流动性涌入股市和房地产市场。东京银座的土地价格一度高到可以买下整个加州。1920年代末的美国股市泡沫（咆哮的二十年代）：保证金交易（高杠杆）盛行，无线电、汽车等新兴产业股票受到狂热追捧。关键点：泡沫阶段是不可持续的。债务的过度累积使得经济对利率和流动性变得高度敏感。央行的紧缩政策，即使是温和的，也可能成为刺破泡沫的最后一根稻草。阶段三：顶部/转折点——盛极而衰特征：央行持续收紧货币政策：利率上升到一定程度，开始对经济活动和资产价格产生抑制作用。偿债成本上升，现金流压力增大：对于高杠杆的个人、企业和金融机构，利息支出增加，可支配收入减少，再融资变得困难。资产价格开始见顶回落：最初可能只是小幅回调或停滞不前，但足以动摇市场信心。经济增长放缓：早期可能是“软着陆”的迹象，但如果债务问题严重，很快会演变成更剧烈的下滑。信贷市场开始出现裂痕：风险较高的借款人首先出现违约，金融机构开始收紧信贷标准。“明斯基时刻”临近：当资产价格下跌导致抵押品价值不足，或现金流无法覆盖债务支出时，借款人被迫抛售资产以偿还债务，形成恶性循环。驱动因素：货币政策的滞后效应显现。市场情绪从极度乐观转向谨慎甚至恐慌。债务负担变得难以承受。举例：美国2007年：美联储从2004年开始持续加息，联邦基金利率从1%升至5.25%。房价从2006年开始见顶回落，次贷危机开始显现（如2007年贝尔斯登旗下两只对冲基金倒闭）。日本1989年底：日本央行开始快速加息，并对房地产贷款进行窗口指导（行政限制）。股市在1989年底达到顶峰后开始暴跌。美国1929年夏季：美联储为抑制投机而提高利率，股市在高位震荡，最终在10月崩盘（黑色星期二）。关键点：顶部的识别往往是滞后的。在当时，很难区分是正常调整还是大危机的开端。但达利欧的模板显示，当债务水平极高、资产价格泡沫化、央行持续紧缩时，发生严重危机的风险显著增加。阶段四：萧条/去杠杆化——痛苦的债务出清这是债务周期的核心和最痛苦的阶段。当债务泡沫破裂，资产价格暴跌，信贷枯竭，经济活动急剧萎缩，就进入了萧条期。去杠杆化是降低债务与收入比率的过程，通常通过以下一种或多种方式实现（达利欧称之为“四种不和谐的去杠杆化方式”）：债务减记/违约：债务人无法偿还债务，债权人被迫接受损失。这会破坏财富，打击信心。财政紧缩/减少支出：政府和私人部门削减开支，试图“勒紧裤腰带”还债。但这会导致总需求下降，加剧经济萎缩，反而可能使债务/收入比率恶化（分母下降更快）。财富从富人向穷人转移：通过对富人增税等方式，将财富转移给受危机冲击更严重的群体，或用于支持经济。这在政治上往往难以实施。债务货币化/“印钞”：央行购买政府债券或直接向经济注入流动性，以减轻债务负担、刺激通胀（从而降低实际债务价值）和支持经济活动。这是后面“和谐的去杠杆化”的关键工具。在萧条的早期阶段，通常以前三者为主，尤其是财政紧缩和债务违约。特征：资产价格暴跌：股票、房地产等价格急剧缩水，导致负财富效应。信贷市场冻结：银行惜贷，企业和个人融资困难，流动性枯竭。企业大规模破产，失业率飙升：需求萎缩，企业倒闭，工人失业。经济活动急剧萎缩 (GDP大幅下降)。通货紧缩压力巨大（在通缩性萧条中）：物价下跌，企业利润减少，实际债务负担加重。社会动荡和政治风险上升：民众不满情绪增加，可能导致政治变革。举例：美国1929-1933年（大萧条初期）：股市暴跌80%以上，数千家银行倒闭，失业率高达25%，GDP缩水近30%，物价大幅下跌。胡佛政府最初采取了平衡预算和紧缩政策，加剧了危机。日本1990年代（失去的十年）：资产泡沫破裂后，日本陷入长期的经济停滞和温和通缩。银行坏账堆积如山，企业忙于修复资产负债表而非投资。2008-2009年全球金融危机初期：雷曼兄弟倒闭引发全球信贷市场冻结，股市暴跌，全球经济陷入同步衰退。关键点：萧条的痛苦程度和持续时间，很大程度上取决于政策制定者如何应对。如果仅仅依靠紧缩和等待市场自行出清，过程会非常漫长且破坏性巨大。达利欧强调，此时需要果断和创新的政策干预。阶段五：“和谐的去杠杆化”——政策的艺术当萧条发展到一定程度，政策制定者（主要是央行和政府）意识到仅靠传统方法无法解决问题时，他们通常会采取更激进的措施，尤其是“印钞”（债务货币化）。“和谐的去杠杆化”是指政策制定者巧妙地组合运用四种去杠杆工具，使得名义GDP增长率略高于名义利率，从而在不引发恶性通胀或过度社会痛苦的前提下，逐步降低债务/收入比率。核心要素：大量的货币创造（“印钞”或量化宽松QE）：央行购买资产（通常是国债和抵押支持证券），向金融体系注入流动性，压低长期利率，抵消通缩压力，刺激信贷和投资。这是最重要的工具。债务重组和有序违约：对不可持续的债务进行减记或重组，减轻债务人负担。例如，对银行进行救助和资本重组，对抵押贷款进行修改。财政刺激：政府增加支出或减税，以弥补私人部门需求的不足。这通常与央行的货币化操作相结合（即央行购买政府发行的债券）。容忍一定的通货膨胀：温和的通胀有助于减轻实际债务负担，并刺激人们消费和投资，而不是持有现金。保持经济活动和就业：政策目标是减轻痛苦，避免社会动荡，为经济复苏创造条件。特征：名义GDP增长开始超过名义利率：这是去杠杆成功的关键信号。债务负担相对于收入开始减轻。通缩压力缓解，甚至出现温和通胀。资产价格（尤其是风险资产如股票）开始反弹：反映了流动性的改善和对未来的信心恢复。信贷市场逐步解冻。经济缓慢复苏，失业率开始下降。举例：美国罗斯福新政（1933年之后）：放弃金本位，美元贬值（变相“印钞”），实施银行假日整顿金融体系，成立联邦存款保险公司（FDIC）恢复信心，推行大规模公共工程（如田纳西河流域管理局）刺激就业和需求。这些措施成功地将美国从大萧条的深渊中拉了回来。美国应对2008年危机：美联储迅速将利率降至零附近（ZIRP），并推出了多轮量化宽松（QE1, QE2, QE3），大规模购买国债和MBS。政府实施了TARP计划救助金融机构，并通过财政刺激法案。这些措施避免了更大规模的萧条，实现了较为“和谐”的去杠杆（尽管也带来了贫富差距扩大等副作用）。关键点：“和谐的去杠杆化”是一项极具挑战性的平衡艺术。印钞太少，无法抵消通缩压力，经济难以复苏；印钞太多，则可能引发恶性通胀（尤其是在非储备货币国家或债务以外币计价的国家）。政策制定者需要密切关注市场信号，灵活调整政策组合。达利欧认为，拥有储备货币地位的国家（如美国）在实施“印钞”时有更大的空间。阶段六：正常化/推绳子效应/再通胀在“和谐的去杠杆化”之后，经济逐步恢复正常。特征：债务/收入比率降至可持续水平。经济恢复温和增长，通胀保持在可控范围内。利率可能在较长时间内保持低位：因为经济复苏初期仍然脆弱，央行不敢过早收紧。这可能导致所谓的“推绳子效应”（Pushing on a String），即货币政策对刺激经济的效果减弱，因为利率已经很低，企业和个人可能因前景不明朗或债务负担仍重而不愿借贷和投资。资产价格可能再次上涨，但驱动因素更多是基本面改善和流动性充裕。新的信贷周期开始萌芽，为下一个长期债务周期奠定基础。举例：美国在2010年代的大部分时间，经济缓慢复苏，美联储长期维持低利率和庞大的资产负债表，直到2015年底才开始缓慢加息。二战后的美国，通过经济增长和温和通胀，逐步消化了战争时期积累的巨额政府债务。关键点：这个阶段是经济重回正轨的过程，但也可能为未来的不平衡埋下种子。如果低利率环境持续过久，可能再次催生资产泡沫和过度负债。历史似乎总在重演，只是形式不同。两种主要的债务危机类型一、通缩性债务危机典型发生国家：债务主要以本国货币计价，且该国通常是储备货币发行国，或者经济实力雄厚，拥有较高的国际信用。核心问题：债务泡沫破裂后，由于资产价格下跌和信贷收缩，导致总需求不足，物价持续下跌（通货紧缩）。通缩会增加实际债务负担（借的钱名义值不变，但能买到的东西更多了，还款压力更大），并抑制消费和投资（因为预期未来价格更低），形成恶性循环。演化特征：债务泡沫：如前述模板中的泡沫阶段。货币紧缩：央行为抑制泡沫而加息或收紧信贷。资产价格暴跌和信贷冻结：引爆点到来，市场恐慌。经济活动急剧萎缩，失业率飙升。通货紧缩：物价下跌，企业利润下降，实际利率上升。银行危机：银行因贷款损失和挤兑而面临困境，可能发生系统性风险。政策应对：初期（通常错误）：坚持紧缩，平衡预算，试图通过市场出清解决问题。这往往加剧危机（如胡佛政府初期）。后期（转向“和谐的去杠杆化”）：降息至零（如果尚未达到）。大规模“印钞”/量化宽松：央行购买国债、MBS等，向市场注入流动性，压低长期利率，对抗通缩。财政刺激：政府增加开支，创造需求。金融体系救助：对重要金融机构进行资本注入、担保或国有化，恢复信贷功能。债务重组：帮助债务人减轻负担。“印钞”的效果：在通缩性危机中，由于私营部门信贷急剧收缩，央行“印钞”主要是为了填补这个窟窿，抵消通缩压力，而不是直接引发高通胀。只要“印钞”的规模和方式得当，可以有效地将经济拉出通缩陷阱。案例：美国1929-1933年大萧条：典型的通缩性萧条，罗斯福新政通过美元贬值（变相印钞）、财政刺激和金融改革成功应对。日本1990年代至今的“失去的几十年”：资产泡沫破裂后，日本陷入长期通缩或低通胀。日本央行行动迟缓且力度不足（早期QE规模小，后来才大规模加码），导致去杠杆过程漫长而痛苦。2008年全球金融危机（主要在发达国家，如美国、英国、欧元区部分国家）：美联储、英国央行、欧洲央行都采取了零利率和大规模QE政策，避免了类似大萧条的局面。关键教训：对于通缩性债务危机，果断、大规模的货币和财政刺激是必要的。政策制定者需要克服对“印钞”的恐惧，理解其在特定环境下的积极作用。核心是让名义增长超过名义利率。二、通胀性债务危机典型发生国家：大量债务以外币计价（尤其是政府外债）。本国货币不是储备货币，国际信用较差。经常账户持续大规模逆差，依赖外部融资。国内政治经济不稳定，通胀预期较高。核心问题：当出现触发因素（如资本外流、大宗商品价格冲击、国内政治危机等）时，投资者对该国货币和资产失去信心，导致资本大规模外逃，本币急剧贬值。由于外债需要用外币偿还，本币贬值使得偿债成本飙升，即使名义债务不变，实际负担也急剧加重。同时，进口商品价格飞涨，国内通胀失控。演化特征：外债积累和依赖：国家过度依赖外债发展经济或弥补财政赤字。资本流入逆转/信心危机：由于某种原因（如外部加息、国内政策失误、政治动荡），外国投资者开始撤资，本国居民也将本币兑换成外币。本币大幅贬值：资本外流导致本币在外汇市场上供过于求，汇率暴跌。恶性通货膨胀：进口商品价格因本币贬值而飙升。政府可能试图通过“印钞”来偿还本币债务或弥补财政赤字，进一步加剧货币贬值和通胀。形成“贬值-通胀”螺旋。外汇储备枯竭：央行试图干预汇市以支撑本币，但很快耗尽外汇储备。债务违约（尤其是外债）：国家无力偿还到期的外债。经济急剧萎缩，生活水平大幅下降：高通胀摧毁储蓄，企业经营困难，社会动荡。政策应对：大幅提高利率：试图吸引资本回流，抑制通胀，但这会扼杀经济增长。资本管制：限制资本外流，但往往效果有限且有副作用。寻求国际援助：如向IMF求助，但通常附带严厉的紧缩条件。债务重组：与外国债权人谈判，进行债务减免或展期。结构性改革：改善财政状况，提高经济竞争力，重建市场信心（长期过程）。“印钞”的灾难性后果：在通胀性危机中，由于债务以外币计价，本国央行无法“印”出美元、欧元等外币来偿还外债。此时“印”本币只会进一步加速本币贬值，加剧通胀，是饮鸩止渴。案例：魏玛德国1920年代初的恶性通胀：巨额战争赔款（以外币支付），政府大量印钞弥补财政，导致马克彻底崩溃。拉丁美洲国家1980年代的债务危机：墨西哥、巴西、阿根廷等国大量借入美元债务，在美国大幅加息后，爆发了严重的债务危机和恶性通胀。亚洲金融危机（1997-1998）：泰国、印尼、韩国等国存在大量短期外债，资本外流导致本币急剧贬值，引发金融和经济危机。津巴布韦、委内瑞拉近年来的恶性通胀：国内经济管理不善，政治动荡，过度依赖资源出口，政府滥发货币。关键教训：对于通胀性债务危机，维护币值稳定和控制通胀是首要任务。需要严格的财政和货币纪律，积极管理外债风险，保持充足的外汇储备，并推动结构性改革以增强经济韧性。轻易“印钞”是万万不可的。案例研究1.德国魏玛共和国的恶性通货膨胀 (1918-1923)背景：第一次世界大战战败，德国背负《凡尔赛条约》规定的巨额战争赔款（主要以黄金或外币支付）。国内生产遭受重创，政府财政极度困难。债务性质：主要是以外币计价的对外债务（战争赔款）。危机演化：初期（1919-1921）：政府试图通过印钞来购买外汇支付赔款，并满足国内财政支出。马克开始贬值，通胀抬头，但尚可控制。加速期（1922）：赔款压力加大，法国和比利时因德国未能按时支付赔款而出兵占领鲁尔工业区，德国经济雪上加霜。政府号召消极抵抗，为罢工工人提供补贴，进一步依赖印钞。马克加速贬值，通胀率飙升。失控期（1923）：通胀进入恶性阶段。物价一日数涨，马克面值从几百、几千到数百万、数十亿、数万亿。人们用手推车装钱去买面包，货币几乎失去所有功能。社会秩序濒临崩溃。“和谐的去杠杆化”（或称稳定化）：1923年底，德国政府任命沙赫特为国家货币委员，推行货币改革。发行新货币“地租马克”（Rentenmark），以土地和工业资产为担保，严格限制发行量。严格控制财政支出，平衡预算。通过“道威斯计划”重新安排了赔款支付，减轻了短期压力。这些措施成功稳定了币值，结束了恶性通胀。达利欧的启示：外债是通胀性危机的核心：当一个国家有大量无法用本币偿还的外债时，印钞解决不了问题，只会摧毁本币。信心至关重要：一旦对货币的信心崩溃，贬值-通胀螺旋就难以遏制。政治因素的影响：战争赔款的政治压力是危机的重要推手。果断的改革和外部协调是稳定的关键：发行有担保的新货币、严格财政纪律和国际债务重组共同作用才稳住了局势。恶性通胀对社会的破坏是毁灭性的：它消灭了中产阶级的储蓄，加剧了社会矛盾，为后来的极端政治势力（纳粹）上台埋下了伏笔。2.美国大萧条 (1929-1939) —— 典型的通缩性萧条背景：1920年代“咆哮的二十年代”的繁荣，股市泡沫，信贷过度扩张。债务性质：主要是以本国货币（美元）计价的国内债务。危机演化：泡沫破裂（1929）：美联储为抑制投机而收紧货币，股市在10月崩盘。萧条初期（1929-1932，胡佛政府时期）：资产价格暴跌，财富蒸发。银行挤兑，大量银行倒闭（当时没有存款保险制度）。信贷全面收缩，企业破产，失业率飙升至25%。严重的通货紧缩，物价下跌约1/3，实际债务负担加重。胡佛政府坚持金本位，奉行平衡预算和自由放任政策，试图通过市场自身力量恢复，但效果适得其反，危机深化。“和谐的去杠杆化”（1933年后，罗斯福新政）：果断的货币政策：银行假日（Bank Holiday）：1933年3月，罗斯福下令全国银行停业整顿，恢复公众对银行体系的信心。放弃金本位，美元贬值：禁止黄金出口，提高黄金官价（从每盎司20.67美元提高到35美元），相当于美元对黄金贬值约40%。这使得美联储可以更自由地“印钞”，增加了货币供应，扭转了通缩。成立联邦存款保险公司（FDIC）：为银行存款提供保险，防止挤兑。积极的财政政策：大规模公共工程：如成立公共工程署（PWA）、土木工程署（CWA）、田纳西河流域管理局（TVA）等，兴建基础设施，创造就业。农业调整法（AAA）：通过补贴减少耕种面积，提高农产品价格，增加农民收入。社会保障法（Social Security Act）：建立养老金和失业保险制度。金融监管改革：如《格拉斯-斯蒂格尔法案》将商业银行业务与投资银行业务分离。达利欧的启示：通缩的危害：通缩会加剧萧条，政策必须果断对抗通缩。金本位的束缚：在通缩性萧条中，金本位限制了央行“印钞”的能力，是导致危机加深的重要原因。放弃金本位是关键一步。“印钞”在通缩环境下的必要性：罗斯福的美元贬值和后续的货币扩张，有效地抵消了私营部门信贷的收缩，是经济复苏的基石。财政与货币政策的协同：货币政策负责提供流动性和降低利率，财政政策负责创造需求和就业。两者缺一不可。领导力的重要性：罗斯福的果断行动和有效沟通（如“炉边谈话”）对于恢复信心至关重要。去杠杆过程漫长：尽管罗斯福新政取得了显著成效，但美国经济完全走出大萧条的阴影，很大程度上还依赖于二战带来的巨大需求刺激。3.2008年全球金融危机 —— 现代通缩性（及部分通胀性）危机的混合体背景：全球低利率环境，美国房地产泡沫，金融衍生品（MBS, CDO）泛滥和高杠杆，监管缺失。债务性质：发达国家（美、英、欧）：主要是本币债务，表现为通缩性危机特征。部分新兴市场国家：也受到冲击，一些国家面临资本外流和本币贬值压力，带有通胀性危机色彩，但由于全球主要央行协同行动，未演变成大规模通胀性危机。危机演化（以美国为核心）：泡沫形成与顶部（2000年代中期-2007）：次级抵押贷款泛滥，房价飙升。美联储从2004年开始加息，房价2006年见顶。危机爆发（2007-2008）：次贷违约率上升，相关金融产品价值暴跌。2007年贝尔斯登旗下基金出问题，2008年3月贝尔斯登被摩根大通在美联储支持下收购。2008年9月，雷曼兄弟破产，引爆全球金融海啸。AIG被政府救助。信贷市场完全冻结，银行间拆借几乎停止。股市暴跌。“和谐的去杠杆化”（2008年底至今）：极度宽松的货币政策：降息至零（ZIRP）：美联储、英国央行、欧洲央行等主要央行迅速将政策利率降至接近零的水平。大规模量化宽松（QE）：美联储先后推出QE1, QE2, QE3，购买数万亿美元的国债和MBS，向市场注入巨额流动性，压低长期利率。其他主要央行也采取了类似措施。前瞻性指引：央行承诺在较长时间内维持低利率，以稳定市场预期。金融机构救助与监管改革：TARP计划（问题资产救助计划）：美国财政部投入数千亿美元救助大型金融机构，防止系统性崩溃。压力测试：对银行进行资本充足率测试，强制其补充资本。《多德-弗兰克法案》：加强金融监管，设立消费者金融保护局，限制银行自营交易（沃尔克规则）等。财政刺激：美国推出《美国复苏与再投资法案》，进行减税和政府支出。各国也纷纷出台财政刺激计划。国际协调：G20峰会成为主要国家协调宏观政策的重要平台。达利欧的启示：现代金融体系的复杂性和脆弱性：金融创新在放大效率的同时也放大了风险。影子银行体系、复杂的衍生品使得风险难以识别和控制。“大到不能倒”问题：系统重要性金融机构的崩溃会引发连锁反应，迫使政府出手救助，引发道德风险。政策反应速度和力度的重要性：与大萧条初期相比，2008年危机中各国央行和政府的反应更为迅速和果断，大规模“印钞”和财政刺激避免了全球经济陷入更深的萧条。达利欧称之为“按下了正确的按钮”。“印钞”的有效性与局限性：QE在危机初期有效地防止了通缩螺旋和信贷市场崩溃，支撑了资产价格。但长期来看，QE也可能导致资产价格过度膨胀、贫富差距扩大、以及央行政策空间受限等问题。去杠杆仍然是一个漫长的过程：尽管避免了最坏情况，但全球经济在危机后经历了较长时间的低增长、低通胀和高债务。债务危机没有一劳永逸的解决方案：每次危机都有其独特性，但底层的债务周期规律依然存在。管理债务危机的原则本文在这里只介绍针对管理者不要让债务增速超过收入增速，不要让收入增速超过生产率增速：这是预防危机的根本。保持债务可持续性是长期经济健康的关键。了解你所处的债务周期阶段：通过监测债务水平、偿债比率、资产价格、信贷利差、央行政策等指标，判断经济处于周期的哪个位置，以便提前预警和准备。“和谐的去杠杆化”是目标：一旦危机爆发，政策目标应该是实现“和谐的去杠杆化”，即在不造成极端通缩或恶性通胀的前提下，平稳地降低债务/收入比率。这需要：名义增长率 > 名义利率：这是去杠杆的核心机制。平衡四种去杠杆工具：财政紧缩、债务重组、财富转移和“印钞”。关键在于“印钞”的规模要足够大，以抵消其他紧缩性工具的负面影响，并刺激名义需求。“印钞”是把双刃剑，但不可或缺：对于通缩性危机：果断、大规模的“印钞”（QE）是必要的，可以打破通缩螺旋，提供流动性，支持资产价格，为财政刺激提供空间。政策制定者需要克服对“印钞”等于恶性通胀的传统观念。对于通胀性危机：严禁滥用“印钞”，因为它只会加剧本币贬值和通胀。此时，稳定币值、控制通胀、进行结构性改革和寻求外部援助（可能伴随债务重组）更为重要。区分本币债务和外币债务：这是决定政策选择的关键。拥有储备货币地位和本币债务的国家，在应对危机时有更大的政策空间（尤其是“印钞”）。依赖外债和非储备货币国家则束手束脚。行动要果断、迅速、规模要大：在危机面前，犹豫不决和力度不足的政策往往会错失良机，导致危机恶化。宁可过度反应，也好过反应不足（尤其是在通缩性危机中）。保护系统重要性机构，但要吸取教训：防止“大到不能倒”的机构崩溃引发系统性风险是必要的，但事后必须加强监管，解决道德风险问题。管理好资本流动：对于易受资本流动冲击的国家，需要审慎管理资本账户，积累充足外汇储备，并在必要时考虑临时性的资本管制（尽管有争议）。关注社会和政治影响：债务危机往往伴随失业、贫富差距扩大等社会问题，可能引发政治动荡。政策制定者需要关注公平性，提供社会安全网，维护社会稳定。从历史中学习：每次危机都有其独特性，但人类行为模式和经济运行的基本规律是相似的。理解历史可以帮助我们避免重复过去的错误。达利欧的整个研究就是基于这一理念。“推绳子”现象：当利率降至极低水平后，单纯依靠货币政策刺激经济的效果会减弱（像推一根绳子一样使不上劲）。此时，财政政策需要发挥更大作用，与货币政策协同配合。警惕“失去的十年”：如果政策应对不当或不及时（如日本的经验），经济可能陷入长期的停滞和低迷。"
  },
  {
    "title": "十二月党人的雨夜",
    "summary": "沙皇俄国，俄历十二月，圣彼得堡。雨，与其说是雨，不如说是凝固的叹息，从铅灰色的天幕无休无止地坠落。寒风卷着冰冷的雨丝，抽打在窗棂上，发出单调而执拗的呜咽，如同这座帝国垂死的呻吟。城市蜷缩在黑暗与湿冷之中，街灯在雨雾中晕开一团团模糊的光，照亮着空寂的石板路，反射着幽暗的水光。在这无边雨夜的深处，某些意志正悄然凝聚。壁炉里的火苗挣扎着，映照着几张年轻而坚毅的面孔。他们是帝国的贵胄，是饱读诗书的军官，是",
    "tags": [],
    "url": "/posts/Essays/1825-december-revolt/",
    "date": "2025-05-20T00:00:00.000Z",
    "content": "沙皇俄国，俄历十二月，圣彼得堡。雨，与其说是雨，不如说是凝固的叹息，从铅灰色的天幕无休无止地坠落。寒风卷着冰冷的雨丝，抽打在窗棂上，发出单调而执拗的呜咽，如同这座帝国垂死的呻吟。城市蜷缩在黑暗与湿冷之中，街灯在雨雾中晕开一团团模糊的光，照亮着空寂的石板路，反射着幽暗的水光。在这无边雨夜的深处，某些意志正悄然凝聚。壁炉里的火苗挣扎着，映照着几张年轻而坚毅的面孔。他们是帝国的贵胄，是饱读诗书的军官，是法兰西启蒙思想的信徒。此刻，他们是密谋者。雨声是他们谈话的天然屏障，也像是他们内心焦灼与决绝的交响。“时机快要到了……”帕维尔·伊万诺维奇·佩斯捷利的声音低沉，像冰刃划过夜色。他的目光如鹰隼俯瞰猎物，在火光与阴影交错间缓缓掠过每一张脸。他不仅是南方协会的精神核心，更是那本《俄罗斯真理》的执笔者——他们未来的蓝图，一部通往共和国的宪章草案，一个没有沙皇、没有农奴枷锁的新世界。“康斯坦丁大公已放弃王位，尼古拉的加冕迫在眉睫。”康德拉季·费奥多罗维奇·雷列耶夫接过话语，他的面庞在火光中显出一种不健康的苍白，仿佛病人，又仿佛殉道者。但那双眼睛却燃烧着剧烈的光——不安分、不妥协，几乎要将沉默的屋顶烧穿。“我们没有时间了，必须在尼古拉宣誓之前动手。”窗外的雨越下越急，像是整座城市的命运在天穹间倾泻。彼得堡仿佛沉入一口阴冷的井中，雨水无情地抽打着街头巡逻兵的斗篷，他们缩着脖子，在水汽中咒骂天气，却毫不知晓风暴正在逼近。那些金碧辉煌的宅邸深处，信使裹着雨衣匆匆穿行，一纸纸命令宛如火种，在雨夜中悄然传递。空气中混杂着潮湿的烟草、廉价伏特加，还有一种更刺激的味道——名为“希望”与“绝望”共酿的烈酒，令人头晕目眩，却无法抗拒。他们谈论着军队的部署，谈论着哪些团会响应他们的号召，谈论着如何在枢密院广场逼迫元老院宣布废除专制。每一个词语都像是一块沉重的石头，投入命运的深潭。窗外的雨声，时而激烈如鼓点，时而低回如挽歌。谢尔盖·彼得洛维奇·特鲁别茨科伊亲王，被推举为起义的名义领袖。他静静听着众人的讨论，手指有节奏地敲击着桌面，仿佛与窗外雨点默契应和。他出身高贵，受过良好教育，法兰西自由的思想曾撼动过他的灵魂，但那股热情此刻似乎被层层顾虑包裹。他知道，这是一条险途，代价沉重——而未来未必属于理想主义者。火光在他眼中闪烁，却映不出决绝——只有一种近乎冷静的踌躇。“我们必须向士兵们解释清楚，我们不是为了康斯坦丁，而是为了宪法，为了‘康斯坦丁与宪法’！”米哈伊尔·巴甫洛维奇·别斯图热夫-留明提高了音量，语气中透出强硬与迫切。他的面孔因激动而泛红，拳头紧握在桌上。一个足够模糊而响亮的口号，足以唤起那些士兵的热血——即使他们并不真正理解这场革命的含义。雨水无情地拍击着彼得堡的街巷，也冲刷着历史的轨迹。这座建立在沼泽之上的城市，在风雨中摇曳，仿佛随时会被拉回那片原始的泥泞之中。贵族青年们的理想与热血，在冰冷的黑夜里躁动、发酵，等待着清晨枪声的引爆。他们明白，等待自己的可能是军法、是流放、是死亡；但更可怕的，是沉默与继续苟活于黑暗之中。十二月十四日，清晨。雨暂时止歇，天幕依旧阴沉，像一块浸透墨汁的旧布，沉重、破碎，压在彼得堡头顶。寒意如刀，直刺骨髓。枢密院广场静默如一具冰冷的石磨，等待着碾碎一切投入其中的血肉与理想。莫斯科近卫团率先抵达，士兵们在军官带领下拒绝向尼古拉宣誓，齐声高呼：“康斯坦丁万岁！宪法万岁！” 队列在寒风中显得单薄，却透出一种悲壮的决绝。紧接着，格列纳德兵团与部分海军近卫军加入，三千余名起义士兵集结在广场中央。围观的市民越来越多，他们挤在边缘，表情复杂：有好奇、有同情、也有不安的战栗。仿佛空气中仍残留着昨夜的雨水，只是这一次，凝固成了即将炸裂的沉默。但他们等待的援军迟迟未至。特鲁别茨科伊亲王没有出现——他被恐惧与犹疑击垮了，在最关键的时刻选择了退缩。起义军失去了指挥，士兵们在寒风中伫立，士气渐散，广场像一口沉默的陷阱，缓缓吞噬着他们的勇气与希望。新任沙皇尼古拉一世则展现出作为沙皇应有的冷酷而果决的意志。他迅速调集忠诚部队，将枢密院广场重重包围。炮兵登上制高点，乌黑的炮口缓缓转动，指向那些曾并肩作战、如今却成了叛军的士兵。对峙。死一般的寂静中，只剩军旗在寒风中猎猎作响，远处涅瓦河冰层断裂的脆响，仿佛命运的钟摆在缓缓摆动。老将米哈伊尔·米洛拉多维奇挺身而出。这位曾在卫国战争中屡建奇功的将军，试图挽回战局，用他沙哑却恳切的声音劝说士兵放下武器。他步步向前，话语中带着诚意，也带着悲悯。但一颗子弹打断了他的努力——他倒在雪地里，胸前血如花绽。开枪的是卡霍夫斯基，这位绝望的青年，用最激烈的方式表达了信仰的终点。鲜血，染红了积雪，也终结了和平解决的最后一线可能。尼古拉的耐心耗尽。他下令开炮——没有动员，没有演讲，只有冰冷简短的指令。第一排炮弹呼啸而出，在广场上炸裂，血肉横飞，惨叫撕裂了彼得堡凝结的天幕。那些本就脆弱的理想，在绝对的火力面前迅速崩解。起义士兵队列开始动摇，他们终究不是久经沙场的战士，面对来自“自己人”的炮火，意志迅速瓦解。“继续开炮！”尼古拉的命令冰冷而坚决，如同西伯利亚的寒风，毫不动摇。炮声不止，连同十二月党人最后的幻梦一同撕碎。广场化为修罗场，尸体遍地。有人四散逃命，有人试图踏上涅瓦河的冰面，却在轰鸣中与冰一同碎裂，沉入冰冷的河水之下。那一日，彼得堡没有雨。却比任何一场冬雨都更加寒冷、沉重。空气中弥漫着硝烟与血腥，比历史上任何一页都更令人窒息。夜幕重新降临，雨又落了下来，细密而冰冷，悄无声息地冲刷着广场上的血迹，也渗透进囚车，浸湿那些曾经炽热如火的胸膛。逮捕、审讯、秘密审判接踵而至。佩斯捷利、雷列耶夫、穆拉维约夫-阿波斯托尔、别斯图热夫-留明与卡霍夫斯基，被判处绞刑。其余一百余人流放西伯利亚，终身苦役。行刑那天，天又下起雨。雷列耶夫在绞索套上脖颈时说：“我知道我为何而死，我为祖国而死。”他的语气平静，像是在陈述一件早已注定的事实。雨，冷冷地下着，没有停。十二月党人的理想并未改变什么。他们的失败迅速而彻底，沙皇的统治因此更加严酷。审查收紧，密探遍布，彼得堡沉入了更深的静默。三十年里，尼古拉一世以铁腕维持帝国秩序，试图把一切动荡扼杀在摇篮中。没有春天到来。只有更多的冬夜、雨水与沉默。理想被钉在绞刑架上，在泥土中腐烂，也在泥土中埋下些许东西。至于它是否会发芽——无人知晓。"
  },
  {
    "title": "博客介绍与选题更新计划",
    "summary": "你好，欢迎来到我的个人博客！我是时歌，一个对世界充满好奇的探索者。我在这里分享读书笔记、技术思考、市场观察以及对人本身的探究。希望我的分享能与你产生共鸣或带来些许启发。快速链接：<a href=\"https://www.lapis.cafe/archive/\" target=\"_blank\" rel=\"noopener noreferrer\">按照发表时间线排列的博客文章</a><a href=\"",
    "tags": [],
    "url": "/posts/blog-welcome/",
    "date": "2025-05-18T00:00:00.000Z",
    "content": "你好，欢迎来到我的个人博客！我是时歌，一个对世界充满好奇的探索者。我在这里分享读书笔记、技术思考、市场观察以及对人本身的探究。希望我的分享能与你产生共鸣或带来些许启发。快速链接：<a href=\"https://www.lapis.cafe/archive/\" target=\"_blank\" rel=\"noopener noreferrer\">按照发表时间线排列的博客文章</a><a href=\"https://www.lapis.cafe/projects/\" target=\"_blank\" rel=\"noopener noreferrer\">隶属于不同项目的部分文章</a><a href=\"https://www.lapis.cafe/about/\" target=\"_blank\" rel=\"noopener noreferrer\">我的个人介绍与友链申请建议标准</a><a href=\"https://www.lapis.cafe/bookshelf/\" target=\"_blank\" rel=\"noopener noreferrer\">我近期已经读过的书</a><a href=\"https://www.notion.so/lap1s/20bacbeeb4628036812acfd0baf029f1?v=20bacbeeb46280a0855b000cfe07a720&source=copy_link\" target=\"_blank\" rel=\"noopener noreferrer\">我的未来选题计划</a>"
  },
  {
    "title": "从“捡到女高中生”到“萝莉妈妈”——看现代社会中男性的爱与性需求",
    "summary": "<div class=\"audio-player-container\" data-audio-src=\"https://data.lapis.cafe/api/raw?path=/%E6%92%AD%E5%AE%A2/%E4%BB%8E%E2%80%9C%E6%8D%A1%E5%88%B0%E5%A5%B3%E9%AB%98%E4%B8%AD%E7%94%9F%E2%80%9D%E5%88%B0%",
    "tags": [
      "亚文化研究"
    ],
    "url": "/posts/HumanSciences/girl-salvation-fantasy/",
    "date": "2025-05-18T00:00:00.000Z",
    "content": "<div class=\"audio-player-container\" data-audio-src=\"https://data.lapis.cafe/api/raw?path=/%E6%92%AD%E5%AE%A2/%E4%BB%8E%E2%80%9C%E6%8D%A1%E5%88%B0%E5%A5%B3%E9%AB%98%E4%B8%AD%E7%94%9F%E2%80%9D%E5%88%B0%E2%80%9C%E8%90%9D%E8%8E%89%E5%A6%88%E5%A6%88%E2%80%9D%E2%80%94%E2%80%94%E7%9C%8B%E7%8E%B0%E4%BB%A3%E7%A4%BE%E4%BC%9A%E4%B8%AD%E7%94%B7%E6%80%A7%E7%9A%84%E7%88%B1%E4%B8%8E%E6%80%A7%E9%9C%80%E6%B1%82.wav\">\n  <h3>从“捡到女高中生”到“萝莉妈妈”——看现代社会中男性的爱与性需求</h3>\n  <audio controls></audio>\n  <p class=\"audio-caption\">你也可以在这里收听本文的AI播客版本</p>\n  <a href=\"#\" class=\"audio-download\">下载音频</a>\n</div>一、前言：恋爱幻想中的“拯救”与退行在当代二次元文化中，有一类叙事反复出现：一位生活失意的成年男性社畜，在街头、桥下、便利店门口“偶遇”一位无家可归、情感破碎或社会脱轨的女高中生。她往往年幼、脆弱、漂亮而神秘，对外界戒备，却被男主捡回家中，在经历或多或少的互动后对男主敞开心扉。于是，在一段名义上的“非恋爱关系”中，男主成为她的庇护所，而她则逐渐“治愈”了他破碎的内心，最终二人幸终，走向了婚姻的殿堂这类作品的代表，如《剃须。然后捡到女高中生》，还有各种海量的本子，都在某种程度上提供了一个极其微妙的幻想空间：男性通过“救赎少女”来重建自我价值，同时获得一种无需承担真正平等关系成本的亲密错觉。剃须这种叙事结构其实非常有趣，它融合了数种心理机制与社会投射：其中最显著的，是一种“父职化的爱情”——男性不再作为传统意义上的情人或伴侣登场，而是扮演着一个照顾者、庇护者甚至救世主的角色。在“她需要我”的关系设定中，男性获得了一种掌控亲密关系走向的权力，同时逃避了成年世界中日益复杂、对等、甚至令人力不从心的两性关系建构。在这种幻想叙事中，“少女”一般是孤儿、无依无靠、被父母遗弃或社会冷落，她最开始当然不会信任男主——她防备、冷漠、甚至偶尔带刺——但正是这份抗拒，使得“被驯服”，被“赢得”之后的信赖更显珍贵。她最终敞开心扉，仅对男主一人袒露软弱、分享伤痛，这种独占性的依赖感让男主获得了高度浓缩的情感回馈：一种“她的幸福只由我决定”的虚拟权力。漫照在这里，“恋爱”本身已不再是双向互动的过程，而更像是一个关于重建男性主体性的仪式剧：通过“收容”一个受伤的他者，男主得以重塑自己作为“有能力、有意义、值得依赖的存在”的认同。甚至可以说，少女越是孤立无援、社会性越低，她越是符合被“拯救”的条件；而男主越是社会边缘人、情感失意者，他越是需要一个纯粹的、干净的“情感容器”来承接自我修复的工程。所以，此类叙事实际上是一种极端安全的情感剧本：没有现实中的两性博弈、沟通障碍、成长压力，甚至没有真正的“她”。“她”只是那位愿意永远仰视你的幻想少女，不会反抗，不会长大，不会真正脱离你而成为一个独立的他者。而在另一类更极端但同样流行的叙事中，这种“去主体化”的女性角色被进一步扭曲为所谓“萝莉妈妈”——既拥有幼态化的外表，又具备母亲般的包容、成熟、照料能力。这类角色常常温柔、听话、善解人意，同时还会做饭打扫、安抚情绪、给予赞美。她集少女的可爱、母亲的抚慰、妻子的顺从于一身，成为了一种几乎是算法优化出来的理想情感产品。萝莉妈妈常见的写萝莉的作品，例如夏花娘笔下的安南秀，总是天真刁蛮需要好好哄好好照顾的形象，这样的萝莉很香，但还没有萝莉妈妈香；偶像大师U149中的樱井桃华是塑造得绝对正点的萝莉妈妈，早熟、优雅与善解人意，总是将自己最端正真实的一面展现出来从“捡到女高中生”到“萝莉妈妈”，这些看似截然不同的角色形象，实际上共享着同一个结构——她们的功能是为男性提供单向情感满足与权力认同，而非作为具有自主性的情感主体存在。那么，问题也就出现了：为何在当代社会中，尤其是在以日本、中国、韩国为代表的东亚语境中，这样的幻想越来越常见？ 是什么样的心理需求与社会结构，使得这些温柔却失语的形象成为男性欲望的庇护所？又是什么使得“拯救”与“退行”变成一种普遍的男性亲密策略？接下来，我们将从心理学出发，梳理隐藏在这些幻想结构之下的内在机制。二、心理学维度：男性的“弥赛亚情节”与“控制型亲密幻想”弥赛亚情节在表面上，“捡到女高中生”是一种关于温柔、信任与成长的叙事……但如果我真的相信了这个童话般的说法，那还要写这篇博客做什么呢？从心理学结构来看，我倾向于认为这是一种以救赎之名实现情感控制的结构，体现了现代男性在亲密关系中深藏的弥赛亚情节、依恋障碍与退行性欲望。1.弥赛亚情节（Messiah Complex）：拯救他人以完成自我在开头我必须要声明，所谓的弥赛亚情节并不是严格的临床诊断术语，其在心理分析中通常描述某些人痴迷于扮演“救世主”角色的倾向，他们深信自己有责任去拯救弱者、改变他人命运。这一情结常常建立在两种动机之上：一是对他人苦难的过度认同，二是对自身价值的深度怀疑。在“捡到少女”的叙事中，这一情节表现得淋漓尽致。男主通常是处于失落边缘状态的“社畜”：孤独、厌世、社会地位低下，与家庭或恋爱断裂，无法在工作与社会中实现自我价值。在这样的心理背景下，少女的出现便成为一种“意义的投递”——她的弱小、困境与依赖，为男主提供了一个可以毫无风险地实现“我很重要”的场域。通过拯救少女，男主不仅在物理上提供了庇护，更在情感上成为了少女的“唯一依靠”和“世界中心”。这种“我对她来说是不可或缺的”的体验，极大地补偿了他们在现实世界中的失落感与无力感。少女的感激、依赖和最终的“爱”，成为了衡量男主自我价值的直接标尺，这份价值感的获得远比在复杂社会中打拼要来得简单纯粹。换句话说，这是典型的补偿机制。在现实生活中被结构性剥夺的男性，通过幻想一个“全然依赖我的少女”来建构“我值得被爱”“我拥有改变命运的能力”这种被现实否定的信念。更进一步，这种“我拯救了她”的剧情设置还隐含着一个更深层的心理奖赏系统：她的幸福与存在被绑定在“我是否存在”这一前提上。这是弥赛亚情节的终极快感——不是爱她，而是“她只能被我所救”。2.“照顾型亲密” vs “对等型亲密”：逃避与幻想的亲密替代品现代亲密关系的核心难点，在于它越来越倾向于“对等性”：伴侣间需要相互理解、共同承担、情绪沟通以及权力协商。对于许多处于身份焦虑与社交能力不足的男性而言，这种关系不仅“难以驾驭”，甚至被视为危险且令人筋疲力尽的心理负担。面对这种复杂性，一部分男性可能会感到力不从心或者选择回避——幻想中的“少女”作为一种去平权化的亲密关系替代品，正好提供了一种逃避性的解决方案。她们的需求是简单直接的（食物、住所、陪伴），她们的情感是纯粹透明的，她们的信赖是不设防线的。这种关系模式免除了复杂的情感博弈、沟通障碍与责任压力。男主无需猜测对方的心意，无需处理棘手的矛盾，只需扮演好“照顾者”的角色，就能获得稳定的情感回馈。这种关系表面上充满“父爱”，实际上是一种将亲密关系单向化与等级化的情感架构。在这种结构中，男性拥有绝对解释权与情感主导权，而女性则被限制为依赖方、被照料方、情绪承接方。从依恋理论的视角来看，这类亲密架构高度契合回避型依恋与控制型依恋人格的模式特征：渴望亲密，但害怕对等；需要连接，但回避深度。与其在现实中承担真实关系的不确定性，不如创造一个“完美、安全、不反抗”的幻想对象。3.投射与退行：恋爱中的“非成年化”对象少女之所以在这类幻想中反复出现，绝不仅仅是因为她“可爱”或“单纯”，而是因为她处于一种心理上极为便利的位置——她是非成年化的情感容器。这种“非成年化”既是视觉上的（幼态化面孔、娇小身体、制服诱惑），也是精神上的（不谙世事、容易受伤、缺乏自我意识），更是制度上的（未成年、社会边缘、法律保护空白地带）。这意味着她们不会像成年女性那样带来现实的挑战，不会质疑男性的权威，不会要求平等对话，更不会因自身的成长而“背叛”或“脱离”。她们的存在，仿佛将时间凝固在了一个理想化的、男性占据主导地位的初始阶段。这种设定，本质上是拒绝承认女性的主体性与成长性。在心理层面，她的存在使得男性可以进行以下三种心理活动：父职幻想：我成为她的引导者、保护者、教育者——这是传统男性身份认同的一种自我修复；性控制：由于她的“未成熟”，男性可以在其中获得压倒性权力与主动性，几乎没有真实互动的风险；心理退行：与其面对一个强势、复杂、有意志的成熟女性，不如退行到一种婴儿式的关系——我给予一切，她全然顺从。这三者合一，构成了一个极其强大的文化心理装置：“她不会长大”，因此也永远不会挑战父权秩序与男性主体的位置。 这也解释了为什么“萝莉妈妈”这一看似荒谬的角色在二次元作品中逐渐泛滥：她既具有母性的照料能力，又被永久锁定在“不会长大”的可控状态中。她是慰藉之母，是少女（同时当然也是处女）之身，是理想化的情感机器。萝莉妈妈是神从“捡到女高中生”到“娶了萝莉妈妈”，这些猛戳大家 xp 的情节并非孤立的性癖表达，而是一种对现实关系中男性焦虑与权力退潮的心理反应。它将复杂的两性关系结构简化、等级化，使男性在亲密中重新占据主导，并借助“拯救”他人的表象，完成对自我意义的救赎与维护。而这，也正是我们必须认真审视这些幻想的原因——它不仅塑造了“理想情人”的模样，更深刻地影响着当代男性如何理解亲密、责任与爱本身。三、社会结构维度：父权焦虑、青年男性的失位与“宅文化”的慰藉功能现实社会中任何心理结构的形成都不可能脱离其所处的社会语境。若要真正理解这类幻想的流行，我们必须将目光投向其背后的结构性张力——男性角色的制度性失位与二次元文化的补偿性发展。1. 结构性男性身份失落：当“丈夫”与“父亲”不再可行在传统社会中，“成年男性”的身份建构与路径几乎是线性的：完成学业、进入职场、结婚生子、养家糊口，成为丈夫与父亲。在这一剧本中，男性获得的是明确的社会定位、权力结构与自我认同。但进入21世纪后，这一剧本开始全面崩塌，特别是在日本、中国、韩国等东亚社会，以下几个趋势交织叠加：就业结构不稳定：非正规就业增加、阶层固化、内卷加剧，使得“通过劳动获得体面人生”的路径受阻；婚恋结构紧缩：婚姻率与生育率双降，结婚不再是男性身份的默认通道；父职功能的模糊：在女性觉醒与家庭结构变化中，父亲身份不再稳固、权威日益边缘化。这些变迁意味着：“成为一个合格男人”这件事，变得既不清晰，也越来越难达成。在这一背景下，许多男性面临一种深层的结构性焦虑：我该如何被需要？我该如何爱？我还能扮演什么样的角色？正是在这种身份真空中，“捡到女高中生”“与萝莉同居”式的故事，提供了一种仿佛还能回到传统父职、夫职轨道的幻象：虽然现实中我无法成为别人的丈夫或父亲，但在虚拟空间里，我仍然可以成为某个人唯一的支柱、依靠与意义来源。在这样的社会语境下，“女高/初中生”这一形象逐渐分裂出两个极端变体：地雷女与萝莉妈妈。地雷女：危险、崩坏与欲望的焦点“地雷系”少女是在日本流行文化中常见的标签，通常指那些外表可爱或有吸引力，但精神状态不稳定、情感需求极度强烈、行为模式极端甚至带有自毁倾向的年轻女性。她们在作品中通常拥有创伤性背景（家暴、校园霸凌、抑郁自残），情绪波动剧烈且极度依赖男主。这类角色是一种对现实中女性“复杂性”的极端投射：她们危险，但性感；她们情绪化，却激发保护欲。地雷女“地雷女”在交往的语境时，其形象一般被形容为“一开始看起来很可爱、楚楚可怜，病气与厌世感十足，让人产生保护欲与想要交往的冲动；但交往后发现反而爱得很沉重”的类型，也不乏类似如病娇、郁娇中的强烈渴望被爱的欲求、对伴侣的强烈掌控欲、病弱、自虐、厌世的一面。这种角色体现出当代男性在女性独立性日益增强后的某种矛盾情感：既恐惧现实女性的主体性，又渴望重新获得“她需要我”的位置。地雷女正是这种矛盾的浓缩体——一个可以激发男性拯救欲，又始终维持依赖与弱势地位的“问题他者”。因此，地雷女并非仅仅是“危险的恋人”或“问题少女”，她更是一种对现实女性复杂性与不可控性的文化回应。当现实中的亲密关系越来越趋向平等、协商与双向性，地雷女的形象则提供了一个似是而非的替代路径：她有情绪，有故事，有痛苦，但她的所有复杂性最终都围绕着“我需要你”这一核心展开。这类角色激发的，往往不是对女性主体的尊重，而是对男性“控制权”的回收。她的脆弱、病态、崩坏——看似挑战社会常规，实则强化了一种文化剧本：女性的极端表现是男性行动的理由。她越是精神不稳定，越是需要拯救；她越是依赖与崩溃，越能让男主在“照顾她”的过程中感受到自我存在的确定性。雷雷雷因此，地雷女的情感复杂性与危险性，并不构成男性撤退的理由，反而正是吸引力的来源。她是既安全又刺激的他者：在她身上，男性可以体验到情绪激荡的浪漫幻想，却始终保持权力的上位地位。她不会真正反抗、不会质疑男主的决定，也不会真正脱离对他的依附状态。更进一步地，这种角色还与某种 “负面女性欲望的文化调解” 机制有关。在现实中，女性的愤怒、情绪化、抑郁、自伤往往被社会视为需要“被治理”的问题，而在二次元文化中，这些行为被转译成了情感游戏的一部分。也就是说，“她疯得刚刚好”——既能凸显男主的理智与稳定，又不会真正打破恋爱关系的结构稳定性。最终，地雷女是一种对现代女性主体性的去势重构：她的魅力在于“可控的危险”，她的病态不是真正的反叛，而是通往更深依附的情感通道。这种设定无疑迎合了当代部分男性在社会结构动荡、性别权力平衡重塑过程中的身份焦虑：在无法应对真正平等、复杂的亲密关系时，便转向更为戏剧化但可控的幻想情境，在其中重建自我意义与性别角色的认同。萝莉妈妈：家庭幻想与性别秩序的再编码可可萝例如《公主连结Re:Dive》中的可可萝，便是“萝莉妈妈”的典型代表，以幼态形象承担着对主角无微不至的照料与引导责任而另一类更为“综合性”的形象则是“萝莉妈妈”——如图所示角色那样，外形为幼女，却拥有母性气质和家庭管理能力。她是恋爱对象、照料者、家庭重建者的复合体。如前文所述，这类角色将“幼态化的外表”与“母性化的内在”奇异地结合。她既能满足男性对年轻、纯真、顺从的审美与控制欲，又能提供传统家庭中妻子/母亲所承担的照料、抚慰、情感支持等功能。这本质上是对传统女性角色的二次元化扭曲再生产。在现实中组建家庭、拥有一个“贤妻良母”的成本与难度日益增高时，“萝莉妈妈”提供了一种低成本、高回报的幻想替代品。从社会学角度看，萝莉妈妈是一种将传统“妻子”与“母亲”角色压缩进一个去年龄化的躯体中的文化产物。她将现实中早已解构的性别功能重新复原，但通过“少女皮肤”使其去现实化、去对抗性、去责任化。她不是现实女性，而是一种合成的性别符号——满足男性的欲望、安慰男性的孤独，同时不会威胁男性的权威。萝莉妈妈中的“妈妈”成分满足了每一位男性潜在的恋母需求，而”萝莉“又代表她是纯洁的处女，是任君采撷的初花本质上，地雷女与萝莉妈妈分别是“破碎的爱”与“理想的家”的投射对象，它们共同组成了“宅文化”中的幻想空间，满足现实中无法实现的两性亲密、权力稳定与情感回报。2.宅文化的“补偿性结构”：虚拟空间中的情感避难所面对现实中结构性机会的收缩与亲密关系的复杂化，二次元文化，特别是“宅文化”，成为许多青年男性的情感避难所。与传统大众文化不同，宅文化允许极高的参与度与角色操控性。角色不再是遥不可及的“明星”或“社会范本”，而是可以收藏、改造、共鸣的“数字对象”。在这种媒介结构中，“恋爱”与“家庭”也不再依赖现实互动，而是可以在幻想中达成。其中的“少女救赎物语”，正是这种补偿性机制的核心形式：它提供了一个低风险、高回报的情感游戏：只要付出最低限度的关怀，便可获得纯粹的信任与依恋；它避开了现实关系中的模糊地带：不需要承担真正的责任、妥协与代价；它制造了一种高度浓缩的幸福图景：恋爱、家庭、父职、性欲一应俱全，且随时可控。这种结构之所以迷人，恰恰在于它模拟了一种已在现实中失效的亲密关系剧本。它不解决问题，它慰藉问题。最终，我们必须认识到：这些“捡到女高中生”“与萝莉同居”的叙事，并非只是“男性的小癖好”，而是一种被结构性挤压后的文化应激反应。它讲述的是一个社会中主导权力逐渐退潮的群体，如何在幻象中重建意义、认同与情感秩序的故事。然而，幻象终究是幻象。它不能替代真正的亲密关系，也无法解决男性在现实中的情感困境与性别定位危机。四、性别权力分析：为何是男性捡女高中生，而不是反过来？这个问题乍看之下或许只是一个叙事惯性，但如果你去细想，会发现其中隐藏着极为深刻的性别权力机制与文化脚本——它不仅决定了“谁有资格拯救”，也规定了“谁必须被拯救”。1.性别脚本的根源:谁有资格“拯救”?在父权制文化中，男性长久以来被社会建构为行动者、保护者与施予者，而女性则被定位为被动者、依附者与受助者。这种结构深植于神话、宗教、文学、影视、甚至主流新闻话语中，构成了我们对于“英雄”“浪漫”“爱情”“家庭”等概念的默认前提。于是，“拯救少女”的叙事并非随机生成，而是文化深处的性别分工在幻想层面的自然延伸。在这些叙事中，男性之所以有资格“收容”与“引导”少女，是因为他们被赋予了理性、成熟、社会资源与道德上的主动权；而女性之所以必须等待被拯救，是因为她们被设定为情感脆弱、社会断裂、失去控制力的“被动体”。尤其当“女高中生”这一形象，更是被性别文化精细打磨后的结晶体：她足够年轻以不构成权威挑战，足够性化以激发欲望，足够无助以需要救赎，足够纯洁以避免罪责。在这些叙事中，女高中生往往被符号化为一种“性化的纯洁”——她兼具性的吸引力与道德上的无瑕疵（至少在被男主“拯救”后是如此）。这种纯洁性使得男性的“拯救”行为带上了一层道德光环。相应地，男主，无论现实中多么不堪，在“拯救”这一行为中被赋予了“正义的强者”的临时身份。他不再是现实中的失败者，而是在特定情境下拥有资源、能力与道德制高点的行动者。正因为如此，才从未（或很少）出现过“女白领收留男高中生”的主流作品——那不仅打破了性别客体的逻辑，也破坏了父权结构下“谁有权利付出、谁必须感恩”的稳定配置，它瓦解了男性在幻想中寻求权力补偿与角色认同的心理基础。因为这类幻想的核心，正是通过扮演“拯救者”来确认男性气概与价值。2.去主体化的少女形象：为了让男性方便“进入”要让“捡女高中生”成为一个可被消费的幻想，它首先必须将少女塑造达成一个去社会性、去能动性、去家庭化的空壳角色。她没有父母、没有朋友、没有学校，没有社保体系，没有说“不”的权力，也没有离开的能力。她被彻底“清空”，以便让男性幻想得以毫无障碍地进入和支配：一个拥有健全家庭、朋友支持、有自我生存能力的少女，根本不需要、也不可能被一个陌生男性轻易“捡”回家。她的孤立无援，是男主介入并扮演“救世主”的前提。在这个场景中，被拯救的少女通常是失语的（不善表达、内心封闭，只有男主能“打开”她的心扉）、失能的（缺乏基本生存技能，完全依赖男主照料）、失权的（在关系中没有议价能力，男主的决定就是她的方向）。她的“三失”状态，使其成为一个不会反抗、不会质疑、易于掌控的客体，为男性提供了一个理想的、可控的情感互动对象。男性无需面对真实关系中的平等对话、权力协商和责任分担，只需单方面付出“关爱”，即可收获“回报”。这种去主体化的操作，使得少女更像是一个承载男性欲望与认同需求的“功能性角色”，而非一个具有独立意志与复杂性的个体。她的存在意义，似乎就是为了“被拯救”并“治愈”男主。3. 道德免疫与合法化技术成年男性与未成年少女的同居关系，在现实中无疑会触碰法律红线与道德底线。然而，在二次元幻想叙事中，创作者通过一系列巧妙的“合法化技术”，为这种关系赋予了一层“道德豁免权”，让观众（主要是男性）能够无负罪感地代入和消费。首先，叙事往往会强调是少女“主动”寻求帮助、赖着不走，甚至是她先对男主产生好感或依赖。例如，“她无家可归，自己找上门来”，“她主动提出要为我做饭打扫以报答”，或者在《剃须》中，沙优甚至主动提出用身体交换留宿（虽然被男主“正义”拒绝）。这种设定将责任与主动权部分转移给少女，弱化了男主的潜在剥削者色彩，将其塑造为“善良的”“勉为其难的”接纳者。道德免疫男主通常会被刻画成一个有道德底线的人，他会克制自己的欲望，强调双方是“保护与被保护”或“同居人”而非恋爱关系（至少在初期是这样）。这种“柏拉图式”的开局，暂时悬置了性的维度，将关系纯化为“照顾”与“治愈”，从而在伦理上获得喘息空间。性的张力被延后或模糊化，使得初期的互动显得“纯洁无害”。而少女呢？少女的处境往往被描绘得极端悲惨（如被家暴、被抛弃、流浪街头），使得男主的“收留”行为不仅不是诱拐，反而成为一种“人道主义救援”。在这种极端情境下，常规的社会伦理规范似乎暂时失效了，男主的行为被赋予了超越常规的合理性。这些叙事技巧共同构建了一个“伦理特区”：在这个特区内，男性的欲望（无论是保护欲、控制欲还是潜在的性欲）都得到了合理化乃至美化。通过剥离现实世界复杂的伦理考量与法律责任，强调男主的“善意”与少女的“自愿”，使得这种幻想消费变得心安理得。最后……在男主的善意同意和少女的自愿请求下……就是大家很大程度上喜闻乐见的剧情了。五、结语：这类幻想是病态、趋势，还是一种文化症候？“捡到女高中生“与”萝莉妈妈“式的叙事当然不能简单的被归为性癖或者偶发的文化怪象，作为如此风靡的几个 xp，它更像是一面镜子，映照出特定历史阶段中男性在亲密关系、社会角色与性别秩序变动中的深层不安。我们很难用“病态\"与否作为唯一评判标准，因为幻想本身并不必然通往现实行为，而是一种心理自我调节机制的表现。正如梦境之于精神分析，幻想常常承载着难以表达的欲望、焦虑与结构性压抑。在这类\"救赎少女”的幻想中，我们读到的是一种被现代性挤压后的男性主体自我修复尝试——既想爱，又无法承担;既渴望亲密，又畏惧平等;既失去了传统父职的路径，又未找到新的认同锚点。但与此同时，我们也必须警惕这种幻想的趋势性扩散所带来的结构性后果。当越来越多的作品以“少女依赖男性\"为核心建立亲密关系脚本时，当\"她不会反抗、不会长大、不会离开\"被不断重复时，这种幻想便不再是私密的情绪出口，而逐渐固化为一种文化默认值(cultural default)。它将男性的主体性与女性的客体性重新编码，赋予\"救赎叙事\"一种权力上的合法性与美学上的正当性。而这，恰恰构成了它的危险之处。这种幻想在流行文化、商品设计乃至社交平台算法的协同推动下，正在成为一种被规模化生产与流通的“男性安抚机制\"。在情感市场高度不确定、男性认同日益崩解的今天，市场早已敏锐捕捉到这一集体情绪缺口，并通过角色设定、情节模板与互动剧本持续输出“软性父权\"的治愈幻想。因此，我们也许应该将这类叙事视为一种文化症候——它不是\"病”，但它揭示了系统性的社会张力与性别秩序重构过程中的摩擦地带。它像一面棱镜，折射出现代社会中男性，特别是青年男性，在身份认同、情感需求、权力关系乃至生存意义层面遭遇的结构性困境与焦虑。它是对“失落的掌控感”的代偿性回应：在日益原子化、竞争激烈、充满不确定性的现代社会中，传统男性角色所能提供的确定性（如事业成功、家庭支柱）正在瓦解。当现实世界无法提供足够的掌控感与价值感时，幻想便成为一个重要的心理出口。通过“拯救”一个弱小、依赖的女性形象，男性得以在虚拟情境中重建“我很重要”“我能主导”的积极自我认知。它是对“复杂亲密关系”的简化性逃避：现代亲密关系强调平等、沟通、共情与相互成长，这对许多在传统性别脚本中长大，或缺乏相应社交与情感能力的男性而言，构成巨大的挑战。与其在现实中处理复杂难解的两性互动，不如退守到一个单向付出、即时回报、权力结构清晰的幻想关系中。少女的“纯粹”与“顺从”，本质上是对真实女性复杂主体性的刻意悬置。它是对“父权焦虑”的象征性修复：当社会结构变迁导致传统父权地位受到挑战，男性在家庭与社会中的权威感有所旁落时，“捡到女高中生”或“萝莉妈妈”的叙事，在幻想层面提供了一种“重回伊甸园”的可能——在那里，男性依然是保护者、供给者、引导者，女性则依然是仰望者、依赖者、被规训者。这是一种对逝去性别秩序的怀旧式想象。它是对“情感荒漠化”的慰藉性填充：在高度强调效率与功绩的社会中，真实、深厚的情感连接往往成为奢侈品。许多男性在现实中可能面临情感表达的困境、孤独感的侵蚀。“萝莉妈妈”这类集多种理想特质于一身的形象，如同一个完美的情感机器人，能够精准满足其被理解、被照顾、被崇拜的需求，填补了现实情感的真空。所以，与其急于贴上“变态”或“堕落”的标签，我们更应把目光投向其背后——那一整套关于亲密、性别、身份与情感连接的文化逻辑正在发生怎样的重组。它们不是疯癫的边缘语言，而是社会病灶的显影剂，是现代性碎片化进程中，一部分人用来填补情感缺席与身份失重的精神缝合术。最终，这些幻想告诉我们的，不是少女有多甜美，也不是宅男有多离谱，而是我们这个时代，对爱的理解，已经变得多么畸形又迫切。"
  },
  {
    "title": "基于Koishi、Chatluna和NapCat：QQ群聊机器人的部署教程",
    "summary": "今天闲来无事，折腾了下QQ机器人。主要是想实现一个能在QQ群里自动回复、调用AI接口、甚至管理群聊内容的工具。根据之前其他群友的先进经验，我决定采用 Koishi + Chatluna + NapCat 这套组合部署一个机器人。虽然过程稍微有点折腾，但配置完成后，整体体验还不错。本文就记录一下这次部署的流程、遇到的问题以及一些踩坑经验，希望能帮到也想尝试自建QQ机器人的朋友。我自己走通全部流程大概",
    "tags": [],
    "url": "/posts/TechnicalTutorials/koishi-napcat-chatluna-qqbot-guide/",
    "date": "2025-05-17T00:00:00.000Z",
    "content": "今天闲来无事，折腾了下QQ机器人。主要是想实现一个能在QQ群里自动回复、调用AI接口、甚至管理群聊内容的工具。根据之前其他群友的先进经验，我决定采用 Koishi + Chatluna + NapCat 这套组合部署一个机器人。虽然过程稍微有点折腾，但配置完成后，整体体验还不错。本文就记录一下这次部署的流程、遇到的问题以及一些踩坑经验，希望能帮到也想尝试自建QQ机器人的朋友。我自己走通全部流程大概一共花了五十分钟，如果之前没有接触过Koishi的朋友可能会在插件那里绕一会一、从架构开始说起如果你之前从来没接触过QQ机器人，或者说只接触过官方的bot，那么一定会对 Koishi + Chatluna + NapCat 这三个项目一头雾水。接下来，我会一个项目一个项目的解释：NapCat：这是最底层的“信使”。由于QQ官方并没有为普通开发者提供稳定且功能全面的机器人API，我们需要一个工具来模拟QQ客户端的行为，接收和发送消息。NapCat 支持onebot协议，它的核心任务是打通你的服务器与QQ服务器之间的消息通道，提供一个标准的API接口（比如符合OneBot标准的接口），供上层应用调用。Koishi：这是整个机器人的“大脑”和“操作系统”。Koishi 是一个功能强大且高度可扩展的机器人框架。在NapCat帮你接通了QQ消息之后，Koishi就负责处理这些消息。它提供了一个统一的平台，让你能够：接收和发送消息：通过连接到NapCat等适配器。指令处理：定义各种命令，比如 /天气 北京。插件系统：这是Koishi的精髓所在。你可以通过安装不同的插件来给机器人增加各种功能，比如签到、玩游戏、搜索图片、管理群成员等等。我们后面要说的Chatluna就是以插件的形式集成进Koishi的。权限管理：控制谁可以使用哪些命令。数据存储：记录用户信息、插件数据等。 Koishi 的设计理念是“开箱即用，高度可定制”，它屏蔽了不同聊天平台（比如QQ、Discord、Telegram等）的差异，让你可以用一套逻辑来开发跨平台的机器人。Koishi的部署确实非常方便，Docker命令一行的事，但配置起来还是稍微有点麻烦的Chatluna：这是赋予机器人“灵魂”的AI模块，通常作为Koishi的一个插件存在。Chatluna 的主要作用是对接各种大型语言模型（LLM），比如 OpenAI 的 GPT 系列、国内的文心一言、通义千问，或者其他开源/闭源的AI模型。通过Chatluna，你的Koishi机器人就能够：进行智能对话，理解并回应用户的自然语言。根据你的指令生成文本、写代码、翻译语言等。结合其他Koishi插件，实现更复杂的AI应用场景。 你可以把它看作是连接Koishi和AI模型之间的“翻译官”和“调度员”。所以，整个工作流程大致是这样的：用户在QQ群里发送一条消息。NapCat 监听到这条消息，并将其通过OneBot协议标准推送到Koishi。Koishi 接收到消息，进行分析。如果这条消息触发了某个指令或需要AI处理：如果是一般指令（如查询天气），Koishi会调用相应的插件进行处理。如果需要AI进行对话或内容生成，Koishi会将请求传递给 Chatluna 插件。Chatluna 插件接收到请求后，会根据配置调用你选定的AI模型（比如Gemini），并将用户的输入发送给AI。AI模型处理完毕后，返回结果给Chatluna。Chatluna 再将AI的回复传递回Koishi。Koishi 将最终的回复，通过NapCat发送回QQ群。用户在QQ群里看到机器人的回复。理解了这个基础架构，我们就能更有条理地进行接下来的安装和配置了。这套组合的优势在于每一层都相对独立，可以根据需求替换或升级。比如，如果未来出现了更好的QQ协议端，理论上可以替换掉NapCat而无需大规模改动Koishi的配置（只要新的协议端也支持Koishi能理解的适配器标准，如OneBot）。同样，Chatluna也可以灵活配置不同的AI后端。二、部署流程我是懒狗，所以我只写在vps（建议2c2g以上，最好在环大陆地区）上的部署方法。1.NapcatDocker容器配置首先，在你的 VPS 上新建一个目录用于存放 NapCat 的相关文件。命名随意，我这里用的是 napcat：mkdir napcat && cd napcat接下来，在该目录下创建一个名为 docker-compose.yml 的文件，并写入以下内容：# docker-compose.yml\nversion: \"3\"\nservices:\n  napcat:\n    environment:\n      - NAPCAT_UID=${NAPCAT_UID}\n      - NAPCAT_GID=${NAPCAT_GID}\n    ports:\n      - 3000:3000\n      - 3001:3001\n      - 6099:6099\n    container_name: napcat\n    network_mode: bridge\n    restart: always\n    image: mlikiowa/napcat-docker:latest这段配置的作用是使用 NapCat 官方提供的 Docker 镜像，映射好端口，并确保容器在重启后自动运行。写好之后，执行以下命令启动容器：docker-compose up -d如果网络状况良好，一会儿你就能看到容器启动成功的提示。此时 NapCat 已经在后台运行，等待你通过网页界面进行登录配置。NapCat 配置当容器启动成功后，你应该能在日志中看到类似如下的提示信息：[info] [NapCat] [WebUi] WebUi Local Panel Url: http://127.0.0.1:6099/webui?token=xxxxxxxx这是 NapCat 的本地管理面板地址。在访问之前，记得开放防火墙的 6099、3000和3001 端口，并将 127.0.0.1 替换为你的 VPS 公网 IP。例如：http://<你的服务器IP>:6099/webui?token=xxxxxxxx在浏览器中打开这个地址，即可进入 NapCat 的 Web 控制台界面。此外，日志中还会提示你扫码登录的步骤，大致如下：[warn] 请扫描下面的二维码，然后在手Q上授权登录：\n[warn] 这里是二维码\n二维码解码URL: https://txz.qq.com/p?k=xxxxxxxxxxxxxxxxxxx&f=xxxxxxxxxxxx\n[warn] 二维码已保存到 /app/napcat/cache/qrcode.png如果你的控制台不能正常显示二维码，也没关系——你可以复制日志中的 二维码解码链接（URL），粘贴到一个二维码生成网站（如草料二维码），生成图片后扫码即可完成登录。你也可以直接通过 SFTP 等方式访问 qrcode.png 所在路径，从本地打开二维码图片进行扫码。扫码授权成功后，回到 Web 控制台页面，在“基础信息”板块你就能看到你的 QQ 账号信息，说明 NapCat 已成功连接。账号信息登录成功后回到NapCat控制台，点击左侧的网络配置，再点击左上角的添加配置，新建一个Websocket服务器，格式如下图：格式其他设置项按图中所示即可，Token建议自行设置一个后妥善保存，后面要用。2.Koishi安装与更新依赖Koishi 的安装非常简单，只需一条命令即可：docker run -p 5140:5140 koishijs/koishi执行完后，打开浏览器，访问 http://<你的服务器IP>:5140，即可进入 Koishi 的 Web 控制台。首次进入时会弹出用户协议，同意协议后，就可以开始使用这个功能强大、插件生态丰富的机器人框架了。⚠️ 记得开放防火墙的 5140 端口，否则你将无法通过网页访问控制台。接下来，为了确保系统运行顺畅，你需要更新 Koishi 的所有依赖组件：在控制台左侧点击「依赖管理」；然后点击右上角的 刷新按钮 和 更新全部 按钮；稍等片刻，待所有依赖安装完成即可。更新依赖将 Koishi 连接到 NapCat前面我们提到，NapCat 采用了兼容 OneBot 协议，因此在对接 Koishi 时，我们需要使用 Koishi 的 OneBot 适配器插件。在 Koishi 控制台左侧打开「插件市场」，搜索并安装名为 adapter-onebot 的插件。安装完成后，系统会自动跳转到插件配置页面，但此时你可能看不到具体的配置项。别慌，我们手动来：回到「插件市场」；在「已安装插件」列表中找到 adapter-onebot；点击右侧的「修改」，然后在弹窗中点击「配置」。你将看到如下配置界面：配置在这个页面中，我们需要填写以下四个关键字段：selfId（机器人账号）：填写你在 NapCat 中登录的 QQ 号；token：填写你在 NapCat 面板中添加网络配置时设置的 Token（注意，不是用于登录控制台的 WebUI Token）；protocol：选择 ws（WebSocket 协议）；endpoint：填写 NapCat 容器的地址（我直接用外网地址了）加上端口 3001，例如：http://xxx.xxx.xxx.xxx:3001⚠️ 重点提醒：此处 不要填写 127.0.0.1 或 localhost，那样只会连接到 Koishi 容器自己，导致连接失败。务必使用 NapCat 容器的实际 IP 地址！配置填写完成后，点击右上角的「保存配置」并「启用插件」。如果一切设置正确，此时你可以尝试向机器人的 QQ 号发送 status、help 等 Koishi 内置命令。如果成功收到回复，说明 Koishi 已顺利与 NapCat 建立连接，基本功能已经就绪！3.配置Chatluna和大模型此时，我们的机器人已经可以通过 NapCat 接收和发送 QQ 消息，Koishi 这个“大脑”也顺利上线。现在我们需要通过 Chatluna 插件 接入大语言模型，让机器人具备对话和理解能力。Chatluna 的强大之处在于其高度可拓展的架构，支持对接多种主流的大模型服务，包括国内外的 API 接口（如 OpenAI、Claude、Gemini、讯飞、文心一言等），你可以根据自己的需求和预算灵活选择。安装 Chatluna 插件的流程与前面的 adapter-onebot 类似：打开 Koishi 控制台左侧导航栏，点击「插件市场」；在搜索框中输入 chatluna，回车；安装 Chatluna 本体插件（chatluna）；根据你想使用的大模型平台，选择对应的 适配器插件（例如：chatluna-google-gemini-adapter）。如下图，我选择的是 Google 的 Gemini，所以除了安装 Chatluna 本体外，还额外安装了 Gemini 的适配器插件：截图安装完成后，分别进入这两个插件的配置界面，填写你的 API 密钥、选择或自定义你喜欢的人设（人格设定）、回复风格、上下文长度等参数。配置完成后记得点击保存。此时，你就可以在 QQ 中与机器人自由对话，享受类 ChatGPT 的智能聊天体验啦！"
  },
  {
    "title": "从神经递质到临床药理：ADHD的机制与干预逻辑解析",
    "summary": "观前注意不去伤害别人，不去伤害自己我不能对这篇博客内容的科学性、真实性和有效性做任何保证以下列出的多为处方药，需经医生诊断并结合个人状况开具。请勿擅自购买或使用药物反应存在显著个体差异，具体用药和剂量需由医生根据健康状况、病情轻重及既往用药综合判断药物通常需辅以心理治疗（如CBT/CBT-I）及生活方式干预（如作息规律、适度运动、放松训练等）以提升疗效如果你对华尔街工作压力之大略有耳闻，或者至少刷",
    "tags": [
      "心理学与神经科学"
    ],
    "url": "/posts/HumanSciences/adhd-pharmacology-and-normality/",
    "date": "2025-05-15T00:00:00.000Z",
    "content": "观前注意不去伤害别人，不去伤害自己我不能对这篇博客内容的科学性、真实性和有效性做任何保证以下列出的多为处方药，需经医生诊断并结合个人状况开具。请勿擅自购买或使用药物反应存在显著个体差异，具体用药和剂量需由医生根据健康状况、病情轻重及既往用药综合判断药物通常需辅以心理治疗（如CBT/CBT-I）及生活方式干预（如作息规律、适度运动、放松训练等）以提升疗效如果你对华尔街工作压力之大略有耳闻，或者至少刷过点金融从业者的论坛，那你大概知道：在这个一杯冰美式管不了十分钟精神状态的行业里，嗑药，是一种职场生存策略。不是吸毒，而是处方药——Ritalin（哌甲酯）、Adderall（安非他命复合制剂），这些原本被贴上“多动症儿童专用”的药瓶，如今成了成人世界里提升注意力、延长清醒时间的灰色工具。你很难说这是不是病，但它确实有处方。更难说的是，这是不是药，还是某种制度性焦虑的“合法出口”。注意缺陷多动障碍（ADHD）正变得越来越“流行”：一些研究表明，自2000年以来，英国的ADHD诊断率增加了20倍，仅在2021年到2022年，ADHD药物的处方量就增加了20%。与此相关的是，同一时期，成年人开具ADHD药物处方的数量首次超过了儿童。而在某些高压行业，有症状的、不愿承认的、假装有症状的，最终都通向了同一张药单。但这就引出了一个更基础的问题——ADHD到底是一种什么样的病？ADHD并不是单纯的“坐不住”或“注意力差”，而是一系列复杂神经机制失调的表征。从神经递质的视角来看，ADHD被认为与多巴胺与去甲肾上腺素的调控功能失衡密切相关，这也是为何中枢神经刺激剂反而能够“抚平”ADHD患者的躁动。本篇文章将尝试从神经机制出发，拆解ADHD的成因、药物干预逻辑与背后的社会文化意义。我们会聊聊那些和“奖励系统”有关的神经环路，聊聊为什么你的大脑在需要专注时反而去找刺激，以及这些“聪明药”究竟在药理学层面做了些什么。而在最后，我们也许还得回到那个最令人不安的问题——在一个时时刻刻都要“在线”的社会里，什么样的注意力，才算是正常的？一、ADHD的病因概览：从基因到神经发育要理解为何哌甲酯和安非他命这类中枢神经刺激剂能够“治疗”注意力缺陷多动障碍（ADHD），我们首先需要深入探究ADHD的生物学根源。1.遗传的烙印：ADHD的高遗传性首先，ADHD具有高度的遗传性。双生子研究、家庭研究和领养研究一致表明，遗传因素在ADHD的病因中占据主导地位，遗传度估计高达70-80%。这意味着，如果父母一方患有ADHD，其子女患病的风险显著高于普通人群。病症的遗传并非由单一“ADHD基因”决定，而是多基因共同作用的结果。这些基因大多与大脑中关键神经递质的调控有关，尤其是我们前文提到的多巴胺（Dopamine, DA） 和 去甲肾上腺素（Norepinephrine, NE）。具体来说，研究指向了两大类基因：多巴胺系统基因：如多巴胺转运体基因（DAT1/SLC6A3）、多巴胺D4/D5受体基因（DRD4/DRD5）等。这些基因的变异可能导致多巴胺信号传递效率低下或失衡。去甲肾上腺素系统基因：如肾上腺素能α2A受体基因（ADRA2A），影响去甲肾上腺素的信号接收。此外，ADHD还可能和一些与神经元生长、突触可塑性、神经元迁移相关的基因，如SNAP25、BDNF等有关。这些基因的微小变异（多态性）本身可能并不直接“致病”，但它们共同构成了一种遗传易感性，使得个体在神经系统发育过程中更容易出现ADHD相关的神经环路功能障碍。2.神经发育的轨迹：大脑结构与功能的差异ADHD通常在儿童早期就开始显现症状，其与大脑的神经发育过程密切相关。目前神经影像学研究（如MRI、fMRI）揭示了ADHD患者大脑在结构和功能上与正常发育个体的一些系统性差异。a.脑区发育延迟或体积差异最先受到关注的是前额叶皮层，尤其是右侧前额叶和前扣带回——这些区域被视为执行功能的核心，参与计划、决策、工作记忆和冲动控制等过程。而在ADHD患者中，这些区域往往呈现发育延迟、皮层厚度减薄或体积偏小等特征，直接关联到日常生活中常见的“坐不住”“没耐心”与“容易分心”。除了前额叶，基底神经节也是ADHD病理机制的重要一环，尤其是其中的纹状体，包括尾状核和壳核。在正常发育中，该区域帮助个体在奖赏与动机之间建立稳固联系，从而形成有计划的行为习惯。但在ADHD中，这种系统似乎“短路”了：患者更偏好即时奖励，难以耐受延迟满足，其背后往往隐藏着多巴胺信号传导的异常。此外，还有我们传统上被视为主要参与运动控制的小脑——小脑可能在时间感知、注意力调节及执行功能方面扮演重要角色，ADHD患者小脑特定区域的结构变化，可能进一步加剧其注意力维持和任务切换的困难。b.神经环路功能失调从更宏观的角度看，ADHD并非局限于某一孤立脑区的异常，而是涉及多个关键神经环路的协同失调。其中，额叶—纹状体环路功能减弱已被反复验证，这一环路对多巴胺和去甲肾上腺素极为敏感，是调节奖赏、动机、认知灵活性及觉醒状态的中枢系统。而所谓“走神”的现象，则可能源于默认模式网络（DMN）的过度活跃，这一网络在安静休息状态下应当逐渐被任务导向的网络所抑制，但在ADHD中，这种转换往往失败，使得患者难以集中精力完成目标导向行为。最后，还有一组更细致但同样关键的注意力网络——包括警觉网络、定向网络与执行控制网络——也在ADHD患者中表现出不同程度的功能障碍，使其难以有效过滤无关刺激、维持专注或在任务间灵活切换。所以啊所以，ADHD实际上是系统性的，由多个相互连接的脑区及其构成的复杂神经环路在发育和功能上的失调。这些失调往往会指向儿茶酚胺类神经递质（主要是DA和NE）的信号传递不足或不平衡。3.环境因素与基因-环境交互虽然遗传因素是主导，但环境因素也在ADHD的发生发展中扮演一定角色，那些具有遗传易感性的个体尤甚。如果母亲孕期吸烟、饮酒、药物暴露、早产、低出生体重、出生时缺氧等，都可能增加ADHD的风险。出生后如果儿童早期暴露在不良环境中，如铅暴露、严重的早期社会心理逆境（如虐待、忽视）等，也可能对神经发育产生负面影响。携带特定风险基因的个体，在暴露于不利环境因素时，其患ADHD的风险可能会被放大。例如，携带某些多巴胺系统基因变异的个体，如果母亲在孕期吸烟，其子女出现ADHD症状的风险会比单独暴露于任一因素时更高。二、神经递质的失衡：多巴胺与去甲肾上腺素在ADHD中的关键角色与药物干预靶点我们在第一部分谈到，ADHD的核心神经生物学机制指向了大脑中，尤其是前额叶皮层及其相关环路中，多巴胺（DA）和去甲肾上腺素（NE）的信号传递失衡。现在，让我们深入探讨这两种神经递质的具体功能，以及它们在ADHD患者大脑中是如何“失调”的，这又如何成为药物干预的关键靶点。1.多巴胺(Dopamine, DA)：不仅仅是“快乐分子”关于多巴胺及其中脑-边缘奖赏通路的基本机制，我已在《神经药理学笔记：可卡因等药物如何操控人脑奖赏系统》中详细阐述，此处不再赘述，感兴趣的读者可参阅原文。然而，ADHD的神经基础远不止“奖赏系统的异常活跃”这么简单。在这一节，我们将视线从伏隔核等“奖赏中枢”移至另一个关键脑区——前额叶皮层（Prefrontal Cortex, PFC）。这部分区域正是ADHD研究的焦点之一，而多巴胺在其中的作用，也远远超出了“愉悦”二字所能概括。PFC被视为大脑的“执行控制中枢”，承担着计划、决策、工作记忆、注意力调节和抑制冲动等复杂功能。这些功能的正常运作，极度依赖一个“恰到好处”的多巴胺浓度——过高或过低都可能扰乱神经元间的协同。具体来说，多巴胺通过激活D1和D2样受体，帮助PFC神经网络进行“调谐”：强化目标任务相关的信息（信号），压制无关干扰（噪声）。就像一台精密的收音机，PFC需要多巴胺精准地对准频道、过滤杂音，才能保持专注。而相比中脑边缘通路所主导的“获得奖赏”的即时反馈，PFC中的多巴胺则更侧重于将动机转化为有组织的、延迟满足的目标导向行为。它不仅参与评估远期回报的价值，还支撑我们为达成目标持续投入注意力和认知资源。这种调节机制对于工作记忆、信息操作，以及不同任务间的灵活切换都至关重要——也是ADHD患者普遍受损的核心功能。ADHD患者的多巴胺系统功能失调，并非简单地“多巴胺太少”，而是多巴胺信号传递效率低下或失衡，可能涉及到的问题有三：突触间隙多巴胺水平不足：正如第一部分提到的，多巴胺转运体（DAT1）基因的某些变异可能导致DAT功能亢进，使得突触间隙的多巴胺被过快地清除回突触前神经元，从而减少了作用于突触后受体的多巴胺量。受体功能异常：多巴胺D4、D5受体基因的变异，可能导致这些受体的数量、亲和力或信号转导效率发生改变，使得即使有多巴胺存在，其效应也无法正常发挥。“奖励延迟厌恶”：一些理论认为，ADHD患者的多巴胺系统对即时奖励的反应相对正常甚至更敏感，但对延迟奖励的反应则显著减弱。这导致他们难以为了未来的、更大的奖励而忍耐和坚持，表现为冲动和寻求即时满足。这种多巴胺信号的“动力不足”，使得前额叶皮层难以有效执行其调控功能，从而表现为注意力不集中、组织计划能力差、容易分心、冲动控制困难等ADHD核心症状。2.去甲肾上腺素(Norepinephrine, NE)：警觉与执行的“调音师”与多巴胺同属于儿茶酚胺类神经递质的去甲肾上腺素，在ADHD的病理生理中扮演着同样重要的角色。NE主要由脑干的蓝斑核（Locus Coeruleus, LC）合成并投射到大脑的广泛区域，包括对ADHD至关重要的前额叶皮层。这里，我直接懒得再写一套新的了，就直接引用我《参考：抗失眠与抑郁药物清单》的原文吧：正如其名所示，SNRIs的作用涉及到两种关键的神经递质：血清素 (Serotonin, 5-HT) 和 去甲肾上腺素 (Norepinephrine, NE)。SNRIs与SSRIs类似，也是现代常用的抗抑郁药，但它们的作用机制略有不同，影响的神经递质范围更广一些。除了抑郁症，它们也常用于治疗广泛性焦虑障碍、社交焦虑障碍、惊恐障碍以及某些类型的慢性疼痛（尤其是神经病理性疼痛）。在大脑中，去甲肾上腺素主要与警觉性、注意力、能量水平、动机以及身体对压力的反应（“战斗或逃跑”反应）有关。它也对情绪调节有重要作用。甲肾上腺素系统的功能失调也可能与抑郁症和焦虑症的症状（如疲劳、注意力不集中、缺乏动力）有关。通过抑制这两种转运体，SNRIs能够提高突触间隙中血清素和去甲肾上腺素的浓度，延长它们的作用时间，从而同时增强血清素能和去甲肾上腺素能神经系统的信号传递。与多巴胺类似，NE通过作用于PFC中的肾上腺素能受体（主要是α2A受体），同样参与调节注意力、工作记忆和抑制控制。NE有助于增强PFC神经元对“目标”信号的反应，同时抑制对“干扰”信息的处理，从而提高信噪比。在适度压力或需要高度专注的任务情境下，NE的释放会增加，帮助我们集中认知资源以应对挑战。我们的ADHD患者的NE系统也常常表现出功能不足或失衡，其机制与多巴胺系统有相似之处：NE转运体（NET）功能异常：类似于DAT，NET负责将突触间隙的NE回收至突触前神经元。NET基因的变异或功能改变可能影响NE的清除效率。有趣的是，在前额叶皮层，多巴胺转运体（DAT）的密度相对较低，因此NE转运体（NET）也部分承担了清除多巴胺的功能。这意味着NET功能异常不仅影响NE信号，也间接影响PFC中的DA信号。肾上腺素能受体敏感性改变：特别是α2A肾上腺素能受体（ADRA2A），其基因变异与ADHD的易感性相关。这些受体对于PFC网络的正常“连接”和信号传递至关重要，能增强工作记忆相关神经回路的稳定性。NE信号的不足或失调，会直接导致警觉性降低、难以维持注意力、容易疲劳、执行功能受损等问题，这些都是ADHD的典型表现。3.双管齐下在明确了多巴胺（DA）与去甲肾上腺素（NE）在ADHD中的关键角色及其失调机制之后，当前主流药物的干预逻辑也就水落石出：核心目标是提升这些关键神经递质在前额叶皮层等相关脑区的有效浓度与信号传导效率，从而“调谐”失衡的大脑功能网络。临床上一线治疗药物主要是中枢神经刺激剂，包括哌甲酯（Methylphenidate, MPH，如利他林、专注达）和安非他命类药物（Amphetamine, AMP，如阿得拉）。关于它们的具体临床差异我们将在下一节详述，此处先简要解析它们的作用机制。哌甲酯（MPH）通过阻断多巴胺转运体（DAT）和去甲肾上腺素转运体（NET），抑制突触间隙中的DA与NE被神经元“回收”，从而延长这些递质的作用时间，增强信号的强度与持续性。相比之下，安非他命（AMP）机制更为激进。除了阻断DAT和NET，它还能促进突触前神经元内囊泡中储存的DA与NE的主动释放，甚至可能通过逆转转运体的方向，直接将神经递质“泵出”细胞，大幅提升突触间的递质浓度。这两类药物虽然机制有所不同，但最终指向一致——增强前额叶皮层中DA与NE的神经信号，从而显著改善执行功能、注意维持与冲动控制。这也解释了一个表面看似矛盾、实则合理的现象：“兴奋剂”反而能让ADHD患者“安静下来”并集中注意力。事实上，药物并非让一个正常系统“过度兴奋”，而是补偿神经递质的原初不足，使大脑功能更接近常态水平。这种机制被称为“治疗性矛盾效应”，更准确地说，是一种神经系统的“正常化效应”。接下来，我们将更具体地走近临床实践中的药物治疗方案，看看这些“兴奋剂”与“非兴奋剂”类药物是如何发挥作用的，以及它们在疗效、安全性与适应人群上的差异。每一种药物，都是对神经环路失衡的一种“回答”。三、常见的ADHD药物在上一部分，我们已经明确了ADHD的药物干预核心在于调节大脑内多巴胺（DA）和去甲肾上腺素（NE）的信号传递。基于此，临床上主要有两大类药物用于治疗ADHD：兴奋剂类药物和非兴奋剂类药物。我们将首先深入探讨占据一线治疗地位的兴奋剂类药物。1.兴奋剂类药物：快效的“调谐器”兴奋剂类药物是治疗ADHD历史最悠久、研究最充分、且通常被认为是疗效最显著的一线选择。其核心机制，正如前文所述，在于直接且快速地提升突触间隙中多巴胺和去甲肾上腺素的浓度，从而“校准”前额叶皮层及其相关神经环路的功能。尽管名为“兴奋剂”，但用于ADHD治疗时，它们并非旨在让患者过度兴奋，而是通过补充关键神经递质的不足，帮助患者达到一个更“正常”的觉醒和认知状态，从而改善注意力、减少冲动和多动行为。下面我们具体看两种主要的兴奋剂：a.哌甲酯（Methylphenidate, MPH）及其衍生物哌甲酯是全球范围内使用最广泛的ADHD治疗药物之一,主要作为多巴胺转运体（DAT）和去甲肾上腺素转运体（NET）的阻断剂。通过抑制这些转运体对DA和NE的再摄取，MPH能够有效提高突触间隙中这两种神经递质的浓度，延长其作用时间，从而增强神经信号传递。尤其是在前额叶皮层，NET也负责清除部分DA，因此MPH对NET的阻断能同时提升DA和NE水平。代表药物与剂型：利他林（Ritalin）：这是最经典的哌甲酯制剂，通常为速释型，作用迅速但持续时间较短（约3-4小时），可能需要每日多次服药。利他林（Ritalin） 是最早问世的哌甲酯制剂，通常为速释型。其优势在于起效迅速，适用于需要短时间专注的情境。但由于作用时间较短（约3~4小时），往往需要每日多次服用，血药浓度波动较大，也容易带来“反弹”效应。专注达（Concerta） 是一种采用 OROS（渗透泵控释）技术的长效哌甲酯制剂。它能在12小时内稳定释放药物，实现每日一次服药，大幅减少波动性带来的副作用，同时提升患者的服药依从性。哌甲酯缓释剂型 如 Ritalin LA、Metadate CD 等，则通过不同的控释技术提供中效或长效作用时间，介于Ritalin与Concerta之间，适合需要“覆盖半天”或“上学时间段”专注控制的群体。右旋哌甲酯（Dexmethylphenidate），如 Focalin 和 Focalin XR，是哌甲酯的对映异构体制剂。相比原始的外消旋混合物，右旋形式具有更高的药理活性，因此在等效剂量下可能带来更强的疗效，且副作用风险相对较低。这种“高效低毒”的特点使其成为部分成人或对副作用较敏感患者的优选。一般来说，MPH能显著改善ADHD的核心症状，包括注意力不集中、冲动控制困难和多动。患者通常报告能够更好地专注于任务、减少分心、提高组织能力。常见副作用：食欲下降：尤其在药物作用高峰期，可能导致体重增长缓慢（儿童）或体重减轻（成人）。失眠：特别是如果下午或晚上服用速释剂型，或长效剂型作用时间过长。头痛、胃肠道不适：通常在治疗初期出现，可能随时间减轻。情绪波动/易怒：部分患者可能在药效消退时（“反跳效应”）出现。心血管影响：可能导致心率和血压轻微升高，对于有潜在心脏问题的患者需谨慎。抽动症：少数情况下可能诱发或加重抽动。b.安非他命类（Amphetamines, AMP）药物安非他命及其盐类是另一类重要的中枢神经兴奋剂，在美国等地使用非常普遍。安非他命的作用机制比哌甲酯更为复杂和“激进”。它不仅阻断DAT和NET，还能促进突触前神经元囊泡中的DA和NE释放到突触间隙,通过与 痕量胺相关受体1（TAAR1） 相互作用，进一步增强单胺类神经递质的释放，并可能逆转DAT和NET的转运方向，将胞内的DA和NE“泵出”到突触间隙.这些多重作用使得安非他命能更强效地提升突触间隙的DA和NE水平。代表药物与剂型：混合安非他命盐（Mixed Amphetamine Salts, MAS，如阿得拉/Adderall, Adderall XR）：包含多种安非他命盐（如右旋安非他命硫酸盐、阿司匹林酸右旋安非他命、右旋安非他命糖胶脂、外消旋安非他命硫酸盐、外消旋安非他命阿司匹林酸盐等），有速释和长效缓释（XR）剂型。右旋安非他命（Dextroamphetamine，如Dexedrine）：安非他命的右旋异构体，是其主要活性成分。赖右苯丙胺（Lisdexamfetamine，如维凡斯/Vyvanse）：这是一种前体药物。口服后，赖右苯丙胺在体内通过红细胞水解酶缓慢代谢为活性成分右旋安非他命。这种转化过程使得药物起效更平缓，作用时间更长且稳定（可达12-14小时），并且由于其需要酶解激活的特性，理论上鼻吸或注射滥用的快感较低，从而可能降低滥用潜力。与MPH类似，AMP类药物能有效改善ADHD的核心症状。部分研究和临床经验表明，对于某些对MPH反应不佳或副作用不耐受的患者，AMP可能提供更好的疗效或耐受性，反之亦然。个体差异显著。常见副作用：与MPH相似，包括食欲下降、失眠、头痛、胃肠道不适、情绪波动、心率和血压升高等。由于其作用机制更强，部分副作用（如失眠、焦虑、心血管影响）的发生率或强度可能略高于MPH，但这也因人而异。同样需要关注潜在的心脏风险和抽动问题。常用兴奋剂类 ADHD 药物一览表| 类别        | 药物（中文 / 英文）                    | 剂型与商品名（示例）   | 起效与持续时间*                    | 主要特点／机制摘要                        | 常见副作用（高发顺位）                |\n| --------- | ------------------------------ | ------------ | --------------------------- | -------------------------------- | -------------------------- |\n| 哌甲酯类  | 利他林 / Ritalin                  | 速释片          | 起效快，维持约 3‑4 h           | 经典 DAT/NET 再摄取抑制剂，血药浓度波动大，需每日多次服 | 食欲下降、失眠、头痛／胃肠不适、情绪反跳、轻度心率↑ |\n|           | 专注达 / Concerta                 | OROS 长效片     | 起效平缓，维持约 12 h           | 渗透泵控释；每日一次，依从性好，波动小              | 同上；长效故晚服可能失眠               |\n|           | Ritalin LA、Metadate CD         | 双相／微粒控释胶囊    | 6‑8 h 左右                | 覆盖“半天”场景；可拆胶囊撒入食物                | 同上                         |\n|           | 右旋哌甲酯 / Focalin、Focalin XR     | 速释 / 长效      | 速释 3‑4 h；XR 10‑12 h | 仅含高活性右旋异构体；等效剂量更小，副作用略低          | 同上；部分患者更耐受                 |\n| 安非他命类 | 混合安非他命盐 / Adderall、Adderall XR | 速释片 / 微球缓释胶囊 | 速释 4‑6 h；XR 10‑12 h | 阻断+逆转 DAT/NET 并促单胺外排；疗效强劲        | 食欲下降、失眠、焦虑／情绪波动、心率血压↑、胃肠不适 |\n|           | 右旋安非他命 / Dexedrine             | 速释片          | 4‑6 h                   | 含主要活性异构体；可减轻部分不良反应               | 同上                         |\n|           | 赖右苯丙胺 / Vyvanse                | 前体胶囊 / 咀嚼片   | 12‑14 h                 | 经红细胞水解酶缓释为右旋安非他命；滥用潜力较低          | 同上；因起效慢，焦躁感略低              |2.非兴奋剂类药物：平稳的“调节阀”虽然兴奋剂是ADHD治疗的“金标准”，但并非所有患者都适用或耐受。对于那些对兴奋剂反应不佳、副作用难以忍受、存在物质滥用风险，或者同时患有某些不宜使用兴奋剂的共病（如严重的焦虑症、抽动障碍）的患者，非兴奋剂类药物提供了重要的替代或补充选择。与兴奋剂立竿见影的效果不同，非兴奋剂通常需要数周时间才能充分显现疗效，其作用机制也更为间接或特异。它们主要通过调节去甲肾上腺素系统或其下游通路来改善ADHD症状。a.阿托西汀（Atomoxetine, ATX, 如择思达/Strattera）阿托西汀是第一个被FDA批准用于治疗ADHD的非兴奋剂药物，也是目前应用最广泛的非兴奋剂之一。阿托西汀是一种选择性去甲肾上腺素再摄取抑制剂（SNRI，但特指Norepinephrine Selective Reuptake Inhibitor）。它通过高度选择性地阻断突触前神经元上的去甲肾上腺素转运体（NET），从而增加突触间隙中NE的浓度，增强NE能神经传递。值得注意的是，在前额叶皮层，DAT的表达相对稀疏，NE转运体（NET）也负责清除一部分多巴胺。因此，阿托西汀通过抑制NET，间接提高了PFC中多巴胺的水平，同时在全脑范围内提升NE水平。与兴奋剂不同，它对纹状体等多巴胺通路核心区域的DA释放影响甚微，因此几乎没有滥用潜力。一般来说，阿托西汀能够改善ADHD的核心症状，包括注意力、冲动控制和多动。其疗效通常在持续用药2-4周后开始显现，并在6-8周达到最佳。它提供24小时的持续症状控制，避免了兴奋剂长效制剂药效消退后可能出现的“反跳”现象。对于伴有焦虑症状的ADHD患者，阿托西汀可能是一个特别好的选择，因为它本身也具有一定的抗焦虑作用。因为人家阿托西汀是血清素和去甲肾上腺素再摄取抑制剂 (SNRIs) 嘛，具体可参见《参考：抗失眠与抑郁药物清单》2-2常见副作用：胃肠道反应：如恶心、呕吐、腹痛、食欲下降（但通常不如兴奋剂明显）、便秘。疲劳/镇静：尤其在治疗初期，部分患者可能会感到困倦。失眠：虽然部分人会镇静，但也有报告失眠。口干、头晕。心血管影响：可能引起心率和血压的轻微升高，但通常幅度小于兴奋剂。罕见但严重副作用：包括肝损伤（需监测肝功能）和在儿童青少年中可能增加自杀观念的风险（FDA黑框警告，需密切关注情绪变化）。由于起效慢，需要患者和家属有耐心。一旦起效，其平稳的血药浓度和持续的疗效是其优势。无需像兴奋剂那样严格管制。b.α2-肾上腺素能受体激动剂（Alpha-2 Adrenergic Agonists）这类药物最初是作为降压药开发的，后来发现它们对ADHD症状，特别是多动、冲动和攻击性行为有改善作用，尤其适用于对兴奋剂不耐受或需要联合治疗以控制某些特定症状（如抽动、睡眠问题）的患者。作用机制：这类药物（如可乐定、胍法辛）通过激动突触后α2A-肾上腺素能受体，主要在前额叶皮层发挥作用。激活这些受体可以强化PFC的神经环路连接，增强“信号”传递，降低“噪声”干扰，从而改善工作记忆、抑制控制和注意力调节。它们并非直接提升NE的整体水平，而是更精细地“调谐”PFC的功能。胍法辛相对于可乐定对α2A受体的选择性更高，因此在认知改善方面可能更有优势，且镇静副作用相对较轻。代表药物与剂型：胍法辛缓释剂（Guanfacine ER, 如专注妥/Intuniv）：每日一次的长效制剂，主要用于治疗6-17岁儿童及青少年的ADHD，也可作为兴奋剂的辅助治疗。可乐定缓释剂（Clonidine ER, 如Kapvay）：同样是每日一次的长效制剂，用于ADHD的单一治疗或辅助治疗。α2激动剂对于改善多动、冲动、攻击性、情绪易怒以及ADHD相关的抽动障碍（Tics）有较好效果。它们对注意力的改善效果可能不如兴奋剂或阿托西汀显著，但对于特定亚型的ADHD患者或作为联合治疗的一部分非常有价值。它们也可以帮助改善由兴奋剂引起的失眠问题（例如晚上服用可乐定）。常见副作用：镇静/嗜睡：这是最常见的副作用，尤其在治疗初期和剂量增加时，通常会随时间逐渐减轻。低血压、头晕：因为它们本身有降压作用，需要监测血压，尤其在站立时。口干、便秘。心动过缓。停药反应：突然停药可能导致血压反跳性升高（尤其是可乐定），因此需要逐渐减量停药。α2-肾上腺素能受体激动剂起效也相对较慢，通常需要数周。由于其镇静作用，常在睡前给药，特别是可乐定。对于伴有严重多动、冲动、攻击行为或抽动障碍的ADHD患者，α2激动剂是重要的治疗选择。常用 非兴奋剂 ADHD 药物一览表| 类别                 | 药物（中文 / 英文）           | 剂型与商品名（示例）             | 起效与持续时间*                                 | 主要特点／机制摘要                                     | 常见副作用（高发顺位）                                     |\n| ------------------ | --------------------- | ---------------------- | ---------------------------------------- | --------------------------------------------- | ----------------------------------------------- |\n| 选择性 NET 抑制剂    | 阿托西汀 / Atomoxetine    | 胶囊（择思达 / Strattera）    | 起效 2‑4 周；稳态疗效 6‑8 周；每日一次，24 h 控制 | 高度选择性阻断 NET → ↑NE 且间接 ↑PFC‑DA；无滥用潜力；兼具一定抗焦虑效应 | 胃肠道不适（恶心、食欲↓）、疲劳或失眠、口干头晕、轻度心率血压↑；罕见肝损伤、儿童自杀念头风险 |\n| α2A‑肾上腺素能受体激动剂 | 胍法辛缓释 / Guanfacine ER | 每日一次长效片（专注妥 / Intuniv） | 起效 2‑4 周；持续 24 h                 | 选择性激活 α2A 受体；“精细调谐”PFC，提高工作记忆、抑制冲动；对抽动、睡眠问题有益 | 嗜睡、低血压／头晕、口干便秘、心动过缓；停药需渐减以防反跳                   |\n|                    | 可乐定缓释 / Clonidine ER  | 每日一次长效片（Kapvay）        | 同上                                       | α2 选择性稍低，镇静更明显；对多动、攻击性与睡眠障碍效果佳                | 嗜睡更显著、低血压／头晕、口干便秘、心动过缓；骤停易引发反跳性高血压              |四、总表：ADHD 常用药物列表|药物（中文 / 英文）|药物类别|常见剂型|主要适用/批准地区¹|推荐星级²|备注要点|\n|---|---|---|---|---|---|\n|利他林 / Ritalin|哌甲酯速释|速释片|US, EU, CN, JP|★★★★★|起效快，需每日多次；儿童一线经典用药|\n|专注达 / Concerta|哌甲酯长效|OROS 控释片|US, EU, CN, JP|★★★★★|每日一次，依从性高；成人/青少年常首选|\n|Ritalin LA / Metadate CD|哌甲酯中长效|微粒控释胶囊|US, EU|★★★★☆|覆盖上学/半天场景；可拆胶囊混食|\n|右旋哌甲酯 / Focalin & XR|右旋‑MPH|速释 & 长效|US, EU (部分)|★★★★☆|等效剂量低、副作用略少；成人友好|\n|Adderall / Adderall XR|混合安非他命盐|速释片 / 微球缓释胶囊|US (首选)|★★★★★|疗效强，反应率高；需关注滥用与心血管风险|\n|Dexedrine|右旋安非他命|速释片|US, CA|★★★★☆|单一活性异构体；可替代 Adderall|\n|Vyvanse / Lisdexamfetamine|赖右苯丙胺（前体）|胶囊 / 咀嚼片|US, EU, JP|★★★★★|起效平缓、滥用潜力低；儿童 & 成年人一线|\n|阿托西汀 / Strattera|选择性 NET 抑制剂|胶囊|US, EU, CN, JP|★★★★☆|无管制，无滥用；焦虑共病优先；起效慢|\n|胍法辛 ER / Intuniv|α2A 受体激动剂|长效片|US (FDA 2010) , UK（私处方）|★★★☆☆|对冲动/抽动突出者有益；嗜睡较常见|\n|可乐定 ER / Kapvay|α2 受体激动剂|长效片|US (FDA 2010)|★★★☆☆|睡前服助眠；停药需缓停防血压反跳|\n|Viloxazine ER / Qelbree|去甲肾上腺素调节剂³|长效胶囊|US (FDA 2021)|★★★★☆|最新非兴奋剂；疗效≈阿托西汀，胃肠耐受更好|注释与说明主要适用/批准地区：US = FDA 已批准并普及处方EU = EMA/各成员国批准；使用程度视国家而定CN = 国家药监局（NMPA）已批准上市或进口注册（截至 2025 年）JP = 日本 PMDA 批准如仅列 US，代表暂未在欧亚广泛获批或仍属自费/进口许可推荐星级：综合国际临床指南（AAP 2023、NICE 2024、CHADD 等）、疗效‑安全性‑依从性‑可及性四维度主观评分（满分 5 星）。★数越高表示在常规临床实践中越常被推荐为首选或重要备选。并非绝对疗效排行，个体化差异需遵医嘱评估。Viloxazine ER：2021 年起在美国作为 6‑17 岁儿童/青少年 ADHD 非兴奋剂获批；目前尚未在 EU/CN 获批，临床数据渐增。⚠️ 免责声明表中信息截至 2025 年 5 月，不同国家法规、可及性与医保报销政策可能随时更新。推荐星级仅供快速参考，不构成医疗建议；药物选择须由精神科/儿科/神经科医师依据患者病史、并发症、心血管状况及滥用风险等综合决定。所有兴奋剂在多数国家为管制药品，处方与续方皆需严格遵守当地法规。五、结语：关于“正常”与“病理”的边界思考在我们穷尽神经递质、基因变异、药理机制与药品清单之后，或许真正困扰人的那个问题，才刚刚开始——ADHD到底是一种“疾病”，还是某种不合时宜的神经变异？而我们在诊断、干预与用药的过程中，究竟是在治疗，还是在“校正”？从一方面来看，ADHD无疑是一种痛苦的体验。注意力的飘忽、冲动的难以抑制、多动所带来的社会排斥感，都会显著削弱一个人在学习、工作、人际交往中的功能与尊严。医学的使命之一，就是让个体的神经系统更适配这个社会的节奏与规则，使“难以生存”的人变得“更能生活”。然而，另一个角度却更为隐晦而尖锐：我们对“正常注意力”的定义，本身是否就深受社会结构与生产制度的塑形？ 在一个推崇效率、专注、目标导向行为的社会中，持续注意、延迟满足成为了“好孩子”与“好员工”的基本素质。那些在神经机制上更偏向探索、多任务、即时反馈的人，被视为“不合格者”，并由此进入一套被病理化的医疗体系。是个体不适应社会，还是社会无法容纳差异？兴奋剂的流行既是对“神经差异”的医学回应，也暴露了这个系统本身的张力——它让我们得以运行得更快、更久，却也让人质疑：我们是在帮助一个孩子更好地学习/一个员工更好地做好自己的本职工作，还是在训练一个更高效的齿轮？ADHD的研究与治疗走到了一个转折点。在药物不断推陈出新、干预方式日益精细的同时，我们也应当开始反思“注意力”背后的价值观与规范标准。未来的ADHD干预，不应只是“修复偏差”，而是寻求一种更宽容的神经多样性框架——承认差异、理解不同、灵活支持。医学的温度，不在于消灭“异常”，而在于为每一种脑的存在方式，提供活得更好的可能性。"
  },
  {
    "title": "风自东方来｜鸿蒙PC市场生态前瞻与私货输出",
    "summary": "如果说操作系统是一个生态的灵魂，那么鸿蒙的野心，显然从一开始就不止步于手机。从万物互联的理想出发，HarmonyOS历经数年布局，在智能手机、智慧屏、可穿戴设备等多个终端实现了系统级统一。而今，随着去年 HarmonyOS 5 （Harmony Next & 鸿蒙星河版）正式发布、首款鸿蒙笔记本的即将问世（定于 2025 年 5 月 19 日发布会正式亮相），华为正将这场生态构建推向通用计算设备这",
    "tags": [
      "风自东方来"
    ],
    "url": "/posts/Finance and Economics/harmonyos-pc-ecology-2025/",
    "date": "2025-05-14T00:00:00.000Z",
    "content": "如果说操作系统是一个生态的灵魂，那么鸿蒙的野心，显然从一开始就不止步于手机。从万物互联的理想出发，HarmonyOS历经数年布局，在智能手机、智慧屏、可穿戴设备等多个终端实现了系统级统一。而今，随着去年 HarmonyOS 5 （Harmony Next & 鸿蒙星河版）正式发布、首款鸿蒙笔记本的即将问世（定于 2025 年 5 月 19 日发布会正式亮相），华为正将这场生态构建推向通用计算设备这一全新战场。这是对传统 PC 操作系统格局的一次正面冲击，也是鸿蒙商业化路径中的又一次关键探索。本文将聚焦 HarmonyOS 5 的系统进展与 PC 端适配策略，并分析其在国产化替代、开发生态与市场落地层面的现实挑战与潜在机会。纯从我个人的审美角度，HarmonyOS 5 的桌面端+MateBook 还是非常 Sexy 的，我愿称之为Macbook Next如果你不想看芯片性能和系统架构分析，可以直接看 三、市场落地上的优势与隐忧一、芯片与性能浅析决定一台电脑性能的基石，始终是其底层芯片。与苹果 MacBook、英特尔 Ultra 系列类似，鸿蒙笔记本也采用了高度集成化的 SoC（System on Chip）方案。这种将 CPU、GPU、NPU、内存控制器等模块集成于一体的架构，原本流行于手机，如今正加速迁移至 PC 平台，带来更高能效比、更低功耗以及更强的系统协同能力。华为此次为鸿蒙PC配备的麒麟 X90，是海思首款桌面级 SoC，采用 10 核设计（4+4+2架构），结合最新一代泰山架构核心，支持高线程并发与精细功耗控制。虽然具体频率和性能表现仍待实测，但从手机到桌面芯片的跨越，已为 HarmonyOS 的 PC 化奠定了自研算力基础。GPU 部分则延续了 Mate70 Pro 同款的马良 920，这部分没有太多值得着墨的地方。麒麟x90从目前已知的硬件信息来看，我对这台鸿蒙PC的性能预期是“中规中矩、轻巧够用”。麒麟X90的CPU架构相较于移动端已有明显升级，但受限于工艺、功耗墙以及系统调度优化，这套SoC大概率仍处在苹果M2下限~英特尔i5-1240P之间的区间，主打轻办公、教育、日常内容消费等轻负载场景。换句话说，这不是一台为剪辑4k视频、建模渲染或极限电竞而生的设备，它的定位更多和之前同模具的matebook x 类似，通过自研芯片+自研系统的高度协同，实现“够用+顺滑”的基础体验，尤其在设备间无缝流转、续航控制和发热压制等方面，可能会带来优于传统x86笔电的全新感知。GPU 部分则更不必报以“生产力工具”期待——马良920虽然在移动端尚可，但在面对桌面级图形渲染时仍有明显短板。不过在 HarmonyOS 加持下，未来可能会借助插帧、AI超分等技术“巧劲补硬伤”，实现60帧运行《原神》移动版或星铁pad端这类轻量游戏的目标。二、系统1.微内核与宏内核其实真到系统架构设计这部分我也不懂，只能简单的说说HarmonyOS 的一个核心创新，在于采用了自研微内核架构，这与传统桌面操作系统的宏内核设计有本质差异。微内核的理念，是将操作系统内核精简到只保留最基础的功能（如进程调度、进程间通信等），而将设备驱动、文件系统、网络协议栈等服务移至用户态独立运行，通过消息机制进行交互。相比之下，Windows 与大多数 Linux 发行版则采用宏内核架构，几乎所有底层服务都运行在内核态。macOS 的 XNU 则属于一种混合内核，集成了 Mach 微内核与 BSD 宏内核的特点。微内核那么，微内核到底好在哪？首先是安全性与稳定性的大幅提升。由于核心功能极度精简，内核代码体量小、攻击面窄，出错概率低；各模块在用户态隔离运行，通过“基于能力的访问控制”机制进行通信，容错性与安全性都更高。其次是性能优化带来的体验提升。微内核早期常被诟病通信效率低，但华为通过诸如“确定时延引擎”和高性能 IPC 的技术手段，显著提升了响应速度。鸿蒙OS NEXT 的数据显示，微内核在进程通信性能上相较传统架构提升了约 5 倍，整体内核性能较 Linux 内核高出约 10.7%。同时得益于系统级调度优化和资源复用机制，搭载 HarmonyOS 5 的整机性能相比前代提升约 30%，其中一部分正是来自内核层的改进。这两部分中译中就是，微内核让系统更安全、更稳定，与之伴随着的就是华为生态圈内各终端的互联互通能力也会进一步提高。至于因为架构所导致的性能问题，鸿蒙也通过极致的优化解决了个七七八八，不太影响日常使用。2.分布式能力与软总线：多设备协同架构HarmonyOS 的核心差异化优势之一，就是其原生分布式架构。在 PC 端，HarmonyOS 5 继承并强化了这一设计，借助 分布式软总线 等关键技术，实现多终端之间的无缝协同与资源共享。所谓“分布式软总线”，可以理解为鸿蒙设备之间的通信中枢。它不依赖固定物理连接，支持动态设备发现与高速互联，为手机、平板、PC 等设备提供统一的通信平台。当多台鸿蒙设备处于同一局域网或近场环境时，软总线可自动发现并建立安全、稳定的通信通道。与传统蓝牙或 Wi-Fi 直连不同，软总线屏蔽了底层协议差异，为上层应用提供了高度统一、极简透明的通信接口。得益于这一底层支持，鸿蒙PC具备了“超级终端”能力：不同设备可通过控制中心自由组合、协同操作，实现虚拟硬件聚合。在分布式数据管理机制下，多个设备可以对共享数据进行实时同步；分布式任务调度则使应用可根据各设备性能，动态分派任务，提高整体资源利用效率。例如，用户在鸿蒙PC上编辑文档时，可以直接调用手机摄像头进行扫描，照片即时传输并插入文档；又如，用户可用PC键鼠直接操控平板或手机，通过“键鼠共享”“手眼同行”等功能，一套外设流畅控制多设备。任务接续功能也支持在手机与PC之间无缝切换操作场景，保持应用状态与数据连续。这类功能在苹果生态中以 Continuity 系列（如Handoff、Universal Control）实现，而鸿蒙则从操作系统底层即构建了更普适、更实时的分布式能力，其适配范围不仅限于同一系统内的高端设备，还可扩展至更广泛的 IoT 终端。3.对x86与ARM架构的适配策略与传统生态体系中 PC 与移动端设备在架构上的割裂不同，鸿蒙PC选择了另一条路径：芯片、内核与生态的统一。其核心策略是通过 ARM 架构的自研 SoC + 鸿蒙微内核，打造一个从手机到平板、再到 PC “一次开发、三端通用” 的操作系统平台。华为为鸿蒙PC所配备的麒麟 X90 同样采用的是 ARM 指令集，与手机和平板端的麒麟系列芯片高度统一。这意味着开发者只需面向鸿蒙的统一 API 进行一次开发，就能让应用在不同终端上无缝适配运行，真正实现从移动到桌面场景的连续性体验。这种“生态内一致性”是 x86 架构的 Windows 或 Linux 在移动端难以复制的。在系统底层，HarmonyOS NEXT 彻底移除了 Linux 内核与 AOSP 层，转而全面运行基于鸿蒙微内核的闭源操作系统（HMkernel），这一点不仅标志着鸿蒙自研体系的彻底独立化，也为“跨终端分布式”打下了系统级的技术基础。华为通过统一的运行时、统一的分布式框架（如ArkTS语言、ArkUI框架、分布式软总线等），进一步简化开发流程，使开发者能以一次编码适配多端设备，降低应用生态碎片化的风险。当然，过渡期的问题也不容忽视。由于鸿蒙 NEXT 不再支持传统 Android 的 ART 虚拟机，历史上的 APK 应用将无法直接运行。华为选择大力推进“鸿蒙原生应用”路线，在应用商店提供专门为鸿蒙平台编译的版本，同时借助诸如“卓易通”等转译层兼容部分安卓老应用。Windows 方面，由于架构完全不同，目前鸿蒙PC也无法直接运行 .exe 程序，用户需依赖商店中的原生适配版本。不过似乎目前已经有用户放出鸿蒙PC通过虚拟机运行Win11的视频，如果未来的商用版本支持使用虚拟机，那么华为在电脑软件生态这方面的窘境会好很多。虚拟机尽管面临生态冷启动压力，鸿蒙PC展现出的架构一致性优势，是过去多年 Android 阵营在 PC 化探索中从未解决的问题。在底层统一的架构之上推进生态统一，华为正试图重构操作系统意义上的“全终端”，这也是它与 Wintel 联盟、苹果生态最根本的分野所在。在统一架构的基础上，HarmonyOS 进一步将“多端适配”扩展为“多端融合”。不同设备之间不再只是运行同一应用，而是作为一个协同运作的有机整体，打破传统终端边界。这一设计理念的集大成者，正是鸿蒙的“超级终端”机制。为了更清晰理解其创新程度，我们不妨将其与当前行业中最具代表性的另一种方案——苹果的 Continuity（连续互通）机制——进行一番对比。4.万物互联：多终端协同实现方式对比基本理念上，HarmonyOS 的“超级终端”与苹果的 Continuity（连续互通）都致力于构建跨设备无缝体验，但在实现路径和系统架构层面存在显著差异。鸿蒙超级终端是建立在操作系统层面的分布式协同机制。它通过分布式软总线、分布式文件系统和分布式任务调度等底层技术，将多台设备逻辑上虚拟为一台终端。用户只需在控制中心拖拽“组合”，即可实现手机作为PC的摄像头、麦克风或协同屏幕，平板则可变为手写板或副屏；甚至可以将一个应用拆分为多个界面分布在不同设备上协同运行。这种“多端融合”对开发者几乎透明，只需调用 HarmonyOS 提供的统一接口即可完成分布式部署。超级终端相比之下，苹果的 Continuity 更多是以“设备间协作”为核心思路，其功能构建于独立操作系统之间的协议协同：Handoff 允许在不同设备间接力打开同一应用页面；通用剪贴板、电话/SMS 继承、Continuity Camera 等通过 iCloud 和蓝牙/Wi-Fi 进行状态同步；Universal Control 和 Sidecar 实现跨设备输入与屏幕拓展，但每个功能都需专门适配。\n本质上，苹果通过功能级整合构建多终端体验，而鸿蒙则通过系统级融合将设备资源打通为一个“终端集合体”。苹果从实现难度来看，鸿蒙的超级终端依赖于统一的系统内核和可信通信机制，因此目前仅支持华为自家设备，且最好都是Harmony Next系统；而苹果的 Continuity 则依赖 Apple ID、蓝牙发现与局域网同步，跨设备适配更灵活，对系统异构容忍度更高。在用户体验方面，苹果胜在“即插即用”的顺滑感，用户几乎无需配置即可完成诸如Mac解锁、iPhone拍照自动插入文档等细节操作；而鸿蒙的优势则在于自由度与可拓展性：比如你可以任意指定手机作为PC的辅助模组，或让平板实时接管App的某部分界面，用键鼠控制多台设备等，实现更具创造力的多端协同逻辑。最后，在系统哲学上，苹果坚持 OS 边界分明、功能彼此衔接但不打散，而鸿蒙选择“融合即未来”，以统一架构和运行时将终端虚拟化为资源池。这代表了两种技术哲学的分野：一个更现实实用，一个更具理想主义。因此，鸿蒙超级终端与苹果 Continuity 的差异，不仅是功能清单的不同，更是操作系统未来演化路径的分岔口：鸿蒙在探索“万物即终端”的泛在计算形态，而苹果则在精致打磨“多终端体验”的成熟闭环。从当前生态来看，鸿蒙仍在爬坡阶段，但其架构的指数级扩展潜力，值得持续关注。三、市场落地上的优势与隐忧好的，终于，前面的技术分析和套话都说完了，现在该真情实意地输出了。对于鸿蒙PC这样一个新生事物，我们既要看到它在技术架构上的前瞻性，也要清醒地认识到它在市场推广中将面临的挑战。但首先，我们必须承认，HarmonyOS 5 搭配鸿蒙笔记本，确实握有一些传统 PC 厂商难以企及的优势。优势1.一张白纸好作画——纯粹的现代化操作系统，轻装上阵无历史包袱这可能是鸿蒙 PC 最被低估，却也最核心的优势。Windows 之所以庞大臃肿，macOS 在某些底层逻辑上显得“固执”，很大程度上是因为它们都背负着长达数十年的历史代码和兼容性包袱。每一行新增的代码，每一个新的功能，都可能需要考虑对几十年前某个旧标准、旧硬件、旧软件的兼容，这就像给一栋老房子不断加盖新房间，结构越来越复杂，隐患也越来越多。而鸿蒙 PC，或者说 HarmonyOS NEXT，则是一张全新的蓝图。它不需要为x86的陈旧指令集妥协，不需要兼容Win32的古老API，也不需要背负上亿行为了兼容性而存在的“祖传代码”。这意味着它可以完全基于最新的软硬件理念进行设计，例如前面提到的微内核、分布式能力，这些都是从底层构建，而非后期“打补丁”实现。最新的设计，最新的代码，代表系统没有历史冗余，自然可以更轻巧、更高效。针对ARM架构的深度优化，结合自研芯片，可以实现超越同级别x86设备的能效比和响应速度；设计师和工程师可以大胆采用最符合当下用户习惯和未来趋势的交互逻辑，而不必担心破坏旧有用户的使用习惯或兼容性。简单来说，鸿蒙 PC 有机会成为一个真正为21世纪20年代及以后设计的操作系统，它甩掉了历史的“屎山”，得以“轻装上阵”，这为其后续的快速迭代和体验优化提供了巨大的想象空间。2.多端一体的生态协同——“一次开发，三端（多端）通用”的真实吸引力“一次开发，多端运行”的口号，在软件行业喊了许多年，从Java的“Write Once, Run Anywhere”到各类跨平台框架，但真正能做到体验良好且开发高效的寥寥无几。症结在于，这些方案大多是在不同操作系统、不同硬件架构的上层进行“抹平”和“适配”，治标不治本。鸿蒙的策略则是釜底抽薪：从底层统一操作系统内核与核心框架。正如前文所述，麒麟X90的ARM架构与手机、平板一脉相承，HarmonyOS NEXT更是彻底统一了系统基础。这意味着开发者使用ArkTS语言和ArkUI框架，理论上确实可以更低成本地将一个为手机设计的鸿蒙原生应用，平滑迁移并良好运行在平板和PC上。对于华为而言，在PC端从零构建一个全新的应用生态难度极大。但如果能将手机端庞大的鸿蒙原生应用开发者和存量应用，快速引导至PC端，无疑是一条捷径。当开发者发现适配PC的成本极低，且能额外覆盖一片新用户时，其适配意愿和速度自然会大大增强。从用户角度，用户在不同鸿蒙设备上使用同一款应用，可以获得高度相似的操作逻辑和视觉感受，数据和任务也能更顺畅地流转，这对于提升用户粘性和生态认同感也至关重要。过去安卓平板生态之所以孱弱，很大原因就是应用适配糟糕，手机应用直接放大，体验极差。鸿蒙通过底层统一，试图从根本上解决这个问题，将其从手机、平板自然延伸到PC，这种“降维打击”般的生态建设思路，是传统PC厂商和操作系统难以复制的。3.国家战略层面的东风——国产化采购市场的降维打击这一点，虽然不完全是产品本身的优势，但却是鸿蒙PC在中国市场落地时最强大的“助推器”。在当前国际形势和国家大力推进“信创产业”（信息技术应用创新产业）、强调“自主可控”的背景下，鸿蒙PC的出现恰逢其时。相信所有的，用过那些信创采购PC的人都能感受到那一坨到底有多难用。目前市场上的国产操作系统（如UOS、麒麟OS）虽然在进步，但大多基于Linux二次开发，在生态、易用性和移动端联动方面仍有不足。但鸿蒙笔记本不一样——手机厂商设计产品的资源和经验下放到这个领域简直是降维打击。在华为成熟的硬件设计体系、统一的多端生态架构和高水准的UI/UX审美基础上，HarmonyOS PC 天然就具备一种此前国产系统所不具备的“完整性”与“现代感”。 过去那些基于Linux改出来的系统，不论多努力优化，终究像是拧出来拼凑的东西；而鸿蒙，从芯片、内核到界面逻辑，都是“一家人”，它不是“兼容”什么，而是自成体系地“统一”。这种统一，最大的优势是体验的连续性。政企用户不再需要在手机、平板、PC之间来回折腾格式、权限、兼容性问题。只要在鸿蒙生态中开发一次，文件、应用、指令流都能自然流动，办公效率和协同水平就是另一个维度的事情。而对于采购决策者来说，这种生态内的高度一致性也意味着更少的运维成本、更少的兼容障碍、更少的安全漏洞和更高的可控性——这正是他们在“信创采购”中最在意的指标。过去是“有什么能用就上”，现在是“既然可以好用，何必凑合”。更重要的是，HarmonyOS NEXT 从一开始就彻底摆脱了AOSP和Linux内核的桎梏，意味着华为掌握了对整个操作系统从内核到应用层的全栈控制权。这种“根正苗红”的架构，搭配自主可控的麒麟芯片，天然就是国家队最爱用的那种选手。它能为政府、国企、重要基础设施等敏感单位带来一种技术主权上的安全感，而这种安全感在当今的国际博弈中，比什么都值钱。所以说，鸿蒙PC不是在和UOS、麒麟OS比谁做得更像Windows，而是在直接重新定义一套新范式：不是追着别人兼容，而是建立属于自己的办公生态和操作逻辑。而只要第一波“信创采购”落地顺利，有了这些政企用户的背书与反馈作为样本，鸿蒙PC的生态建设就有了第一个闭环。下一步，就是从“够用”走向“好用”，从政企走向大众——到那时，真正的国产化替代才刚刚开始。隐忧好的说完了，现在我们来说点坏的。1.应用生态的“冷启动”困局——“先有鸡还是先有蛋”的世纪难题这是所有新兴操作系统都必须面对，也最难逾越的鸿沟。Windows之所以难以替代，核心在于其数十年积累下来的、汪洋大海般的 .exe 应用生态，覆盖了从办公、设计、开发到娱乐的方方面面。macOS也凭借其在创意设计、影音编辑等专业领域的深耕，以及近年来iOS生态的反哺，稳固了自身地位。鸿蒙PC面临的第一个大考，就是如何快速构建起一个足够丰富且高质量的原生PC应用生态。尽管华子自己本身也在大力推Top500、Top5000应用的适配，尽管“一次开发，多端部署”为开发者降低了门槛，但将一个为触控优化的手机应用直接“拉皮”到PC上，体验往往不佳。PC用户习惯了精密的键鼠操作、高效的多窗口管理、以及专业软件的强大功能。鸿蒙PC需要的是真正为桌面环境设计和优化的原生应用，这需要开发者投入额外的适配和开发精力。初期，核心的高频应用（如Office套件、主流浏览器、专业设计软件、大型生产力工具）能否快速跟进，将直接影响用户的尝鲜意愿。目前，轻办公、日常使用或许能通过现有移动生态应用和Web应用勉强覆盖，但对于有特定专业需求（如Adobe全家桶、CAD、行业专用软件）或重度游戏需求的用户，鸿蒙PC短期内几乎没有吸引力。虽然上文中提到有“卓易通”等转译方案，以及可能存在的虚拟机运行Windows的可能性，但这终究是权宜之计。转译效率、兼容性和稳定性难以保证，虚拟机则会牺牲性能和原生体验。这些方案可以作为过渡，但无法成为构建健康生态的基石。这些“头部应用”的缺失，会直接将大量潜在用户拒之门外。华为需要投入巨大的资源去激励和扶持开发者，打造标杆应用，形成正向循环。但这需要时间，也需要运气。2.用户习惯的惯性与迁移成本——“温水煮青蛙”的舒适区效应尽管鸿蒙PC拥有自主可控的操作系统、芯片和生态系统，但要在一个已高度成熟且被Windows牢牢掌控的市场上，打破用户的心理防线，并非易事。市场教育是鸿蒙PC面临的又一大挑战。用户长期习惯了Windows的操作逻辑、文件结构、工作流程，以及Windows平台上丰富的第三方应用支持。要让这些用户放弃“老朋友”并拥抱鸿蒙PC，不仅仅是向他们展示硬件和软件的优势，更重要的是说服他们“换个系统”的理由。尤其是对于中小企业和个人用户，现有的办公软件和日常应用几乎都能在Windows上完美运行，他们不会轻易考虑改变。甚至对于一些习惯了Windows的高级用户来说，想要放弃现有的系统和软件，重新适应一个全新的环境，是一种心理上的“巨大的负担”。即使鸿蒙PC提供了丰富的多端协同功能，并且具备一定的系统安全性和自定义性优势，想要从消费者和企业层面真正实现切换，依然需要大量的教育和示范。单纯的技术优势并不足以说服用户，真正的突破点在于如何改变他们的使用习惯和观念。除非鸿蒙PC能提供远超现有平台的独特价值和体验，否则用户很难有足够的动力跳出自己熟悉的“舒适区”。我自己的碎碎念写完上面那么多分析，其实我心里早就有个结论了：从我个人的商业直觉来说，我从来都不认为华为的鸿蒙笔记本会失败。这不是盲目乐观，而是基于三点非常现实、非常朴素的判断。第一，需求是真实存在的。目前信创市场最需要的，不是什么“性能炸裂”或者“界面花哨”的系统，而是一个 “能用、稳定、不恶心人”的国产PC。说难听点，现在市场上很多信创产品的体验，连“能用”这条线都够不着。如果鸿蒙PC能做到不掉链子、不卡顿、不出奇葩bug，那就已经超过半数竞品了——这就是它最大的竞争力。这个市场此刻不是在找最优秀的产品，而是在找最不差的产品。政企单位不是不想用好的，是真的没得选。现在突然告诉你，有一款PC，它可能性能不是顶尖的，但它：界面是现代的、流畅的（毕竟是做手机UI出身的，审美在线）；系统是相对稳定、安全的（自研内核，有技术底气）；你平常工作要用的软件它都有，而且不卡（实在不行性能也支持跑个win虚拟机）跟你的手机、平板能无缝联动（鸿蒙生态的核心卖点）；关键是，它是“根正苗红”的纯国产方案（麒麟芯+鸿蒙OS）。那……我觉得已经没有悬念了。第二，供给端终于来“干大事”的了。过去几十年，PC行业在“Wintel”联盟的统治下，创新其实挺缓慢的，尤其是在用户体验和产品定义的精细度上，很多传统PC厂的思维还停留在“堆料”和“控制成本”的阶段。PC行业进展缓慢，以前做国产PC系统的更是卧龙凤雏——大多是小厂、小团队，干着“国家任务”的活，拿着不多的预算，一边做一边填坑，最后做出一个“像系统又不像系统”的半成品。而手机行业是什么？是地球上竞争最惨烈的消费电子市场，是把用户体验、工业设计、软硬件协同、供应链管理卷到极致的修罗场。华为这种从手机血海里杀出来的巨头，它对产品的理解、对用户的洞察、对细节的打磨，以及它能调动的研发资源和供应链议价能力，根本不是那些主要靠“关系”和“政策”吃饭、做个“能开机”的信创PC就能比的。你让一群习惯了“差不多就行”的厨子，去跟米其林三星大厨比做菜，结果可想而知。华为把做旗舰手机的劲头和标准，拿出一部分来做PC，哪怕初期性能上有所取舍，但在“精致感”、“易用性”和“生态协同”这些软实力上，大概率会给那些扎古扎古们好好上一课。第三，华为没有退路。这一点最简单也最关键。对华为来说，鸿蒙PC根本不是一个“试试水”的项目，而是决定“能不能在桌面计算平台上有自己立足之地”的生死赌局。在经历了被封锁、被打压、被切断外部系统和软件服务的教训之后，华为不可能再把PC业务建立在别人家的体系上。 要么做成一个闭环生态，要么就退出这条赛道。而“做成”这两个字，对于一个在通讯、手机、芯片上都硬生生杀出血路的企业来说，并不算陌生。这种“破釜沉舟”的决心，会转化为巨大的资源投入和不惜一切代价也要做成的执行力。你永远不能低估一个被逼到墙角、又手握核心技术的巨头的能量。他们会想尽一切办法，克服前面提到的所有“隐忧”。所以我反而觉得，鸿蒙PC不是“能不能”的问题，而是“多久能成”的问题。 当然，它短期内不一定能打动你我这些普通消费者。但没关系，To C短期内增长潜力稍逊，还有 To G和 To B。它肯定会经历一段磕磕绊绊、边做边补的起步阶段，但只要政企市场能守住，开发者生态能慢慢起来，这件事就一定有解。写在最后：命运的十字路口在国产化的时代浪潮中，鸿蒙PC像是一艘破冰船，迎着风口也顶着寒流。它的出现，毫无疑问为当前信创格局注入了一种前所未有的变量：一个真正意义上从“芯”到“云”都能自成闭环的操作系统生态。在政策助推、自主意识觉醒的语境中，它拥有“天时地利人和”的罕见组合。但我们也必须清醒地看到，在用户心智、应用生态、迁移成本等维度，它要跨越的门槛依旧高得令人望而生畏。从政企市场切入、构建种子用户群，是鸿蒙PC相对稳妥的路径选择。但能否从“工具性满足”走向“体验性吸引”，从“被选项”成长为“主动选择”，最终进入大众消费市场，那才是真正决定鸿蒙PC能否改写PC生态格局的关键一跃。这是一场长期战役，不是靠一款产品赢下的战争，而是靠一整套生态、节奏、战略和时间积累的胜利。而我们作为观察者，唯一能做的，或许就是睁大眼睛，站在时代变局的十字路口，看看这一次，风究竟能吹多远，又能吹多久。"
  },
  {
    "title": "IMF FSSA 2025：中国金融系统稳定性评估解读",
    "summary": "我必须要在开头承认，我分享的都是带有我自己立场与惯性的叙事和分析框架，不是什么科学真理、惊天秘辛，也不是借助所谓的冲塔或者别的什么立场来提高自己的论证可靠性。在现在的舆论上，批评公有制主体、唱空经济的可信度天然高人一等，为公有制辩护、解释政策的论证义务从头重上三分，这可不算什么“独立思考”。所以还希望所有的读者仅仅只把我的文章当作参考，去形成自己的分析评价框架，反过来自己思考我的文章具体逻辑是否通",
    "tags": [
      "暗涌"
    ],
    "url": "/posts/Finance and Economics/imf-fssa-2025-china-risk-review/",
    "date": "2025-05-12T00:00:00.000Z",
    "content": "我必须要在开头承认，我分享的都是带有我自己立场与惯性的叙事和分析框架，不是什么科学真理、惊天秘辛，也不是借助所谓的冲塔或者别的什么立场来提高自己的论证可靠性。在现在的舆论上，批评公有制主体、唱空经济的可信度天然高人一等，为公有制辩护、解释政策的论证义务从头重上三分，这可不算什么“独立思考”。所以还希望所有的读者仅仅只把我的文章当作参考，去形成自己的分析评价框架，反过来自己思考我的文章具体逻辑是否通顺、符合经济运行事物，让自己的脑子和嘴真正地思自己所思、言自己所言，以理性的形式主张自己的经济权益。在全球经济复苏乏力与地缘政治持续震荡的大背景下，金融系统的韧性就显得愈发重要。2025年4月30日，国际货币基金组织（IMF）发布了新一轮对中国的《金融系统稳定性评估》（FSSA，Financial System Stability Assessment）报告，该报告是2023年7月到2024年9月期间，IMF通过多次实地考察和评估后形成的，完成于2025年2月4日，4月4日由IMF执行董事会审议通过。作为对全球系统重要性金融体系的例行“体检”，这份报告从系统性风险、监管框架、影子银行到跨境资本流动等多个维度审视了中国金融体系的健康状况，更对中国在“双重转型”背景下——即经济结构转型与绿色金融推进过程中的挑战与前景做出了深刻剖析。本篇博客将尝试以解读者的视角，拆解报告中的核心判断、技术性指标与政策建议，并结合当前国内金融改革进程，探讨报告所反映的问题背后隐藏的制度张力与政策抉择。在宏观审慎监管、金融开放、风险治理三者之间，中国如何平衡短期稳定与中长期改革？IMF眼中的“风险”是否也是我们必须正视的“现实”？你可以点击这个链接，查看IMF FSSA报告的原文和双语翻译。一、FSSA研究背景1.宏观金融环境根据IMF的观察，中国正处于关键的宏观金融转型期：经济增速放缓、房地产市场经历深刻调整、地方政府债务风险（特别是LGFV）凸显、货币政策在宽松与需求不足之间寻求平衡，同时伴随着低通胀甚至通缩的风险。 这些因素相互交织，共同构成了IMF评估中国金融系统稳定性时面临的主要宏观经济逆风（headwinds），并直接指向了报告中反复强调的两大核心风险敞口——房地产和LGFV。经济增长面临下行压力：中国经济过去依赖投资拉动的高速增长模式动能有所减弱，经济增速面临下行压力，中期增长前景预计将低于疫情前水平。这构成了金融系统运行的宏观基础，经济放缓可能影响企业和居民的偿债能力，进而传导至金融体系。房地产市场深度调整：这是IMF关注的重中之重。报告明确指出中国房地产行业正经历“近代史上最深的调整”（deepest correction in recent history），这对宏观金融产生了深远影响（profound macrofinancial implications）。自2021年起，新房销售大幅下滑，导致大型房企违约，尽管二手房市场在价格下跌的情况下交易量尚可，但整体销售依然疲软。IMF认为，超出预期的房地产调整期将对投资、抵押贷款增长构成风险，信贷损失和息差压力可能侵蚀金融机构的健康度。\n中国：住房价格走势图：中国住房价格走势左图：二级市场房价呈持续下跌态势，调整速度快于一级市场右图：不同层级城市间历史性价格分化现象正逐步消退地方政府融资平台（LGFV）压力显现：与房地产市场的困境紧密相关的是地方政府融资平台（LGFV）的风险。房地产市场的下滑严重削弱了地方公共财政（尤其是依赖土地出让收入的地区）和LGFV的财务状况。截至2023年末，IMF估计LGFV债务相当于GDP的46%，许多LGFV面临融资紧张和偿债能力恶化的挑战。考虑到银行体系持有约75%的LGFV债务，LGFV的违约风险被视为对金融稳定的重大威胁。\n地方债风险货币政策宽松但信贷需求疲软：尽管中国当局采取了降息、降准等宽松货币政策措施，并引导资金流向重点领域（如政府白名单项目、中小微企业等），但整体信贷需求依然疲软。家庭部门提前偿还抵押贷款，企业借贷意愿减弱。这反映了实体经济的预期和信心问题，同时也对银行的盈利能力（尤其是净息差）构成压力。房地产敞口与小微企业贷款激增带来的债务压力：2023年居民对金融机构债务约占系统总资产的9%，储蓄占可支配收入比重近32%。实物资产在居民财富中占比较高。2023年银⾏对非金融企业（含城投平台）信贷规模达GDP的134%，企业杠杆率⾃2020年来微升至38%左右。可能蕴含未来⻛险的⼩微企业贷款占比在2023年激增至银⾏贷款总额的12%。2.中国金融体系全景中国的金融体系作为全球最大规模的金融系统之一，仍以银行为核心、政府高度管控且内部高度关联。自2017年以来银行业的相对重要性微升，而监管与改革措施抑制了非银部门的增长（打击影子银行），这缓解了2017年指出的风险源头。中国的银行业由五大国有全球系统重要性银行（G-SIBs）和另一家大型银行主导，合计约占银行体系总资产的42%，但也包含中型银行（股份制银行和城商行，占银行资产30%）及小型银行（农商行和村镇银行，占银行资产12%）。多数金融机构直接或间接为国有控股，中央与地方政府、国有企业及金融机构间交叉持股，形成复杂且高度关联的⾏业格局。跨境⻛险敞⼝有限，但中资银⾏在多个⼩型市场中占据主导地位。\n我国金融系统机构和信贷规模我国银行资产和负债结构/非银金融系统二、系统性金融风险评估1.核心风险敞口：房地产与地方政府融资平台（LGFV）如果有读者想了解房地产与政府城投债危机的来龙去脉，可以看我这篇博客：中国与世界的现代化专题（三）：城投与地方债-从分税制改革到房地产经济的逻辑报告的核心判断是，金融稳定风险较2017年上次评估时显著上升，主要来源于两大相互关联的风险源：（1）房地产行业的深度调整报告认为自2021年以来房地产市场的急剧下滑及其持续影响，已成为金融系统面临的最直接挑战之一。这不仅表现为开发商的违约风险，更通过抵押贷款质量、银行资产负债表敞口（直接贷款和通过债券、信托等间接持有）、以及对整体经济信心的影响，向金融体系传导压力。IMF强调，这种调整可能比预期更为漫长，持续侵蚀银行的资产质量和盈利能力。（2）地方政府融资平台（LGFV）的债务压力LGFV的债务问题在2017年报告中已被提及，而本次评估认为风险正在“显性化”。报告估计，LGFV债务规模庞大（截至2023年底约占GDP的46%），且其偿债能力因房地产市场下滑（土地出让收入锐减）和自身经营效率问题而显著削弱。银行体系作为LGFV债务的主要持有者（约75%），面临着巨大的信用风险敞口。IMF特别指出，债务展期、隐性担保以及“非市场化”处置方式可能掩盖了真实损失（veiled losses），延迟了风险暴露，但同时也可能扭曲资源配置，累积更大的宏观经济风险。平台债务重组的影响债务压力注：中国当局在《执行董事的声明》（Statement by the Executive Director, p.108, p.111-113）中对此表达了不同看法，认为IMF可能高估了LGFV的债务规模（指出其对总额的估算与中方数据不符，且未能充分考虑政府支持、资产出售及2024年末推出的债务置换计划等风险缓释措施），并强调自2024年下半年以来，随着一系列稳定房地产和化解地方债务风险政策的落地，相关风险已得到有效控制且趋于下降。这种观点的差异本身就反映了评估风险视角与政策实践效果感知之间的张力。2.银行体系的韧性与脆弱性并存FSSA报告通过压力测试（Solvency Stress Tests, p.23-25; Liquidity Stress Tests, p.26-27）对中国银行体系的抗压能力进行了量化评估。总体韧性：报告承认，中国大型银行（尤其是国有大行G-SIBs）整体上资本充足，流动性缓冲较好，在压力测试的极端情景下仍能保持韧性。这得益于它们较强的盈利能力（尽管有所减弱）、稳定的资金来源以及潜在的政府支持。结构性脆弱点：然而，报告也揭示了不容忽视的脆弱性：中小银行风险：中型银行（股份制和城商行）和小型银行（农商行、村镇银行等）被认为是系统中的薄弱环节。它们资本缓冲更低、融资成本更高、盈利能力下降更快（如净息差收窄），且对特定区域或行业的风险集中度更高。压力测试显示，在不利情景下，部分中小银行将跌破监管最低要求，尽管总体资本缺口被认为是“可控的”。资产质量的隐忧：尽管官方不良贷款率（NPL）保持在相对较低水平（<2%），但IMF对其“透明度”表示担忧。报告认为，不良资产认定标准、广泛存在的贷款展期、通过资产管理公司（AMC）以“可能虚高的价格”进行处置等做法，可能延迟了损失确认，使得账面数据未能完全反映真实的信用风险。盈利能力承压：在经济增速放缓、净息差收窄以及政策引导下向特定领域（如中小微企业）增加信贷投放的背景下，银行的内生盈利能力正在减弱。这削弱了银行吸收损失和补充资本的能力。流动性风险结构：部分银行（尤其是股份制和城商行）更依赖批发融资和同业负债，这在市场承压时可能面临更大的挤兑风险。虽然LCR、NSFR等指标总体达标，但对存款稳定性的假设（尤其是国有企业存款）可能存在过度乐观的风险。3.非银金融机构与系统关联性（影子银行）报告肯定了中国自2017年以来在整顿资产管理行业、削弱影子银行风险方面取得的“显著进展”。然而，非银行金融机构（NBFI）体系依旧庞大且结构高度复杂，依然是系统性风险的重要来源（Nonbank Financial System, p.20）。截至目前，广义资管产品的总规模依然高达GDP的95%，涵盖银行理财、公募/私募基金与信托等多种形态，作为家庭与企业储蓄的主要配置渠道，其体量之大本身即构成潜在风险。金融最怕的就是“系统性金融风险”，而之所以会出现“系统性”正是因为影子银行和银行之间的联系错综复杂。股权交叉持有、债券资产（尤其是地方政府融资平台，即LGFV相关债务）的共同投资以及资金拆借，使得NBFI与银行体系紧密绑定，风险边界变得模糊。一旦发生大规模赎回冲击，相关资产的流动性枯竭将可能迅速在机构之间乃至市场层面引发传染效应（Executive Summary, p.12；Contagion Analysis, p.27, 30）。报告特别警示，LGFV债务一旦出现重组或违约，不仅直接冲击银行资产质量，也会通过资管产品的净值波动触发赎回连锁反应，进而放大系统性压力。IMF在“互联互通与传染分析”章节指出，虽然大型银行具有更强的跨机构传染潜力，但中小银行和证券公司同样可能在特定情境下成为系统性风险的触发点。需要强调的是，由于分析仅覆盖111家银行的有限同业暴露数据，实际的金融系统关联度与传染强度可能被低估。4.数据可得性与评估局限贯穿风险评估部分的一个关键注脚是数据缺口问题（Data gaps, p.12, 21）。IMF团队指出，尽管当局提供了大量数据，但在获取某些关键领域的细粒度数据（如机构层面LGFV和房地产开发商的具体敞口、小银行的详细风险状况、资产分类的底层细节、利率风险数据等）方面仍存在限制。这在一定程度上限制了风险评估的深度和精确度，使得某些分析（尤其是针对LGFV和中小银行的风险）更多依赖公开数据和模型推断。对此，中国当局在《执行董事的声明》（p.118）中回应，认为提供的数据范围（覆盖银行体系总资产80%以上的55家银行用于偿付能力测试，覆盖87%的111家银行用于流动性测试）已相当广泛，足以满足系统性风险分析和压力测试的需求，并符合近期其他国家的FSAP实践。这一分歧凸显了国际评估方法论与东道国数据提供意愿、能力及保密要求之间的持续博弈。三、金融监管框架与政策建议1.微观审慎监管：从合规到风险为本的深化IMF指出，尽管近年来中国金融监管体系在工具箱建设上日益完善，但在具体执行层面，仍需更加坚决地推进“风险为本”的监管范式。当前框架下，监管过于依赖统一标准的合规性要求，而对机构个体的风险状况、治理水平和系统重要性缺乏足够的差异化应对。在银行监管方面，IMF建议更积极地运用《巴塞尔协议》第二支柱，针对不同银行面临的特定风险——如利率波动、资产集中等——引入差异化的资本充足性要求，以提升整体监管的风险敏感性。中小银行作为体系中最脆弱的环节之一，其治理结构、风险文化、资本规划及流动性管理等方面亟需强化监管介入。同时，报告呼吁提升银行信息披露的质量与透明度，特别是在审慎指标方面，包括资本充足率、资产质量、盈利水平与流动性等，以更贴近国际标准，提升市场的风险识别能力。值得注意的是，IMF明确要求逐步废止“监管容忍”政策及对资产分类的例外处理，避免风险长期被掩盖而延迟暴露。同时，还需加强对银行实际控制人和股东结构的穿透监管，防止关联交易集中度过高带来的利益输送和风险传导。在非银行金融机构（NBFI）和大型科技企业监管方面，IMF呼吁确立一个统一的牵头机构，系统评估NBFI领域的潜在风险，打破当前监管碎片化格局。对系统重要性的支付服务提供商和大型科技集团，则应建立分层审慎监管机制，并引入并表监管框架，以应对其跨行业、跨市场的复杂风险结构。段末，IMF再次强调监管独立性和资源保障的重要性。如同过去评估中所指出的那样，监管机构（特别是新设立的国家金融监督管理总局）应获得充足人力与专业资源，特别是在风险分析、压力测试和模型验证等关键技术领域具备独立判断与决策能力。尽管中国当局强调监管目标始终以维护金融稳定为核心，并认为在“发展”与“安全”之间的平衡是合理的，但IMF提醒应尽量减少非监管因素对风险判断的干扰，强化监管机构“安全与稳健”的首要职责。2.宏观审慎政策与系统性风险监测报告肯定了中国在建立宏观审慎政策框架方面的进展，建议进一步增强系统性风险监测和压力测试能力，特别是人民银行（PBC）的分析能力，建议建立压力事件数据库，对风险指标进行回测，开发更精密的模型和场景。在资源协调方面，IMF建议设立一个包含关键机构的宏观审慎政策委员会（Macroprudential Policy Committee），加强跨部门数据共享和政策协调。方法论层面，IMF建议采取前瞻性（forward-looking）方法评估系统性风险，特别是对于那些通过延迟损失确认等方式隐藏的风险。提高宏观审慎政策工具（如逆周期资本缓冲）的分析基础和透明度。3.危机管理与处置框架：亟待建立的“防火墙这是IMF着墨最多、措辞最为严厉的部分之一。报告认为，中国当前的危机管理框架不完整、效率低下、过度依赖公共资金且缺乏明确规则（p.12, p.39），难以有效应对系统性危机。关键建议包括：完善法律基础：尽快通过并完善《金融稳定法》（草案），使其与国际最佳实践（如金融稳定理事会FSB的关键属性）充分对接，明确处置权力、触发条件、资金来源和法律保护。设立独立的处置当局：指定并运作一个拥有充分资源和操作自主权的、专门的处置牵头机构被认为是改革的核心。同时需厘清中央金融委员会（CFC）在危机管理中的角色。强化处置资金和工具：扩大总损失吸收能力（TLAC/LAC）要求：建议将损失吸收能力要求至少扩展至所有国内系统重要性银行（D-SIBs），并限制（或至少封顶）将存款保险基金（DIF）资源视为TLAC的折扣。改革存款保险基金（DIF）：严格限制DIF资源的使用范围（仅限于存款人赔付和“最低成本”的转让策略），并增加行业缴费以弥补资金缺口。规范金融稳定保障基金（FSGF）：需明确FSGF的**资金目标、治理结构、缴费机制、使用规则和公共资金支持。建立有效的紧急流动性援助（ELA）框架：设计并实施符合国际最佳实践的、专门的ELA框架，取代目前效率不高的通过降低准备金要求等方式提供的支持。这需要明确的合格标准、抵押品政策、估值和风险控制措施。完善破产和重组制度：更新《企业破产法》，规范预重整程序、依照国际标准修改重整条款、引入集团和跨境破产规定。同时，加强对资产管理公司（AMC）的监管和透明度，考虑向AMC以外的购买者开放不良贷款一级市场。针对当前中国金融系统中最受关注的风险领域，IMF提出了多项具有针对性的建议：LGFV债务：最核心的建议是制定并实施一个中长期的综合解决方案，以系统性地解决LGFV债务积压问题，而非依赖临时或局部的措施。及时确认损失：采取果断措施，全面确认金融机构资产负债表上的预期损失，并持续推动金融资产的市场化定价。这被认为是提升透明度、改善资源配置效率的关键。气候风险：作为绿色金融的先行者，建议中国加强对气候相关金融风险的分析能力，改善数据收集和机构间协作，统一和完善绿色金融标准和信息披露。小结：改革的紧迫性与系统性IMF的政策建议构成了一个相互关联的整体，核心逻辑是：在风险高企的背景下，必须通过强化监管的独立性、资源和风险敏感性来“强身健体”；通过建立健全的危机管理框架来构建“防火墙”，确保风险发生时能够有序处置；通过市场化改革（如及时确认损失、减少隐性担保）来理顺激励机制，提高资源配置效率。这些建议直指中国金融体系长期存在的深层次问题，如政府与市场的边界、中央与地方的协调、短期稳定与长期改革的平衡。中国当局的回应虽然对部分风险判断和建议细节持有不同看法，但也承认持续改革和与国际标准对接的重要性，并强调《金融稳定法》将为系统性风险管理提供关键框架。四、IMF中国执行董事的回应总结在IMF发布FSSA报告的同时，也按照惯例发布了中国执行董事代表当局提交的声明。总体基调：赞赏合作，但对风险评估持更乐观态度声明首先对IMF FSAP团队的专业工作和坦诚交流表示感谢，认为评估为理解中国金融发展和改革提供了有价值的参考。然而，其核心基调明显比IMF工作人员报告更为乐观。当局认为中国金融体系是稳健且有韧性的，金融风险是可控的，并且自IMF评估期（主要数据截至2024年9月）结束后，尤其是2024年下半年一系列宏观政策实施以来，关键领域的风险已显著下降（substantially declined）。这与IMF报告中“风险高企且仍在上升”的核心判断形成了鲜明对比。1.关键风险点的反驳与澄清地方政府融资平台（LGFV）风险：这是当局回应的重点。规模与性质高估：当局认为IMF高估了LGFV的债务总额和风险敞口，指出IMF的估算方法可能存在重复计算，且未能充分区分由地方政府负责偿还的隐性债务（已通过10万亿人民币的债务置换计划处理）和LGFV自身的经营性债务。当局估计的金融体系对LGFV的真实风险敞口远低于IMF报告所述。偿付能力与区域差异：声明强调，在评估LGFV偿付能力时，需充分考虑资产清算（特别是土地）、地方政府的财政支持能力以及正在进行的资产注入和重组。此外，LGFV债务具有明显的地域特征，债务负担较重的省份往往经济和财政实力也较强，有能力独立化解风险。政策有效性：当局认为，自2023年以来实施的化债方案，包括债务置换、展期降息谈判、以及强化地方政府主体责任等措施，已显著缓解了LGFV的偿债压力，市场对LGFV风险的担忧已大幅降低（体现在LGFV债券利差收窄上）。房地产风险：当局认为IMF未能充分反映近期市场的积极变化。市场趋稳：声明指出，随着一系列支持政策（如降低首付比例、取消利率下限、保障性住房再贷款工具等）落地，房地产市场已出现企稳迹象，交易量回升，部分城市房价出现环比上涨或降幅收窄。风险可控且溢出有限：当局强调，中国在按揭贷款方面一直采取审慎政策（如较高的首付比例），按揭贷款资产质量优良，NPL率长期低于1%。开发贷风险虽有暴露，但通过“白名单”等融资协调机制得到了有力支持。因此，房地产风险向金融体系的溢出效应是有限且正在减弱的。2.肯定压力测试结果，强调系统韧性有趣的是，当局援引了IMF自身的压力测试结果来佐证其观点，即便是在极端压力情景下，中国银行体系（特别是占绝对主导地位的银行部门）仍表现出韧性，资本缺口可控，主要银行LCR达标且资金来源稳定。这表明，即使采用IMF的方法论，系统性崩溃的风险也较低。3.认可监管改革进展，强调国情与平衡当局欢迎IMF对中国在宏观审慎框架、巴塞尔协议III实施、金融控股公司监管、规范资管行业等方面取得进展的认可。然而，在以下几点上表达了不同看法：监管目标：不同意IMF关于监管存在“稳定”与“发展”目标冲突的看法。当局认为，维护金融稳定始终是首要职责，但平衡稳定与发展是国际通行做法，尤其对于中国这样的发展阶段。监管独立性：认为监管机构依据法律拥有履行职责所需的决策独立性。市场化定价：不同意IMF关于“市场化定价转型停滞”的判断，强调中国一直坚持市场化、法治化改革方向，例如全面注册制的实施已显著提升了资本市场的市场化程度。不良资产处置：认为稳定的NPL率主要归功于积极主动的不良资产市场化处置，而非监管容忍或价格扭曲。在数据充足性方面，当局认为，为本次FSAP提供的数据范围、类型、粒度和时间序列是充分的，符合近期IMF对其他国家的评估标准，足以支持系统性风险分析和压力测试的需要，不同意IMF关于数据缺口限制了评估深度的说法。总结与展望：在稳定与改革间寻求平衡的中国金融叙事中国当前金融体系所面临的挑战当然不仅仅是宏观经济周期波动的产物，更从深层映射出一个发展中大国在现代金融体制构建过程中的“结构性紧张”。一方面，系统性风险正从边缘走向核心，房地产与地方政府债务问题折射出资源错配、激励扭曲与治理结构失灵的累积效应；另一方面，作为全球最大、最复杂的国家金融体系之一，中国又必须在维护短期稳定、推动长期改革、参与国际规则博弈三者之间，维持高度精密的动态平衡。IMF的FSSA报告系统性地梳理了成就与挑战，肯定了中国在完善监管框架、化解部分历史风险方面取得的进展，也毫不讳言地指出：在房地产深度调整、地方政府债务压力之下，系统性风险正在显著上升，潜在脆弱性不断累积。报告的核心关切集中于风险定价机制的扭曲、损失确认的滞后，以及危机管理框架的缺失——这些都构成了制约中国金融体系实现中长期稳健运行的深层障碍。然而，正如中国执行董事的声明所凸显的，理解中国金融稳定不能脱离其独特的政策实践和制度背景。在追求短期宏观经济稳定、避免硬着陆与推动长期结构性改革、打破隐性担保、硬化预算约束之间，政策制定者面临着复杂的“政策三元悖论”甚至多元困境。IMF眼中的“风险”延迟暴露，或许在中国政策制定者看来，是为了赢得时间和空间、以更平稳方式化解风险的必要策略。展望未来，中国金融体系的改革重心应逐步从“救火式应对”向“机制性重构”转移：建立市场化损失确认机制，以穿透性数据和审慎监管实现“真实透明”；在法治框架下形成有序的破产与重组路径，打破“刚性兑付”预期；同时，通过强化金融稳定法律基础、改革处置工具箱与危机预案体系，建设真正具有韧性的防火墙。这一过程注定艰难，却不可或缺——未来可能讲更有意思的话，著更其完美的文，做更其壮丽的事业，但今天只是今天，未来也只是今天的未来。制度建设亦然，它不可能在某个“理想的未来”中自动成熟，而只能在每一个“今天”的制度选择与博弈中，一步步得以奠基。真正的韧性，不是来自于无限兜底，而是源于在可控范围内容忍失败、吸收损失、逐步出清的制度能力。中国金融的叙事，将继续在“稳定”与“改革”的张力之中展开；而它的未来，终将取决于我们是否有能力构建一个在复杂博弈中依然能够透明、公正、有效运行的制度秩序。"
  },
  {
    "title": "教书为生，非命为代价：不眠的教培机器与增长困境",
    "summary": "<div class=\"audio-player-container\" data-audio-src=\"https://data.lapis.cafe/api/raw?path=/%E6%92%AD%E5%AE%A2/%E6%95%99%E4%B9%A6%E4%B8%BA%E7%94%9F%EF%BC%8C%E9%9D%9E%E5%91%BD%E4%B8%BA%E4%BB%A3%E4%BB%B7%",
    "tags": [
      "暗涌"
    ],
    "url": "/posts/Finance and Economics/education-growth-cost/",
    "date": "2025-05-08T00:00:00.000Z",
    "content": "<div class=\"audio-player-container\" data-audio-src=\"https://data.lapis.cafe/api/raw?path=/%E6%92%AD%E5%AE%A2/%E6%95%99%E4%B9%A6%E4%B8%BA%E7%94%9F%EF%BC%8C%E9%9D%9E%E5%91%BD%E4%B8%BA%E4%BB%A3%E4%BB%B7%EF%BC%9A%E4%B8%8D%E7%9C%A0%E7%9A%84%E6%95%99%E5%9F%B9%E6%9C%BA%E5%99%A8%E4%B8%8E%E5%A2%9E%E9%95%BF%E5%9B%B0%E5%A2%83.wav\">\n  <h3>教书为生，非命为代价</h3>\n  <audio controls></audio>\n  <p class=\"audio-caption\">你也可以在这里收听本文的AI播客版本</p>\n  <a href=\"#\" class=\"audio-download\">下载音频</a>\n</div>4月24日，一位年仅二十六七的年轻老师在武汉光谷猿辅导公司工作时猝死。当然，这对于教培行业来说不是第一次，也恐怕不是最后一次。一个原本理论上应当孕育着希望与智慧的行业却有越来越多的老师在这些”非人的节奏“中耗尽生命，而这一切只为支撑起教培机构和资本市场眼中那套永不停歇的增长曲线。本文无意渲染情绪，更无意消费个体的悲剧。我只是试图拨开“过劳”这一表象，去触摸背后那套运转迅猛却日渐失衡的系统——它为何必须高速运转？又为何在增长的尽头，竟要以人的生命为代价？前言因为本文的专业性相对较强，且篇幅较长，我深知并非每位读者都有充裕的时间通读全文。因此，我特设此导读，希望能帮助您在短时间内把握文章的核心脉络与主要观点。如果您时间有限，可以通过阅读以下各部分的简要介绍，快速了解本文的探讨路径与核心结论：第一部分：资本视角下的教培产业结构本部分将带您回顾“双减”政策前后，资本如何深度介入并塑造了教培行业的格局。我们将分析从资本催熟的“黄金时代”到政策冲击下的“结构重塑”，揭示行业在资本驱动下形成的结构性压力，这是理解从业者“过劳”现象的宏观起点。如果你不想看冗长的主要玩家分析，可以直接跳到第二部分。第二部分：一门“教育”生意的资本公式（盈利逻辑）在这一部分，我们将为您拆解一家典型教培机构（尤其是在线教育）的“增长公式”。通过剖析LTV（用户生命周期价值）最大化与CAC（用户获取成本）及运营成本压缩的核心逻辑，您将看到“教育”这门生意在资本眼中是如何被量化、计算，并最终在“双减”后如何将压力传导至“人效”的极致追求。第三部分：资本公式下的「异化」：当数字压倒一切本部分聚焦于资本公式对教育本质的“异化”。我们将探讨在LTV、续报率等KPI驱动下，教育使命如何偏转，教师如何在教学与“销售”角色间挣扎，学生与家长又如何被“数据化”和“被操纵”，以及机构内部“增长拜物教”的形成。第四部分：剖析“不眠的机器”：过劳常态化的内部机制与文化这里，我们将深入教培机构内部，剖析其“不眠机器”得以运转的具体机制。从以续报率为核心的KPI体系，到标准化与效率至上的原则，再到无处不在的“增长文化”与“狼性文化”，您将看到这些因素如何共同作用，将从业者推向了过劳的常态。第五部分：教育的尽头不是增长：如何理解这架“机器”的未来最后，我们将跳出对个体或机构的简单指责，从更宏观的视角探讨教培困境的本质。本文认为，核心在于“代价”的转移与分配逻辑。在资本退潮后，原本由资本泡沫承担的部分代价，如何转移至机构、从业者乃至家庭身上。并由此反思，教育的未来不应仅仅是增长数字的比拼，而需要行业进行深刻的价值重构。我们希望，即便您只阅读这篇前言提要，也能对这台“不眠的教培机器”的运作逻辑、增长困境及其深层原因有一个相对清晰的认知。当然，若时间允许，我们更鼓励您完整阅读全文，以获得更深入、更全面的洞察。一、资本视角下的教培产业结构要理解今日教培从业者所承受的巨大压力，我们首先需要跳出个体经历，从更宏观的产业结构层面进行审视。特别是要理解资本在其中扮演的角色——资本既是驱动增长的燃料，又是塑造整个行业形态与竞争规则的关键力量。教培行业的现有格局并非自然演化的结果，而是在过去十余年间，资本高强度介入、政策频繁调整、市场急剧扩张的多重力量下，逐步被塑造成一个结构高度集中的系统。在这一过程中，“教育”不再单纯关乎知识的传授，而逐渐演变为一门可被拆解、估值和加杠杆的商业生意。1.“双减”前的狂飙猛进：资本催熟的黄金时代与结构雏形（2015年至2021年）2015年至2021年，“双减”政策出台前，中国课外教培行业正处于资本最为狂热的时期。围绕K12领域（中小学）学生的课外培训和在线教育平台迅速扩张，用户规模与营收同步激增，资本蜂拥而入，催熟了一批估值高速膨胀、融资频次惊人的新兴独角兽。在这一阶段，大型线下培训机构（如新东方、好未来）加速在线化转型和扩张，新兴的在线教育独角兽（如猿辅导、作业帮等）频繁获得巨额融资，甚至出现“一年融资数轮、估值倍增”的现象​。这四家也是我们今天的主角，基本上主导了整个教培市场（1）新东方教育科技集团（新东方）新东方创立于1993年，最初以线下应试与语言培训起家，逐步扩展至涵盖中小学课外辅导、留学咨询与在线教育等多个板块。作为最早接受资本市场洗礼的教培企业之一，新东方可视为行业结构演化的一个缩影。2006年9月，新东方登陆纽交所，成为中国首家赴美上市的教育培训企业。此后其不断扩张业务版图，在全国范围设立实体学校，并通过“新东方在线”等平台拓展线上教学能力。到2019年，“新东方在线”独立在港上市，进一步强化集团的在线化布局。2020年，公司完成港股二次上市，募资超百亿港元，加速推进数字化转型。新东方2006年9月 ：在美IPO，发行价9.5美元，募资逾1.12亿美元，市值约6.4亿美元。新东方成为中国教育培训行业赴美上市第一股。2017–2019年 ：新东方主营业务稳健增长，并投资布局在线教育（拆分新东方在线在港上市）。公司美股市值在此阶段稳步上涨。2020年11月 ：新东方登陆香港交易所二次上市，发行价1190港元，募资净额约98.13亿港元（约合12.6亿美元）。上市后新东方总市值约300亿美元（美股+港股合计）。估值变化 ：2015年新东方美股市值约50亿美元左右；到2020年末美股+港股市值一度超过2000亿元人民币。新东方创始人俞敏洪凭借公司股价飙升，个人财富也水涨船高。（2）好未来教育集团（好未来/TAL Education）好未来的前身是“学而思培优”，成立于2003年，主营中小学课后辅导，以小班教学模式起家，并于2010年在纽约证券交易所挂牌上市。其核心业务围绕K12课外教育，逐步发展出线下小班教学、1对1辅导与在线课程“三位一体”的架构。其中，“学而思”是线下主品牌，而“学而思网校”则代表其在线直播业务。上市之后，好未来持续保持高速扩张步伐，不仅在全国范围内开设学习中心，还大力投资教育科技和相关并购项目（如收购少儿编程平台 CodeMonkey）。2013年，公司正式更名为“好未来”，以体现其“科技驱动教育”的战略定位，并积极转向智能化教育和在线化发展方向。到2020年疫情期间，受在线教育需求激增影响，好未来市值一度攀升至近465亿美元，超越同期的新东方，成为中国市值最高的教育公司之一。2010年10月 ：学而思教育在纽交所IPO，发行价10美元，募资1.2亿美元，市值约6.7亿美元。上市首日市值即突破10亿美元。2013年8月 ：学而思更名为“好未来”，定位科技助力教育，开启投资并购和线上探索的新篇章。2018年 ：好未来市值首次超越新东方，成为中国最具价值的教育公司。2020年10月 ：受疫情催化和在线教育增长影响，好未来美股股价创新高，市值峰值接近500亿美元。2020年12月 ：好未来趁高增发股票并发行可转债，合计募资约33亿美元。此举为其储备充足现金以应对竞争。估值变化 ：2015财年好未来营收约4.3亿美元，市值约30亿美元左右；到2021年初市值一度达到约500亿美元量级，十年间市值增长超过百倍，凸显资本对其增长预期的认可。（3）猿辅导相比起传统机构的转型路径，猿辅导则代表了另一路径——它自出生起便根植于互联网，几乎将教育完全“平台化”。猿辅导成立于2012年，起初依靠“小猿搜题”“猿题库”等工具类产品切入市场，借助拍照搜题与题库服务积累了庞大的用户基础和学习行为数据。2016年品牌升级为“猿辅导”后，企业转型为B2C在线教育平台，全面聚焦K12阶段的大班直播课，采用“主讲老师+助教双师”模式，快速切入主流教培赛道。凭借技术起家、产品矩阵多元、用户获取成本低的优势，猿辅导在2017年后快速启动融资与扩张：用户增长迅猛，收入曲线陡峭，其在与作业帮的头部竞争中逐渐确立“双雄格局”。与此同时，猿辅导在市场投放上展现出典型的互联网打法。自2019年起，公司广告投入爆炸式增长，仅2020年上半年在字节跳动系平台上的单日广告投放即高达3666万元人民币。此外，猿辅导还以赞助《开讲啦》和北京冬奥会等方式强化品牌曝光。这种以“烧钱换规模”的策略带来了高速成长，也使其长年处于亏损状态——截至“双减”前，公司尚未实现盈利。猿辅导也是中国在线教育赛道融资最频繁、金额最大的玩家之一。自2012年起其融资累计超过53亿美元，尤其是2020年一年内三轮融资共筹资32亿美元，估值从年初的78亿美元飙升至年底的170亿美元，成为当年全球估值最高的EdTech公司。猿辅导创始人李勇猿辅导在2015–2021年间共进行了多达10轮融资，累计融资额超过53亿美元。其融资路径和估值演进如下表所示：| 融资时间         | 轮次         | 融资额       | 投后估值       | 主要投资方（部分）                                       |\n| ------------ | ---------- | --------- | ---------- | ----------------------------------------------- |\n| 2012年8月      | A轮         | 1000万人民币  | -         | IDG资本（唯一投资方）                                    |\n| 2013年8月      | B轮         | 700万美元    | -         | 经纬中国、IDG资本                                      |\n| 2014年7月      | C轮         | 1500万美元   | -         | 经纬中国、IDG资本                                      |\n| 2015年3月      | D轮         | 6000万美元   | -         | 华人文化产业基金、新天域资本等                                 |\n| 2016年5月      | D+轮        | 4000万美元   | -         | 腾讯（战略投资）                                        |\n| 2017年5月      | E轮         | 1.2亿美元    | 10亿美元      | 华平投资（PE）领投，腾讯跟投                                 |\n| 2018年12月     | F轮         | 3亿美元      | -         | 腾讯领投，华平、经纬、IDG等跟投                               |\n| 2020年3月  | G轮     | 10亿美元 | 78亿美元  | 高瓴资本领投，腾讯、博裕、IDG等参与                             |\n| 2020年10月 | G1+G2轮 | 22亿美元 | 155亿美元 | G1：腾讯领投，高瓴、博裕、IDG等   G2：DST Global领投，GIC、淡马锡等参与 |\n| 2020年12月     | 战略融资       | 3亿美元      | 170亿美元     | 云锋基金（马云旗下基金）等                                   |猿辅导自2016年起几乎每年都有融资进账，特别是2020年一年内融资总额高达32亿美元，估值从年初的78亿美元飙升至年底的170亿美元。顶级风投和互联网巨头纷纷押注：如腾讯自D+轮起多轮加码，高瓴资本、DST、GIC、淡马锡等国内外资管巨头先后入局。猿辅导也由此在2020年一举成为全球估值最高的教育科技初创公司。（4）作业帮作业帮创立于2015年，是另一家从工具类产品起步、最终跻身K12在线教育第一梯队的独角兽企业。其最初依靠拍照搜题功能在中小学生群体中迅速积累用户，借助“作业帮”App打通题目搜索、解析与互动答疑流程，形成早期流量闭环。在此基础上，公司陆续推出作业帮直播课（大班课）、作业帮口算、作业帮一对一等产品矩阵，覆盖小学至高中全学科辅导，并同样采用“双师模式”优化教学效果。作业帮作业帮由前百度团队创立，天然具备互联网产品基因。成立当年即获A轮融资，此后在2016至2018年间连续完成多轮融资，用户规模呈指数级增长。凭借其强大的搜索技术和精准推荐算法，作业帮成为国内用户覆盖最广的在线教育平台之一。自2019年起，作业帮加速发力直播课业务，迅速与猿辅导展开正面竞争。在获客层面，作业帮凭借工具类产品所构建的庞大流量池，在下沉市场拥有显著优势。截至2020年，公司累计激活用户已超8亿，付费用户达数百万，连续多年入选教育行业影响力品牌榜。相较于猿辅导的“高举高打”策略，作业帮更侧重低客单价 + 高转化效率，依托技术和精细化运营提升ROI。创始团队大多出身互联网行业，对产品与数据迭代极为重视。虽然其市场推广亦不吝投入——包括综艺冠名、大量线上投放、与地方电视台合作等——但在单位获客成本上，作业帮相对更为克制。在三线以下城市与低龄段用户中，作业帮展现出极强的渗透能力，成为猿辅导之外最具竞争力的对手。在资本层面，作业帮的发展路径几乎与猿辅导并驾齐驱。从早期即获得红杉资本等头部VC支持，融资节奏高度同步。2018年底，其估值即突破30亿美元，正式跻身独角兽行列。2020年，公司分别完成E轮和E+轮融资，总金额高达23.5亿美元，投资方阵容扩展至阿里巴巴、软银愿景基金等全球巨头。据业内估算，作业帮在2020年底的投后估值已接近百亿美元，与猿辅导共同稳居K12在线教育估值榜前列。其主要融资事件如下：| 融资时间       | 轮次         | 融资额       | 投后估值            | 主要投资方（部分）                              |\n| ------------ | ---------- | --------- | ---------------- | ------------------------------------ |\n| 2015年9月      | A轮         | 2500万美元  | -               | 红杉资本中国、君联资本                       |\n| 2016年8月      | B轮         | 6000万美元  | -               | 纪源资本(GGV)、襄禾资本、红杉、君联        |\n| 2017年8月      | C轮         | 1.5亿美元   | -               | H Capital、老虎基金、红杉等                  |\n| 2018年7月      | D轮         | 3.5亿美元   | -               | Coatue、高盛、春华资本等                     |\n| 2018年10月     | D+轮/E轮?   | 5亿美元     | -               | 软银中国资本（领投）                         |\n| 2020年6月      | E轮         | 7.5亿美元   | 约65亿美元       | 方源资本、Tiger Global、卡塔尔投资局       |\n| 2020年12月     | E+轮        | 16亿美元    | 约95亿美元       | 阿里巴巴、Tiger Global、软银愿景基金、红杉中国 |（5）高途高途（原名“跟谁学”）成立于2014年，由新东方前高管陈向东创办，最初以C2C在线教育平台起家，旨在撮合学生与个体教师。但该模式发展受限，平台在2017年前后战略性转型，全面进军K12在线直播大班课赛道，并推出“高途课堂”品牌，主打“名师授课 + 辅导老师跟进”的双师模式，与猿辅导、作业帮形成正面竞争。与其他教育独角兽不同，高途在资本路径上走得极为迅猛。公司在仅完成一轮私募融资后，便于2019年6月成功赴美上市，发行价10.5美元，募资约2.08亿美元。彼时公司以“首家盈利的在线教育平台”自居，确实凭借较高的获客效率和成本控制，在上市前后连续多个季度实现盈利，成为烧钱成风的行业中少有的“盈利范本”。2020年初，受在线教育热潮和疫情催化影响，高途股价暴涨，市值一度突破210亿美元，涨幅超10倍，成为仅次于好未来的中国第二大教育公司。然而，其“接近完美”的增长数据也引发市场质疑。自2020年起，高途接连遭遇15次做空报告围攻，质疑其存在刷单、营收夸大等问题。尽管公司坚决否认并进行内部审计，但市场信心仍受到冲击。面对猿辅导、作业帮的高额市场投放压力，高途自2020年下半年起也加入“烧钱大战”。第三季度单季销售费用高达20.56亿元，同比增长522%，直接导致公司当季转盈为亏（净亏损9.3亿元）。为应对激烈竞争，公司于2020年12月定向增发融资8.7亿美元，资金主要用于加码高途课堂的师资储备、技术研发和市场拓展。高途高途的发展轨迹堪称行业资本逻辑的缩影——前期依靠极致效率实现快速盈利，后期则为守住市场地位不得不重金扩张，终被迫卷入融资–烧钱–亏损的循环。2015年3月 ：获得A轮5000万美元融资（真格基金、启明、华创等参与），这一巨额A轮在当时创下教育行业之最。值得一提的是，跟谁学在此之后并未进行更多私募轮融资。2019年6月 ：登陆美股纽交所，IPO发行价10.5美元，募资约2.08亿美元，首日收盘市值约28亿美元。IPO被视为一级市场投资人的成功退出。2020年7月 ：股价飙升至近100美元高点，公司市值突破200亿美元。创始人陈向东所持股份市值一度超过百亿美元，跟谁学成为市值增长最快的中概股之一。2020年12月 ：面临激烈竞争和亏损局面，跟谁学宣布定向增发新股，获得8.7亿美元资金，发行股份占增发后公司总股本约6.2%。据此推算增发时公司估值约14亿美元，反映股价已较高点大幅回落。估值变化 ：跟谁学从2015年估值不到3亿美元的初创公司，在2020年初达到市值百亿美元量级的巅峰，随后因做空风波和行业竞争，市值在“双减”前已出现明显波动下滑。但总体而言，其用6年时间走完了“A轮融资—上市—市值冲高”的传奇历程。（6）资本市场融资进程总结在互联网黄金时期，资本的逻辑是规模优先，赢家通吃，教培企业被视为通往用户流量与平台化潜力的入口。在这样的逻辑下，融资不仅是企业生存手段，更成为行业“马太效应”的放大器。2015至2021年，中国课外教培行业迎来一轮波澜壮阔的资本盛宴，尤其在2018–2020年达到顶峰。据网经社数据，2020年中国在线教育共发生111起融资事件，尽管数量同比下降近三成，但融资总额却飙升至539亿元人民币，同比增长267%，创下历史新高。这一年度的融资金额，甚至超过了2016至2019年四年的总和。而资本更集中地流向了头部平台：2020年十大融资案例中，前四笔全部被猿辅导与作业帮瓜分，合计金额高达55.5亿美元，占全年前十融资总额的82%。“两极吸金”的格局基本确立，巨头几乎垄断了赛道资源。 而即便是已上市的教育巨头也未错过这波红利：好未来通过增发与可转债筹资约33亿美元，新东方借港股二次上市募资超110亿港元，高途则完成了8.7亿美元的定增。资本梳理这个时期的教培产业，被深刻地烙上了资本的印记：它追求速度、崇尚规模、容忍亏损（以期未来垄断），并将教育服务一定程度上商品化、流量化。这种结构为后续的“不眠机器”奠定了基础——庞大的组织架构、对增长的路径依赖以及初步形成的“效率至上”文化，该时期的特点主要如下：高度竞争与产品同质化：头部机构在广告、地推、体验课等方面毫无下限地“卷”，教育产品趋于“名师+低价+科技辅助”的标准模板。烧钱换增长：盈利被搁置，市场份额成为唯一KPI。巨额亏损换取用户增长与高估值已成行业“共识”。结构两极化：资本向巨头集中，中小机构要么被并购，要么退场，行业呈现出“哑铃型”格局——巨头高耸，腰部稀薄，底部混乱。就像战锤40K里的大只佬教新兵回忆黄金时代，双减之后的教培老兵们有时也会感慨：“你知道吗，那时候我们晚上加班打车是可以报销的，办公室有咖啡机，午餐不用自己掏钱……2.“双减”后的骤然转向：结构重塑与新战场后来的事我们都知道了：2021年7月，“双减政策”正式出台。（1）核心业务的坍塌与“大撤退”“双减”政策的出台，对以K12学科培训为核心的教培产业结构带来了颠覆性的冲击。资本逻辑赖以生存的基础——学科类培训的营利性被政策直接否定。原本依靠“规模+转化”滚动增长的商业闭环被强行中断，行业在一夜之间从“烧钱竞速”被迫切换为“降速求稳”。电视剧《小舍得》剧照政策落地后的数月内，大批K12学科类业务被迫关停、转型或剥离。头部企业如新东方和好未来高峰时期积累的庞大教学、教研、运营、销售、技术、市场团队迅速被“优化”，员工流失率创历史新高。中小机构更是在缺乏资金缓冲的情况下快速退出市场。二级市场上，中概教育股股价断崖式下跌，新东方、好未来、高途等市值一度蒸发超过90%。一级市场上，未上市的独角兽（如猿辅导、作业帮）估值大幅缩水，后续融资基本停滞，曾经炙手可热的赛道瞬间冷却。资本从狂热追捧转为迅速撤离，进一步加剧了行业的资金困境。这一时期，教培行业经历了大规模的裁员、业务关停和市值暴跌，进入了一场系统性去杠杆与主动性去泡沫的震荡周期。（2）艰难的转型面对主营业务的政策性“死亡”，幸存下来的教培机构被迫在废墟之上寻找新的生机，主要的方向有以下几个：素质教育（非学科培训）：这是最自然的延伸方向，包括艺术、体育、编程、科学素养、口才、研学等。新东方成立了“素质成长中心”，好未来推出了“学而思素养中心”，猿辅导则孵化了“南瓜科学”等。但素质教育市场本身规模有限、付费意愿相对较低、标准化难度大、竞争同样激烈，难以完全承接原有K12学科业务的体量。成人教育与职业培训：面向大学生和职场人士的考研、考公、职业技能、语言培训等成为另一个重点。新东方在这方面有传统优势，其他机构也纷纷加码。但这同样是一个成熟且竞争充分的市场。教育科技与智能硬件：利用前期积累的技术和数据，转向教育信息化（To B/To G，服务学校或政府）或开发智能教育硬件（如学习平板、词典笔、智能台灯）。好未来的“美校”平台、猿辅导的“小猿学练机”、作业帮的“喵喵机”等均属此类。硬件是重资产投入，且面临科技公司的跨界竞争。出海与国际教育：部分机构尝试将国内模式复制到海外市场，或拓展留学服务。直播带货及其他跨界尝试：最引人注目的当属新东方的“东方甄选”，凭借知识型带货意外出圈，但这具有高度偶然性，难以被其他机构大规模复制。（3）新特征”双减“之后，原本的全国性、大规模和标准化的K12学科培训巨头格局被瓦解，市场变得更加分散和区域化。大型教培集团往往同时布局素质教育、职业教育、教育科技、甚至直播带货等多个领域，试图“东方不亮西方亮”。但每个新领域都有其固有的挑战和天花板，尚未形成能替代昔日K12学科培训的绝对支柱。在咆哮着冲向IPO的资本引擎熄火之后，失去了资本持续输血和高速增长的预期，骤然的转向使得原本在资本催化下高速膨胀、内部管理相对粗放的教培“巨兽”，不得不在短时间内进行剧烈的“瘦身”和“变形”，教培巨头们的核心逻辑从“不计成本换增长”转变为“极致的成本控制和人效提升”。而这种结构性的压力，最终必然会层层传导至每一个具体的岗位和员工身上。当外部增长空间被锁死，内部的“压榨”几乎成为了维持机器运转的唯一选项。这为理解后续章节中“非人节奏”的形成埋下了伏笔：旧的增长引擎熄火了，新的引擎尚未建立，机器为了维持运转，只能开始消耗自身的零件。结论：结构性压力是理解“过劳”的起点综上所述，教培行业的产业结构，无论在“双减”前后，都深受资本逻辑的影响。从早期追求规模扩张的“增长飞轮”，到后期寻求转型生存的“效率机器”，资本始终是塑造行业形态和竞争规则的核心力量。“双减”之后狂热的外部输血减少，但存量资本的退出需求、新业务的盈利压力以及行业竞争格局的变化，共同构成了一种结构性的压力。这种压力自上而下传导，最终具体化为对每一个基层员工，尤其是教师群体近乎严苛的绩效要求和工作强度。理解了这层结构性的根源，我们才能更好地理解下一章将要探讨的：在这架“机器”内部，一门名为“教育”的生意，其资本公式是如何计算的？它又是如何一步步将“育人”的目标，替换为冷冰冰的增长数字的？二、一门“教育”生意的资本公式（盈利逻辑）上一章我列举了教培市场的主要玩家，和整个市场的起落沉浮。现在让我们更进一步，拆解一家典型的教培机构（尤其是在线教育机构，因其更依赖标准化的数据驱动模式），看看它的“盈利”，或者更准确地说，在资本市场眼中“增长潜力”的公式是如何被构建和计算的；观察这套公式是如何将“育人”这一复杂且难以量化的过程一步步拆解、简化，最终异化为冷冰冰的财务和运营指标。核心公式：企业价值 ≈ 市场规模 x 渗透率 x (LTV - CAC) / (1 + 折现率)^n对于资本市场而言，一个企业的价值（尤其是成长型企业）往往与其未来的现金流创造能力和增长潜力挂钩。简化来看，我们可以将教培机构的运营逻辑拆解为以下几个核心要素的相互作用：1.「开源」的魔法：最大化追求 LTV（用户生命周期价值）LTV（Lifetime value，用户生命周期价值）是衡量每个用户在未来可能为企业带来的总收入。在教培行业，尤其是K12阶段，LTV的想象空间一度非常巨大。一个学生从小学一年级到高三，理论上可以持续付费12年。那么，作为教培企业应该如何提高LTV呢？主要有以下几个关键杠杆：（1）客单价(ASP - Average Selling Price per Order 或 ARPU - Average Revenue Per User)顾名思义，客单价就是每一位顾客可以付费的单价。一般提升这类指标有三种方法：课程单价：通过打造名师、精品课程、小班课等形式提高单期课程的价格。但“双减”后监管部门直接锁死了课程价格，所以目前这种方法已经不再那么有效了。课程包/组合销售：鼓励用户一次性购买多科目、多学期课程，提前锁定收入（这个是最常见的）增值服务：教辅材料、答疑服务、专属辅导。目前大家都处于卷生卷死卷服务的状态，一般不会在这里压榨利润点。（2）续报率/复购率 (Renewal/Repurchase Rate)诶！这是LTV计算中最为核心也最为残酷的一环。一个班级的续报率高低，直接决定了机构能否以较低成本持续获得收入。因此，续报率往往是压在授课老师、班主任（辅导老师）身上最重的KPI。它被视为教学质量、服务水平、用户满意度的直接体现，也是机构“锁客”能力的关键。一般来讲，教培机构的员工如果猝死的话那也就大概率会在一年四次左右的续报期了猿辅导（3）用户生命周期时长（Customer Lifespan）向上/向下拓展： 从低年级向高年级延伸，或从学前向小学延伸。扩科： 引导学生从单一学科（如数学）扩展到多学科（如数学+英语+物理）。（4）转介绍率（Referral Rate） 俗称“老带新”，通过现有用户的口碑推荐获取新用户，这部分用户的CAC（用户获取成本）极低。在“双减”前，资本市场对LTV的预期极高，认为在线教育可以凭借技术优势和规模效应，不断提升这些杠杆的效率。而“双减”后，K12学科培训的LTV基本归零。机构转向素质教育、成人教育等领域，LTV的计算模型需要重构，但其核心逻辑——尽可能从单个用户身上获取更多、更持久的收入——并未改变。2.「节流」的艺术：CAC（用户获取成本）与运营成本的极致压缩如果说LTV用户生命周期价值是“做大蛋糕”，那么成本控制就是“少分蛋糕”，以期留下更多利润。（1）用户获取成本 (CAC - Customer Acquisition Cost)在“双减”前，这是教培机构，尤其是在线教育公司烧钱最凶猛的地方。巨额的营销投入（广告、地推、电销、体验课）是常态。行业普遍共识为，先通过烧钱换取市场份额，形成垄断或寡头效应后，再通过规模效应降低CAC，并通过高LTV实现盈利。这导致了“营销大战”，CAC一度高企不下。双减之后，外部大规模买量变得不可持续，降低CAC成为生死线。目前教培机构的主要手段包括：私域流量运营： 更加依赖自有APP、公众号、社群等进行用户沉淀和转化。口碑与转介绍： 依赖优质内容和服务驱动自然增长。内容营销： 通过短视频、直播等低成本方式获客。渠道合作： 与学校、其他机构等进行合作导流。（2）运营成本在运营中，最核心也是最大的成本项之一也就是 师资成本。为了压缩这部分成本，机构（在业内以学而思为例）通常会采用标准化教研的方式减少对顶尖名师的依赖，即相关课件课程设计由总部教研团队来承担，设计完成之后下发到全国分部，授课老师只作为一个合格的传声器即可。在线上平台，普遍采用大班课模式，一位老师服务更多学生（200-300人），摊薄单位学生成本；同时还会设置“双师”，即主讲老师+辅导老师模式，讲老师负责授课，薪资较高；辅导老师（班主任）负责课后答疑、作业批改、督学、续报沟通等，薪资相对较低，但工作强度极大，兼顾教学、服务和续报三方面职能。从教师的薪资结构角度考虑，目前教培机构普遍采用极低的底薪（一般和当地最低工资持平）+强绩效（与课时量、班级人数、续报率、好评率等挂钩），可有效降低五险一金的缴纳成本，也未尝不是另一种雇佣员工与机构博弈后的平衡解。3.盈利的平衡木：LTV > CAC 是生存底线，规模化盈利是目标一个健康的商业模式，必须保证 LTV > CAC。简单来说，从一个用户身上赚到的钱，必须大于获取这个用户所花费的成本。LTV/CAC的比率是衡量获客效率和盈利能力的关键指标，一般认为，LTV/CAC > 3 是一个比较理想的状态。在“双减”政策落地之前，在线教育行业普遍处于一种“流血换增长”的状态，即长期处于 LTV < CAC 或 LTV ≈ CAC 的状态。尽管如此，资本市场仍然容忍甚至鼓励这种模式的存在，因为投资者相信，随着企业规模的扩大，市场份额的提升，企业最终可以凭借规模效应和市场垄断地位显著提高LTV、降低CAC，从而实现盈利。这种模式下，增长速度和市场份额是最重要的指挥棒。然而“双减”政策实施后，在线教育行业的外部资金输血迅速断绝，原本赖以为生的K12学科培训业务的LTV迅速崩塌。在此情形下，机构必须在新的业务领域迅速跑通 LTV > CAC 的模型，并且是健康的、可持续的盈利模型，而非依赖融资输血。这种模式不仅要求机构快速验证新业务的PMF，推出用户愿意长期付费并能产生正向现金流的产品，还需要机构在运营成本控制方面做到极致，使每一分钱都花得精准且高效。同时，由于市场投入预算大幅缩减，企业不得不将提高续报率、扩科率和用户转介绍作为增长的关键策略，这种策略极大地依赖于一线教师和运营人员长期超负荷的工作，导致机构内部“人效”的压榨被推至极致。三、资本公式下的「异化」：当数字压倒一切上面我们提到的核心公式：企业价值 ≈ 市场规模 x 渗透率 x (LTV - CAC) / (1 + 折现率)^n 在资本眼中，清晰、理性、可量化、可优化。然而，当这套冰冷的逻辑开始主导一个以“人”为核心，以“育”为目标的行业时，“异化”便不可避免地发生了。最直接的，就是教育使命本身的偏转。当然我觉得我们其实也不能奢求所谓资本驱动下的教育真的能多有良心在LTV（用户生命周期价值）最大化的驱动下，课程的设计与教学的安排的首要考量的已不再是如何最好地促进学生的长远发展与心智成熟，而是如何更有效地提升续报率、扩科率这些直接关乎利润的数字。一期课程在结束前（很多时候续报工作在一期课程的中间就开始了）必须要巧妙地埋钩子，暗示下一期课程的重要性，教育内容被人为切割、重组，只为精准服务于一个个续报周期。老师的授课技巧中，除了知识传递，还被植入了大量“促续报”的话术和引导。身处这架机器核心的教师们，则最深切地感受到了这种异化带来的撕裂感。为了快速起量、降低边际成本，课程被高度标准化、模块化，如同工业流水线上的产品。老师的个性化教学风格被压缩，创造性空间受限，更多时候是执行标准化的教学流程。他们的价值不再仅仅通过传道授业解惑来体现，而是越来越多地被续报率、满班率、好评率乃至转介绍率等一系列KPI数字所定义，这些数字直接与他们的薪酬、晋升甚至饭碗紧密相连。续报的疯狂于是，讲台上的师者，在教授知识的同时，也不得不时刻扮演起“销售顾问”的角色，在每一个可能的节点，运用精心设计的话术，旁敲侧击地引导续报、扩科。这种身份的错位与精神的内耗，给许多怀揣教育理想的教师带来了巨大的心理压力和职业认同危机。尤其是承担着大量课后服务与续报任务的辅导老师或班主任岗位更是集中体现了这种异化。他们往往薪资不高，却要承担答疑解惑、作业批改、学习进度跟踪、家校沟通、情绪安抚，以及最重要的——续报指标的直接背负者。他们成了维系LTV链条的关键齿轮，是机构眼中提升“人效”、压缩服务成本的“超级工具人”，日复一日地进行着高强度的情感劳动。而这种本应自然流露的师生关怀，一旦未能有效转化为续报数字，便可能被系统视为一种“无效付出”。在这套资本公式的审视下，学生和家长也难以幸免于被“数据化”和“被操纵”的命运。学生不再仅仅是一个个鲜活的、对知识充满渴望的个体，而更多地被视为LTV的承载单元，是需要通过各种运营手段（如精准推送学习报告、限时优惠组合、 被老师和销售顾问制造的“危机感”营销）来不断挖掘价值的“用户档案”。他们的每一次点击、每一次互动、每一次答题，都化为冰冷的数据流，被系统收集、分析，表面上是为了实现“个性化推荐”与“精准辅导”，深层次里却是为了更精准地预测其续报可能性，并针对性地施加营销影响。家长的焦虑，则成了教培机构眼中可以被精准捕捉并巧妙“变现”的宝贵资源。通过不断强化“不能输在起跑线上”的社会叙事，或巧妙地利用同伴间的比较心理，机构有效地刺激着家长的付费意愿，将教育消费推向一个又一个看似理性的高峰。当LTV、CAC、续报率、增长率这些数字成为衡量组织健康度乃至生存权的唯一或核心尺度时，它们便被赋予了至高无上的地位，甚至在机构内部演变成一种深入骨髓的“增长拜物教”。为了短期内数据的好看，尤其是在关键的融资节点或财报发布期，机构可能不惜采取竭泽而渔的方式，过度营销、过度承诺，在无形中牺牲着长期的品牌口碑与用户信任。在“唯KPI论英雄”的文化氛围下，那些能够迅速带来漂亮数据的行为模式和个人往往会得到即时奖赏与快速晋升，而那些坚守教育良知、注重长远育人效果但短期内无法贡献亮眼KPI的理念和做法，则可能被无情地边缘化，甚至被系统视为“低效”而加以优化。这种机制使得整个组织向着“数字最优化”的方向加速内卷，内部竞争也因此变得异常残酷。部门之间、团队之间，甚至老师个体之间，都可能为了争抢有限的生源或更高的续报指标而陷入零和博弈的紧张关系，进一步消磨着教育应有的协同与温情。四、剖析“不眠的机器”：过劳常态化的内部机制与文化一般来说，资本对人与机构的异化是贯彻骨髓的，系统性的异化，是通过一套精密设计、层层加固的内部机制与特定文化，渗透到教培机构的日常运营之中，最终将从业者，尤其是教师，裹挟进一个高速旋转却令人窒息的系统。从最关键的指标设计来看，最有效的就是以续报率为核心的KPI（关键绩效指标）体系，它如同一根无形的指挥棒，精准而严厉地校准着机器的每一个动作。在教培行业，特别是“双减”之后，当外部获客成本高企且增长空间受限，存量用户的价值便被推至前所未有的高度。续报率，作为衡量用户留存和LTV（用户生命周期价值）最直接的指标，自然成为了考核体系中的“王冠明珠”，甚至在许多机构演变为一种具有“一票否决权”的生死线。一个班级的续报率高低，不再仅仅是教学质量的反馈，而被视为教师综合能力的终极体现——囊括了教学效果、服务水平、沟通技巧乃至“销售”潜能。于是，围绕这一核心指标，衍生出月度排名、季度考核、末位警示乃至淘汰的严酷机制。这种压力从管理层层层传递，最终如巨石般压在每一位一线教师，尤其是承担大量课后服务与续报沟通的辅导老师或班主任身上。他们不仅要在教学上尽心尽力，更要在续报期化身为不知疲倦的“客服+销售”，其薪酬、晋升乃至职业安全感，都与那跳动的续报百分比紧密相连。然而，KPI的“指挥棒”并非只有续报率这一根。一张由满班率、扩科率、课消（课程消耗）、家长满意度评分、转介绍数量，甚至包括社群活跃度、互动评论数等构成的细密网络，将教师的工作包裹得密不透风。 这种“量化一切”的冲动，源于资本对确定性增长的渴求和对运营效率的极致追求。教育这一本应充满人文关怀与个性化差异的过程，被迫切割为一个个可被追踪、被衡量、被优化的数据节点。教师的每一项工作内容，从课前预习提醒到课后作业批改，从家长群的日常互动到特定节点的续报宣讲，都被赋予了明确的量化目标和考核权重。这种机制固然在一定程度上提升了运营的标准化与效率，但也无情地将教师推向了“数据工人”的境地，使其在繁复的数字游戏中疲于奔命，而真正关乎“育人”的深层思考与情感投入，则可能因难以量化而被系统性地忽视。与KPI体系相辅相成，“标准化”与“效率至上”的原则共同构筑了这部机器的“流水线”。为了快速复制、规模扩张并降低对少数“名师”的依赖，教培机构（尤以大型连锁和在线平台为甚）普遍推行高度标准化的教研与教学体系。课程内容、教学课件、授课流程、互动环节乃至话术脚本，都由总部教研团队统一研发和规定。一线教师的主要职责，从某种意义上讲，是成为这套标准化体系的精准执行者和高效传递者。这种模式在一定程度上保证了教学质量的下限和规模化复制的可行性，但也像一个“标准化的囚笼”，压缩了教师的教学个性和创造性发挥的空间。在此基础上，“双师模式”（主讲老师+辅导老师/班主任）的广泛应用，更是将“效率至上”推向了极致。主讲老师负责核心授课，凭借其专业性与表现力吸引学生；而数量更为庞大、薪资相对更低的辅导老师，则承担了繁重的课后服务工作——答疑、作业批改、学习跟踪、家校沟通、情绪安抚，以及最为关键的续报指标。辅导老师群体成为了维系LTV链条、压缩人力成本、提升“人效”的关键节点，他们往往是机构内部工作强度最大、压力最重、情感劳动透支最为严重的一群人。同时，各类技术工具，如CRM系统、教学管理平台、数据分析后台等，在“赋能”教学管理、提升运营效率的同时，也无形中成为了精细化监控与量化考核的利器，让教师的每一个工作环节都处于系统的“注视”之下。如果说KPI是指挥棒，标准化是流水线，那么无处不在的“增长文化”与“狼性文化”则是驱动这台机器持续高速运转的“燃料”与“润滑剂”。在资本的强力驱动下，“增长”被奉为圭臬，成为衡量一切工作的首要标准。机构内部充斥着“拥抱变化”、“使命必达”、“客户第一（但要续报）”、“业绩为王”等口号。为了激发员工的“潜能”，各种形式的内部竞争被制度化，如公开的业绩龙虎榜、频繁的表彰大会与惩罚机制，营造出一种“不进则退，慢进也是退”的紧张氛围。所谓“狼性精神”，在很多时候异化为对无休止加班的默许、对高压竞争的认同，以及对个人生活空间的极致压缩。“奋斗者”叙事被巧妙地用于合理化超负荷的工作状态，使得员工即便身心俱疲，也可能因担心被贴上“不努力”、“不合群”的标签而选择默默承受。这种文化氛围下，个体的教育理想与职业尊严，往往在集体性的增长狂热中被消磨殆尽。而教师，尤其是辅导老师，所付出的大量情感劳动——安抚焦虑的家长、激励倦怠的学生、维系脆弱的师生关系——在这种重数字、轻人文的文化中，其价值往往难以得到充分的承认与回报，最终导致普遍的职业倦怠与意义感的失落。这一整套内部机制与文化，最终物化为教培从业者“不眠”的时间表与“非人”的工作节奏。对于许多教师而言，一个典型的续报周期往往意味着每日超过12小时的工作时长是家常便饭。清晨，他们可能就要开始回复前一晚积压的家长信息；白天，除了数小时的授课，还要投入大量时间进行备课、磨课、批改作业、组织线上答疑；傍晚和深夜，则是与家长沟通的黄金时段，既要反馈学生学习情况，又要巧妙铺垫续报的必要性与紧迫感。周末和节假日，往往是课程最密集、续报冲刺最关键的时刻，休息成了一种奢望。电话不敢轻易静音，微信消息提示音此起彼伏，个人的生活完全被工作切割得支离破碎。因此，我们看到，教培行业的“过劳”并非孤立的个体现象，而是源于一套精心构建、环环相扣的内部系统。这套系统以KPI为牵引，以标准化为路径，以“增长文化”为驱动，将每一个身处其中的人，都变成了这架“不眠的机器”上一个高速运转的零件。机器轰鸣作响，创造着资本眼中亮眼的增长数据，却也可能在不经意间，碾压着个体的健康、情感与最初的教育梦想。五、教育的尽头不是增长：如何理解这架“机器”的未来什么，难道你以为看到这里，我终于要鼓吹自由竞争全面放开教培市场了吗？做什么梦呢，我又不是既得利益者，家里也没有小孩要鸡。教培这台“不眠的机器”的困境，以及它所引发的种种问题，远非一句“市场化”或“去市场化”就能简单概括或解决的。它背后牵扯的是教育资源分配、社会焦虑传导、以及资本逻辑与公共利益的深刻博弈。一个残酷的现实是：在现有的社会结构与资源分配格局下，教育的“复杂性”与随之而生的“代价”，并不会因为某种政策或模式的改变而凭空消失，它只会在不同的主体之间被巧妙地转移和重新分配。双减政策实行之前的教培产业风风光光和老师们拿钱拿到手软当然不是因为资本良心，而是那会有汹涌的资本热钱源源不断地涌入，充当了整个体系的“润滑剂”与“缓冲垫”。在那个“增长就是一切”的黄金时代，资本愿意为高昂的营销费用买单，为教师（尤其是名师）的溢价薪酬买单，甚至为一时的亏损买单，赌的是未来的垄断地位和更高的LTV（用户生命周期价值）。彼时，一部分“代价”是由风险投资和二级市场上的股民们承担的，他们用真金白银支撑着教培机构不计成本的扩张与获客大战。家长们虽然也付出了不菲的学费，但至少在选择面上相对丰富，优质师资的供给也因资本的催化而显得充裕。教师们虽然也承受着KPI压力，但高薪的诱惑和行业上升期的红利，在一定程度上也对冲了部分辛劳。然而，当“双减”的铁锤落下，资本的潮水迅速退去，这套原本依赖外部输血来维持平衡的系统便骤然失稳。资本不再愿意（也不能）为学科培训的“代价”买单了，政策也明确禁止了学科类培训的营利性。那么，这部分原本由资本和市场泡沫所吸收的“代价”——包括对优质教育资源的渴求、对升学竞争的焦虑、以及维持庞大教研教学体系的成本——便开始寻找新的承载者。首当其冲的，便是教培机构自身及其从业者。失去了资本的持续供养，机构必须在极短的时间内实现自我造血，而且是在业务范围大幅受限、合规成本显著增加的前提下。于是，我们看到了前文所述的对内极致的成本压缩与“人效”压榨。教师们，尤其是那些转型到非学科培训或依然坚守在合规业务一线的教师，便直接承受了这部分转移过来的代价：薪资待遇可能不再像过去那般优厚，但工作强度和KPI压力却有过之而无不及，因为机构需要从每一个存量用户、每一个在职员工身上“挤”出利润来维持生存。曾经被高薪掩盖的职业倦怠和身心损耗，此刻便更加赤裸地暴露出来。与此同时，一部分代价也悄然转移回了家长身上，只是形式更为隐蔽和多样。学科类培训被严格限制后，那些依旧对孩子成绩提升有强烈需求的家长，不得不寻求其他途径。合规的非学科培训，如素质拓展、思维训练等，虽然在一定程度上填补了市场空白，但其提分效果的直接性和确定性远不如学科培训，且价格可能同样不菲。更隐秘的“代价”则体现在时间和精力的投入上：一些家长可能需要花费更多时间辅导孩子功课，或者在信息不对称的市场中艰难辨别和寻找合规的、高质量的教育资源。而对于那些有能力、有门路的家庭，高端的“一对一”家教、私下的“小作坊”辅导，甚至某些打着“咨询”、“规划”旗号的类学科服务，则可能成为新的选择，但这无疑进一步加剧了教育资源获取的不平等，将“代价”更多地压向了那些缺乏信息和经济优势的家庭。当“双减”政策强行中断了K12学科培训这条曾经最汹涌的“增长”管道后，许多教培机构试图在素质教育、职业培训乃至智能硬件等新领域复制昔日的辉煌。但问题在于，如果驱动这台机器的底层逻辑——即对短期财务回报的极致追求和对“人效”的残酷压榨——没有根本改变，那么无论切换到哪个赛道，都可能只是将同样的“不眠”模式换一个新的外壳继续上演。素质教育的“育人”周期更长，效果更难量化；职业教育的竞争本就激烈，利润空间有限。若依然沿用过去“烧钱换增长、高压促转化”的逻辑，不仅难以构建可持续的盈利模型，反而可能更快地耗尽新赛道的潜力，甚至将其也拖入过度商业化和信任危机。从这个角度看，“双减”或许也为行业提供了一个被迫“慢下来”反思的契机：资本加持下教育的尽头，真的只能是永无止境的增长数字吗？所以，问题的关键并不在于简单地指责教培机构的“唯利是图”，或是将所有希望寄托于政策的“一刀切”。更重要的是要认识到，在教育这盘棋局中，每一个参与者——无论是焦虑的家长、迷茫的学生、疲惫的教师，还是逐利的资本、调控的政府——都在这个复杂系统中相互作用，共同承担着某种“代价”。当机构将成本和压力极致地转移到教师身上时，我们看到了生命的耗损和教育的变形；当政策试图压制机构的过度扩张时，部分家长的焦虑可能无处安放，又会以其他形式（如“一对一”家教、高端“私订”）寻找出口，进一步加剧教育资源分配的不均。因此，当我们审视教培行业的困境时，不能仅仅停留在指责资本的无情或政策的突兀。更应该看到，这背后是一个复杂社会系统中“代价”不断流转的过程。“双减”在试图减轻学生过重课业负担和家长经济压力的同时，也必然会在其他环节引发新的压力点。这台“不眠的机器”之所以难以停歇，正是因为它承载了太多结构性的矛盾与期望。而理解这种代价的转移逻辑，是我们思考如何构建一个更健康、更可持续的教育生态的前提。教育教培问题不是一个简单的“开放”或“关闭”就能解决的问题，而是一个如何在多方博弈中寻找更优“代价分配”方案的持续过程。这台机器或许不会彻底消失，但它必须经历深刻的重构与进化，才能摆脱“吞噬自身”的命运。而这个过程，无疑将充满痛苦与挣扎。"
  },
  {
    "title": "身份置换与拟态情缘：青少年用户在《蔚蓝档案》中心理补偿机制浅析",
    "summary": "前言这篇浅析很粗糙也很浅薄。我无意提供任何终极答案，本文更像是一次对前人理论笨拙的描摹，试图描绘景观社会下的又一场消费的奇观。作为一个老二次元和互联网深度冲浪选手（还有BA的老玩家），我观察到二游《蔚蓝档案》有一个非常有趣的现象：游戏社区和忠实拥趸中存在大量的13-17岁的青少年玩家。当然，我们一方面不能否认这部分群体本身就是二游（如明日方舟、原神、崩坏系列等）的重要客群之一；但另一方面，最起码根",
    "tags": [
      "亚文化研究"
    ],
    "url": "/posts/HumanSciences/identity-mimesis-blue-archive/",
    "date": "2025-05-03T00:00:00.000Z",
    "content": "前言这篇浅析很粗糙也很浅薄。我无意提供任何终极答案，本文更像是一次对前人理论笨拙的描摹，试图描绘景观社会下的又一场消费的奇观。作为一个老二次元和互联网深度冲浪选手（还有BA的老玩家），我观察到二游《蔚蓝档案》有一个非常有趣的现象：游戏社区和忠实拥趸中存在大量的13-17岁的青少年玩家。当然，我们一方面不能否认这部分群体本身就是二游（如明日方舟、原神、崩坏系列等）的重要客群之一；但另一方面，最起码根据我的身边统计学，我们同样不能忽略《蔚蓝档案》中显著存在一大批高情感投入、高社区粘性的青少年男性用户，这在二游社区中是非常特殊的。相较于其他同类产品，《蔚蓝档案》究竟具备何种独特的吸引力，能够如此深刻地嵌入青少年玩家的情感世界？仅仅将其归因于精美的立绘、轻松的日常剧情或是“萌系”标签，似乎不足以解释这种高度的用户粘性，尤其是我们还需考虑到这部分玩家群体在现实生活中的独特位置与心理发展阶段。本篇博客的核心关注点之一，便在于《蔚蓝档案》为青少年玩家提供的“老师”（Sensei）这一身份。游戏通过剧情叙事、游戏机制（如指导学生战斗、解决她们的“麻烦事”）、以及学生们近乎无条件的信赖与依赖，精心塑造了一个理想化的“引导者”形象。对于现实生活中正处于被引导、被教育位置的青少年而言，扮演一位被众多青春少女所依赖、尊敬甚至仰慕的“老师”，无疑构成了一种强烈的身份置换。老师这种角色扮演不仅是对现实权力结构的一种镜像反转与现实位置的投射互换，更是一种深刻的心理补偿——满足了他们在现实中可能缺失的权威感、责任感与被需要感。玩家不再是被管束的学生，而是成为了引导者和关怀者，“老师”的称谓本身就赋予了一种超越年龄的成熟感与掌控感。在游戏中，“我”的决策至关重要，“我”的存在被热切期盼。这种主体性的强化，对于正处在自我认同探索关键期的青少年而言，具有难以估量的吸引力。:::note\n不仅是BA，就像玩家会在明日方舟中扮演“博士”，原神中扮演“旅行者”，公主连结Re:Dive中扮演“骑士君“，几乎所有的二游中玩家扮演的都是带有某种形式的中心地位、特殊能力或身份的角色，并且这个角色几乎无一例外地被游戏世界中的众多角色（尤其是那些构成核心吸引力的、通常是异性的可收集角色）所需要、信赖、仰慕、甚至产生特殊的情感连结。\n:::此外，游戏中大量设定为与玩家年龄相仿（或至少在设定上贴近）的学生角色，及其与“老师”之间建立的亲密、信任甚至略带暧昧的关系网络，则构成了我们探讨的第二个关键维度：拟态情缘（Mimetic Romance）与被压抑性幻想的满足。在青春期这一特定的人生阶段，个体对亲密关系、情感归属乃至性意识的探索往往伴随着困惑与社会规范的压力。游戏中的“情缘”并非指向传统意义上的恋爱关系，而是一种经过“安全化”、“纯粹化”处理的亲密互动模式。大量的女性学生角色，其设定往往围绕着对“老师”的某种特殊情感（敬仰、依恋、好奇、甚至带有朦胧爱意的试探）展开。我们将分析，游戏如何通过“羁绊剧情”（Momotalk）、角色个人故事、以及日常互动中的细节（如触摸反馈、特殊语音），营造出一种既亲密又保持距离的“拟态”情感氛围。这种氛围巧妙地回应了青少年用户在青春期萌发的、对异性/亲密关系的好奇与渴望，同时又规避了现实中可能遭遇的社交焦虑、拒绝风险以及道德规训。我们将探讨这些年龄相仿（或心理上可代入为同龄人）的角色，如何成为了青少年被压抑或无处安放的力比多（Libido）能量的投射对象，以及这种投射如何在虚拟世界中以一种被美化、被接纳的形式得以“安全”释放与满足。这不仅关乎情感慰藉，更触及了在特定文化和社会环境下，青少年性意识探索的替代性路径问题。本篇博客旨在深入剖析这两种机制——“老师”角色的身份置换与现实位置的投射互换，以及通过与年龄相仿角色互动实现的拟态情缘与潜在的幻想满足——如何共同作用，构成了《蔚蓝档案》吸引并维系大量高投入青少年用户的核心心理补偿逻辑。一、扮演“老师”——权力反转、身份认同与现实投射1.1 权力的颠倒：从被规训者到引导者的角色置换青少年时期，在社会结构和生命历程的双重定义下，一般来说我们会认为本质上是一个被引导、被教育、被规训的阶段。无论是在家庭场域中面对父母的权威，还是在学校场域中接受教师的指导与评价，亦或是在更广泛的社会规范网络中学习行为准则，青少年普遍处于权力关系的相对底层。他们的自主性受到限制，决策权相对匮乏，其行为与价值往往处于持续的外部审视与塑造之下。法国哲学家米歇尔·福柯（Michel Foucault）在其权力理论中深刻揭示了现代社会中无处不在的规训权力（Disciplinary Power），学校、家庭等机构正是这种权力的重要实践场所，通过空间分配、时间管理、行为监控、知识传授等机制，塑造着“顺从的身体”与“规范的主体”。现实中的青少年，正是这种规训权力的主要对象。他们体验到的，往往是权力的不对等性与个体能动性的受限。蔚蓝档案所建构的世界观就有趣了，游戏很巧妙地利用了这一现实背景，构建了一个权力关系彻底反转的虚拟舞台。玩家所扮演的“老师”，并非现实教育体系中层级分明、受规章制度约束的一员，而是被设定为近乎超然的权威——联邦搜查社“沙勒”（Schale）的顾问，拥有跨越学园自治壁垒的调查权与指导权。在职位之外，游戏叙事反复强调“老师”对于解决“基沃托斯”（Kivotos）——游戏世界——所面临的重重危机具有不可替代的关键作用。学生们（几乎囊括了游戏中所有核心的可收集角色）不仅在战斗策略上依赖“老师”的指挥，更在个人困境、学园纠纷乃至情感迷茫时，主动寻求“老师”的帮助与指引。沙勒的地位这种设定构成了对青少年现实处境的戏剧性颠覆。玩家从现实中的被动接受者，一跃成为虚拟世界中主动施予指导、握有决策权、并被广泛需要的核心人物。游戏机制进一步强化了这种权力感：战术指挥权：玩家在战斗中直接部署学生、施放技能，战局的胜负直接与玩家的“指挥才能”挂钩（不过一般都是赢的，除了凹总力战）。资源分配权：玩家决定如何分配有限的游戏资源（体力、材料、信用点）来培养学生、推进事务，体现了管理与决策的权力。事务处理权：“老师”需要处理来自各个学园学生的“麻烦事”，从寻找失物到调解冲突，甚至介入重大学园危机，每一次成功解决都巩固了其“可靠的大人”形象。情感回应权：在羁绊剧情（Momotalk）和个人故事中，“老师”的选择（对话选项、行动决策）直接影响与学生关系的发展，玩家拥有定义和引导这些亲密关系的主动权。由此，这种权力反转的体验，对于长期处于权力结构下游的青少年而言，具有极强的吸引力。游戏的世界观建构并非简单地赋予玩家虚拟的“力量”（如战斗力数值），而是赋予了一种社会性权力——被尊重、被依赖、被需要、能影响他人的权力。奥地利心理学家阿尔弗雷德·阿德勒的个体心理学理论认为，人类行为的一个核心驱动力是追求优越，以克服与生俱来的自卑感。青少年在现实中感受到的权力缺失、能力限制与社会地位的相对低下，可能催生潜在的自卑情绪。扮演“老师”这一角色，恰恰提供了一个补偿的场域。在游戏中获得的权威感、掌控感与成就感，能够有效缓解现实中的无力感与不确定感，满足其对自主性和能力感的基本心理需求（如 Deci & Ryan 的自我决定理论所述）。1.2 身份认同的锚点：在“成为老师”中寻求理想自我青春期是自我认同形成的关键时期。根据埃里克·埃里克森的心理社会发展阶段理论，青少年正经历“同一性对角色混乱”的危机。他们积极探索“我是谁”、“我将成为怎样的人”等根本性问题，尝试不同的角色、价值观和归属群体，以建构一个稳定、统一的自我概念。然而，这一过程往往伴随着迷茫、焦虑与不确定性。现实社会的评价标准多元且严苛，同伴压力、学业竞争、家庭期望等多重因素交织，使得青少年在寻求自我认同的道路上常常感到困惑与挣扎。《蔚蓝档案》中的“老师”身份，为处于这一发展阶段的青少年提供了一个理想化的身份范本与稳固的认同锚点。“老师”总是智慧而可靠的，能够在复杂局势下沉着冷静地做出决策，总能在学生们陷入困惑和迷茫时，敏锐地察觉并回应她们尚未表达的内心需求。“老师”体现出包容和关怀精神，对待每位学生都给予一视同仁的支持与陪伴，理解并接纳她们的困境与烦恼，提供情感上的慰藉与指导。同时，这个身份还具备强烈的责任感与担当精神，能在关键时刻挺身而出，为保护学生和维护基沃托斯的和平不惜付出努力乃至牺牲。会长的话这个形象高度契合了青少年对于“理想成人”或“理想自我”的某种想象。它提供了一种清晰、正面且被高度认可的社会角色。玩家通过代入“老师”，不仅是进行角色扮演，更是在体验一种理想化的自我状态。人本主义心理学理论强调真实自我与理想自我之间的差距对个体心理健康的影响。当现实中的青少年感觉自身（真实自我）与他们渴望成为的样子（理想自我）之间存在巨大鸿沟时，可能会产生焦虑和不满。《蔚蓝档案》允许玩家在虚拟世界中暂时弥合这一差距，通过扮演“老师”来体验理想自我，获得一种短暂的自我实现感。更进一步，从乔治·赫伯特·米德的符号互动论视角来看，个体的自我概念是在与他人的互动中形成的，特别是通过“概化他人”（Generalized Other）的眼光来审视自己。在《蔚蓝档案》中，构成“概化他人”核心的，正是那些对“老师”充满积极评价（尊敬、依赖、喜爱）的学生角色。她们的反应——游戏中大量的文本、语音和剧情演出——不断向玩家传递“你（作为老师）是重要的、有能力的、被喜爱的”这一信息。这构成了强烈的社会性肯定。这种源源不断的正面反馈，如同米德所说的“镜中我”效应，让玩家在“学生们”这面镜子中看到了一个积极、理想化的自我形象，从而极大地提升了自尊感与自我价值感。对于在现实中可能面临学业挫败、社交困境或缺乏足够肯定的青少年而言，这种虚拟世界中的持续性正面反馈无疑具有强大的心理慰藉作用。因此，“老师”身份不仅是对现实权力结构的颠覆，更成为了青少年在身份探索迷雾中的一个临时避风港和理想自我投射屏。它提供了一个安全、稳定、且充满正向反馈的环境，让玩家得以演练、体验一种成熟、负责、被需要的理想状态，这对于缓解现实中的认同危机具有重要的心理功能。1.3 现实欲求的投射：补偿机制我们必须认识到，玩家对“老师”角色的投入，并非仅仅是对一个虚构身份的扮演，而往往伴随着深刻的现实欲求投射。“老师”这一身份及其在游戏中所处的环境，成为了青少年玩家内心深处某些未被满足或被压抑需求的理想载体。这种投射是心理补偿机制得以有效运作的关键。主要的投射与补偿体现在以下几个层面：（1）对掌控感与能动性的补偿如前所述，青少年在现实生活中常常感到缺乏对环境和自身命运的掌控力。学业压力、家庭规定、社交规则等外部力量往往占据主导。在《蔚蓝档案》中，玩家作为“老师”，其决策直接影响剧情走向、角色成长和战斗结果。这种显著的因果关系（即使是游戏设计好的脚本）赋予了玩家强烈的能动感。每一次“正确”的决策带来的积极后果（战斗胜利、学生好感度提升、危机解除），都在强化“我能行”、“我的选择很重要”的信念，从而补偿现实中可能存在的无力感与被动感。（2）对社会承认与归属感的补偿青少年极其渴望得到同伴、长辈乃至社会的认可与接纳。然而，现实中的社会评价体系复杂且竞争激烈，获得持续的正面反馈并非易事。社交焦虑、害怕被排斥、担心达不到他人期望，是青少年常见的困扰。《蔚蓝档案》构建了一个高度理想化的人际环境。“老师”几乎天然地被置于所有学生群体的中心，被无条件地信任和依赖。学生们频繁表达的感谢、敬佩、关心甚至略带占有欲的亲近，为玩家提供了丰富、直接且几乎零风险的社会承认。游戏中的“羁绊系统”更是将这种关系量化和具象化，玩家的投入（送礼物、互动）能稳定地转化为“好感度”提升和更亲密的剧情解锁。这种确定性的、低风险的社会连接，有效补偿了现实中可能遭遇的社交挫折感与归属感缺失。（3）对责任感与成熟感的模拟体验与补偿虽然青少年渴望独立与成熟，但现实中承担真正“成人式”责任的机会有限，且往往伴随着巨大的压力和风险。《蔚蓝档案》中的“老师”角色，虽然肩负“拯救世界”、“引导学生”的重任，但这种责任在游戏框架内被安全化和游戏化了——失败的代价通常是可承受的（如消耗体力重试关卡），而成功的报酬则是显著的（剧情推进、角色成长、玩家满足感）。这为青少年提供了一个低风险的环境来模拟体验承担责任、展现成熟（如做出深思熟虑的决策、关心他人）的感觉。这种“扮演成熟”的体验，满足了他们向往成人角色、希望被视为“可靠”的心理需求，同时又不必承担现实责任的真正重负。（4）对“被需要”感的补偿存在主义心理学认为，人需要感受到自身存在的意义和价值。“被他人需要”是确认自身价值的重要途径之一。青少年在家庭和学校中，有时可能感觉自己是“麻烦制造者”或仅仅是“需要被照顾的对象”，而非“被需要者”。而在《蔚蓝档案》中，“老师”的存在被设定为不可或缺。没有“老师”，学生们的问题无法解决，基沃托斯的危机无法化解。这种强烈的被需要感，极大地满足了玩家对自身存在价值的确认需求。当游戏中的角色反复强调“老师，拜托你了！”、“只有老师能做到”、“老师来了就安心了”时，玩家内心深处的存在焦虑得到了有效的安抚。老师是大人这种多维度的心理补偿，使得“老师”角色超越了一个简单的游戏设定，成为了青少年玩家安放现实焦虑、满足内心欲求、构建理想自我的重要心理空间。游戏世界成为了现实世界的镜像与避难所，玩家通过在其中扮演“老师”，获得了现实中稀缺或难以获得的心理资源。1.4 “老师”身份的特殊性：仁慈的权威与可塑的自我容器BA里的老师Sensei形象可不是传统师长一般的冷酷或专制的权力象征，而被刻意塑造为一种仁慈的权威。“老师”的力量主要用于保护、引导和帮助学生，而非控制或压迫。其决策往往以学生的福祉为出发点，其关怀充满了理解与耐心。这种设定迎合了青少年内心对于理想化、非强制性权威的期待，区别于现实中可能遇到的严厉、僵化或令人不满的权威形象（如过于严苛的父母或老师）。这种“好老师”的形象，更容易引发玩家的认同与情感投入，使得权力反转的体验更具积极意义和道德舒适感。为了玩家的代入感，“老师”角色本身通常被设计为相对的“空白”（Blank Slate）或玩家代理（Player Avatar）。游戏很少对“老师”的背景、性格、外貌进行过于具体和强制性的设定。这种模糊性为玩家的自我投射留下了充足的空间。玩家可以相对自由地将自己的想法、感受甚至理想中的人格特质注入到“老师”这一角色容器中。这使得扮演“老师”的过程更像是一种个性化的自我表达，而非仅仅是扮演一个固定的他人。这种可塑性进一步增强了角色身份的吸引力，因为它允许每个玩家在“成为老师”的过程中，都能找到与自身内在体验相契合的部分，使得身份置换的体验更加个人化和深刻。小结综上所述，“扮演老师”这一核心机制在《蔚蓝档案》中，绝非仅仅是一种游戏设定或叙事手法。它深刻地触及了青少年用户的核心心理需求与发展困境。通过权力场域的颠倒，游戏提供了对现实权力不对等性的补偿，满足了对自主与掌控的渴望。通过提供一个理想化的身份范本，游戏为处于认同危机中的青少年提供了一个稳固的锚点和体验理想自我的机会，并通过持续的社会性肯定提升其自尊感。通过作为现实欲求的投射屏幕，游戏有效补偿了青少年在现实中可能缺失的掌控感、社会承认、归属感、责任体验与被需要感。而“老师”身份所特有的仁慈权威属性与可塑性，进一步增强了这种身份置换的吸引力与心理舒适度。正是这些复杂而精妙的心理机制的运用，使得“老师”（Sensei）这一角色身份成为了《蔚蓝档案》吸引并深度维系大量青少年用户的关键变量之一。老师的角色为青少年在现实世界的压力与迷茫中，开辟了一片得以喘息、重塑力量、并短暂实现理想自我的虚拟天地。接下来，我们将探讨这一身份基础之上，游戏如何通过与年龄相仿的学生角色的互动，构建起“拟态情缘”的场域，进一步满足青少年更为隐秘和复杂的情感与心理需求。二、摆在货架上的待消费角色与被压抑性幻想的满足在前一章中，我们剖析了《蔚蓝档案》中“老师”这一身份如何通过权力反转、身份认同构建和现实欲求投射，为青少年玩家提供了一种强有力的心理补偿机制。然而，“老师”身份的价值实现，离不开其互动的核心对象——即游戏中数量庞大、各具魅力的学生角色。本章将聚焦于这些被精心设计、并通过特定游戏机制（尤其是 Gacha 抽卡系统）呈现的学生角色，探讨她们如何在现代消费主义语境下成为可供“消费”的情感与幻想载体，并如何通过构建一种 “拟态情缘” 的互动模式，巧妙地回应并满足了青少年用户在特定发展阶段被压抑或无处安放的力比多（Libido）能量与对亲密关系的潜在渴望。我们将借用现代社会学与政治经济学批判理论，特别是景观社会的视角，来审视这一现象。2.1 景观的生产：Gacha机制下的角色商品化与关系幻象《蔚蓝档案》作为一款典型的 Gacha 游戏，其核心商业模式建立在玩家对角色的获取欲之上。玩家通过投入时间（肝度）或金钱（氪金）进行“招募”（抽卡），以期获得心仪的学生角色。这一机制本身，就深刻地嵌入了现代资本主义的消费逻辑。学生角色在此语境下，已不仅仅是叙事中的人物，更是在根本上被转化为一种可供获取、拥有、展示和比较的“商品”。法国思想家居伊·德波在其著作《景观社会》中指出，在晚期资本主义社会，“全部的社会生活本身都表现为一种巨大的景观的积累”，“直接存在的一切全都转化为一个表象”。景观并非简单的图像集合，而是一种以影像为中介的人们之间的社会关系。Gacha 游戏，特别是以角色吸引力为核心驱动力的二次元 Gacha 游戏，堪称“景观社会”理论的绝佳注脚。在蔚蓝档案（或者说几乎所有的二游里），每一个角色都通过精美的立绘、细腻的 Live2D 动画、专业的声优配音、精心编写的个人剧情以及独特的战斗技能被 “奇观化” 。她们的形象被高度符号化和类型化（如傲娇、天然呆、元气娘、高冷御姐等），以满足市场细分下的不同用户偏好。这种呈现方式强调的是角色的视觉吸引力与可欲性，而非其内在的复杂性或自主性。角色成为了流动的、可供凝视和欲求的影像。这里理论上是要放色图的，但我寻思看到这的观众直接打开b站/p站直接搜对应tag不就行了（除了角色设计，Gacha 抽卡过程本身被设计成一种充满悬念、期待与瞬间满足（或挫败）的仪式化景观。华丽的动画效果、稀有度指示（如彩光、三星标志）、概率公式与“欧/非”讨论的社区文化，共同将获取角色的过程渲染成一场激动人心的“事件”。这种对过程的强调，使得获取行为本身也成为景观的一部分，玩家消费的不仅是结果（角色），也是抽卡这一行为所带来的情绪波动与社交谈资。可以看到抽卡的设计更进一步地，玩家与角色之间建立的“关系”（羁绊、好感度）同样被纳入了景观生产的逻辑。这种关系不再是现实中复杂、动态、充满不确定性的人际互动，而被转化为可通过特定行为（送礼、互动、完成任务）稳定提升的数值，以及可解锁的、标准化的“亲密”内容（羁绊剧情、特殊语音、触摸反馈）。德波所言的“以影像为中介的人们之间的社会关系”在此体现得淋漓尽致——玩家与角色的“情缘”，本质上是一种被预设好、被量化、被程序化了的景观化关系。玩家通过消费行为（投入资源提升羁绊）来购买和体验这种标准化的亲密感幻象。卡尔·马克思关于商品拜物教的理论，同样有助于我们理解这一现象。在商品经济中，物（商品）的社会属性被看作是物本身的自然属性，而人与人之间的社会关系（生产者与消费者的关系，或在此处的玩家与开发者/角色之间的关系）反而采取了物与物之间关系的虚幻形式。在《蔚蓝档案》中，学生角色这一“商品”，其价值（稀有度、强度、萌点、剧情分量）似乎内在于角色本身，掩盖了其背后复杂的设计、生产、营销过程，以及玩家自身投入的情感劳动。玩家与角色之间的情感连接，这种本应属于人际领域的关系，被物化为对特定角色（商品）的拥有和互动。对角色的喜爱与欲求，在某种程度上遮蔽或替代了对真实、复杂人际关系的需求。玩家追求的是拥有“角色”这一物，以及通过与该“物”互动所获得的程序化反馈，而非建立在相互理解、共同经历基础上的真实情感纽带。因此，Gacha 机制不仅是商业模式，更是一种深刻的文化与社会机制。它将角色乃至关系本身转化为可供消费的景观，塑造了玩家的欲求模式，并提供了一种以物（角色）为中介的、标准化的、可控的关系体验。这为我们接下来讨论“拟态情缘”奠定了基础。2.2 拟态情缘：安全距离下的亲密模拟与情感代偿基于上述商品化与景观化的背景，“拟态情缘”构成了《蔚蓝档案》满足青少年情感需求的核心策略。此处的“情缘”并非指向现实意义上对等的、相互承诺的恋爱关系，而是一种精心调控的、单向度为主（由玩家“老师”主导选择与接受反馈）的、高度理想化的亲密关系模拟。首先我们要谈论的前提就是——安全距离。游戏中的互动始终维持在一个“安全”的框架内。“老师”与学生的关系被定义为师生，辅以“顾问”与“被帮助者”的身份，这层设定本身就提供了一层伦理与社会规范的保护膜。尽管存在大量暗示性的对话、暧昧的场景和肢体接触（如摸头互动），但游戏极少（甚至可以说几乎从不）跨越明确的“恋爱关系”或“性关系”界限。剧情中的情感表达往往是朦胧的、试探性的、点到为止的。这种模糊性至关重要：它既能撩拨玩家的情感，引发遐想，满足对亲密接触的渴望，又巧妙地规避了现实中可能涉及的道德风险、社会压力以及青少年自身可能感到的不安或罪恶感。它创造了一个 “似是而非”（as-if）的情感空间。在这个前提之下，与现实人际交往的复杂性和不可预测性相比，游戏中的“拟态情缘”提供了高度的可控性和确定性。Momotalk 系统：模拟即时通讯软件，玩家可以选择对话分支（当然分支本身其实没有什么意义），这种设计给予玩家掌控对话走向的权力感，减少了现实社交中可能出现的误解、尴尬或冲突。羁绊剧情：随着好感度提升解锁的个人故事，通常围绕学生对“老师”的依赖、敬仰展开，并逐步深入到她们的内心世界与私人烦恼。这些剧情是单向解锁的，玩家只需满足条件即可“获得”，保证了情感投入的正向回报。Live2D 互动与触摸反馈：玩家可以通过点击屏幕与角色互动（如摸头），角色会给出预设好的、通常是积极或羞涩的语音和动作反馈。这种即时的、可重复的、程序化的积极反馈，强化了玩家被接纳、被喜爱的感觉，且无需承担现实互动中可能遭遇的拒绝或冷漠。亲密模拟说完了，情感代偿呢？青春期是情感需求（尤其是对亲密关系、被理解、被关怀的需求）急剧增长的时期。然而，现实中满足这些需求可能面临诸多挑战：社交技能的缺乏、对拒绝的恐惧、家庭环境的限制、学业压力对社交时间的挤压、以及社会文化对青少年情感表达（特别是性相关方面）的规训。《蔚蓝档案》的“拟态情缘”恰好填补了这一需求与现实满足之间的鸿沟。它提供了一个：低风险的情感演练场：玩家可以在没有真实后果的压力下，练习如何“关心”他人（选择关怀性对话）、如何“回应”好感（送礼物）、如何处理“亲密”互动（体验羁绊剧情）。稳定的情感慰藉来源：无论玩家在现实中经历了什么，游戏中的学生角色始终在那里，以一种理想化的、不变的姿态等待着“老师”的到来，提供持续的情感支持与肯定。这种可靠性本身就具有强大的心理安抚作用。美化的关系想象空间：游戏中的关系被过滤掉了现实中的矛盾、争吵、厌倦和责任。它呈现的是一种纯粹化、浪漫化（即使并非明确恋爱）的亲密关系图景，满足了青少年对理想人际关系的憧憬。社会学家齐格蒙特·鲍曼在其关于 “流动的现代性” 的论述中，探讨了现代社会中人际关系的脆弱性、短暂性与不确定性。人们既渴望连接，又害怕承诺带来的束缚和伤害。《蔚蓝档案》这类游戏提供的“拟态情缘”，恰恰迎合了这种心态。它提供了一种 “轻量化”、“可控化”、“即时满足” 的情感连接模式，允许玩家在享受亲密感的同时，规避了真实关系的风险与重负。对于尚未准备好或缺乏机会进入真实复杂情感世界的青少年而言，这种模拟提供了一种临时的、替代性的满足。2.3 力比多的投射：年龄相仿角色的吸引力与幻想满足现在我们必须触及一个更为核心但也更为敏感的议题：这些学生角色如何成为青少年玩家被压抑或无处安放的力比多能量的投射对象。精神分析理论，特别是弗洛伊德关于力比多（性驱力，广义上也包含生命能量与爱的驱力）的学说，为我们提供了理解的框架。青春期是生理发育导致力比多（性冲动）急剧高涨的阶段。个体开始对性产生好奇，体验到强烈的性吸引力，并渴望建立亲密的身体与情感连接。然而，社会文化规范（家庭、学校、宗教、法律）往往对青少年直接的性表达施加严格的限制和禁忌。这种生理驱动与社会压抑之间的张力，使得青少年的力比多常常处于被压抑、被转移或寻求替代性满足的状态。在这种背景下，《蔚蓝档案》中的学生角色，便巧妙地成为了青少年玩家理想的投射对象与情感出口：年龄与身份的接近性：游戏中绝大多数核心角色都被设定为“学生”，其外貌、言行举止、所思所想（如对学业、社团、友谊的关注）往往带有鲜明的青少年或准青少年特征。即使某些角色设定上可能年龄稍大或心智超常，其核心互动模式和视觉呈现也常常保持在“学生”框架内。这种年龄上的接近性（或至少是心理上的可代入性）至关重要。它使得青少年玩家更容易将这些角色视为潜在的同伴或倾慕对象，而非遥不可及的成人。与这些“同龄人”（或感觉上的同龄人）建立“亲密关系”，相比于和明显是成年人（如现实中的老师或长辈）的角色互动，更能自然地对接青少年自身萌发的、主要指向同辈群体的浪漫幻想和性意识。视觉符号与性暗示的精心运用：尽管游戏整体基调偏向“青春日常”，但不可否认，角色的视觉设计（立绘、CG）中常常有意无意地嵌入了满足男性凝视（Male Gaze）的元素。这可能包括：特定的服装设计（如短裙、紧身衣、低领口）、强调身体曲线的姿态、带有羞涩或诱惑意味的表情、以及在特定剧情或互动中出现的“杀必死”（サービス，一个挺远古的词了）场景。这些元素并非总是露骨的色情，但它们足以激发玩家的性趣，为力比多的投射提供视觉上的“钩子”。它们在“纯洁”的整体氛围中，埋入了暧昧的、可供幻想的种子。理论上这里也是要放图的“纯洁”外壳下的“安全”幻想：游戏巧妙地将潜在的性吸引力包裹在“可爱”、“纯真”、“需要保护”的外壳之下。学生们的“麻烦事”往往是天真的、非指向性的，她们对“老师”的情感也常被描绘为懵懂的、非占有性的敬仰或依恋。这种 “去性化”或“弱性化”的包装，使得玩家投射其力比多时，心理负担大大降低。幻想的对象是“纯洁可爱的学生”，而非直接的性对象，这在心理上更容易被自我接受，也更符合社会对青少年“应有”状态的想象。玩家可以在这种被美化、被安全化的语境下，间接地满足其被压抑的性好奇与幻想，而无需直面现实中可能伴随的焦虑、罪恶感或社会谴责。这是一种象征性的、替代性的力比多释放。所有权与控制权的幻想：通过 Gacha 获取角色，并在游戏中“培养”她们、“指导”她们、解锁她们的“心事”，玩家在某种程度上获得了对这些角色的虚拟所有权和互动主导权。这种掌控感，可以被视为对现实中可能在人际关系（特别是与异性交往）中感到的不确定性、无力感甚至被拒绝恐惧的一种补偿性幻想。在游戏里，“我”是中心，“我”的投入能稳定地换来角色的“好感”与“亲近”，“她们”在某种意义上是“属于我”的。这种可控的、被拥有的关系，可以暂时性地满足青少年在现实中难以实现的对亲密关系确定性的渴望，甚至在潜意识层面，也可能部分满足了对伴侣关系的支配欲或占有欲的幻想投射。因此，《蔚蓝档案》的学生角色，作为被精心设计、摆在 Gacha 货架上的“商品”，不仅仅是满足收集癖或视觉享受的对象。她们更重要的功能在于，成为了青少年玩家复杂情感与心理需求的投射屏。她们的年龄设定、视觉符号、以及被“安全化”处理的互动模式，共同构建了一个场域，让玩家得以在其中模拟亲密关系，并以一种象征性的、被美化和被接纳的方式，安放和满足其在青春期被压抑的力比多能量与幻想。2.4 消费主义逻辑下的情感驯化最后，我们需要警惕这种以消费为基础的“拟态情缘”和幻想满足可能带来的潜在影响。当亲密关系、情感慰藉乃至性幻想的满足都高度依赖于商业游戏提供的、标准化的、可购买的“产品”时，这可能在潜移默化中塑造和驯化着青少年的情感模式与人际交往期待。这种驯化首先表现为情感体验的同质化与浅层化。游戏里的“情感套餐”看似丰富多样，但本质上不过是预设好的、有限的剧本。玩家逐渐习惯于通过简单的操作（比如点击、送礼）获得即时且正向的反馈，而这在无形中削弱了他们在现实中处理复杂、模糊、甚至负面情感的能力和意愿。现实中的关系需要时间、耐心、同理心、沟通技巧，以及承担不确定性的勇气，而这些都与游戏中一键达成的“快捷方式”形成了鲜明对比。过度沉浸其中，很容易让人低估或回避真实关系中的困难。游戏的机制也强化了关系的工具化和对象化倾向。Gacha 抽卡和好感度系统内嵌着“投入-回报”的计算逻辑，游戏将获取角色、提升亲密度与氪金或肝度紧密挂钩，把消费行为塑造成通往情感满足的前提与主要途径，使玩家逐渐习惯于用资源堆砌来“攻略”或“获取”角色，而非在平等、互惠的基础上进行交流与付出。久而久之，这种思维方式可能会渗透到现实生活中，让玩家在不知不觉中把人际关系简化为“能否满足我的需求”的功利化评判。用马克思主义的异化概念来审视，玩家在这种高度商品化的虚拟情感体验中，可能与其真实的、完整的情感能力发生某种程度的疏离。他们体验到的情感是被设计、被引导、被物化的情感，可能与自发的、基于真实互动的、更深层次的情感连接产生距离。景观社会提供的幻象，终究只是幻象。三、庞大的二创社区——从被动吸收到主动再生产在前两章中，我们分别剖析了《蔚蓝档案》如何通过“老师”身份的置换提供权力反转与认同补偿，以及如何通过商品化的角色与“拟态情缘”机制满足玩家的情感投射与幻想需求。然而，对《蔚蓝档案》现象的分析若止步于玩家在游戏内的被动体验，则忽视了其生态中一个极为活跃且重要的组成部分——异常繁荣的二次创作（二创）社区。可以看到，BA有一个庞大的社区从像素级的表情包、玩梗图片（MEME），到高质量的同人画作、漫画、小说，乃至动画短片、MMD（MikuMikuDance）模型及视频、自制音乐等，《蔚蓝档案》的二创产出无论在数量、质量还是传播广度上，都在同类游戏中表现突出。这并非简单的用户热情体现，而是一个值得深入探究的社会文化现象。它标志着玩家群体并未仅仅停留在对游戏官方内容的被动消费层面，而是大规模地转向了主动的意义再生产与文化参与。本章将探讨这一现象背后的驱动力，及其与前述心理补偿机制的关联。3.1 从“景观消费者”到“文化生产者”：参与式文化与意义的共构游戏，尤其是像《蔚蓝档案》这样以角色和世界观为核心吸引力的产品，本质上提供的是一套符号系统和叙事框架。根据前文对“景观社会”的讨论，这些元素在商业逻辑下被精心打包、奇观化，呈现给玩家进行消费。然而，景观的强大之处不仅在于其被观看，更在于其引发阐释和激发再创造的潜力。著名媒介理论家亨利·詹金斯提出的 “参与式文化” 概念，为我们理解《蔚蓝档案》的二创现象提供了工具。参与式文化的核心特征在于：进入门槛相对较低、支持创作与分享、存在非正式的知识传递、成员相信自己的贡献是重要的、成员间感受到某种社会连接——恰同BA二创社区的生态。与传统单向输出的媒介不同，《蔚蓝档案》虽然提供了官方剧情和角色设定，但其叙事往往留有大量的“空白”与“模糊地带”。例如，“老师”的具体形象与个性、学生们在主线之外的日常生活细节、角色之间更深层次的关系互动、基沃托斯世界观的未解之谜等。这些 “未被讲述”或“可以被不同解读” 的空间，成为了玩家进行二创的沃土。玩家通过二次创作，不再仅仅是官方设定和剧情的被动接受者，而成为了主动的诠释者、拓展者甚至改写者。他们运用官方提供的“原材料”（角色形象、基本设定、世界观元素），结合自身的理解、想象、情感和欲求，创造出新的文本（图像、文字、视频等）。这一过程，是玩家将自身主体性注入游戏世界，并积极参与到游戏意义共构过程中的体现。这种从“消费者”到“生产者”（Prosumer，阿尔文·托夫勒概念）的转变，本身就具有重要的心理意义。在充斥着标准化产品和被动接收信息的现代社会，能够主动创造并分享，本身就是一种赋权 的体验。它满足了人类基本的创造欲和表达欲，也进一步强化了玩家对游戏世界的归属感和主人翁感。二创社区的存在，将原本可能止于个体屏幕内的游戏体验，转化为一场集体的、持续进行的文化实践。3.2 “老师”身份的延伸与主体性的再确认我们在第一章分析了“老师”身份如何为青少年玩家提供身份认同的锚点和现实欲求的投射。二次创作，尤其是那些以“老师”（Sensei）为中心或重要参与者的作品，进一步延伸和固化了这一机制。为了照顾玩家的多样性和个性，BA官方对“老师”的设定相对模糊，以便于玩家代入。二创则允许玩家根据自己的理解和偏好，塑造出更为具体、个性化的“老师”形象。TA 可以是风趣幽默的，可以是严肃认真的，可以是笨拙但温柔的，可以是抽象的，甚至可以是带有某种“缺陷”的（例如，在某些搞笑二创中被描绘成被学生捉弄的对象）。这种再创造过程，使得“老师”这一身份不再仅仅是官方赋予的空壳，而被注入了玩家自身的意志和想象，成为更贴合其理想自我或情感投射的载体。玩家通过创作，主动定义了“我”在基沃托斯的样貌与行为方式。在二创中，玩家（作为创作者）拥有了绝对的叙事主导权。他们可以自由安排“老师”与学生们的互动情节，决定关系的发展方向，甚至创造官方剧情中不存在的“名场面”。这种对叙事和关系的掌控感，是对游戏内“老师”权力的一种创造性延伸。在游戏里，玩家的选择权是有限的（对话选项、资源分配等）；而在二创中，这种权力近乎无限。这进一步满足了玩家对能动性和影响力的渴望，强化了扮演“老师”所带来的主体性满足感。如埃里克森所述，青少年时期是探索不同角色和可能性的阶段。二创提供了一个安全的沙盒，让玩家可以借由“老师”这一身份，演练不同的社会角色面向（引导者、保护者、倾听者、甚至被依赖的脆弱者），探索不同的应对方式和情感表达。如创作“老师”如何处理棘手学生问题的同人小说，或描绘“老师”在压力下的内心挣扎的漫画，都是在借虚拟角色进行自我探索和情感梳理。因此，二创活动成为了玩家巩固、深化并个性化其“老师”身份认同的重要途径。它将游戏内被动扮演的角色，转化为一个可以被主动塑造、演绎和分享的自我延伸，从而更深刻地实现了身份置换所带来的心理补偿。3.3 “拟态情缘”的深化、变奏与情感的创造性升华第二章分析了游戏如何通过“拟态情缘”满足玩家对亲密关系的渴望，并作为力比多投射的载体。二创社区则将这种模拟的、程序化的关系，提升到了一个更复杂、更具创造性、也更个人化的层面。在深化情缘方面，官方剧情和羁绊故事提供的互动往往是点到为止、带有普遍性的。二创则可以无限聚焦于特定角色或特定关系，进行深度挖掘和细致描绘。创作者可以想象“老师”与某个学生在某个特定情境下的对话、眼神交流、心理活动，将官方暗示的朦胧好感具象化、细节化。这种创作过程本身，就是一种深度浸入和情感投入，它极大地强化了玩家与角色之间的虚拟情感纽带。根据精神分析理论，创作活动本身可以被视为一种升华机制——即将本能冲动（如力比多）或心理冲突（如被压抑的欲望、焦虑）转化为具有社会文化价值或个人认可的创造性行为。二创正是这样一种升华途径。玩家在游戏中感受到的、对角色的喜爱、依恋乃至潜在的性吸引力，这些可能在现实中难以直接表达或被社会完全接纳的情感能量，可以通过绘画、写作等创作形式得到建设性的、被社群认可的表达。作品成为了情感的容器和幻想的出口。这不仅缓解了内在的心理张力，也带来了创作本身的成就感和满足感。相比于仅仅停留在幻想层面，将其物化为具体的作品，并获得他人的观看与回应，其心理满足感更为强烈和持久。主流审美之外，二创社区是“配对”（Coupling, CP）文化的重要阵地。玩家不仅探索“老师”与学生的关系，也大量创作学生之间的配对（百合CP尤为盛行）（白！河！豚！）。这表明玩家的情感投射并非完全局限于官方设定的“老师中心”模式。他们同样对角色自身的魅力、以及角色之间可能产生的化学反应抱有浓厚兴趣。创作和消费CP内容，是玩家在官方框架之外，自主构建理想关系图景的一种方式。它既满足了对特定类型亲密关系（如同性情谊、浪漫爱）的偏好与想象，也反映了玩家渴望更丰富、更多元的人际互动模式。总而言之，二创活动将游戏内相对标准化、安全化的“拟态情缘”，转化为一场充满活力、个性化且不断演变的情感实践。玩家通过创作，不仅加深了与角色的情感连接，也得以更自由、更深刻地探索、表达和升华其复杂的情感需求与幻想。3.4 共同体的构建：共享符号、集体认同与社会资本的循环《蔚蓝档案》庞大的二创社区不仅是个体创作的集合，更是一个具有强大凝聚力的趣缘共同体。其存在本身，就构成了对玩家社会归属感需求的又一重补偿。二创过程中诞生了大量的梗（MEME）、社区黑话、以及被广泛接受的“二次设定”（Fanon）。例如，某些角色的特定口癖被反复模仿、某个剧情细节被引申出无数搞笑段子、某些角色组合被赋予了约定俗成的互动模式。这些共享的符号和阐释，如同部落的图腾和传说，将分散的玩家凝聚在一起，形成了独特的社群文化和集体认同（Collective Identity）。理解并运用这些梗和设定，成为了区分“圈内人”与“圈外人”的标志，强化了成员的归属感。“圈内人”所活跃的二创社区则是一个活跃的社会互动平台。创作者发布作品，期待观看者的评论、点赞、转发；观看者通过互动表达喜爱、认同，并与其他同好交流。这种围绕共同兴趣展开的社会交往，为玩家提供了现实社交之外的另一种连接。获得社群的认可（作品受欢迎、评论积极），能够极大地提升创作者的自尊感和成就感，这在社会学中可视为获取了某种形式的 “社会资本” ，对于在现实生活中可能缺乏足够社会支持或认可的青少年而言，这种来自同好社群的肯定尤为宝贵。因此，二创社区不仅是玩家个体表达和创造的场所，更是一个社会性空间。它通过共享符号、持续互动和知识传递，构建了一个充满活力的趣缘共同体，为玩家提供了强烈的归属感、认同感和社会支持。这种社群层面的补偿，与前述个体层面的身份和情感补偿机制相互叠加，共同构成了《蔚蓝档案》对青少年用户强大吸引力的重要维度。结语当理论的脚手架被撤去，“景观社会”、“力比多”、“心理补偿”这些略显冰冷的词汇褪下其学术的硬壳，我们最终所看到的，或许仍是那片在无数屏幕微光中浮现的、名为“基沃托斯”的奇幻都市，以及都市背后，那一个个在现实坐标系中略显迷茫、却在虚拟世界里戴上“老师”冠冕的年轻身影。我们谈论权力反转，仿佛能听到现实中被规训的少年，在虚拟的指挥席上发出一声如释重负的轻叹；我们剖析拟态情缘，似乎能看见那些被小心翼翼折叠起来的、青春期特有的朦胧心事，在安全距离的互动中，悄然绽放又悄然隐匿，如同幽灵兰悄然的开合。本文将少女角色视为“货架上的待消费品”，用“景观”、“商品拜物教”来解构那份投入，无疑是锐利甚至残酷的。但这并非意在贬低玩家的情感——那份喜爱、那份沉浸，往往是极为真切的。只是，我们不能忽视，这真切的情感，正被一套精密的商业逻辑和文化机制所引导、所塑造、甚至所利用。抽卡信封每一次闪耀的彩光，不仅仅是随机数的舞蹈，更是资本触角轻抚玩家最深层欲求的野望。它承诺满足，却也在无形中驯化着我们感知爱与连接的方式。从一个更乐观的角度，在二创社区中，被动的消费者摇身一变，成为了热情的文化生产者。梗图在社群中病毒般扩散，同人画手笔下的角色流露出官方未曾赋予的眼神，文字织就出超越羁绊剧情的深刻羁绊——这是主体性的宣告，是创造欲的奔流，是年轻人用自己的语言和想象，对那个被给予的世界进行着不懈的“重写”与“再占有”。他们不甘于只做景观的凝视者，他们要成为意义的共舞者。所以，《蔚蓝档案》（乃至于所有的二游）究竟是什么？是一个精心设计的心理补偿机器？一个贩卖标准化情感体验的数字商店？还是一个激发了无数创造与连接的文化触媒？或许，它同时是这一切的矛盾统一体。它像一面多棱镜，折射出当代青少年在身份认同、情感需求、社交压力、以及无处不在的消费主义浪潮中复杂的生存图景。这篇浅析很粗糙也很浅薄。我无意提供任何终极答案，本文更像是一次对前人理论笨拙的描摹，试图描绘景观社会下的又一场消费的奇观。旅程至此，思绪纷飞，言犹未尽，感谢阅读。参见[1]杨馨.赛博空间中的“爱情买卖”——“二次元手游”玩家的数字身体与爱欲张力研究[J].新闻记者,2023,(07):65-77.DOI:10.16057/j.cnki.31-1171/g2.2023.07.005.[2]尹金凤,陈梓潇.亲密关系的新技术想象：恋爱养成类游戏情感文化的底层逻辑与批判性分析[J].学术研究,2024,(09):9-15+177.[3]丁皓天.符号消费、算法互动与情感沉浸：玩家群体的同人创作实践研究——以二次元手游玩家为例[J].科技传播,2024,16(12):174-178.DOI:10.16607/j.cnki.1674-6708.2024.12.036.[4]毛睿喆.角色游戏与独异玩家——从《原神》看二次元玩家的保守面相[J].中国图书评论,2023,(11):29-40.[5]王宁,于滢.虚实之间：乙女游戏玩家的游戏体验[J].中国青年研究,2025,(02):23-31+13.DOI:10.19633/j.cnki.11-2579/d.20250109.007.[6]尹金凤,陈梓潇.亲密关系的新技术想象：恋爱养成类游戏情感文化的底层逻辑与批判性分析[J].学术研究,2024,(09):9-15+177.[7]李彪,高琳轩.游戏角色会影响玩家真实社会角色认知吗？——技术中介论视角下玩家与网络游戏角色互动关系研究[J].新闻记者,2021,(05):67-82.DOI:10.16057/j.cnki.31-1171/g2.2021.05.008."
  },
  {
    "title": "仓鼠速递：远程VPS+TG Bot实现离线下载并上传至OneDrive",
    "summary": "事情是这样的，我有一个基于onedrive-cf-index-ng又自己魔改的公开在线网盘，平时会托管一点公开论文、数据集或者其他鸡零狗碎的资料。但每次上传文件我都得先在本地下好，再手动传到云端，过程繁琐、耗时，还经常卡在 macOS OneDrive 客户端的莫名其妙错误上，令人怀疑人类是否真的配拥有自动化工具。于是我萌生了个念头：干脆做个自己的 TG Bot，让它在远程 VPS 上帮我完成下载",
    "tags": [],
    "url": "/posts/TechnicalTutorials/hamster-vps-onedrive-bot/",
    "date": "2025-04-30T00:00:00.000Z",
    "content": "事情是这样的，我有一个基于onedrive-cf-index-ng又自己魔改的公开在线网盘，平时会托管一点公开论文、数据集或者其他鸡零狗碎的资料。但每次上传文件我都得先在本地下好，再手动传到云端，过程繁琐、耗时，还经常卡在 macOS OneDrive 客户端的莫名其妙错误上，令人怀疑人类是否真的配拥有自动化工具。于是我萌生了个念头：干脆做个自己的 TG Bot，让它在远程 VPS 上帮我完成下载和上传的全流程，彻底摆脱手工操作。最开始我还打算完全自己从零写一个新 bot，但写着写着就意识到，其实市面上已经有不少功能成熟的开源项目。比起造轮子，魔改一个现成的项目更省心高效。最终我选择了 jw-star/aria2bot 作为基础，它已经实现了 Telegram 控制 Aria2 离线下载的主流程，但原版仅支持将下载好的文件直接发送回 Telegram，对于我这种需要长期归档上云的场景并不适用。所以我对它进行了一点小魔改：集成了 rclone 作为上传工具，并添加了默认自动上传到 OneDrive 的逻辑。除此之外，原项目还需要用户自行配置 Aria2，我干脆一并打包好了 Aria2 + rclone 的完整环境，重新封装了镜像，做到项目开箱即用——部署后即可在 Telegram 上指令发送链接，远程下载+上传全自动跑完。项目链接：\n::github{repo=\"jw-star/aria2bot\"}\n::github{repo=\"Lapis0x0/MistRelay\"}具体部署方式也可以选择直接看项目的README使用方法1.准备工作：你需要什么最好是国外的+大带宽。确保安装了 Docker 和 Docker Compose。Telegram 账号：你需要创建一个 Telegram Bot 并获取它的 Token，再拿到你自己的 Telegram User ID。找 @BotFather 发送 /newbot创建机器人，获取 BOT_TOKEN。找 @userinfobot 获取你的 ADMIN_ID (纯数字)。访问 https://my.telegram.org/apps 创建应用，获取 API_ID 和 API_HASH。Rclone 配置文件：由于 VPS 通常没有桌面环境，直接在上面配置 rclone 连接 OneDrive 会比较麻烦（需要浏览器授权）。最佳实践是：先在你的本地电脑上安装并配置好 rclone，完成 OneDrive 的授权。（用 rclone config命令，跟着向导走）Windows: 下载安装包 https://rclone.org/downloads/macOS: brew install rcloneLinux: curl https://rclone.org/install.sh | sudo bash找到本地生成的 rclone.conf文件。（Windows 在 %USERPROFILE%\\.config\\rclone\\，macOS/Linux 在 ~/.config/rclone/rclone.conf这个文件很重要，等下要上传到 VPS。2.正式配置项目下载项目到本地：\ngit clone https://github.com/Lapis0x0/MistRelay.git\n\ncd MistRelay\n重命名 db/config.example.yml 为 config.yml 并设置参数：\nAPI_ID: xxxx # Telegram API ID\n\nAPI_HASH: xxxxxxxx # Telegram API Hash\n\nBOT_TOKEN: xxxx:xxxxxxxxxxxx # Telegram Bot Token\n\nADMIN_ID: 管理员ID # 管理员的Telegram ID\n\nFORWARD_ID: 文件转发目标id # 可选，文件转发目标ID\n\n  \n\n# 上传设置\n\nUP_TELEGRAM: false # 是否上传到电报\n\nUP_ONEDRIVE: true # 是否启用rclone上传到OneDrive\n\n  \n\n# rclone配置\n\nRCLONE_REMOTE: onedrive # 你在 rclone config 时给 OneDrive 远程配置起的名字（比如 onedrive）。\n\nRCLONE_PATH: /Downloads # 你想让文件上传到 OneDrive 的哪个路径下（比如 /Downloads 或 /Public/Data）。\n\n  \n\n# aria2c设置（Docker集成后可使用默认值）\n\nRPC_SECRET: xxxxxxx # RPC密钥（建议修改为自定义密钥）\n\nRPC_URL: localhost:6800/jsonrpc # 使用Docker部署时必须使用localhost或127.0.0.1。一般保持默认 localhost:6800/jsonrpc 就好，因为 Aria2 和 Bot 都在一个 Docker 网络里。\n\n  \n\n# 代理设置（可选）\n\nPROXY_IP: # 代理IP，不需要则留空\n\nPROXY_PORT: # 代理端口，不需要则留空\n\n  \n\n# 自动删除本地文件设置\n\nAUTO_DELETE_AFTER_UPLOAD: true # 是否在成功上传到 OneDrive 后自动删除 VPS 上的文件，true 是删除，false 是保留。根据自己需求设置。\n3.启动！Unleash the Hamster!配置完成后，使用 Docker Compose 一键启动所有服务：docker compose up -d --build第一次启动会因为 --build 参数而需要一些时间来构建镜像。之后如果修改了代码或 Dockerfile，也需要加上 --build 参数重新构建。想看看仓鼠在忙什么？可以用下面的命令查看实时日志：docker compose logs -f4.开始使唤仓鼠现在，打开 Telegram，找到你创建的机器人：发送 /start，你的机器人应该会回应你。直接把 HTTP/HTTPS 链接、磁力链接（magnet: 开头）或者 .torrent 文件发送给它。仓鼠收到任务后，会开始下载，并在下载完成后自动开始上传到你指定的 OneDrive 路径。整个过程，它都会在 Telegram 里向你汇报进度（下载进度、上传进度、完成/失败信息）。你可以使用 /help 查看所有可用命令，比如 /info 看系统状态，/path 切换下载目录（不影响上传路径），/web 获取 AriaNg 的 WebUI 地址（如果你需要更精细地管理下载任务）。效果未来计划[ ] 支持重命名文件[ ] 更清晰、强大的菜单键[ ] 支持通过大模型来自动管理文件列表"
  },
  {
    "title": "论文选读：基于LLM的中国街道与社区犯罪时空分布数据集",
    "summary": "介绍我在之前的博客从最近的恶性事件看类《看门狗》中CtOS犯罪评估系统的可能性中曾经介绍过，现代犯罪预测领域中最核心的两个模型分别是“近重复理论（Near Repeat Theory）”和“风险地形建模（Risk Terrain Modeling）”，对具体理论内容感兴趣的读者，可以点击超链接查看详细介绍，这里就不再赘述。不过，无论是近重复理论还是风险地形建模，它们在实际应用时都面临着同一个基础性",
    "tags": [
      "论文选读"
    ],
    "url": "/posts/AI and Deep Learning/dataset-china-crime-spacetime/",
    "date": "2025-04-27T00:00:00.000Z",
    "content": "介绍我在之前的博客从最近的恶性事件看类《看门狗》中CtOS犯罪评估系统的可能性中曾经介绍过，现代犯罪预测领域中最核心的两个模型分别是“近重复理论（Near Repeat Theory）”和“风险地形建模（Risk Terrain Modeling）”，对具体理论内容感兴趣的读者，可以点击超链接查看详细介绍，这里就不再赘述。不过，无论是近重复理论还是风险地形建模，它们在实际应用时都面临着同一个基础性要求：高质量、细粒度的犯罪时空数据集。然而，受限于隐私保护、数据收集难度与信息敏感性，中国目前公开可得的犯罪数据通常只能精确到城市或区县级，街道乃至社区层面的数据几乎是一片空白。这种局限不仅削弱了犯罪风险的精准识别能力，也制约了微观层面上预防与干预措施的制定。来自武大/港中文的张岩博士的论文《A dataset on the spatiotemporal distributions of street and neighborhood crime in China》就非常有趣，这篇论文/数据集做的事简而言之就是爬取了中国裁判文书网大约一百万条犯罪记录，使用大模型从海量的非结构化司法文本中提取社区乃至建筑尺度的犯罪事件，最终构建出了一个开放的、覆盖街道与社区尺度的犯罪时空数据库。论文与数据集链接你也可以在这里查看论文原文、翻译后的双语PDF文件和我自己托管的ChinaCrimeDatasets数据集一、论文速览1.数据来源研究者的主要数据来源是中国裁判文书网 (China Judgments Online)。这个由最高人民法院运营的平台公布了超过一亿份经过匿名化处理的全国范围内的刑事案件判决书。这些文书格式高度标准化，经过司法程序核实，包含了丰富的案件细节（时间、地点、案情等），具有全国一致性和公开可访问性。然而，这些信息是以非结构化的文本形式存在的。想象一下，要从数百万份、每份都可能长达数页的判决书中，手动提取精确到“某某街道某某小区几号楼”的犯罪地点和具体到“某年某月某日几点几分”的案发时间，工作量无疑是巨大的，几乎不可能完成。这么庞大的工作量哪怕全部外包给黑叔叔都有点不太可能于是，这就提现到大模型的好了。研究者使用了LLM进行数据的清洗与提取：筛选与检索： 首先，使用“抢劫 (robbery)”、“抢夺 (snatching)”、“盗窃 (theft)”等关键词，从海量文书中检索出超过200万份与街头和社区犯罪相关的判决书。LLM信息抽取： 接着，研究人员选用了 Google的Gemini-1.5-Flash模型API（在输出质量和API定价间取得了较好平衡），设计了特定的指令（Prompt），让LLM扮演“专业的法律文书分析助手”。LLM负责阅读每份判决书的文本，并按照预设的JSON格式，自动提取关键信息，包括：案件编号 (case_number)法院名称及地点 (court_name, court_location)案件类型 (case_type)判决日期 (judgment_date)案发时间 (incident_time)案发地点 (incident_location)当事人信息（被告、受害人等，已做脱敏处理）(party_info)地理编码 (Geocoding)： 提取出的文本格式的案发地点（例如：“武汉市洪山区珞喻路129号”）还需要转换为精确的地理坐标。研究团队使用了百度地图API的地理编码服务，将这些地址文本转化为经纬度 (longitude, latitude)。对于涉及多个地点的案件，优先提取第一个地点作为主要犯罪位置。时间标准化： 同样，从文本中提取的案发时间（可能包含“上午”、“傍晚”等模糊描述）也需要标准化。研究团队设计了基于正则表达式的解析方法，将其统一转换为ISO 8601标准格式（例如：“2024-01-05 10:00”），方便后续进行时序分析。2.数据集概览通过上述流程，研究团队最终构建了一个包含约100万条街头和社区犯罪记录的数据集，总容量约为7GB。\n这个数据集具有几个显著特征：首先，在空间粒度上，数据精确到街道、社区，甚至是建筑级别，提供了前所未有的微观细节；其次，每条记录都附有标准化处理的案发时间戳，确保了时序分析的可行性；在覆盖范围上，数据横跨中国大陆31个省级行政区、222个地级市与548个县级/区级单位，具备广泛的地域代表性；此外，除了核心的时空信息外，数据中还包含了案件类型、法院信息及部分脱敏的案件详情描述，信息维度丰富；最后，整个数据集以CC BY 4.0许可协议在Figshare平台上开放发布，供研究人员和公众免费下载与使用，极大地促进了后续研究与应用的可能性。3.比较有趣的几个初步发现时间分布\n可以看到一天内的犯罪可能会集中在上午9点，中午12点，下午3点和晚上8点当然，这也可能是数据集选取策略导致的（） 很多案件报告会采用相对模糊的时间表述，常用“上午”和“下午”等术语指代犯罪事件，所以模型会直接匹配到9、12、3、8等时间点。我们还可以看到数据主要集中在13-19年这是因为大规模数据上网也就集中在这个时间段，19年之后文书获取相对受限；另一个重要原因是电子支付的普及减少了现金携带⾏为，可能影响了特定犯罪类型。因素\n作者以2016年数据为例，分析了城市层面的犯罪数量与年平均人口、人均GDP、平均工资、城镇登记失业人数、第三产业就业人数等社会经济指标的关系。研究发现犯罪数量与城市人口、失业人数呈显著正相关，而与人均GDP、平均工资的关系呈倒U型曲线，与第三产业劳动力的相关性则呈现正U型。总结一下，这篇论文/数据集的核心贡献在于：方法创新： 成功演示了如何利用LLM技术从大规模、非结构化的公开法律文本中高效、低成本地提取细粒度的结构化信息。数据填补： 构建并公开了一个在中国背景下前所未有的、覆盖街道/社区尺度的犯罪时空数据库，极大地填补了该领域的数据空白。应用潜力： 为犯罪学、社会学、地理学、城市规划、公共政策等多个领域的研究者提供了宝贵的实证数据，有助于更深入地理解中国城市犯罪的时空动态，并为更精准的犯罪预测和预防策略提供数据支撑。二、数据集的价值与意义1.填补关键数据空白，推动微观犯罪研究正如前文所述，在中国获取公开、细粒度的犯罪时空数据一直是一个巨大的挑战。在以往的中国城市犯罪研究中，研究者们往往不得不依赖粗粒度的数据（如年度犯罪率、区县级别统计），这极大限制了理论模型的验证与微观机制的探索。而本数据集首次将分析单位下沉至街道乃至建筑尺度，让很多在国际上广泛应用但在中国长期无法验证的理论（例如近重复犯罪模式、环境犯罪学、社会无序假说）有了实证测试的可能。我们终于可以：在微观尺度上检验犯罪的热点、时序模式以及扩散规律。更精确地分析特定社区环境（如POI分布、路网结构、建筑密度、社会经济构成）与犯罪风险之间的复杂关系。为理解中国城市内部犯罪分布的异质性提供坚实的实证基础。2.展示LLM在社会科学研究中的巨大潜力该研究是利用大型语言模型处理海量、非结构化法律文本以进行社会科学数据挖掘的典范应用。传统上，从数百万份判决书中提取结构化信息需要耗费巨大的人力物力，成本高昂且效率低下。通过引入LLM，研究团队实现了自动化、规模化、低成本的信息提取，极大地提高了研究效率和可行性。这不仅为犯罪学研究开辟了新路径，也为其他依赖文本分析的社会科学领域（如政策分析、历史研究、舆情分析等）提供了重要的方法论启示：LLM可以成为解锁隐藏在海量文本数据中社会现象规律的强大工具。3.推动循证的犯罪预防与城市治理精确的数据是现代社会制定有效公共政策的前提，数据集最不应该被忽视的是它在公共安全与社会治理领域的潜在意义。有了街道和社区级别的犯罪数据，地方政府、公安部门以及社区管理者可以：更精准地识别犯罪高风险区域和时段，从而优化警力部署、巡逻路线和治安资源配置，实现“精确打击”和“靶向预防”。评估特定干预措施（如增加照明、安装监控、社区警务活动）的实际效果，为政策调整提供数据支持。在城市规划和社区设计中融入犯罪预防的考量（CPTED - Crime Prevention Through Environmental Design），例如，通过改善空间可 K 视性、增强领域感等方式降低犯罪机会。提升城市安全治理的科学化、精细化水平，增强居民的安全感。最后，该数据集以CC BY 4.0协议开放共享，伟大无需多言。三、可能的几个研究方向与应用1.犯罪学与社会学视角城市犯罪的空间分布特征\n利用高精度经纬度信息，可以系统性分析：犯罪是否呈现热点聚集效应（Hotspot Clustering）？不同类型的街道布局（主干道、支路、城中村）是否对应不同的犯罪风险？犯罪发生的时空模式，比如“午后入室盗窃”“夜晚抢劫”是否有一致性的时间窗口？\n这些分析可以进一步验证或挑战国际上已有的犯罪地理理论，比如“环境设计减少犯罪（CPTED）”理念在中国城市是否同样有效。社会经济因素与犯罪的关系建模\n结合城市级别的人口、收入、失业率、教育水平等统计数据，可以探索：哪些社会经济变量对街头犯罪有显著影响？贫富差距扩大是否真的对应局部区域犯罪率上升？人口流动性、租房比例等指标在犯罪分布中扮演什么角色？2.城市科学与公共政策应用城市空间规划与风险管理\n基于犯罪数据叠加POI（如地铁站、酒吧、学校等兴趣点），可以绘制出城市高风险区域热力图。这在以下场景非常有用：优化摄像头布控与照明设施配置；指导新建住宅小区或商业区选址时考虑安全因素；帮助警方制定更具针对性的巡逻路线和时段安排。\n如果进一步引入人口密度变化、节假日效应等动态因素，还可以做更精细的动态风险预测。公共安全干预政策效果评估比如，在某个区域引入新的警务措施后（如“热点警力加强巡逻”），可以通过对比前后犯罪数据变化，评估干预效果是否显著。也可以尝试反事实推断（Counterfactual Inference），模拟在没有干预的情况下，犯罪数量可能的演变趋势。\n这类实证检验，有助于推动公共安全领域从经验主义向数据驱动转型。3.机器学习犯罪时空预测建模\n利用现有数据，配合时序建模技术（如LSTM、Transformer），可以尝试建立短期犯罪风险预测模型，比如：给定当前时间、地理位置，预测未来24小时内某街区的犯罪发生概率。识别出不同犯罪类型在空间和时间上的演化趋势。文本挖掘与自然语言处理（NLP）\n由于原始数据是从非结构化判决文书中提取的，研究者可以进一步探索：设计更高效的Prompt或微调专用LLM，优化法律文书中的信息抽取任务。分析文书叙事风格与案件类型的潜在关联，比如某些用词、描述细节是否能帮助案件自动分类。建立法律知识图谱（Legal Knowledge Graph），挖掘案件之间潜在的关系网络。这种跨界融合，可以让传统法律文本挖掘更进一步迈向智能化、系统化。最后总结一下说实话，看到这份数据集我是非常惊喜的。长期以来，在中国语境下进行微观层面的犯罪时空分析，一直受限于数据的可得性，许多精细化的研究方法和理论验证都如同空中楼阁。我们知道问题可能存在于街道、社区，甚至某个特定的角落，但缺乏足够的数据去精确地描绘、量化和分析它。在中国这样一个对数据隐私、信息披露相对谨慎的环境下，能有研究者以如此创新的方式，基于公开渠道，结合大模型技术，构建出细粒度、高质量、而且开放共享的犯罪时空数据库，真的非常难得。在它之前，很多关于城市犯罪动态、微观社会治理的研究设想，往往只能停留在“如果有合适数据的话就能做”的假设阶段；而现在，这样的数据终于变成了可以触摸、可以下载、可以真正展开实证研究的现实。当然，正如任何数据一样，这份数据集本身也有它的局限，比如：来源于判决文书，可能存在案件选取偏差（严重犯罪案件的记录更全面，轻微案件则可能遗漏）；地理编码过程中存在一定误差；时间范围主要集中在2013-2019年，可能不完全反映当前的犯罪态势。但瑕不掩瑜。对于国内城市犯罪空间研究、社会治理建模、甚至AI法律应用探索来说，这都是一个巨大的前进步伐。如果说，数据科学在很多领域早已可以肆意驰骋，那么在犯罪学、社会学这些与人性、制度、环境高度交织的复杂领域，每一份这样真实、细致的数据，都格外值得珍惜。希望未来能有更多这样的项目，让我们在理解世界、改善世界的路上，走得更远一点，也走得更踏实一点。"
  },
  {
    "title": "MacOS使用Crossover&Wine运行Galgame（常轨脱离）崩溃解决记录",
    "summary": "你家族有精神病史吗？我有个叔叔买MAC打游戏。今天刚把PC主机寄走，想着趁空档把之前没玩完的Galgame《常轨脱离》拷到Mac上，用 Crossover（其实就是 Wine 的商用壳）继续补完进度，但结果在crossover里启动游戏后却连主菜单都没看到直接白屏然后哐哐一堆报错。一开始我以为是路径错了、容器设置有问题，甚至还试了装 DXVK、换 Windows 版本、切字体，但全都没用——白屏照",
    "tags": [],
    "url": "/posts/TechnicalTutorials/crossover-hamidashi-debug/",
    "date": "2025-04-23T00:00:00.000Z",
    "content": "你家族有精神病史吗？我有个叔叔买MAC打游戏。今天刚把PC主机寄走，想着趁空档把之前没玩完的Galgame《常轨脱离》拷到Mac上，用 Crossover（其实就是 Wine 的商用壳）继续补完进度，但结果在crossover里启动游戏后却连主菜单都没看到直接白屏然后哐哐一堆报错。一开始我以为是路径错了、容器设置有问题，甚至还试了装 DXVK、换 Windows 版本、切字体，但全都没用——白屏照旧，报错日志倒是越来越长。在谷歌和Gemini老师的帮助下，我终于排查出了问题：《常轨脱离》在启动时会尝试加载一段视频（也就是主菜单的那段），而这段视频用了 WVC1 编码的视频流 + WMA 编码的音频流，也就是 Windows 系统里常见的那套多媒体格式组合。问题就出在这里了——Wine 本身虽然能模拟 Windows 环境，但它并不包含这些视频/音频的解码器，而是试图调用 macOS 端的 GStreamer 插件来替代。可惜的是，Mac 默认根本不支持 WVC1 和 WMA，更别提我这台是 Apple Silicon 架构，很多 GStreamer 插件还得自己编译，直接完蛋。本篇博客将记录我的排查和解决流程，给诸位不畏艰难在Mac上折腾Galgame的朋友们留个参考。一、遇到的问题：启动即为崩溃，错误代码 c0000005我是用的设备是2020年的MacBook air M1， macOS Sonoma 系统，CrossOver 版本是 24.0.7。在一个新建的 Windows 10 (64位) Bottle 环境中安装了汉化版的 hamidashi_cn.exe。但每次运行程序，往往在加载界面、播放片头动画 (OP) 或刚进入主菜单时，程序就会直接崩溃退出，没有任何明确的错误提示框。为了弄清原因，我启用了 CrossOver 的日志记录功能。在冗长的日志文件 (+seh +tid +process +debugstr) 和G老师的帮助下，我发现了关键信息：GStreamer 报错： 日志中反复出现 winegstreamer error: decodebin1: Your GStreamer installation is missing a plug-in. 的错误，并且明确指出缺少 Windows Media Video 9 (video/x-wmv, wmvversion=(int)3, format=(string)WVC1) 和 Windows Media Audio (audio/x-wma, ...) 的解码器 (decoder)。致命错误： 紧随 GStreamer 错误之后，出现了 EXCEPTION_ACCESS_VIOLATION exception (code=c0000005) 的错误，表明程序试图访问无效内存，导致崩溃。地址指向了与多媒体处理相关的模块。二、分析原因，解决问题结合日志信息，问题就很明显了：游戏需要播放使用 WMV (WVC1) 视频编码和/或 WMA 音频编码的媒体文件（很可能是片头 OP 或背景音乐 BGM）。Wine/CrossOver 默认尝试使用 macOS 系统自带的多媒体框架 GStreamer 来解码这些文件。但是，我的系统环境缺少处理这些特定编码所需的 GStreamer 插件，或者存在架构不匹配的问题（我的程序是 32 位的，而 Homebrew 安装的 GStreamer 插件是 arm64 的）。解码失败导致 Wine 内部处理多媒体播放的代码出错，最终引发了 c0000005 访问冲突，程序崩溃。1.尝试：安装系统级 GStreamer 插件根据错误提示，我首先想到的解决方案是为 macOS 安装缺失的 GStreamer 插件。我打开终端，使用 Homebrew 执行了：brew install gst-plugins-ugly gst-plugins-bad gst-libav，安装确实顺利，但重启crossover之后问题依旧，甚至日志都和之前的一模一样。Crossover似乎没有能力正确调用这些系统级的 arm64 插件来处理 32 位的 Windows 程序请求。当然我毕竟不是这方面的专业人士，这只是我的猜测（2.尝试：修复安装 Wine 的多媒体组件既然系统级的不行，那我们可以把目光转向Wine环境（也就是 CrossOver 的 Bottle）内部模拟 Windows 原生的解码能力。Windows 处理这些媒体格式主要依赖 DirectShow 框架。一开始，我听从G老师的建议安装了Windows Media Player 10（WMP 10）。确实，这理论上应该能一劳永逸地解决所有 Windows Media 相关的解码问题。但在 CrossOver 的“安装 Windows 应用程序”里找到 WMP 10 并尝试安装后，过程并不顺利，弹出了若干错误提示，似乎是 WMP 10 的某些依赖组件在 Wine 环境下无法正确安装或注册。最终结果就是——安装失败，游戏启动依然白屏报错。在检索后，我发现 DirectShow Filters 也能满足游戏的组件需求。这次的下载安装过程就非常顺利：在 CrossOver 对应容器“安装软件”中选择“DirectShow Filters”，一键安装完成，不需要额外配置、不需要自己找 DLL，也没有出现之前 WMP 安装时那种依赖冲突或组件注册失败的问题。泪目泪目，终于顺利进游戏了最终结果当然也是游戏顺利启动并渲染，直到现在都没有碰到过任何报错。三、Wine的原理是什么？1.Wine 不是模拟器，而是翻译器首先，很多人会有一个常见的误解：Wine是虚拟机或模拟器。那你猜猜Wine的全名是什么？实际上，Wine就是“Wine Is Not an Emulator”（Wine不是模拟器）的缩写，Wine不是在模拟一个完整的 Windows 系统环境，它的本质是把 Windows 应用的系统调用（System Calls）实时翻译为宿主系统（这里是 macOS）的本地调用。比如你调用了 CreateFileA，Wine 就会把这个 API 翻译成 Unix 的 open() 或 macOS 的相关系统调用。这种设计理念非常聪明，也非常“极限压榨资源”，因为它不需要虚拟 CPU、内存、驱动、内核。理论上运行效率极高，启动快，内存占用低。但，代价也极其明显：它必须 准确复现海量 Windows API 行为和子系统逻辑，哪怕是一些没人用的陈年旧接口也得想办法“魔改”兼容。在M系列的MacBook上，情况还会更复杂。Windows 程序通常是为 x86/x64 架构编译的，而 M 芯片是 ARM 架构。这里需要苹果的 Rosetta 2 转译层先介入，将 x86/x64 指令实时翻译成 ARM 指令，让 CPU 能够执行程序代码。然后，Wine 再在这个基础上进行 Windows API 到 macOS API 的翻译。这等于是在一个翻译层 (Rosetta 2) 之上又叠加了另一个翻译层 (Wine)。2.为什么Wine/CrossOver问题这么多？理解了基本原理，我们就能更好地理解为什么用 Wine 跑 Windows 程序时会遇到各种问题。首先， Windows API 是一个极其庞大、历史悠久且充满“黑魔法”（未公开或非标准用法）的系统。Wine 项目需要通过逆向工程和文档研究，一点点地重新实现成千上万个 API 函数及其各种行为和边缘情况。这必然是一个持续进行且永远无法达到 100% 完美兼容的过程。很多程序的崩溃或功能异常，就是因为它调用了 Wine 尚未实现、实现有误或行为与原生 Windows 不完全一致的 API。这就是屎山代码，听巨硬说在API之上，Windows程序通常依赖于大量的动态链接库 (DLL)。这包括：系统核心 DLL： 如 kernel32.dll, user32.dll, gdi32.dll 等，Wine 会提供内建的替代实现。运行时库： 如 Visual C++ Runtimes (msvcr*.dll, vcruntime*.dll), .NET Framework 等。Wine 可能需要用户手动安装这些（通过 Winetricks 或 CrossOver 的内建安装器）。特定功能库： 如 DirectX (d3d*.dll, dinput*.dll), Media Foundation (mf*.dll), DirectShow (quartz.dll) 等。Wine 要么提供内建实现（可能不完整），要么需要安装原生版本。程序自带的 DLL。管理这些依赖关系非常复杂。版本冲突、DLL 丢失、注册不正确等问题都可能导致程序无法运行。我遇到的 WVC1/WMA 解码问题，本质上就是缺少了提供特定解码功能的原生 DirectShow Filter DLL 依赖。\n这还没完，我们打游戏的画面需要通过图形API来进行渲染，好死不死这里也是一大坨问题。 \nWindows 游戏大量使用 DirectX，在 macOS 上，图形 API 主要是 Metal (较新) 和 OpenGL (较旧) ，这就需要 Wine 需要将 DirectX 调用转换。传统方式是转为 OpenGL (WineD3D)，兼容性较好但性能一般。现代方式是通过 DXVK 转为 Vulkan，再通过 MoltenVK 将 Vulkan 转为 Metal (macOS 上的主流方案)，性能通常更好，但兼容性问题和图形错误 (glitches) 也可能更多。这个转换过程非常复杂，是许多游戏图形问题的根源。对于20年之后统一换装ARM架构芯片的MacBook而言，Rosetta 2 + Wine 的双重翻译增加了复杂性。虽然 Rosetta 2 效率惊人，但它并非完美。尤其当 x86 程序试图调用或交互 macOS 原生的 ARM 组件时（比如 Wine 试图调用系统级的 ARM 架构 GStreamer 插件来处理 32 位 x86 程序的媒体请求），就可能因为架构不匹配而失败。这很可能是我安装系统级 GStreamer 插件无效的关键原因之一。在我这次运行《常轨脱离》的过程中，我们就见识到了 Wine 的一个典型“弱点”：对 Windows 多媒体子系统（尤其是 DirectShow）的不完整支持。Windows 的 DirectShow 是个庞大又历史悠久的系统，它本质上是一个“模块化媒体处理管道”：各种格式的媒体文件会先被 Source Filter 拆包然后交给 Splitter 分离音视频流再分别由 Video 和 Audio Decoder 解码最后送入 Renderer 进行播放渲染这个过程中，每一个 Filter 都可能依赖系统预装的 DLL 或注册组件。但 Wine 并不自带这些解码器，它靠的是 winegstreamer.dll，试图把 DirectShow 的逻辑“桥接”到 GStreamer 上去，也就是让 macOS 来代打解码器的活。但我们知道，macOS 本身就不支持 WVC1 和 WMA 格式，而且 GStreamer 的 arm64 插件还经常缺失或不兼容 32 位调用，所以整条链直接断了。Wine 就在这里崩了——它试图“翻译” Windows 的 DirectShow 调用，但发现对面根本没人接电话，最后就只能以 c0000005 异常死在内存访问上。最终，我 通过 CrossOver 安装 \"DirectShow Filters\"，实际上是在 Wine 的 Bottle (模拟 C:\\ 环境) 内部，放置了原生 Windows 的、x86 架构的解码器 DLL 文件 (如 wmvdecod.dll 等) 并正确注册了它们。这样，当游戏通过 DirectShow 请求解码 WVC1/WMA 时，Wine 就能在 Bottle 内部找到并直接使用这些“原装零件”，完全绕开了与宿主系统 GStreamer 的交互及其带来的架构和插件缺失问题。这正是 Wine (和 Winetricks/CrossOver) 解决依赖问题的经典模式：缺啥补啥，尽量在模拟环境内部搞定。总结Wine 是一个伟大的项目，但它永远不是完美替代 Windows 的解法，尤其是在涉及到复杂子系统（如多媒体、字体渲染、打印系统、USB 设备调用）时。Mac 用户用 Wine 的时候，踩坑基本是常态，而不是例外。这也是为什么我强烈建议：打游戏有Win优先选win，没Win有主机优先选主机，没Win没主机优先选Linux系统（因为Linux Steam有proton兼容层），如果你既没有Win也没有主机还没有x86的Linux只能用MacOS，那你还可以考虑Parallels Desktop这种虚拟机。解决《常轨脱离》崩溃问题的整个过程，说实话比我打算玩的这部Galgame还要曲折。从白屏报错到一点点分析日志，再到理解GStreamer与DirectShow的差异、补齐Windows解码器依赖，甚至牵扯到了Apple Silicon架构和x86兼容性的问题……这大概是我为一部游戏写过最长的“序章”。Wine 能让你“运行”Windows程序，但从来没承诺你能“顺利使用”它们。 它更像是那种“不保证好用”的实验室装置——每次能跑成功都像是靠人品，能打补丁的地方比操作系统本身还多。所以，当有人问我：“你家族有精神病史吗？”我大概会平静地回答：“我有个叔叔……买 Mac 打游戏。”愿读到这里的你，至少成功启动了自己想玩的那款Gal。"
  },
  {
    "title": "评OpenAI发布o3&o4mini：喧嚣落幕，长路开启",
    "summary": ":::note\n4月23日更新：外部信源佐证4月份发布的o3确实和12月份的o3不是同一个模型，相关争议和解读已更新在2-1部分\n:::2023年初，GPT-4横空出世，重塑了人们对大模型“极限”的认知。彼时，GPT-3.5已是业内翘楚，而GPT-4的发布则像是一记重锤，砸下了OpenAI在自然语言处理、逻辑推理、代码生成乃至跨模态理解等多项能力的霸主地位，推动整个行业进入SOTA（State-o",
    "tags": [
      "模型考古学"
    ],
    "url": "/posts/AI and Deep Learning/tech-review-OpenAI-o3/",
    "date": "2025-04-20T00:00:00.000Z",
    "content": ":::note\n4月23日更新：外部信源佐证4月份发布的o3确实和12月份的o3不是同一个模型，相关争议和解读已更新在2-1部分\n:::2023年初，GPT-4横空出世，重塑了人们对大模型“极限”的认知。彼时，GPT-3.5已是业内翘楚，而GPT-4的发布则像是一记重锤，砸下了OpenAI在自然语言处理、逻辑推理、代码生成乃至跨模态理解等多项能力的霸主地位，推动整个行业进入SOTA（State-of-the-Art）不断刷新的加速通道。两年后，2025年4月16日，OpenAI正式在直播中发布o3和o4mini，模型同步上线ChatGPT官网和客户端。形式上，这是一场延续传统节奏的模型发布会；情感上，它本该是又一次“引领新范式”的时刻。但落实到生产环境，当我们审视OpenAI近期的模型更新，包括最新的o3、o4mini以及前两天的GPT 4.1系列，却发现那种“一骑绝尘”的领先优势似乎正在消退。无论是在标准评测中被Gemini 2.5 Pro超车，还是在编码能力和长上下文处理上逐步被Anthropic与Google追平乃至长期超越，OpenAI所面临的，不再是“引领一切”的熟悉剧本，而是一个对手林立、标准碎片化、差异化竞争加剧的“后神话时代”。大模型的黄金纪元或许尚未终结，但那种每一次发布都能重新定义“AI时代”的光环，已然暗淡。:::note\n如果你不想看各种Benchmark表格数据，可以直接快进到第二节“几个比较刁钻的隐忧”\n:::一、模型速览与Benchmark观察认识一个模型性能最直接和简单的方法就是看各种benchmark。虽然榜单可能会被刷/因为各种算法原因导致不公平评估，但终究是比我们自己“俺寻思”能更加拟合实际性能曲线的。1.OpenAI自己的报告OpenAI后面的各种OpenAI自己的编程基准测试还有指令遵循榜单什么就不放了，总之结论是o3 和 o4mini的性能表现比之前的o1还有o3mini要好一大截，o3 和 o4-mini 是 OpenAI 迄今为止发布的最智能模型，而且它们通常也比其前辈 o1 和 o3-mini 更高效。例如，在 2025 年 AIME 数学竞赛中，o3 的性价比边界比 o1 有显著提升；同样，o4-mini 的性价比边界也比 o3-mini 有显著提升。更普遍地讲，OpenAI 预计，在大多数实际应用中，o3 和 o4-mini 也将分别比 o1 和 o3-mini 更智能、更经济。2.Artificial Analysis LLM Leaderboard榜单可以看到排名还是稳的3.Aider LLM Leaderboards 衡量模型编码能力的榜单Aider\n目前理论上的最优解是让O3当架构师，4.1作为最终的执行者去编写具体代码4.LiveBench 我目前认为最权威的衡量模型性能的榜单Livebench\n可以看到，目前的模型性能排行里最强的是o3 High，其次是o4-Mini High，第三是Gemini 2.5 Pro。5.总结综合来看，各项Benchmark数据显示，o3与o4mini相较于前代模型（o1、o3mini）在性能和效率上均有显著提升。特别是在LiveBench等综合性及编码能力评测中，o3（尤其是o3 High）展现出了顶尖水平，位列榜首。然而，值得注意的是，Gemini 2.5 Pro等竞争对手紧随其后，差距微小。这表明虽然OpenAI在新模型上依然保持了强大的竞争力，但大模型领域的竞争已进入白热化阶段，领先优势并非牢不可破。注意，这是Benchmark的数据显示二、几个比较刁钻的隐忧1.o3在输出风格上很有R1味作为一个从2022年12月注册ChatGPT，23年年末DeepSeek V1发布就第一时间上手试用，24年年中DeepSeek V2发布就哐哐注册api给深度求索送钱，24年年末R1发布当晚直接爽玩，4月16日o3发布凌晨掀开被窝激情开测的开发者来说……目前的o3似乎在中文输出风格上，R1味有点太冲了。我在这里很难用书面的方法去展现R1味到底冲在哪了。我只能说如果你熟悉R1 或者V3 new遣词造句的文风格式，熟悉那种“味”，那么一旦当你开始使用o3，那种好比是Speed终于遇到大张伟的熟悉感会顿然涌上你的心头，让你发出释怀的笑。关于这个现象，我有一个很恶毒的猜测和一个不是那么恶毒的猜测。恶毒一点的猜测是：OpenAI在训练模型的中文能力时，可能“参考”了R1的对话数据，甚至在某些阶段直接用于蒸馏或风格迁移的微调，导致中文输出风格趋同。考虑到R1在中文长文本和特定领域（如写作、知识问答）的优异表现，且R1发布即开源，所有人都可以自由托管和商业使用R1模型，在这个数据黑箱化、预训练巨量语料不可见的时代，边界从来不是清清楚楚的，很多东西模糊又灰色，最后都只能靠“味觉”来判断。所以，如果o3在某个阶段真的“借鉴”了R1的语料或生成内容，无论是“用户行为间接采集”还是“平台内容重采样”，那倒也不能算是完全不可想象的事。更别说，R1本身就是当前中文市场最能打的模型之一，语料的结构和分布天然就带有训练价值——作为一家完全商业化的大模型公司，OpenAI确实是有这个动机去学习参考的。不那么恶毒的猜测是：o3与o4mini之所以展现出浓厚的“R1风格”，可能并非数据“致敬”，而是技术路径上的自然趋同。一方面，o3和o4mini在训练过程中均采用了DS R1同款的RL强化学习策略，RL虽然可以有效且显著的提升模型的推理能力、对齐人类偏好，但同时也会造成模型幻觉率的飙升：OpenAI技术报告称，o3和o4-mini「幻觉率」远高于此前的推理模型，甚至超过了传统模型GPT-4o。根据PersonQA基准测试，o3在33%的问题回答中产生了幻觉，几乎是o1（16%）的2倍。而o4-mini的表现更加糟糕，幻觉率高达48%。前OpenAI研究员Neil Chowdhury表示，o系列模型使用的强化学习算法，可能是问题的根源。甚至，有网友一针见血地指出，「o3对编写和开发超1000行代码的项目极其不利，幻觉率极高，且执行指令能力非常差」。不管是在Cursor，还是Windsurf中，o3编码幻觉问题显著。另一方面，这或许也是中文大模型在发展至现阶段后的一种风格收敛现象。就像早期神经机器翻译刚刚兴起时，各家的“机翻腔”都像是同一个老师教出来的那样呆板，现在反而越来越接近自然语言的真实语感；中文LLM经过大规模语料预训练和长时间对齐优化后，也许都在逼近一个“通用且高效”的表达范式——而R1，只是率先踏入了这个风格带的那一位。张口闭口量子力学夹点洋人腔这种事不要啊（有群友表示o3和o4mini那个文风肯定是蒸了R1的，只有V3和R1会那么说话，令人感慨所以，这件事其实巨他妈抽象，原来都是大家集体蒸OpenAI的，谁能想到现在的OpenAI（有可能）去反过来蒸别人了呢？实际上，我自己倾向于第二种说法。如果你上手体验了字节的Doubao 1.5 thinking模型，会发现R1、o3和doubao 1.5 thinking在输出内容风格和幻觉程度上存在很大程度上的相似性，只是o3和doubao相对来说风格不是那么肆意飞扬，稍微好了一些。1.1 4月23日 更新有网友提出反对意见：o3 参考 r1 是没道理的，无论是数据还是训练机制。因为 r1 是 1 月发布的，而 o3 在 12 月就已经训练完了，并且已经开始测试。而后训练顶多微调一下输出风格，不可能大修大改，所以无论是加数据还是改机制都是不可能的。这是我当时的解释：1.同名不同魂，4月的o3不等于12月份的o3OpenAI 一贯的节奏是「mini 先行 → 正式版」。在 o1 代，mini 与正式版的文本风格几乎一致，差异主要来自模型规模带来的知识覆盖度。而这次，o3mini 与 4 月发布的 o3 在行文语气与幻觉率上判若两人：后者的幻觉水平、口吻乃至措辞，均出现倍数级跃升。这很难用「同一条主干、不同尺寸」去解释——更像是 o3mini 仍停留在 2024 年 12 月的 checkpoint，而现在的 o3 可能是另一套训练策略和数据炼下来的新o3。2.从12月到4月，四个月的时间足够改变风格OpenAI 自己的技术报告反复提到：在冻结的基础模型上，通过 SFT → RM → PPO 的轻量级 RL 流水线， 几天就能大幅改写模型偏好。若 o3 底座真在 2024 年 12 月「出炉」，随后的 1‑4 月完全可以做多轮强化微调，把 大量新对话（包括 R1 风格样本） 注入奖励模型。3.ORM确实可以解释更多的幻觉，但文风仍然存疑将幻觉率的上升归咎于 Outcome‑supervised RM（ORM） 合理，却并不排斥「向 R1 学习文风」。PRM vs ORM 只决定模型敢不敢胡说八道；胡说八道时用什么腔调，则取决于奖励模型/指令集里灌了什么样的示例。如果 R1 的大段长句、吐槽式比喻、专业术语堆叠被高频采样进 RM，那么在弱化 PRM 之后，o3 自然会呈现出 几乎同款的“R1 味道”。从我个人角度，我自己不太认同OpenAI会使用如此低级和没有价值的手段去直接蒸，而更愿意采信 o3 和 o4mini 在训练过程中确实采用了与 DeepSeek R1 相近的强化学习策略（用大剂量 ORM + 低成本自监督产出样例 → 快速迭代 RM → 把人力标注压到极低）。DeepSeek R1的成功相当于为大家探明了这条路是可以走的大有可为的，所以没有必要去死守那些昂贵的过程监督了。今天，ARC Prize发布的报道也可以佐证我的观点：虽然前后两个模型名称一样，但实际并非相同的模型，OpenAI当下最新的o3，已针对聊天和产品应用进行了微调。图源ARC官网2.部分友商模型“跑分没赢过，实际体验没输过”是的，我指的就是Claude 3.5 sonnet和Claude 3.7 sonnet。这俩模型在开发者社区和编码领域是近乎无敌的存在。在LiveBench、MMLU、GSM8K这些标准化评测中，Claude 3.5/3.7 Sonnet 虽然始终未能站上榜首，甚至在部分任务上连Top 3都摸不到边，但一旦你真正上手用它们来做开发任务、代码辅助、文档生成和工具调用时，它就是一种诡异的「越用越顺手」的存在。尤其是工具调用，我不知道是 Cursor 和 Windsurf 等 IDE 的系统设计是不是专门为了 Claude 优化过的，但 Claude 的表现真的离谱地好：精准调用函数、不乱跳步、能推理工具的设计意图，还不会偷懒。你让它接入一个外部函数、调试一个中间状态、改一段提示逻辑，它不仅能照做，而且能顺带帮你兜一圈上下文逻辑，修个你没察觉的 bug。Claude舒服的地方在于它不像 GPT 系列那样“非要你把指令说到尽头才开始动手”，也不会像 Gemini 那样喜欢大搞“破坏性编程”，Claude 更像是你熟悉多年的牛马资深程序员，不仅懂你的代码，还开始懂你的人了——你要的是 功能、可维护性 和 语义一致性，它全给你打包搞定。而在 Claude 3.7 上，这种感受进一步升级。3.7 不仅延续了 3.5 的超强上下文连贯能力，在自然语言生成、内容总结、信息检索与重组方面也逐渐逼近该领域SOTA模型的水平，同时解决了之前 Claude 系列偶尔“机械重复”或“语言风格偏保守”的问题，让整体交互过程更松弛、更自然。对比之下，GPT 系列虽然依旧强势，但在工具调用的鲁棒性、代码生成的意图一致性、以及复杂任务的状态记忆能力上，已经在许多实操场景中开始被 Claude 逐渐蚕食。这就很像是我们这些早期模型用户熟悉的一个体验悖论：跑分高的，未必是你愿意日常用的；跑分中等的，反而是你一直留在侧栏、舍不得关的模型。现在，这种悖论正在被 Claude 重新定义：不吵不闹，不炫技，也不搞什么“仿生”表演，而是扎扎实实把你的生产力抬一档。从这一点来看，OpenAI 的领先确实还在，但竞争对手们也已经不再是“差一个世代”，而是“差一个偏好”和“差一个界面集成”而已。3.降智！降智！还是降智！奥特曼那点心思全对付他客户去了，防客户防比防友商还狠传说中，这个世界上有两种GPT：一种是大家普遍用到手的，已经降智到连自己爹都不认识的普通GPT；还有一种是只活在KOL和OpenAI信徒的嘴里的那种无降智的薄纱其他所有模型的GPT。遗憾的是，我和大多数开发者、写作者、爱好者一样，接触到的，绝大多数情况下是第一种。自从 GPT-4 于 2023 年初发布以来，关于「降智」的争议就没停过。4.0 刚出那阵子，是真的震撼，那种一眼惊艳、处处可靠的语言组织力与多步推理能力，堪称 AI 使用体验的黄金时代。但从 2023 年 Q3 开始，一切都开始变了：不该忘的上下文，它开始忘；明明能回答的问题，它开始扯别的；结构化提问，它能写出洋洋洒洒一大段模糊废话，但就是不肯列点；你让它生成代码，它会直接偷懒给你一个摘要，剩下的要求你自己写可能不是我们不会用了，而是被“打上标签”了。一个月200刀的Pro用户可以纵享丝滑，API用户才配享真正的智能，免费用户看看热闹就行，Plus用户……嗯，Plus用户交了钱也不是人。用户体验一路走来有点像开盲盒：你永远不知道今晚上线的，是哪一个版本的GPT在陪你过夜。这在体验层面造成了极大的挫败感。明明你知道它「本来是会的」，甚至可能「一个月前还会」，可现在它偏偏不愿给你写、不愿继续、不愿回答。而这一切的最终解释，永远是那句玄学通用句：“模型行为是不可预测的。”上述三点，导致了新模型o3和o4 mini跑分很好看，但落到现实使用中可能综合体验并不如Claude 3.7 sonnet/Gemini 2.5 Pro，甚至是自家上一代模型4o。新的模型确实进一步拓展了推理模型的性能边际，但距离一个大家设想中的新全能旗舰模型还差得很远。\n:::note\n此处致敬传奇万亿参数再过几个月就要从api里下线的肺雾模型GPT 4.5\n:::三、批判性观点：OpenAI的优势/护城河是什么？当然啊当然，本篇博客我无意疯狂看空OpenAI，无论如何OpenAI作为大模型领域的先驱者，仍然拥有着巨大的存量优势。o3和o4mini的优势区间为模型基础的视觉能力，OpenAI黑科技一般的对齐能力，和ChatGPT本身作为一个大的Agent产品的设计能力。1.自GPT 3.5发布以来就无人能及的黑科技一般的对齐能力我不得不承认的是，OpenAI在模型对齐方面确实直到现在都无人能及。无论是指令遵循、角色扮演、场景安全，还是整体语言风格的收束度，GPT 系列依然是“最像人在和你对话”的模型之一。这种极致“拟人感”背后，靠的是大规模的人工反馈、有监督微调、强化学习、分层安全审查等复杂系统协同训练的结果，而不是单纯的“规模压制”或者“架构创新”。这意味着什么？意味着OpenAI并不是只会训练大模型的公司，它更像是一家“AI行为塑造公司”，它在努力训练一种符合当代社会技术伦理、法律红线、审查规范、平台责任的“可控性智能”。也因此，它不再那么锋利，不再那么有趣，也不再那么纯粹。但它很“安全”、很“可控”，很“适合部署到你的CRM系统、医疗建议引擎、或少儿编程辅助助手上”——这就是OpenAI未来会变成的样子。OpenAI的模型可能从来都不是“最好的选择”，但一定是“最不坏的选择”。2.ChatGPT本身就是一个Agent产品你可以在 Hugging Face 上试无数模型，在 Gemini 的AI Studio里爽用Gemini 2.5 Pro，在 Cursor或者Windsurf里疯狂用屎山代码拷打Claude 3.7 ，但你依旧很难不打开 ChatGPT——哪怕是随手查个句子、翻个译、写个提纲，ChatGPT 依旧是 “默认的那个AI”。用户心智才是真正的护城河。ChatGPT 已不再是一个单纯的聊天机器人，而是一个正在变成“默认认知外包入口”的通用朋友 ：它能帮你跑插件、调API、做笔记、分析图像、写代码、讲道理、装懂文学、甚至假装是你女朋友。它接入了浏览器、文件分析、代码编辑、系统指令、Agent任务链……这是 Claude 和 Gemini 暂时还没法完整替代的。这一点在ChatGPT支持索引全部对话记录作为记忆之后显得尤为明显，每个用户和ChatGPT进行的每一次对话都是在调教一个更贴合自己需求的私人AI助理，用户自己产生的对话数据天然成为了留存用户的最佳手段。而你只要是个 Plus 用户，它就能稳稳陪你过夜，不离不弃。所以说，OpenAI在产品设计上的节奏可以不准确的归结为：模型更新节奏可以慢一点，性能差异可以模糊一点，重点是让用户在产品上“沉没成本深一点”。它要的不是你觉得 GPT 最强，它要的是你 “懒得换”。3.但这个护城河真的就稳固吗？表面上看，OpenAI确实构筑起了一道又厚又高的护城河：最强对齐能力 + 最广泛平台入口 + 最庞大用户体量。但对于一家商业化公司来说，这条护城河真的就稳固吗？我们现在打开ChatGPT，是因为我们“已经在用”；我们让它帮忙，是因为“它都在这儿了”；我们续费Plus，是因为“好像别的也差不多贵”。 但如果哪天Claude开放了插件生态，Gemini支持了真正的记忆，Qwen痛改前非开始用心做产品……用户真的不会走？一个真实的互联网产品规律是：用户习惯可以被迁移，但信任一旦动摇就再难回头。而过去一年中，OpenAI不断在降智争议和过于严苛的风控中消耗用户信任，其平台护城河的根基，其实并没有比任何一家闭源巨头强太多。ChatGPT 是当下最优解，但它不一定是未来最优选。用户不是留在平台上的人，他们只是暂时没离开的流动性。四、从一超多强到六极我现在仍然还记得 GPT-4 刚发布那会给中文互联网造成了多大的震撼。当时“第四次工业革命”“AI亡国论”“中国为什么训练不出GPT这样伟大的模型”等各种速败党言论四起，知乎、微博、B站、虎嗅满天飞都是“完了完了我们这次又要错过了”的语气。舆论普遍带有悲观情绪，哪怕是为建制派辩护的乐观论点，也都集中在“美国擅长颠覆式创新，中国擅长工程化落地”“我们可以慢一点，但最终会赶上”这些“战略腚力论”，言下之意，我们在基础模型能力上似乎已望尘莫及。那是一个“一超多强”格局看似已定的时刻，OpenAI如日中天，其他所有玩家都像是遥远的追赶者。在2023年到2024年上半年，Gemini和Grok持续拉跨，大而无能；Meta的Llama独占开源模型社区鳌头，基本上所有的开源大模型infra项目都是围绕Llama构建的；Mistral初期亮眼但在实际份额中并不瞩目。然而，技术浪潮的演进速度，总是超乎最悲观或最乐观的预言家的想象。先是阿里的Qwen系列异军突起，在开源社区的表现甚至超越了Meta的Llama，一度成为开源模型的新标杆，打破了“西方独大”的神话。紧接着，DeepSeek V3 和之后的DeepSeek R1 横空出世，其优异的性能和极具竞争力的成本效益，不仅在国内引发轰动，更实实在在地“给全世界带来了一点小小的中国AI震撼”。“开源“再也不是落后闭源模型的借口，R1直接让国内的大模型独角兽折了继续搞基础模型预训练的心气。在Llama4给大家拉了一坨大的之后尤甚在海外，Gemini 2.5 Pro彻底给谷歌打了一场翻身仗，在多个榜单持续刷新SOTA成绩；2024年年中Anthropic发布的Claude 3.5 sonnet直到现在在很多编程榜单中依然非常能打，之后的Claude 3.7更是长期被视为最佳Coding模型。过去两年，大模型的竞争格局正在经历从一超多强到全球六极的转变，这六极分别是：OpenAI (GPT系列, o系列): 曾经的绝对领先者，如今仍是综合实力最强的玩家之一，尤其在模型对齐、产品化（ChatGPT）和品牌心智上优势明显，但面临“降智”争议和日益激烈的性能追赶。Google (Gemini系列): 凭借强大的研发实力和数据资源，在Gemini 2.5 Pro后强势回归，展现出在多模态、长上下文和综合推理能力上的顶尖水平，是OpenAI最直接的挑战者。Anthropic (Claude系列): 以其在编码、写作、长文本处理和安全性方面的卓越表现，尤其是在开发者社区中赢得了极高声誉，形成了独特的竞争优势和用户粘性。xAI (Grok): 马斯克麾下的变量，虽然早期模型表现不尽如人意，但靠暴力堆卡堆算力训出了综合表现非常不错的Grok 3系列。DeepSeek (V系列, R系列): 中国AI力量的杰出代表，以技术实力和开源策略（尤其是R1）震撼市场，证明了中国在基础模型研发上的能力，并在性价比上极具竞争力。Alibaba (Qwen系列): 同样是中国头部玩家，通过强大的模型性能和积极的开源贡献，在国内外都获得了广泛认可，尤其在中文能力和企业级应用方面根基深厚。这“六极”的形成，标志着大模型领域进入了一个群雄逐鹿、各擅胜场的新阶段。不再是OpenAI一家独大，定义所有标准；而是多个技术高峰并存，在不同维度（性能、成本、特定任务、开源/闭源、区域市场）上展开激烈厮杀。曾经我们以为，大模型的未来属于“一个GPT，统治所有API”的超级智能。但今天看来，大模型的终点很可能不是“一个超神的AI”，而是“多个足够好的AI，共享一个复杂的社会系统”，也就是Multi Agent系统。对OpenAI而言，这意味着曾经遥遥领先的“代差”优势正在快速消失。它的对手们不仅在Benchmark上步步紧逼，更在实际应用场景中找到了差异化的突破口（如Claude的编码、Gemini的多模态）。“护城河”在变浅，挑战者在变强。这正是本文探讨的OpenAI“颓势尚显”的宏观背景——并非其自身能力的绝对下降，而是在一个更强大、更多元的竞争环境中，其相对领先地位所面临的严峻挑战。尾声：喧嚣落幕，长路开启2023年是浮躁的，GPT-4横空出世，一切都像是“科技奇点”在提前兑现。OpenAI带着超级模型、超级叙事和超级平台，把所有人拉进了一场压倒性的“快变量”竞赛：谁模型更大？谁token更长？谁benchmark更高？谁先把AI Agent跑起来？但2024年到2025年这段时间里，快变量的边际红利，正在迅速递减。不再有“谁一发模型所有人都闭嘴”的时代；不再有“你跑得快就能吃下整个生态”的黄金窗口；不再有“训练规模等于智能程度”的直线逻辑。那个大家寄予厚望的GPT 4.5拉了，GPT5也不再是之前投资人和极客们设想的真全能模型，而是基于多模型自动路由的Agent系统。GPT-4之后，所有的新模型都开始变得越来越像“一个可接受的答案”，而不是“唯一的真理”。而当“唯一正确”的神话破灭，真正重要的问题才刚刚开始：我们要什么样的智能？我们希望它在哪些地方参与，又在哪些地方克制？我们是要一个全知的“黑盒神明”，还是要一套透明的“协作工具”？我们是想复制人类，还是补足人类？这些问题，不可能在一个模型版本中回答清楚，也不可能靠一次技术突破终结争议。它们只能被长期摸索、被无数次部署试错、被现实场景一遍又一遍打磨修正。AI真正进入了“工程-反馈-伦理-演化”四步循环的慢变量阶段。喧嚣落幕，长路开启——行百里者半九十，前半段是热血，是风口，是资本与算力的狂奔；后半段却是细活，是冷静，是系统性工程与“慢变量”的博弈。从模型到平台，从平台到生态，从生态到社会接口，AI这场漫长的工业化进程，已经越过神话阶段，进入基础设施时代。这条路不会再有太多奇迹，但它值得我们走下去。慢一点也没关系，关键是别停，也别偏。AI的“黄金热潮”也许正在冷却，但它的真实时代才刚刚展开。"
  },
  {
    "title": "神经药理学笔记：可卡因等药物如何操控人脑奖赏系统",
    "summary": "观前注意我不能对这篇博客内容的科学性、真实性和有效性做任何保证不去伤害别人，不去伤害自己引言：天生的快乐与化学的“捷径”“The cost of a thing is the amount of what I will call life which is required to be exchanged for it.”一件东西的成本，是你必须为它交换多少‘生命’。—— Henry David ",
    "tags": [
      "心理学与神经科学"
    ],
    "url": "/posts/HumanSciences/dopamine-hijack-and-addiction/",
    "date": "2025-04-16T00:00:00.000Z",
    "content": "观前注意我不能对这篇博客内容的科学性、真实性和有效性做任何保证不去伤害别人，不去伤害自己引言：天生的快乐与化学的“捷径”“The cost of a thing is the amount of what I will call life which is required to be exchanged for it.”一件东西的成本，是你必须为它交换多少‘生命’。—— Henry David Thoreau, 《Walden》阳光洒在身上的暖意，品尝美食的满足感，与挚友相聚的欢愉，达成目标的成就感……这些我们生活中自然而然体验到的“快乐” 并非凭空而来，并非什么神秘力量的恩赐，而是来源于我们的生物本能，是一堆神经元产生的生物信号，，是大自然为了鼓励我们重复那些有利于生存和繁衍的行为（如进食、社交、学习）而设下的“驱动程序”，构成了我们生活、成长乃至探索世界的原始动力。人类在探索世界的过程中，也发现了许多外来的化学物质。从一杯驱散困意的咖啡，到历史上用于缓解疲劳的古柯叶（可卡因的来源），再到现代实验室合成的强效物质如芬太尼，它们似乎提供了一条“捷径”，能够绕过自然的努力和等待，直接作用于我们的大脑，引发从温和提神到强烈欣快感（Euphoria）的各种体验。这便引出了一个核心问题： 这些看似与生存本能无关的外来分子，为何能如此深刻地影响，甚至“劫持”我们大脑中掌管情绪和动机的精密系统？它们是如何模拟、放大我们天生的快乐信号，仿佛一把能强行开启愉悦之门的“化学万能钥匙”？本篇博客将从药理学的视角出发，探讨大脑中负责处理奖赏和动机的关键区域——中脑边缘多巴胺通路。我们将聚焦几种典型物质：剖析可卡因如何通过强效干扰多巴胺信号，制造出短暂却极具诱惑力的欣快感；同时，我们也会审视日常接触的咖啡因，理解它相对温和的提神作用背后，与多巴胺系统发生的微妙互动。此外，我们还将简要探讨阿片类药物、酒精、尼古丁等其他物质影响大脑奖赏系统的多样化途径。需要强调的是， 本文旨在科普相关的药理学知识，帮助读者理解这些物质作用于大脑的生物学基础，从而更清晰地认识其潜在风险，尤其是成瘾的可能性。本文绝不鼓励或美化任何形式的非医疗目的药物使用。 了解这些化学“钥匙”如何与我们大脑的“锁孔”互动，是科学认识自我、保护身心健康、并做出明智选择的重要一步。一、大脑的“奖赏中心”：中脑边缘多巴胺通路配图人感觉到“快乐”不是因为大脑有一个快乐按钮，按一下就能原地化学极乐，而是有一个复杂精密的网络来负责处理与奖赏、动机和学习相关的信息。这个网络的核心，被称为大脑奖赏通路（Reward Pathway），其中最关键的一条线路，就是我们接下来要重点介绍的中脑边缘多巴胺通路（Mesolimbic Dopamine Pathway）。这条通路就像大脑内部的一条“高速公路”，连接着几个关键的“站点”，共同调控着我们的欲望和行为。1.中脑边缘多巴胺通路结构如上图，该通路主要涉及三个脑区，分别是腹侧被盖区（Ventral Tegmental Area, VTA）、伏隔核（Nucleus Accumbens, NAc）和前额叶皮层（Prefrontal Cortex, PFC）。腹侧被盖区（VTA）位于中脑，可以看作是这条通路的“起点”或“多巴胺工厂”。这里聚集着大量的多巴胺能神经元（产生和释放神经递质多巴胺的神经细胞）。当VTA被激活时，它就会向通路下游的区域释放多巴胺。伏隔核（NAc）则位于大脑前部的基底神经节，是VTA投射的主要目标之一，也是奖赏回路的“核心枢纽”或“快感体验区”。伏隔核接收来自VTA的多巴胺信号，并在整合来自其他脑区（如杏仁核-处理情绪，海马体-处理记忆）的信息后，在产生愉悦感、驱动动机（“想要”去做某事）和强化学习（记住哪些行为能带来好结果）中扮演着至关重要的角色。最后就是我们的前额叶皮层（PFC），它位于大脑的最前端，是我们的“决策中心”和“执行控制官”。它接收来自VTA和NAc的信息，并参与更高级的认知功能，如规划、决策、冲动控制以及赋予奖赏信息更复杂的意义。PFC帮助我们将奖赏感受与具体的目标和行为联系起来，评估行为的长期后果。除了这三个核心结构，杏仁核（Amygdala）和海马体（Hippocampus）等也与奖赏通路紧密相连，分别负责将奖赏与情绪和记忆联系起来，使得奖赏体验更加丰富和持久。2.多巴胺（Dopamine, DA）：远不止“快乐分子”长期以来，多巴胺被通俗地称为“快乐分子”。虽然多巴胺的释放确实与愉悦感受有关，但现代神经科学的研究表明，它的作用远比这复杂和深刻。与其说多巴胺直接制造快乐（“喜欢”，liking），不如说它更像是一个“动机”和“显著性”信号：驱动动机（Motivation）：多巴胺激发我们去追求目标的“渴望”或“想要”（wanting）。它告诉我们：“嘿，这个东西很重要，值得你付出努力去得到它！”标记显著性（Salience）：当环境中出现意想不到的、或者比预期更好的奖赏（或与奖赏相关的线索）时，多巴胺会飙升，仿佛给这个刺激贴上了一个“高亮”标签，使其在众多信息中脱颖而出，引起我们的注意。强化学习（Reinforcement Learning）：多巴胺帮助我们学习和巩固那些能够带来奖赏的行为。当一个行为导致了多巴胺的释放，大脑就会倾向于重复这个行为。这是一种强大的学习机制。3.自然奖赏如何激活这条通路？想象一下：当你饥肠辘辘时吃到美味佳肴，口干舌燥时饮下清泉，或者完成一项挑战获得认可与赞美时，这些自然奖赏会有效地激活VTA的多巴胺神经元。随后，多巴胺被释放到伏隔核（NAc） 及前额叶皮层（PFC） 等区域。\n在NAc，多巴胺的增加不仅带来了愉悦感，还强化了与获取食物、水或认可相关的行为模式和环境线索（比如你记住是哪家餐厅的菜特别好吃，或者完成哪种任务会得到表扬）。这种强化作用极大地增加了我们未来在类似情境下再次寻求这些奖赏的可能性。同时，信息传递到PFC，帮助我们思考：“嗯，这种感觉真不错，下次我还想体验。我该如何计划才能再次获得呢？”这个由自然奖赏驱动的多巴胺通路活动，是一个完全正常且对生存至关重要的生物学过程。它确保我们积极从事那些有利于个体生存和繁衍的活动（如进食、饮水、社交、学习）。理解了这个天然的奖赏系统，我们就能更好地理解，为什么某些药物能够如此轻易地“入侵”并“操控”它，从而产生强大的效果和潜在的危害。接下来，我们将看看可卡因是如何通过“劫持”这条通路来发挥作用的。4.药物成瘾的机理综述中脑边缘多巴胺系统在药物成瘾的神经生物学机制中占据核心地位，受到广泛关注。急性给药后，绝大多数成瘾药物都能激活MLDS。该系统不仅是成瘾药物产生奖赏 、强化等共同效应的基础，也是形成条件性信号关联（Cue Association）、诱导渴求（Craving） 和觅药行为（Drug-Seeking Behavior） 的关键神经基础。成瘾药物普遍具有一个关键的共同特性：它们都能引起大脑伏隔核区域多巴胺（Dopamine, DA）神经元末梢释放的DA增加，从而引发药物的奖赏效应。然而，不同药物增加DA释放的起始机制各不相同：直接激活：例如，海洛因（通过作用于阿片受体间接影响，但原文简化为“直接激活”）和尼古丁可以直接激活DA能神经元，促进DA的释放。间接去抑制：吗啡：并非直接作用于DA能神经元，而是通过激动GABA能中间神经元上的阿片受体，抑制这些抑制性中间神经元的活动。这解除了GABA神经元对DA神经元的紧张性抑制，从而使得DA释放增加。酒精和苯环己哌啶（Phencyclidine, PCP）：可能通过拮抗NMDA受体等机制，导致DA神经元发生脱抑制性释放，进而增加DA水平。阻断再摄取：苯丙胺类药物（Amphetamines） 和可卡因（Cocaine） 则通过阻断多巴胺转运体（DAT） 对突触间隙中DA的回收（再摄取），导致突触间隙DA含量急剧升高。这种由药物强制引发的、远超自然奖赏水平的DA急剧增加，最终作用于突触后膜的DA受体，介导了强烈的奖赏效应。这种强大的奖赏效应被认为是 “心瘾” （即强烈的心理渴求）形成、维持、复发以及强迫性觅药行为产生的神经生物学基础。因此，从理论上讲，抑制药物诱导的DA释放增加，或阻断DA与其受体的结合及其下游效应，均可能抑制奖赏效应的形成，从而达到预防药物成瘾的目的。然而，成瘾药物在促进DA释放、产生奖赏效应的同时，往往对DA能神经元本身也具有毒性作用。部分研究在对海洛因成瘾大鼠VTA和NAc区域DA能神经元超微结构的研究中发现，海洛因成瘾及复吸可导致DA神经元发生变性和凋亡，且复吸次数越多，脑损伤越大。另有许多研究证明，长期使用成瘾药物均会导致DA神经元受到一定程度的损害，尽管在戒断一段时间后其形态功能可能才慢慢恢复。基于成瘾药物对DA神经元的损害，保护DA神经元免受损伤被认为是在预防和治疗药物成瘾方面具有重要意义的策略。目前，一些具有预防和治疗成瘾作用的中药或天然药物显示出DA神经元保护作用。例如，经Cedemex（一种治疗成瘾的草药制剂）治疗后，吗啡依赖大鼠的海马（Hippocampus）、VTA以及下丘脑（Hypothalamus）神经元的凋亡较对照组明显减少，说明Cedemex可通过明显抑制神经元的凋亡起到保护作用。二、可卡因：强效“劫持”多巴胺信号可卡因是一种从古柯叶中提取的生物碱，属于强效的中枢神经系统兴奋剂（Psychostimulant），在药理学上被归类为再摄取抑制剂（Reuptake Inhibitor）。它主要的作用靶点是存在于神经末梢突触前膜上的单胺类神经递质转运体（Monoamine Transporters），虽然它对三种主要的单胺类递质——多巴胺（DA）、去甲肾上腺素（NE）和血清素（Serotonin, 5-HT）的转运体都有抑制作用，但其产生强烈欣快感和高成瘾性的主要原因可被归因于其对多巴胺转运体（Dopamine Transporter, DAT） 的强力阻断。1.机制解释可卡因作用图\n在正常情况下，当一个神经冲动到达VTA多巴胺神经元的末梢时，多巴胺被释放到其与伏隔核（NAc）神经元之间的突触间隙中。多巴胺与突触后膜上的多巴胺受体结合，传递信号。为了精确控制信号的强度和持续时间，突触前膜上的DAT会像一个“回收泵”一样，迅速将突触间隙中多余的多巴胺重新泵回突触前神经元内，以便储存和再利用。这个过程有效地终止了多巴胺信号。那么，如果我们摄入了可卡因，此时的可卡因分子就能够高亲和力地结合并阻断DAT，“回收泵”的入口被可卡因堵住了。结果就是，多巴胺一旦被释放到突触间隙，就无法被有效清除。由于再摄取受阻，突触间隙中的多巴胺浓度会急剧、大量地升高，其水平远超自然奖赏（如食物或性）所能引发的生理范围。这种异常高的多巴胺水平，尤其是在奖赏通路的核心区域——伏隔核（NAc）——会过度刺激突触后神经元上的多巴胺受体，产生了多巴胺“洪水”。这种突触间隙多巴胺的“洪水”直接导致了可卡因使用者体验到的强烈欣快感（intense euphoria）、精力极度充沛（boundless energy）、自信心爆棚（inflated self-esteem）、思维敏捷（感觉上）、以及食欲和睡眠需求的降低。同时，可卡因对去甲肾上腺素转运体（NET）和血清素转运体（SERT）的抑制，也分别贡献了其提高警觉性、心率血压升高（NE效应）以及一些情绪调节（5-HT效应）的作用。可卡因通过作用于大脑边缘系统(包括腹侧被盖区(VTA)和伏隔核(NAc)等愉悦与奖赏中枢、杏仁核和海⻢体等记忆中枢、以及负责决策与抑制的额叶皮层)，短期内引发欣快感，⻓期则导致成瘾。可卡因导致神经递质多巴胺在VTA与NAc细胞交界处积聚，触发愉悦感及NAc细胞活动，使大脑对后续用药更加敏感。这些活动包括：增加转录因子(如ΔFosB)的生成、改变基因活性、影响多种蛋白质的合成、以及促进新树突和树突棘的生⻓。2.成瘾机制一般来说，科学研究认为吸食可卡因会导致伏隔核（NAc）神经细胞物理结构的重塑，这种变化在末次接触可卡因后可持续数月甚至更久。长期接触可卡因会促使这些细胞的树突延伸并萌发新分支（Nestler, 2001; Robinson and Berridge, 2001）。树突是从神经元胞体延伸出的分支状纤维，负责接收其他神经细胞的传入信号。如同更大的天线能接收更多无线电波，理论上伏隔核中更多的树突分支将收集更多来自海马体、杏仁核及前额叶皮层等脑区的神经信号。这将强化这些脑区对伏隔核的影响，进而驱动与成瘾相关的某些极持久行为改变。例如当药物相关记忆被触发（如看到吸毒用具）时，来自海马体和杏仁核的增强输入可能引发强烈渴求感。正是这种直接、强效地增加NAc多巴胺水平的能力，使得可卡因能够强力“劫持”奖赏通路。大脑将这种由药物引起的、远超自然的强烈奖赏信号错误地解读为极度重要和值得追求的事件。我们人类大脑学好的很困难，但坏的一学便知。当通过吸入（如快克可卡因）或静脉注射等快速进入大脑的方式使用时，可卡因能在几秒到几分钟内达到峰值效应，带来极为强烈的冲击感。但其作用也相对短暂，因为药物会被身体代谢清除。这种快速起效和快速消退的药代动力学特征，极易诱发反复使用的“渴求”和“连吸”行为。由此，每次使用可卡因，都在强力地强化药物使用行为本身。大脑迅速建立起药物与极端快感的联结，使得与药物相关的线索（人、地点、物品）都变得极具诱惑力，驱动强迫性的觅药和用药行为，即成瘾。临床研究表明可卡因或兴奋剂滥用引起持续的神经和精神损伤，并可能引起神经元变性。包括多部位或全皮层缺血、出血、梗死、眼神经病、皮层萎缩、识别损伤、情绪和运动障碍。表现为认知能力及动机缺陷、视力损伤、行为去抑制、注意缺陷、情绪不稳、抑郁、缺乏快感和持续的运动障碍等。三、咖啡因：温和的“提神剂”与多巴胺的微妙联系这段我直接引用我之前博客的内容了。咖啡因（1,3,7-三甲基黄嘌呤）是一种生物碱，属于甲基黄嘌呤类化合物。它是全球范围内消费最广泛的中枢神经系统 (CNS) 兴奋剂，天然存在于咖啡豆、茶叶（其中咖啡因含量通常低于等量咖啡）、可可豆、瓜拉那果和可乐果等多种植物中。由于其提神醒脑、驱除疲劳的效果，咖啡因被广泛添加到饮料（咖啡、茶、能量饮料、软饮料）、食品以及某些非处方药和处方药中（例如，作为止痛药的辅助成分或用于治疗新生儿呼吸暂停）。咖啡因的主要药理作用机制是非选择性拮抗腺苷受体 (Adenosine Receptors)，特别是A₁和A₂<0xE2><0x82><0x90>亚型。腺苷是一种内源性嘌呤核苷，在中枢神经系统中作为一种重要的抑制性神经调质。它通过与腺苷受体结合，抑制神经元活动，促进睡意和血管舒张。咖啡因的分子结构与腺苷相似，能够竞争性地结合并阻断腺苷受体，从而阻止腺苷发挥其抑制作用。这种去抑制 (Disinhibition) 效应导致许多神经递质（包括多巴胺、去甲肾上腺素、乙酰胆碱、谷氨酸和血清素）的释放增加，神经元兴奋性增强，最终表现为中枢神经系统的兴奋。一般来说，口服咖啡因后会迅速且完全吸收，生物利用度接近100%，通常在摄入后30-120分钟达到血浆峰浓度，咖啡因会广泛分布于全身组织，能够轻易透过血脑屏障和胎盘屏障。摄入体内后，咖啡因主要在肝脏通过细胞色素P450酶系（特别是CYP1A2同工酶）代谢。主要代谢产物为副黄嘌呤 (Paraxanthine, 约占84%)、可可碱 (Theobromine, 约占12%) 和茶碱 (Theophylline, 约占4%)，这些代谢产物本身也具有一定的生物活性。代谢产物主要通过肾脏随尿液排出，仅少量（约1-2%）以原形排出。咖啡因的消除半衰期个体差异较大，成人通常为3-7小时，但受多种因素影响（如遗传因素、吸烟（加速代谢）、怀孕（减缓代谢）、肝病（减缓代谢）以及某些药物（如氟伏沙明可显著抑制CYP1A2））。长期规律摄入咖啡因会导致对其多种效应产生耐受，尤其是对心血管、利尿和睡眠干扰作用；但对主观兴奋作用的耐受性发展相对较慢且不完全，耐受性的产生可能与腺苷受体的上调有关。此外，咖啡因可产生一定程度的心理依赖和轻微的生理依赖，虽然其成瘾潜力远低于强效精神活性物质，但规律摄入者突然停用可能出现戒断症状。最常见的戒断症状是头痛（搏动性），其他症状可包括疲劳、嗜睡、注意力不集中、情绪低落或易怒、类似流感的症状（如肌肉酸痛、恶心）。戒断症状通常在停用后12-24小时出现，20-51小时达到峰值，可持续2-9天。四、机制万花筒：其他药物如何制造“快乐”？我们在上几章节已经初步探讨了可卡因如何通过阻断多巴胺回收来“强制”提升快乐感，以及咖啡因如何通过拮抗腺苷来间接影响警觉性和多巴胺系统。然而，能影响我们情绪和动机状态的化学物质远不止这两种，它们作用于大脑奖赏通路的机制也呈现出多样性，宛如一个“机制万花筒”。尽管初始作用靶点各异，但它们往往殊途同归——最终都不同程度地影响了中脑边缘多巴胺通路的活动，尤其是增加了伏隔核（NAc）中的多巴胺水平。下面，我简要介绍几种常见的成瘾性物质是如何通过各自独特的途径来“拨动”奖赏系统的：1. 阿片类药物（Opioids）：解除“刹车”的欣快感代表物质： 吗啡（Morphine）、海洛因（Heroin）、芬太尼（Fentanyl）、羟考酮（Oxycodone）等。作用机制： 阿片类药物主要通过激动大脑中的阿片受体（特别是μ-阿片受体）发挥作用。在奖赏通路的核心区域VTA，存在着一些抑制性的GABA能中间神经元，它们像“刹车”一样，平时会对多巴胺神经元产生一定的抑制作用。阿片类药物能够抑制这些GABA能神经元的活动。当“刹车”被抑制后，VTA的多巴胺神经元就脱去了束缚，变得更加活跃，从而向伏隔核（NAc）释放更多的多巴胺。效果与结果： 这种多巴胺的增加，加上阿片类药物在其他脑区（如负责疼痛感知和情绪的区域）的作用，共同产生了强烈的欣快感、镇痛效果和深度放松感。正是这种强大的奖赏效应和解除抑制的机制，使得阿片类药物具有极高的成瘾潜力。2. 酒精（Alcohol / Ethanol）：多系统干扰的复杂效应代表物质： 乙醇（各种酒类饮品中的主要活性成分）。作用机制： 酒精的作用机制非常复杂，它并非作用于单一类型的受体，而是广泛影响多个神经递质系统：增强GABA作用： 酒精能增强GABA<0xE2><0x82><0x90>受体的功能，增加抑制性神经传递，这导致了酒精的镇静、抗焦虑和肌肉松弛效果。抑制谷氨酸作用： 酒精会抑制NMDA受体（一种主要的兴奋性谷氨酸受体）的功能，干扰学习、记忆和神经可塑性。影响多巴胺： 关键在于，酒精同样能增加伏隔核（NAc）中多巴胺的释放。其具体机制仍在研究中，但可能涉及对VTA多巴胺神经元的直接或间接刺激（可能通过减少GABA的抑制或影响其他调控通路），以及促进内源性阿片肽（如内啡肽）的释放，后者也能间接促进多巴胺释放并带来愉悦感。效果与结果： 酒精初期可能带来放松、社交意愿增强和轻度欣快感（部分归因于多巴胺的增加和GABA的抑制解除效应），但随着剂量增加，其抑制性作用会逐渐占据主导。其对奖赏通路的影响，是酒精依赖形成的重要因素之一。3. 尼古丁（Nicotine）：直接“点火”多巴胺神经元代表物质： 烟草制品中的主要精神活性成分。作用机制： 尼古丁的结构与神经递质乙酰胆碱（Acetylcholine, ACh）相似，它能直接激动位于VTA多巴胺神经元上的烟碱型乙酰胆碱受体（nAChRs）。想象一下，尼古丁就像一把钥匙，直接插入并“点火”了这些多巴胺神经元的引擎，导致它们更频繁地发放冲动，并向伏隔核（NAc）释放更多的多巴胺。此外，尼古丁还会影响其他神经递质（如谷氨酸、GABA）的释放，进一步调节多巴胺系统的活动和整体的神经兴奋性。效果与结果： 多巴胺的快速释放带来了短暂的愉悦感、警觉性提高和注意力集中。尼古丁作用迅速，但代谢也快，这种药代动力学特点加上其直接刺激多巴胺释放的能力，使其极易成瘾，导致使用者难以戒断。五、 “快乐”的代价：耐受、依赖与成瘾的药理学“The chains of habit are too weak to be felt until they are too strong to be broken.”习惯的锁链在初时轻若无物，待你察觉时，已牢不可破。—— Samuel Johnson化学极乐当然也是有代价。当大脑反复暴露于这些外源化学物质的强烈冲击下，它会启动一系列复杂的适应性变化，试图恢复内部平衡。这些变化正是耐受、依赖 和最终可能导致成瘾 的生物学基础。1.耐受：效果递减的适应耐受 是指身体对药物反复使用的适应性反应，导致药物效果随时间推移而减弱，需要增加剂量才能达到最初的效果。人的大脑不会总是被药物带来的多巴胺“洪水”淹没，它会试图通过各种方式来“关小水龙头”或“降低接收器的灵敏度”，以减轻这种过度的刺激。在神经元水平，大脑可能会减少目标受体（如多巴胺受体）的数量（受体下调），或者降低现有受体对神经递质的反应敏感性（受体脱敏）。这就好比接收快乐信号的‘天线’变少了或不灵敏了，原来剂量的药物再也无法产生同样强度的信号。此外，身体也可能学会更快地代谢和清除药物（代谢耐受），缩短其作用时间。这些因素共同导致了耐受性的产生，使用者为了追求最初的快感或效果，往往被迫不断增加药物剂量，这无疑增加了药物过量和其他相关风险。2.依赖随着耐受性的发展，身体逐渐适应了药物的持续存在，进入了一种新的生理平衡状态，这时便可能产生依赖。依赖是指身体必须依靠药物才能维持（看似）正常的生理功能，一旦停药或大幅减少剂量，就会出现一系列不适的症状，即戒断综合征（Withdrawal Syndrome）。这本质上是身体适应性变化的反弹：之前为了对抗药物效应而进行的调整（如减少受体），在药物突然撤走后，导致内源性神经递质的作用相对不足或系统失衡，引发与药物急性效应通常相反的症状。例如，长期使用阿片类药物后停药可能出现剧烈疼痛、焦虑、失眠和腹泻；停用兴奋剂则可能导致极度疲劳、抑郁、快感缺乏和食欲亢进。需要强调的是，生理依赖本身并不等同于成瘾，即使是遵医嘱长期使用某些药物（如某些止痛药或抗抑郁药）也可能产生依赖，但只要规范管理，患者不一定会表现出成瘾行为。依赖更多反映的是一种生理适应状态，而戒断症状的存在是其关键标志。3.成瘾最可怕的一集成瘾则是一个更为复杂和严重的概念，它是一种慢性、复发性的脑部疾病，其核心特征是对药物使用的失控、强迫性的觅药行为，以及不顾负面后果（如健康受损、家庭破裂、法律问题）的持续用药。虽然耐受和依赖常常伴随成瘾出现，但成瘾的关键在于药物对大脑奖赏、动机、记忆和冲动控制环路的长期、深远的改变。药物反复、过度地刺激中脑边缘多巴胺通路，不仅暂时“劫持”了快乐感，更是在重塑大脑的连接（神经可塑性），使得与药物相关的记忆和线索变得异常强大和持久。这种大脑结构的改变导致与药物相关的线索（人、事、物、情绪）变得异常显著，能轻易触发强烈的渴求（Craving），驱使个体不顾一切地寻求药物。同时，大脑前额叶皮层（负责决策、判断和冲动控制）的功能也可能受损，使得个体难以抑制用药冲动，难以评估长期后果，即使他们主观上可能想戒断。成瘾不仅仅是“意志力薄弱”的问题，而是大脑功能实实在在发生了病理性改变，导致个体失去了对药物使用的控制权。成瘾的复发性极强，即使在长期戒断后，压力、环境线索或偶然的再次接触都可能导致“旧病复发”，这正是成瘾作为一种慢性疾病治疗的难点所在，需要长期、综合的干预策略。七、结论：理解药物与大脑的复杂互动从最初引导我们生存、学习的自然奖赏，到能够瞬间抵达“愉悦巅峰”的药物刺激，大脑奖赏系统展现了惊人的适应性与脆弱性。一杯咖啡可以驱散疲惫，一粒药片可能带来暂时的欣快，也可能在不知不觉中将我们引向依赖甚至成瘾。了解这些知识并不在于让我们“谈药色变”，而是帮助我们更理性地看待自己的身心反应：为什么我们会对某些东西产生渴望？为什么一旦形成习惯就难以摆脱？多巴胺的高峰固然诱人，但它往往意味着更深的代价——从耐受、依赖到成瘾，甚至伤及神经系统本身。只有认清这些化学“钥匙”如何侵入并重塑我们的“大脑锁孔”，我们才能以更明晰的态度去作出选择和承担后果。回到开篇的引言：一件事情的成本，终究是我们用多少“生命”去交换。 如何在享受“快乐信号”的同时，保持身心健康与自我掌控，或许才是我们每个人都需要认真思考与平衡的命题。愿这篇博客能为你提供一些思考的线索，也愿你能更加珍重地对待“快乐”的来之不易。参见[1] 许望超. 脑奖赏系统研究进展 [J]. 广州医药, 2008, 39: 1-2.[2] Pierce RC, Kumaresan V. The mesolimbic dopamine system: the final common pathway for the reinforcing effect of drugs of abuse [J]. Neurosci Biobehav Rev, 2006, 30: 215–223.[3] Clay SW, Allen J, Parran T. A review of addiction [J]. Postgrad Med, 2008, 120: F01–7.[4] Volkow ND, Fowler JS, Wang GJ, et al. Imaging dopamine's role in drug abuse and addiction [J]. Neuropharmacology, 2009, 56: 3–8.[5] Lingford-Hughes A, Nutt D. Neurobiology of addiction and implications for treatment[J]. The British Journal of Psychiatry, 2003, 182(2): 97-100.[6] Nestler E J. The neurobiology of cocaine addiction[J]. Science & practice perspectives, 2005, 3(1): 4.[7] Kreek M J, Levran O, Reed B, et al. Opiate addiction and cocaine addiction: underlying molecular neurobiology and genetics[J]. The Journal of clinical investigation, 2012, 122(10): 3387-3393."
  },
  {
    "title": "中国与世界的现代化专题（三）：城投与地方债-从分税制改革到房地产经济的逻辑",
    "summary": ":::note\n刚好最近这两天股债汇市场都被金毛搞得鸡犬不宁，在事情彻底转向抽象之前市场曾猜测金毛大打贸易战主要还是为了压低美债利率解决帝国财政问题……几天后看纯属是他在发癫。不过虽然拟合金毛决策思路失败，但世界各国的财政和债务危机还是很值得学习研究的。\n本篇另一方面也是为了未来可能的帝国国债与财政问题研究奠定方法论基础，他山之石可以攻玉，实际上人类社会发展中展露出的共性太多了。\n:::我们在之前",
    "tags": [
      "风自东方来"
    ],
    "url": "/posts/Finance and Economics/china-lgfv-debt/",
    "date": "2025-04-12T00:00:00.000Z",
    "content": ":::note\n刚好最近这两天股债汇市场都被金毛搞得鸡犬不宁，在事情彻底转向抽象之前市场曾猜测金毛大打贸易战主要还是为了压低美债利率解决帝国财政问题……几天后看纯属是他在发癫。不过虽然拟合金毛决策思路失败，但世界各国的财政和债务危机还是很值得学习研究的。\n本篇另一方面也是为了未来可能的帝国国债与财政问题研究奠定方法论基础，他山之石可以攻玉，实际上人类社会发展中展露出的共性太多了。\n:::我们在之前的中国与世界的现代化专题（二）：货币的本质与中国的税收体系中回顾了中国税收制度的演变，特别是改革开放以来的财政承包、分税制改革和税费改革，分析了这些改革如何影响政府的宏观调控能力和财政管理。其中，1994年的分税制改革无疑是一个我国财税与央地关系建设的一个关键转折点。然而，正如许多重大制度变革一样，分税制改革也有其复杂和深远的影响。 一方面，中央财政实力得到加强；但另一方面，地方政府在承担日益增长的经济发展、城市建设和公共服务等“事权”的同时，其稳定的、与事权相匹配的“财权”却相对受限。这就产生了一个根本性的问题：地方政府巨大的建设和发展资金需求从何而来？尤其是在中国经历人类历史上规模最大、速度最快的城镇化进程中，基础设施建设（道路、桥梁、管网、新区开发等）需要天文数字般的投入，钱从哪里来？这个答案很大程度上指向了中国经济中一个独特且影响深远的经济模式：土地财政与房地产经济的兴起，以及与之相伴相生的特殊载体——地方政府融资平台，即我们通常所说的“城投公司”。 这些平台如雨后春笋般涌现，成为了地方政府规避《预算法》直接举债限制、进行大规模融资和投资建设的主要工具。它们以政府信用或注入的土地等资产为依托，在金融市场上筹集资金，支撑了地方经济的快速扩张和城市面貌的日新月异。但这枚硬币的另一面，则是地方政府债务（尤其是以城投为核心的隐性债务）的快速累积，其规模之巨、结构之复杂、风险之隐蔽，已成为当前中国经济运行中最受瞩目的焦点和挑战之一。因此，本专题的第三篇——《城投与地方债-从分税制改革到房地产经济的逻辑》将聚焦于此，我们将探讨：分税制改革是如何为地方政府寻求预算外收入和融资渠道埋下伏笔的？土地财政和房地产经济为何能成为地方政府的核心财源和增长引擎？它们之间形成了怎样的互动循环？城投公司是如何“应运而生”并发展壮大的？它们在地方经济和债务形成中扮演了怎样的关键角色？这条“分税制 → 财政压力 → 土地财政 → 房地产驱动 → 城投扩张 → 债务积累”的逻辑链条是如何形成的？其内在机制和风险何在？一、制度的基石与裂痕——1994年分税制改革1.分税制改革的背景与影响要想说清楚城投与地方债，我们就不得不回顾一下94年的分税制改革。改革开放初期至1994年前，中国实行的是多种形式的“财政包干体制”。在这种体制下，中央与地方的财政关系主要通过“包干”合同来确定，地方政府向上级财政上缴固定数额或按比例分享收入后，其余部分留归地方使用。财政包干制在改革开放初期确实有效调动了地方积极性，搞活了地方经济。地方政府获得了较大的财政自主权，可以根据自身情况灵活安排支出，有力地支持了区域经济的起步。然而，随着时间的推移，其弊端也日益凸显：在包干制下，地方政府有强烈的动机通过各种方式（如税收减免、设立预算外资金等）将财政收入留在地方，导致中央财政收入占全国财政收入的比重（“第一个比重”）和中央财政收入占GDP的比重（“第二个比重”）持续下降。这严重削弱了中央政府进行宏观调控、调节地区差距、应对国家级重大事务的能力。这种模式下中央与地方的财政关系变成了“合同”关系，充满了讨价还价。地方政府行为短期化，缺乏稳定的财政预期，税收征管也面临地方保护主义的干扰。面对日益严峻的财政形势和宏观调控乏力的局面，一场旨在重新规范中央与地方财政关系、强化中央财政能力的改革势在必行——1994年，分税制改革正式推行。其核心内容可以概括为：划分税种： 将全国税收划分为中央税、地方税和中央地方共享税。消费税、关税等划为中央税；营业税（后改为增值税的地方部分）、个人所得税的地方部分、土地增值税、房产税等划为地方税；增值税、企业所得税等主体税种被列为共享税（其中增值税中央分享75%，地方分享25%）。设立两套税务机构： 分别设立国家税务局和地方税务局（后于2018年合并），负责征收不同税种。建立税收返还和转移支付制度： 为保证地方既得利益和平衡地区财力，中央对地方实行税收返还，并逐步规范和加大转移支付力度。分税制改革在实现其主要目标方面取得了显著成效，大部分稳定、增长潜力大的税种（如增值税的大头）被划归中央或成为共享税中的中央部分，中央财政收入占比迅速回升，宏观调控能力得到极大加强。地方政府虽然保留了一些税种，但其主体税源的稳定性和增长性相对减弱。\n与财权上移形成对比的是，地方政府承担的“事权”（Administrative Responsibilities）并未相应减少，反而随着经济社会发展和城镇化进程加速，在基础设施建设、招商引资、公共服务（教育、医疗、社保）、环境保护等方面的支出责任日益加重。由此，一个根本性的矛盾浮出水面——地方政府的“财权”与其承担的“事权”出现了制度性的不匹配。地方政府需要花的钱越来越多，但其稳定、可靠的预算内财政收入来源却相对有限，收支缺口成为常态。2.“预算软约束”下的选择：寻找预算外的“活水”面对巨大的财政收支压力，以及在GDP增长竞赛和官员晋升激励下的发展冲动，地方政府必须寻找新的资金来源来弥补缺口、支撑发展。尽管中央通过税收返还和转移支付对地方进行补助，但在改开高速建设高速发展处处缺钱的大背景下，这些资金往往难以完全覆盖地方庞大的建设和发展需求，且在使用上可能存在一定限制。同时，《预算法》（1995年生效，后经修订）严格限制地方政府直接举债。制度性的财权与事权不匹配，叠加尚不完善的预算硬约束机制（地方政府往往预期在遇到困难时能得到上级或中央的某种支持，形成“预算软约束”），共同催生了地方政府寻求预算外收入和融资渠道的强大内在动力。正是这道由分税制改革划开的制度“裂痕”，为后续土地财政的兴盛、房地产经济的深度绑定，以及作为融资主体的城投公司的“野蛮生长”，铺设了最初的轨道。下一部分，我们将探讨地方政府如何找到了那片看似取之不尽的“新大陆”——土地。二、增长的引擎与枷锁——房地产经济与土地财政1.土地爷的魔力：从资源到资本的惊险一跃中国的《宪法》规定，城市土地属于国家所有。1979年，国务院允许城镇对中外合资企业收取场地使用费，拉开了城镇土地有偿使用的序幕。1987年，国务院允许部分沿海开放城市开展土地使用权有偿转让试点，深圳因此落下国有土地使用权公开拍卖的“第一槌”。1988年的《宪法》修正案中明确规定“土地的使用权可以依照法律的规定转让”。经过多年的探索和试点，1996年上海成立了我国第一家土地储备机构，标志着土地收购—储备—开发—出让机制的初步形成。在这一基础上，1998年，全面修订的《土地管理法》及其实施条例正式明确了国有土地有偿使用制度的具体内容。自2001年以来，全国各地大力推行土地使用权招标拍卖，各类经营性用地及市场主体均可公平参与的有偿出让制度不断完善，最终使土地使用权市场化配置制度基本成型。我国对土地使用权市场化配置制度的不断优化和放宽赋予了地方政府在 一级土地市场（即土地从国家/集体所有权转变为建设用地使用权的市场）上的 垄断供应者 地位。地方政府通过“征收、收回、收购”等方式，将农用地或低效利用的存量土地转化为建设用地，再通过“招拍挂”（招标、拍卖、挂牌）等形式，将土地使用权出让给房地产开发商或其他用地单位，从中获取 土地出让收入（俗称“土地财政”的核心）。这一机制的魔力在于它将原本主要作为生产要素的土地，大规模地转化为了可流动、可估值的资本，为地方政府带来了巨额的、传统税收体系之外的现金流。尤其是在城镇化加速、工业化扩张的背景下，对建设用地的需求急剧膨胀，土地价值迅速攀升，使得土地出让收入成为许多地方政府预算外收入中最重要、有时甚至是规模最大的来源。此外，土地出让收入在法律上不属于严格意义的税收，其管理和使用相对预算内收入更为灵活，为地方政府绕开预算约束、快速筹集资金投入基础设施建设和城市开发提供了可能。这笔“第二财政”极大地增强了地方政府的“办事能力”。\n2008—2024 年全国土地出让收入及其占财政收入的比重变化2.房地产经济的崛起：与土地财政的共生循环仅仅拥有土地供应垄断权还不足以解释土地财政的巨大能量。它必须与一个强大的需求方相结合，而这个需求方，就是伴随着城镇化和居民收入增长而蓬勃发展的 房地产经济。“房改”前，我国采用单一福利分房制度。1988年，深圳颁布《深圳经济特区住房制度改革方案》，在全国率先发起住房制度改革，提出“补贴提租、鼓励买房”，住房分配货币化进程由此开启。1998年，国务院出台《关于进一步深化城镇住房制度改革加快住房建设的通知》，提出的各项政策包括提薪降息鼓励消费、完善住房供应体系、开展住房抵押贷款、放开住房二级市场、支持住房企业发展等核心内容，将我国住房建设与分配推向商品化与市场化。在需求端发力之后，房地产经济就开始飞速发展。卖地之后，地方政府将大部分土地出让收入用于“三通一平”（通路、通水、通电、平整土地）以及更广泛的基础设施建设（道路、桥梁、地铁、公园、学校、医院等）。这些投入极大地改善了城市环境和投资吸引力，直接推高了周边土地的价值和房地产价格。 不断上涨的房价和旺盛的购房需求，刺激了房地产开发商的拿地热情和竞价能力，使得地方政府能够以更高的价格出让土地，获得更多的土地出让收入，进而有更多资金投入新一轮的基础设施建设。\n \n 在以GDP增长为核心的政绩考核体系下，大规模的基础设施投资和繁荣的房地产市场都能直接拉动经济增长、增加固定资产投资、带动相关产业（钢铁、水泥、家电、装修等）发展并创造就业。这使得地方政府有极强的动机去维持土地的高价出让和房地产市场的热度。这个“土地出让 → 基建投资 → 土地/房产升值 → 更高土地出让收入/房地产税费 → 再投资”的循环，在过去二十多年里，成为了驱动中国许多城市快速扩张和经济增长的核心引擎之一。它支撑了中国惊人的城镇化速度，极大地改变了城市面貌，但也深刻地重塑了地方政府的行为模式和财政结构。3.风险的积累与路径依赖任何亮面必然催生其暗面，光鲜亮丽的土地财政背后也潜藏着巨大的风险与隐忧，使其逐渐显露出“枷锁”的特性。卖地犹如吸福寿膏，过度依赖土地出让收入使得地方财政收入结构单一，极易受到房地产市场波动的影响。 在土地财政和GDP竞赛的驱动下，可能导致资源过度向基础设施和房地产领域集中，忽视公共服务短板或实体经济发展；同时，也可能催生“摊大饼”式的城市扩张和低效的土地利用。一旦房地产市场降温或土地资源枯竭，地方财政将面临巨大压力。这是一种典型的 “顺周期”财政模式，会放大经济波动。在收支关系上，仅仅依靠当期的土地出让收入，往往仍不足以覆盖地方政府庞大的投资雄心。更重要的是，土地作为一种可以预期产生稳定现金流（未来出让收入）且不断增值的资产，成为了地方政府进行融资的重要信用基础和抵押品。当卖地收入不足或需要进行超前投资时，以未来的土地收益或储备的土地作为“担保”，向金融机构举债，就成为了一个看似自然的选择。这为我们下一部分将要深入探讨的地方政府融资平台（城投公司）的出现和债务扩张埋下了关键伏笔。土地成本最终会转嫁到房价上，不断推高的地价是高房价的重要成因之一，加剧了居民购房负担，可能引发财富分配不均、社会流动性下降等一系列社会问题。31省2023年土地财政依赖程度总结一下，面对分税制改革后的财政现实，地方政府找到了“土地”这把金钥匙，通过土地财政与房地产经济的深度捆绑，成功撬动了大规模的城市建设和经济增长。这既是特定制度环境下的理性选择，也展现了其强大的动员和发展能力。但与此同时，这种模式的内在风险和不可持续性也日益暴露，并将我们引向了下一个关键问题：当卖地本身还不够用，或者需要更灵活、更大规模的融资时，地方政府是如何进一步突破《预算法》的限制，将未来的土地收益、政府的隐性信用转化为今天的建设资金的？ 这就不得不提到那个特殊的主体——城投公司。三、债务的载体与扩张——城投公司的崛起《预算法》像一道红线，限制了地方政府直接发行债券的权力。那么，当卖地收入不足以支撑雄心勃勃的基建蓝图，或者需要提前锁定未来收益进行超前投资时，地方政府如何才能“合法合规”地撬动更多资金呢？答案，就在于地方政府融资平台（Local Government Financing Vehicles, LGFVs），即我们通常所说的“城投公司”。这些看似普通的企业实体成为了连接地方政府隐性信用、土地资源与金融市场的关键枢纽，是理解中国地方政府债务扩张的核心环节。1.“政策创新”还是“制度规避”？城投公司的诞生城投公司的出现可以说是特定制度环境下的“政策创新”和一种巧妙的“制度规避”。其核心逻辑在于：地方政府不能直接借钱，但地方政府可以设立或控股的企业可以。城投公司通常由地方政府（如市政府、区政府、县政府，或其授权的部门如国资委、财政局）出资设立，并被赋予特定的公共项目投融资职能。它们在法律上是独立的企业法人，其债务不直接计入地方政府的官方债务（赤字）。这使得地方政府能够绕开《预算法》关于地方政府不得直接举债的限制，通过这些“影子替身”进行大规模融资。这种模式并非中国独有，许多国家都有类似的公私合营（PPP）或特殊目的载体（SPV）来进行基础设施融资。但中国的城投公司有其特殊性：政府背景深厚： 绝大多数城投公司由地方政府100%控股或绝对控股，其人事任命、经营决策往往与地方政府意图紧密相关。资产注入关键： 地方政府通常会将土地使用权（尤其是储备土地、待开发土地）、存量基础设施资产（如收费公路、供水供暖管网）、股权等注入城投公司，充实其资产负债表，以此作为向金融机构融资的信用基础和抵押品。例： 一个地级市想修建一条新的城市快速路，预计耗资50亿元。市政府不能直接发债，于是它将其控股的“市建设投资集团”（一家典型的城投公司），并将一块评估价值20亿元的待开发商业用地注入该公司。城投公司以此土地作为重要增信手段，向银行申请长期项目贷款，或在债券市场发行“城投债”。职能的混合性： 城投公司常常承担着准市政职能，负责大量公益性或准公益性基础设施项目的投融资、建设和运营，如道路桥梁、保障房、新区开发、土地整理等。这些项目往往自身现金流回报低、周期长，难以完全覆盖融资成本。城投公司的兴起于2008年全球金融危机后，当时中国推出“四万亿”经济刺激计划，其中大量资金需要通过地方配套投入基础设施建设，更是极大地加速了城投平台的设立和扩张。它们成为了承接刺激资金、落实地方投资目标的主要载体。2.城投公司的运作模式：政府的“影子”与融资的“马甲”城投公司作为地方政府的“影子”与“马甲”，其最重要的职能就是作为政府的杠杆工具，利用政府注入的资产和更关键的政府隐性信用担保 (Implicit Government Guarantee)，通过多种渠道筹集资金发挥融资功能。一般来说，城投公司的融资渠道有三种：银行贷款： 这是最主要的融资方式。银行基于对地方政府最终会偿还债务的预期（即隐性担保），愿意向城投公司提供大量贷款，即使项目本身盈利能力不强。发行债券 (城投债)： 在银行间市场或交易所市场发行企业债、公司债、中期票据、短期融资券等。这些债券虽以公司名义发行，但市场普遍将其视为有政府信用背书的“准市政债”。我们假设某省会城市的轨道交通集团（一家城投）为建设新的地铁线路，成功发行了10年期、票面利率4.5%、总额30亿元的项目收益票据。投资者购买的主要信心来源并非项目未来的票务收入，而是对该市政府财政实力的信任（当然还有相信这公司作为政府的外延不可能破产的信心）。非标融资： 通过信托计划、融资租赁、私募基金、资产管理计划等影子银行渠道获取资金，这些方式往往成本更高、透明度更低。一个县级城投可能通过信托公司设立一个信托计划，向高净值个人或机构募集资金，用于当地一个工业园区的早期开发，承诺较高的预期收益率。除了融资功能之外，城投公司会用筹集到的资金，按照地方政府的规划意图，投入到具体的项目中。这使得地方政府能够在预算体制外快速启动和推进大量基础设施和城市建设项目，极大地推动了城镇化进程和区域经济发展。那么，如果钱不够了呢？ 城投公司的偿债来源理论上应包括项目运营收入、政府购买服务或补贴、土地开发收益等。但现实中许多项目自身盈利能力不足或管理不善（毕竟是市场经营机制），偿债高度依赖地方政府。这种情况下，地方政府会通过各种名目将财政资金（包括土地出让收入的一部分）拨付给城投，用于支付利息或偿还本金。但这往往缺乏明确、可持续的制度安排。城投公司通过开发整理注入的土地，待土地升值后由政府收储或直接出让，用所得收益偿还部分债务，使其与土地财政的循环更加紧密。如果政府政务官觉得目前财政有点紧张，城投公司还能自己撑一撑，那么城投公司还会选择借新还旧 (债务滚动) 这种最普遍但也风险最高的方式。当旧债到期时，城投公司通过发行新债或申请新贷款来偿还，使得债务规模像滚雪球一样越滚越大。城投债务不透明、底数不清，形成了规模庞大的地方政府隐性债务。很多时候，一个城市到底有多少家城投平台，这些平台总共借了多少钱，资金具体投向了哪些项目，偿债安排如何，连地方政府自己都可能没有一本完全清晰的账。这使得风险难以评估和管理。在风险传导方面，城投债务风险并非孤立的企业风险，它通过隐性担保与地方政府财政风险紧密相连，并通过金融体系（银行、债券市场、信托等）扩散，可能引发区域性甚至系统性金融风险。一旦土地市场遇冷或经济下行，偿债压力会骤增。这种模式的风险和后果大家都知道了四、总结，和一个更宏观的视角行文至此，我们已经沿着“分税制改革 → 地方财政压力 → 土地财政兴起 → 房地产经济深度绑定 → 城投平台扩张 → 地方隐性债务积累”这条逻辑线索，梳理了过去二三十年间中国地方政府投融资模式演变的核心脉络。我们看到了制度设计、发展需求、市场力量和政策选择如何相互作用，共同塑造了今天我们所面对的局面。我无意在这里继续渲染什么地方债城投债风险。一方面，如实评估其精确规模、结构性风险和区域差异，需要深入细致的、甚至略显枯燥的专业分析，远非一篇博客文章所能承担，我个人能力也确实不足以去做大规模的调研或者一点点去翻各种城投公司的审计报告。另一方面，过度聚焦于风险本身，尤其是简单化、标签化地讨论“崩溃”或“危机”，对于非专业读者而言，除了徒增焦虑和无谓的社会情绪内耗外，并无太大助益。理解现象背后的机制，比简单地判断“好坏”或预测“何时出事”更为重要。从一个更宏观的视角来看，也许更能帮助我们理解当前局面的性质和可能的演进方向。 著名投资家、桥水基金创始人瑞·达利欧（Ray Dalio）在其著作《债务危机》中，系统地阐述了他对经济体中债务周期的观察和理解。他认为，经济体（尤其是现代信用经济体）普遍会经历长期的债务周期，其基本模式大致如下：早期阶段（良性杠杆期）： 债务被用于生产性投资，能够带来超过债务成本的回报。收入增长快于或等于债务增长，经济欣欣向荣，人们对未来充满信心。这有点像我们故事起点，改革开放后地方政府利用各种方式（包括早期的财政包干和后来的土地财政初期）为基础设施和工业发展融资，确实带来了经济的腾飞。泡沫阶段（过度杠杆期）： 随着成功持续，乐观情绪蔓延，信贷标准逐渐放松。债务增长开始持续快于收入增长，越来越多的借贷被用于投机性或回报不确定的项目（例如，某些过剩的基础设施、过热的房地产投资）。资产价格（如房地产）被不断推高，进一步刺激借贷，形成正反馈循环。我们描述的“土地财政-房地产-城投”深度捆绑、债务驱动增长的模式，很大程度上就带有这个阶段的特征。城投平台的大规模扩张和隐性债务的快速积累，正是债务增速超过经济内生增长能力的体现。顶部/反转阶段： 债务负担变得过于沉重，偿债成本开始侵蚀收入和利润。同时，中央银行可能因为通胀或其他原因收紧货币政策，或者资产价格停止上涨甚至下跌，导致借贷能力和意愿下降。经济增长放缓，违约风险开始显现。近年来，中央对地方政府隐性债务风险的严控、对房地产“三道红线”的设定、以及经济增速换挡，都带有这个阶段的特征。去杠杆阶段（萧条或有序调整期）： 这是最痛苦但也必须经历的阶段。为了使债务与偿债能力重新匹配，经济体需要经历一个去杠杆的过程。达利欧总结了四种主要的去杠杆方式：财政紧缩（Austerity）： 削减政府开支，增加税收。债务违约/重组（Debt Defaults/Restructuring）： 债务无法偿还，需要减记或重新安排。财富转移（Redistribution of Wealth）： 通常通过税收等方式将财富从富裕阶层转移到其他阶层或用于偿债。印钞/债务货币化（Printing Money/Monetization）： 中央银行通过购买资产（包括政府债务）向系统注入流动性，减轻债务负担，但也可能引发通胀或货币贬值。达利欧认为，一个成功的“漂亮的去杠杆”（Beautiful Deleveraging）需要政策制定者巧妙地平衡使用这四种工具，以最小的社会和经济代价度过难关。而处理不当则可能导致长期的经济萧条或剧烈的社会动荡（“丑陋的去杠杆”）。将这个宏观债务周期模型套用到我们讨论的中国地方债问题上，并非是我要简单地对号入座或预测未来，而是提供一种理解框架：我们所经历的“城投模式”和地方债务的快速积累，可以被看作是特定国情下一个长债务周期中杠杆快速上升阶段的特殊表现形式。它以惊人的速度支持了中国的现代化和城镇化建设，取得了举世瞩目的成就，这是必须承认的历史功绩。当前中国经济面临的挑战，包括地方财政压力、城投债务风险化解、房地产市场调整等，在很大程度上可以理解为正在进入或已经处于这个长债务周期的顶部区域或开始去杠杆的初期阶段。中央政府从16年开始着手去杠杆化，反复强调“防范化解重大风险”，特别是地方政府债务风险，以及推动经济转型、寻找新的增长动能，正是对这一阶段的现实反应和主动管理。未来的关键，在于中国如何管理和导航这个去杠杆的过程。中央政府已经采取了一系列措施，如债务置换、展期降息、规范融资平台、建立防范化解地方政府隐性债务风险长效机制、推动财政事权和支出责任划分改革等。这些可以看作是在综合运用达利欧提到的多种工具（债务重组、财政约束、可能的中央支持等），试图实现一个相对平稳的过渡。因此，与其陷入对“城投债会不会爆”的简单猜测，不如将视线投向更深层次的问题： 这个以土地为核心、债务驱动的增长模式，其潜能是否已经接近极限？中国经济如何才能平稳地从这一模式，过渡到依靠技术创新、内需驱动、更高质量和更可持续的新发展模式？在这个过程中，如何化解存量债务风险，同时又避免“处置风险的风险”，保持经济社会的稳定？理解了地方债问题的来龙去脉及其在宏观周期中的位置，我们或许能以更平和、更具建设性的心态，去观察和思考中国经济未来的走向。——写于风浪之中，Windsurf依然划得飞快。"
  },
  {
    "title": "通过Github Action实现自动推送英文外刊到Obsidian中",
    "summary": "因为我自己本身也有搜集高质量信源以观察市场的需求+该死的英一对词汇量和翻译能力的要求比较高，我决定开始系统性地精读外文刊物。但……你们知道的，我是懒狗，有没有一种优雅的方法将这些外刊内容同步到我的阅读设备（比如我的 MatePad）上，并且方便我随时打开进行阅读、划词翻译和做笔记，而无需经历繁琐的文件传输和格式转换？——目光转向Obsidian没错，就是那个强大的、基于本地 Markdown 文件",
    "tags": [],
    "url": "/posts/TechnicalTutorials/github-action-obsidian/",
    "date": "2025-04-10T00:00:00.000Z",
    "content": "因为我自己本身也有搜集高质量信源以观察市场的需求+该死的英一对词汇量和翻译能力的要求比较高，我决定开始系统性地精读外文刊物。但……你们知道的，我是懒狗，有没有一种优雅的方法将这些外刊内容同步到我的阅读设备（比如我的 MatePad）上，并且方便我随时打开进行阅读、划词翻译和做笔记，而无需经历繁琐的文件传输和格式转换？——目光转向Obsidian没错，就是那个强大的、基于本地 Markdown 文件的双链笔记软件。因为Obsidian基于本地文件夹结构，我们可以利用各种第三方同步工具实现免费或自托管的同步方案，只要你配置好了多端同步（我是用的是腾讯云cos），那你近乎可以在所有平台体验到完全相同的阅读/笔记体验。Obsidian 看起来能完美解决我的阅读和笔记需求。但最开始的问题——“懒”，还没解决。我总不能每天手动去各大外刊网站寻找、下载文章，再复制粘贴或者转换格式，最后放到 Obsidian 的库（Vault）里吧？这不仅繁琐，而且一点也不“优雅”。好，我们来继续！我偶然发现 awesome-english-ebooks 这个Github库会在每周五定期更新经济学人、纽约客等英语外刊杂志的PDF/Mobi/Epub文件，这个仓库解决了内容来源的问题，而且更新频率稳定。这意味着，理论上，我只需要找到一种方法，在每周五这个仓库更新后，自动抓取最新的期刊文件，然后把它们放到我的 Obsidian （对应云端的s3 cos）库里，就可以实现全自动化的外刊抓取与阅读了。这就是 Github Actions 发挥作用的地方。Github Actions 是 GitHub 提供的一项持续集成和持续部署（CI/CD）服务，但它的能力远不止于此。我们可以利用它来自动化几乎任何与代码仓库相关的任务，包括我们现在这个需求：定时检查外部资源、下载文件、并将这些文件提交到我们自己的仓库中。我的设想流程是这样的：设置一个定时触发器：利用 Github Actions 的 schedule 功能，让工作流（Workflow）每周（比如周五晚上或周六早上）自动运行一次。拉取最新外刊：工作流启动后，它会去 awesome-english-ebooks 仓库，把最新的期刊文件（比如我主要关心的《经济学人》的 PDF 文件）下载到 Action 的运行环境中。处理和组织文件（可选）：可以根据需要对下载的文件进行重命名，或者按照期刊名称、日期创建好文件夹结构，让它们在 Obsidian 中看起来更整洁。将文件推送到“Obsidian 仓库”：这是关键一步。为了让 Github Actions 能够管理我们 Obsidian 的内容，我选择直接让Action把对应的PDF文件上传到S3储存桶的指定文件夹里，由此实现了巧妙的同步。触发同步：当 Github Actions 将新的外刊文件 push 到“Obsidian 仓库”后，本地设备上配置的同步方案（无论是基于 Git 的同步插件如 Obsidian Git，还是像腾讯云 COS + FolderSync/Syncthing 等）就会检测到云端（即 Github 仓库）的变化，并将这些新文件自动拉取到你的 MatePad 等设备上的 Obsidian Vault 中。最终效果：每周什么都不用做，最新的《经济学人》（或其他你选择的刊物）就会自动出现在我所有设备的 Obsidian 中，随时可以打开阅读、划词、做笔记。下载、传输、整理这些繁琐的步骤完全消失，真正实现了“懒人”的优雅阅读。为了复现我的 Workflow，你需要准备：一个Github账号一个S3储存桶账号（腾讯云阿里云Cloudflare都有，选择太多了）Obsidian笔记一点点的耐心一、Obsidian设置为了让 Github Actions 下载的外刊能够自动出现在我们的 Obsidian 中，我们需要先打通 Obsidian 与云存储之间的同步通道。这里我们选用一个广受好评的第三方同步插件：Remotely Save。1. 安装 Remotely Save 插件：打开你的 Obsidian。进入 设置 (Settings) -> 第三方插件 (Community Plugins)。重要提示： 如果你之前没有启用过社区插件，需要先关闭 安全模式 (Safe Mode)。请知晓其中的风险，只安装你信任的插件。点击 浏览 (Browse) 社区插件市场。搜索 Remotely Save。找到插件后，点击 安装 (Install)，安装完成后点击 启用 (Enable)。2. 配置 Remotely Save 连接 S3 服务：安装并启用后，Remotely Save 的设置选项会出现在左侧边栏的 第三方插件 区域。点击进入其设置界面。选择远程服务： 在插件设置中，找到选择远程服务提供商的选项。这里你需要选择 S3 或者专门列出的 Tencent COS (如果插件有此区分选项)。填写 S3 凭证： 这是最关键的一步。你需要填入连接到你云存储桶所需的信息。具体设置界面可能因插件版本略有不同，但核心信息是相同的。\n你可以参考下图所示的配置界面：\n参考获取必要的 S3 凭证信息： 你需要登录你的云服务提供商控制台（以腾讯云对象存储 COS 为例）获取以下四个关键信息。请务必妥善保管，尤其是 SecretKey！COS_SECRET_ID (对应 S3 的 Access Key ID): 访问密钥 ID，用于标识你的账户。COS_SECRET_KEY (对应 S3 的 Secret Access Key): 访问密钥 Key，这是高度敏感信息，请勿泄露！ 它与 Secret ID 配合使用，用于验证你的请求。COS_REGION (对应 S3 的 Region): 你的存储桶所在的区域。例如，北京区域通常是 ap-beijing。请确保填写插件要求的正确格式。COS_BUCKET (对应 S3 的 Bucket Name): 你创建的用于存储 Obsidian 库文件的存储桶名称。填写到插件设置中： 将上面获取到的四个值，准确无误地填写到 Remotely Save 插件设置界面中对应的字段里（例如：Endpoint/Server Address 可能需要根据 COS_REGION 和 COS_BUCKET 构造，或者有单独的 Region 和 Bucket 字段，具体请参照插件说明或界面提示）。\n配置完成后，可以尝试点击插件设置中的 检查 (Check) 或 同步 (Sync/Save) 按钮，看是否能成功连接并同步少量文件到你的 S3 存储桶。二、GitHub设置现在，我们已经配置好了 Obsidian 通过 Remotely Save 与 S3 云存储同步的通道。接下来，我们需要在 GitHub 上设置一个自动化流程，让它定期从源仓库拉取最新的外刊，并将这些文件推送到我们之前配置好的 S3 存储桶中。1.Fork源仓库我们的外刊内容来源于 hehonghui/awesome-english-ebooks 这个优秀的仓库。但我们不能直接在这个仓库上运行我们自己的自动化任务，也无法直接修改它。因此，我们需要先 Fork 这个仓库::github{repo=\"hehonghui/awesome-english-ebooks\"}什么是 Fork？ Forking 操作会在你的 GitHub 账户下创建一个源仓库的完整副本。这个副本完全属于你，你可以自由地修改代码、添加文件（比如我们的 Workflow 文件），而不会影响到原始仓库。如何操作？访问 https://github.com/hehonghui/awesome-english-ebooks登录你的 GitHub 账号。点击页面右上角的 Fork 按钮。选择你自己的 GitHub 账户作为目标位置，并确认 Fork。结果： 完成后，你的 GitHub 账号下就会出现一个名为 awesome-english-ebooks 的新仓库（地址类似 https://github.com/<你的用户名>/awesome-english-ebooks）。后续所有的操作都将在你 Fork 后的这个仓库中进行。2.创建Workflow文件：定义自动化任务GitHub Actions 的核心是 Workflow 文件。这是一个 YAML 格式的文本文件，用来定义自动化任务的触发条件、执行步骤和所需环境。存放位置： GitHub Actions 要求 Workflow 文件必须存放在仓库根目录下的 .github/workflows/ 文件夹内。你需要先在你的 Fork 后的仓库 中创建这个目录结构。创建文件：方法一 (推荐，通过 GitHub 网页界面)：进入你 Fork 后的 awesome-english-ebooks 仓库页面。点击上方的 Actions 标签页。如果仓库还没有 Workflow，GitHub 可能会提示你创建。你可以点击 set up a workflow yourself (或者类似的链接)。这会直接带你到创建新文件的界面，路径已经预设为 .github/workflows/。如果你采用我的防范，那么你需要创建两个yml文件，分别是sync-upstream.yml和sync-to-obsidian.yml。前者负责自动和上游仓库同步，后者负责推送文件到Obsidian库。方法二 (本地操作)：\n不推荐该方法，因为原始仓库过大将你 Fork 后的仓库克隆 (clone) 到本地。在本地仓库的根目录下创建 .github 文件夹，再在其中创建 workflows 文件夹。在 workflows 文件夹内创建一个新的 YAML 文件 (例如 sync-periodicals.yml)。稍后编辑完文件内容后，通过 git add, git commit, git push 将这个文件推送到你的 GitHub 仓库。文件内容： 接下来的一步，我们将在这个 YAML 文件中编写具体的指令，告诉 GitHub Actions 要做什么。现在，你只需要先创建好这个空文件即可。3.配置安全凭证 (GitHub Secrets)：保护你的 S3 访问密钥我们的 Workflow 需要访问你的 S3 存储桶（例如腾讯云 COS）才能上传文件。这就需要用到我们在第一步中获取的四个凭证信息 (COS_SECRET_ID, COS_SECRET_KEY, COS_REGION, COS_BUCKET)。极其重要： 绝对不能 将这些敏感信息直接写在 Workflow 文件 (YAML) 中！因为 Workflow 文件是代码仓库的一部分，会被公开（即使是私有仓库，也存在泄露风险）。正确的做法是使用 GitHub Secrets。Secrets 是 GitHub 提供的用于存储敏感信息（如 API 密钥、密码、访问令牌等）的功能，它们会被加密存储，并且只在 Action 运行时作为环境变量注入，不会在日志或代码中暴露。如何设置 Secrets：进入你 Fork 后的 awesome-english-ebooks 仓库页面。点击上方的 Settings 标签页。在左侧导航栏中，找到 Secrets and variables，点击展开，然后选择 Actions。在 Repository secrets 部分，点击 New repository secret 按钮。你需要 依次创建四个 Secret：Name: COS_SECRET_IDSecret: 粘贴你之前获取的腾讯云 SecretId 值。Name: COS_SECRET_KEYSecret: 粘贴你之前获取的腾讯云 SecretKey 值。 （再次强调，这是最敏感的信息！）Name: COS_REGIONSecret: 粘贴你的腾讯云 COS 区域，例如 ap-beijing。Name: COS_BUCKETSecret: 粘贴你的腾讯云 COS 存储桶名称。确保 Secret 名称完全匹配 (COS_SECRET_ID, COS_SECRET_KEY, COS_REGION, COS_BUCKET)，因为我们稍后会在 Workflow 文件中通过这些名称来引用它们。仔细检查拼写和大小写。4.Github Action YAML文件当然，你也可以直接忽视下面这一坨文件，直接Fork 我的仓库，并按照上文第三小节的步骤修改自己的环境变量来进行同步。4.1 定期同步上游仓库：sync-upstream.yml这个文件的核心目标是：确保你 Fork 的仓库能定期自动拉取 awesome-english-ebooks 源仓库的最新更新。 这样，当源仓库发布新一期杂志时，你的仓库也能及时获取到。\n它的工作流程大致如下：定时触发与手动触发 (on)：它被设置为每周五的特定时间（UTC 16:00，对应北京时间周六 00:00）自动运行。这个时间点通常在源仓库更新之后，确保能拉取到最新的内容。同时，它也允许 workflow_dispatch，意味着你可以随时在 GitHub 仓库的 Actions 页面手动点击运行此流程，方便测试或在非预定时间更新。执行环境 (jobs: sync):指定在最新的 Ubuntu 虚拟机环境中运行。关键步骤 (steps)：检出当前仓库 (actions/checkout): 首先，将你 自己 Fork 后的仓库代码下载到运行环境中。使用了 fetch-depth: 1 进行浅克隆，只获取最新版本历史，节省时间和资源。添加上游仓库 (git remote add upstream... & git fetch upstream...): 将原始的 awesome-english-ebooks 仓库添加为一个名为 upstream 的远程源，并拉取其最新的提交信息（同样使用浅层拉取）。备份 GitHub Action 文件: 这是一个重要的保险步骤。因为接下来的合并操作可能会覆盖你仓库中的 .github/workflows 文件夹（如果上游仓库恰好也有同名文件），所以这里先把这个文件夹备份到临时目录。合并上游仓库的更改 (git merge upstream/...): 尝试将从 upstream 拉取下来的最新更改合并到你当前的分支（通常是 master 或 main）。这一步就是将新的杂志文件同步到你的仓库副本中的关键操作。代码中包含了处理潜在分支名差异 (master vs main) 和自动设置提交者信息的逻辑。恢复 GitHub Action 文件: 将之前备份的 Workflow 文件复制回 .github/workflows 目录，并提交这个更改（如果确实有恢复操作）。这确保了即使合并时上游仓库有冲突或修改，你自己的自动化脚本不会丢失。推送更改到你的仓库 (git push origin): 最后，将所有本地合并、恢复后的更改推送回你自己的 GitHub 远程仓库。至此，你的 Fork 就包含了最新的外刊文件。\n小结：这个 Workflow 的职责是“进货”，它定期检查源头，把最新的杂志文件同步到你的 GitHub 仓库中。\n正式代码：name: 同步上游仓库\n\non:\n  schedule:\n    # 每周六0点运行（UTC时间是每周五16:00，对应北京时间24:00，也就是周六00:00）\n    - cron: '0 16 * * 5'\n  # 允许手动触发工作流\n  workflow_dispatch:\n\njobs:\n  sync:\n    runs-on: ubuntu-latest\n    \n    steps:\n      # 检出当前仓库代码（增加深度以获取更完整的历史记录）\n      - name: 检出当前仓库\n        uses: actions/checkout@v3\n        with:\n          fetch-depth: 0\n      \n      # 添加上游仓库并获取更完整的历史记录\n      - name: 添加上游仓库\n        run: |\n          git remote add upstream https://github.com/hehonghui/awesome-english-ebooks.git\n          git fetch upstream --depth=50\n      \n      # 备份GitHub Action文件\n      - name: 备份GitHub Action文件\n        run: |\n          mkdir -p /tmp/github-actions-backup\n          if [ -d \".github/workflows\" ]; then\n            cp -r .github/workflows /tmp/github-actions-backup/\n          fi\n      \n      # 检测上游仓库的默认分支\n      - name: 检测上游仓库的分支\n        id: detect-branch\n        run: |\n          if git ls-remote --heads upstream main | grep main; then\n            echo \"UPSTREAM_BRANCH=main\" >> $GITHUB_ENV\n          else\n            echo \"UPSTREAM_BRANCH=master\" >> $GITHUB_ENV\n          fi\n          if git rev-parse --verify --quiet main; then\n            echo \"LOCAL_BRANCH=main\" >> $GITHUB_ENV\n          else\n            echo \"LOCAL_BRANCH=master\" >> $GITHUB_ENV\n          fi\n      \n      # 合并上游仓库的更改\n      - name: 合并上游仓库的更改\n        run: |\n          # 确保我们在正确的本地分支上\n          git checkout ${{ env.LOCAL_BRANCH }}\n          \n          # 配置Git用户信息（在合并前设置）\n          git config --global user.email \"github-actions[bot]@users.noreply.github.com\"\n          git config --global user.name \"GitHub Actions\"\n          \n          # 使用--allow-unrelated-histories参数合并上游仓库的更改\n          git merge upstream/${{ env.UPSTREAM_BRANCH }} --allow-unrelated-histories -m \"同步上游仓库更改\" || {\n            echo \"合并冲突，以上游版本为准\"\n            git reset --hard upstream/${{ env.UPSTREAM_BRANCH }}\n          }\n      \n      # 恢复GitHub Action文件\n      - name: 恢复GitHub Action文件\n        run: |\n          if [ -d \"/tmp/github-actions-backup/workflows\" ]; then\n            mkdir -p .github/workflows\n            cp -r /tmp/github-actions-backup/workflows/* .github/workflows/\n            git add .github/workflows\n            git commit -m \"恢复GitHub Action文件\" || echo \"没有需要恢复的文件\"\n          fi\n          \n      # 推送更改到你的仓库\n      - name: 推送更改到仓库\n        run: |\n          git push origin ${{ env.LOCAL_BRANCH }}\n\n4.2 推送文件到Obsidian库：sync-to-obsidian.yml这个文件的核心目标是：在第一个 Workflow 成功同步了最新的外刊文件后，自动找出我们关心的那几本杂志的最新 PDF 文件，并将它们上传到你之前配置好的腾讯云 COS (或其他 S3) 存储桶的指定位置。\n它的工作流程设计如下：触发条件 (on)：主要触发器 (workflow_run): 它被配置为在上一个 同步上游仓库 Workflow 成功完成后自动触发。这是一种链式反应，确保只有在“进货”成功后，才进行“上架”操作。手动触发 (workflow_dispatch): 同样允许手动触发，方便调试或单独执行上传操作。运行条件 (jobs: sync-to-cos -> if)：增加了一个检查：只有当触发它的 同步上游仓库 工作流结论是 success (成功)，或者当它是被手动触发时，这个 Job 才会真正运行。防止在上游同步失败的情况下执行无效的上传。关键步骤 (steps)：检出当前仓库 (actions/checkout): 再次检出你仓库的代码。但这次使用了 sparse-checkout (稀疏检出) 的高级功能。它只下载仓库中你明确指定的几个包含外刊的目录（如 01_economist, 02_new_yorker 等），而不是整个仓库。这极大地提高了效率，尤其当仓库历史越来越大时。安装 AWS CLI: 安装 AWS 命令行工具。虽然我们用的是腾讯云 COS，但 COS 兼容 S3 API，所以可以使用 AWS CLI 来操作。配置 AWS 凭证: 这是连接到你 S3 存储桶的关键。它在运行环境中动态创建 AWS 配置文件 (~/.aws/credentials 和 ~/.aws/config)。这里安全地使用了你之前在 GitHub Secrets 中存储的 COS_SECRET_ID, COS_SECRET_KEY, COS_REGION 和 COS_BUCKET。注意，这里配置了腾讯云 COS 的特定 endpoint_url，让 AWS CLI 知道要连接的不是 AWS S3 而是腾讯云 COS。你的密钥绝不会暴露在代码或日志中。获取文件更新日期: 获取形如 YYYY.MM.DD 的刊物更新日期，存为一个变量，用于后续在 S3 中创建按日期组织的文件夹。列出目录内容: 一个辅助步骤，用于在 Action 日志中打印出检出的目录内容，方便调试时查看文件是否按预期存在。查找最新的杂志文件 (多个步骤): 针对你关心的每种刊物（经济学人、纽约客、大西洋月刊、连线），使用 shell 命令 (find, sort, head) 来定位其对应目录下最新创建的子目录。脚本假设最新的期刊文件存放在最新命名的子目录中。找到的目录路径会保存为输出变量（如 steps.economist.outputs.latest_dir）。同步各刊物到 COS (多个步骤): 这是最终的上传环节。条件执行 (if): 每个上传步骤都先检查上一步是否成功找到了对应的最新目录。遍历 PDF 文件: 在找到的最新期刊目录中，脚本会遍历查找所有的 .pdf 文件。上传 (aws s3api put-object): 对找到的每个 PDF 文件，执行 aws s3api put-object 命令进行上传。--bucket: 指定你的 COS 存储桶名称 (来自 Secret)。--key: 这是文件在存储桶中的最终路径和名称。它被精心构造成 2.外刊/<刊物名称>/<当前日期>/<原始文件名>.pdf 的格式。例如 2.外刊/经济学人/2023.10.27/The Economist - October 27 2023.pdf。这个结构化的路径将直接映射到你 Obsidian 中通过 Remotely Save 同步后的文件夹结构，非常清晰。--body: 指定要上传的本地 PDF 文件。--endpoint-url: 再次确保命令指向腾讯云 COS。小结：这个 Workflow 是“上架”机器人。它在上一个 Workflow 完成后启动，智能地找到你关心的最新 PDF 期刊，然后按照预设的路径结构将它们精准地上传到你的 S3 云存储中，等待 Remotely Save 将它们同步到你的 Obsidian。\n正式代码：name: 同步外刊到Obsidian\n\non:\n  # 在同步上游仓库工作流完成后运行\n  workflow_run:\n    workflows: [\"同步上游仓库\"]\n    types:\n      - completed\n  # 允许手动触发\n  workflow_dispatch:\n\njobs:\n  sync-to-cos:\n    runs-on: ubuntu-latest\n    # 只有当触发的工作流成功完成时才运行\n    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}\n    \n    steps:\n      # 检出当前仓库代码（使用稀疏检出策略，只检出必要的目录结构）\n      - name: 检出当前仓库\n        uses: actions/checkout@v3\n        with:\n          fetch-depth: 1\n          sparse-checkout: |\n            01_economist\n            02_new_yorker\n            04_atlantic\n            05_wired\n          sparse-checkout-cone-mode: true\n      \n      # 安装AWS CLI\n      - name: 安装AWS CLI\n        uses: unfor19/install-aws-cli-action@v1\n        with:\n          version: 2\n      \n      # 配置AWS凭证（用于访问腾讯云COS）\n      - name: 配置AWS凭证\n        run: |\n          mkdir -p ~/.aws\n          cat > ~/.aws/credentials << EOF\n          [default]\n          aws_access_key_id = ${{ secrets.COS_SECRET_ID }}\n          aws_secret_access_key = ${{ secrets.COS_SECRET_KEY }}\n          EOF\n          \n          cat > ~/.aws/config << EOF\n          [default]\n          region = ${{ secrets.COS_REGION }}\n          output = json\n          s3 =\n            addressing_style = virtual\n            endpoint_url = https://cos.${{ secrets.COS_REGION }}.myqcloud.com\n          EOF\n          \n          # 验证配置是否生效\n          echo \"AWS CLI配置完成，当前配置：\"\n          aws configure list\n      \n      # 列出目录内容，以便于调试\n      - name: 列出目录内容\n        run: |\n          echo \"列出经济学人目录内容：\"\n          ls -la ./01_economist || echo \"经济学人目录不存在\"\n          echo \"列出纽约客目录内容：\"\n          ls -la ./02_new_yorker || echo \"纽约客目录不存在\"\n          echo \"列出Atlantic目录内容：\"\n          ls -la ./04_atlantic || echo \"Atlantic目录不存在\"\n          echo \"列出Wired目录内容：\"\n          ls -la ./05_wired || echo \"Wired目录不存在\"\n      \n      # 查找最新的经济学人文件\n      - name: 查找最新的经济学人文件\n        id: economist\n        run: |\n          if [ -d \"./01_economist\" ]; then\n            LATEST_ECONOMIST_DIR=$(find ./01_economist -maxdepth 1 -type d -name \"te_*\" | sort -r | head -n 1)\n            echo \"latest_dir=$LATEST_ECONOMIST_DIR\" >> $GITHUB_OUTPUT\n            \n            # 从目录名中提取日期（格式如te_2025.04.05）\n            if [ -n \"$LATEST_ECONOMIST_DIR\" ]; then\n              DIR_NAME=$(basename \"$LATEST_ECONOMIST_DIR\")\n              ECONOMIST_DATE=$(echo \"$DIR_NAME\" | sed 's/te_//')\n              echo \"date=$ECONOMIST_DATE\" >> $GITHUB_OUTPUT\n              echo \"找到最新的经济学人目录: $LATEST_ECONOMIST_DIR，日期: $ECONOMIST_DATE\"\n            fi\n          else\n            echo \"经济学人目录不存在\"\n            echo \"latest_dir=\" >> $GITHUB_OUTPUT\n          fi\n      \n      # 查找最新的纽约客文件\n      - name: 查找最新的纽约客文件\n        id: newyorker\n        run: |\n          if [ -d \"./02_new_yorker\" ]; then\n            LATEST_NEWYORKER_DIR=$(find ./02_new_yorker -maxdepth 1 -type d -mindepth 1 -not -path \"*/\\.*\" | sort -r | head -n 1)\n            echo \"latest_dir=$LATEST_NEWYORKER_DIR\" >> $GITHUB_OUTPUT\n            \n            # 从目录名中提取日期\n            if [ -n \"$LATEST_NEWYORKER_DIR\" ]; then\n              DIR_NAME=$(basename \"$LATEST_NEWYORKER_DIR\")\n              echo \"date=$DIR_NAME\" >> $GITHUB_OUTPUT\n              echo \"找到最新的纽约客目录: $LATEST_NEWYORKER_DIR，日期: $DIR_NAME\"\n            fi\n          else\n            echo \"纽约客目录不存在\"\n            echo \"latest_dir=\" >> $GITHUB_OUTPUT\n          fi\n      \n      # 同步经济学人到COS\n      - name: 同步经济学人到COS\n        if: steps.economist.outputs.latest_dir != ''\n        run: |\n          echo \"配置AWS S3寻址样式\"\n          aws configure set default.s3.addressing_style virtual\n          \n          echo \"开始同步经济学人目录: ${{ steps.economist.outputs.latest_dir }}\"\n          \n          if [ -d \"${{ steps.economist.outputs.latest_dir }}\" ]; then\n            # 只上传PDF文件\n            for file in \"${{ steps.economist.outputs.latest_dir }}\"/*.pdf; do\n              if [ -f \"$file\" ]; then\n                # 提取文件名\n                filename=$(basename \"$file\")\n                # 构建S3路径\n                s3_key=\"2.外刊/经济学人/${{ steps.economist.outputs.date }}/$filename\"\n                \n                # 检查文件是否已存在\n                echo \"检查COS中是否已存在文件: $s3_key\"\n                if aws s3api head-object --bucket ${{ secrets.COS_BUCKET }} --key \"$s3_key\" --endpoint-url=https://cos.${{ secrets.COS_REGION }}.myqcloud.com 2>/dev/null; then\n                  echo \"文件已存在，跳过上传: $s3_key\"\n                else\n                  echo \"正在上传PDF文件: $file\"\n                  # 获取文件大小\n                  file_size=$(stat -c%s \"$file\")\n                  echo \"文件大小: $file_size 字节\"\n                  \n                  # 直接使用低级命令上传\n                  echo \"使用s3api上传文件...\"\n                  aws s3api put-object \\\n                    --bucket ${{ secrets.COS_BUCKET }} \\\n                    --key \"$s3_key\" \\\n                    --body \"$file\" \\\n                    --content-length $file_size \\\n                    --endpoint-url=https://cos.${{ secrets.COS_REGION }}.myqcloud.com\n                  echo \"文件上传完成: $s3_key\"\n                fi\n              fi\n            done\n            echo \"已同步经济学人PDF到COS\"\n          else\n            echo \"经济学人目录不存在或为空: ${{ steps.economist.outputs.latest_dir }}\"\n          fi\n      \n      # 同步纽约客到COS\n      - name: 同步纽约客到COS\n        if: steps.newyorker.outputs.latest_dir != ''\n        run: |\n          if [ -d \"${{ steps.newyorker.outputs.latest_dir }}\" ]; then\n            # 只上传PDF文件\n            for file in \"${{ steps.newyorker.outputs.latest_dir }}\"/*.pdf; do\n              if [ -f \"$file\" ]; then\n                # 提取文件名\n                filename=$(basename \"$file\")\n                # 构建S3路径\n                s3_key=\"2.外刊/纽约客/${{ steps.newyorker.outputs.date }}/$filename\"\n                \n                # 检查文件是否已存在\n                echo \"检查COS中是否已存在文件: $s3_key\"\n                if aws s3api head-object --bucket ${{ secrets.COS_BUCKET }} --key \"$s3_key\" --endpoint-url=https://cos.${{ secrets.COS_REGION }}.myqcloud.com 2>/dev/null; then\n                  echo \"文件已存在，跳过上传: $s3_key\"\n                else\n                  echo \"正在上传PDF文件: $file\"\n                  # 获取文件大小\n                  file_size=$(stat -c%s \"$file\")\n                  echo \"文件大小: $file_size 字节\"\n                  \n                  # 直接使用低级命令上传\n                  echo \"使用s3api上传文件...\"\n                  aws s3api put-object \\\n                    --bucket ${{ secrets.COS_BUCKET }} \\\n                    --key \"$s3_key\" \\\n                    --body \"$file\" \\\n                    --content-length $file_size \\\n                    --endpoint-url=https://cos.${{ secrets.COS_REGION }}.myqcloud.com\n                  echo \"文件上传完成: $s3_key\"\n                fi\n              fi\n            done\n            echo \"已同步纽约客PDF到COS\"\n          else\n            echo \"纽约客目录不存在或为空: ${{ steps.newyorker.outputs.latest_dir }}\"\n          fi\n      \n      # 同步The Atlantic到COS（如果有更新）\n      - name: 同步The Atlantic到COS\n        run: |\n          if [ -d \"./04_atlantic\" ]; then\n            LATEST_ATLANTIC_DIR=$(find ./04_atlantic -maxdepth 1 -type d -mindepth 1 -not -path \"*/\\.*\" | sort -r | head -n 1)\n            if [ -n \"$LATEST_ATLANTIC_DIR\" ] && [ -d \"$LATEST_ATLANTIC_DIR\" ]; then\n              # 从目录名中提取日期\n              DIR_NAME=$(basename \"$LATEST_ATLANTIC_DIR\")\n              ATLANTIC_DATE=$DIR_NAME\n              echo \"找到最新的大西洋月刊目录: $LATEST_ATLANTIC_DIR，日期: $ATLANTIC_DATE\"\n              \n              # 只上传PDF文件\n              for file in \"$LATEST_ATLANTIC_DIR\"/*.pdf; do\n                if [ -f \"$file\" ]; then\n                  # 提取文件名\n                  filename=$(basename \"$file\")\n                  # 构建S3路径\n                  s3_key=\"2.外刊/大西洋月刊/$ATLANTIC_DATE/$filename\"\n                  \n                  # 检查文件是否已存在\n                  echo \"检查COS中是否已存在文件: $s3_key\"\n                  if aws s3api head-object --bucket ${{ secrets.COS_BUCKET }} --key \"$s3_key\" --endpoint-url=https://cos.${{ secrets.COS_REGION }}.myqcloud.com 2>/dev/null; then\n                    echo \"文件已存在，跳过上传: $s3_key\"\n                  else\n                    echo \"正在上传PDF文件: $file\"\n                    # 获取文件大小\n                    file_size=$(stat -c%s \"$file\")\n                    echo \"文件大小: $file_size 字节\"\n                    \n                    # 直接使用低级命令上传\n                    echo \"使用s3api上传文件...\"\n                    aws s3api put-object \\\n                      --bucket ${{ secrets.COS_BUCKET }} \\\n                      --key \"$s3_key\" \\\n                      --body \"$file\" \\\n                      --content-length $file_size \\\n                      --endpoint-url=https://cos.${{ secrets.COS_REGION }}.myqcloud.com\n                    echo \"文件上传完成: $s3_key\"\n                  fi\n                fi\n              done\n              echo \"已同步The Atlantic PDF到COS\"\n            else\n              echo \"未找到有效的The Atlantic目录\"\n            fi\n          else\n            echo \"Atlantic目录不存在\"\n          fi\n      \n      # 同步Wired到COS（如果有更新）\n      - name: 同步Wired到COS\n        run: |\n          if [ -d \"./05_wired\" ]; then\n            LATEST_WIRED_DIR=$(find ./05_wired -maxdepth 1 -type d -mindepth 1 -not -path \"*/\\.*\" | sort -r | head -n 1)\n            if [ -n \"$LATEST_WIRED_DIR\" ] && [ -d \"$LATEST_WIRED_DIR\" ]; then\n              # 从目录名中提取日期\n              DIR_NAME=$(basename \"$LATEST_WIRED_DIR\")\n              WIRED_DATE=$DIR_NAME\n              echo \"找到最新的连线杂志目录: $LATEST_WIRED_DIR，日期: $WIRED_DATE\"\n              \n              # 只上传PDF文件\n              for file in \"$LATEST_WIRED_DIR\"/*.pdf; do\n                if [ -f \"$file\" ]; then\n                  # 提取文件名\n                  filename=$(basename \"$file\")\n                  # 构建S3路径\n                  s3_key=\"2.外刊/连线杂志/$WIRED_DATE/$filename\"\n                  \n                  # 检查文件是否已存在\n                  echo \"检查COS中是否已存在文件: $s3_key\"\n                  if aws s3api head-object --bucket ${{ secrets.COS_BUCKET }} --key \"$s3_key\" --endpoint-url=https://cos.${{ secrets.COS_REGION }}.myqcloud.com 2>/dev/null; then\n                    echo \"文件已存在，跳过上传: $s3_key\"\n                  else\n                    echo \"正在上传PDF文件: $file\"\n                    # 获取文件大小\n                    file_size=$(stat -c%s \"$file\")\n                    echo \"文件大小: $file_size 字节\"\n                    \n                    # 直接使用低级命令上传\n                    echo \"使用s3api上传文件...\"\n                    aws s3api put-object \\\n                      --bucket ${{ secrets.COS_BUCKET }} \\\n                      --key \"$s3_key\" \\\n                      --body \"$file\" \\\n                      --content-length $file_size \\\n                      --endpoint-url=https://cos.${{ secrets.COS_REGION }}.myqcloud.com\n                    echo \"文件上传完成: $s3_key\"\n                  fi\n                fi\n              done\n              echo \"已同步Wired PDF到COS\"\n            else\n              echo \"未找到有效的Wired目录\"\n            fi\n          else\n            echo \"Wired目录不存在\"\n          fi\n\n三、Cloudflare R2 配置在方法发布后，很多朋友发现Cloudflare R2没办法简单修改使用，我自己改一晚上bug满头包才发现是因为AWS CLI的较新版本(2.23.0和1.37.0以上)引入了默认校验和行为的修改，和Cloudflare R2的API不兼容才导致没办法直接套用的，令人感慨。在腾讯云COS脚本的基础上，我将 AWS CLI 版本降级到已知与 Cloudflare R2 兼容的版本 2.22.35，在 在所有的 aws s3 cp 命令中添加了 --checksum-algorithm CRC32 参数，现在运行脚本之后已经可以正常上传了。\n效果图：\nimage|565x500如果你想要使用R2，需要在github仓库里配置四个环境变量R2_ACCOUNT_IDR2_BUCKET_NAMER2_ACCESS_KEY_IDR2_SECRET_ACCESS_KEY当然，你也可以直接fork我的仓库最新的支持R2的脚本如下：name: 同步外刊到Cloudflare R2\n\non:\n  # 在同步上游仓库工作流完成后运行\n  workflow_run:\n    workflows: [\"同步上游仓库\"]\n    types:\n      - completed\n  # 允许手动触发\n  workflow_dispatch:\n\njobs:\n  sync-to-r2:\n    runs-on: ubuntu-latest\n    # 只有当触发的工作流成功完成时才运行\n    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}\n    \n    steps:\n      # 检出当前仓库代码（使用稀疏检出策略，只检出必要的目录结构）\n      - name: 检出当前仓库\n        uses: actions/checkout@v3\n        with:\n          fetch-depth: 1\n          sparse-checkout: |\n            01_economist\n            02_new_yorker\n            04_atlantic\n            05_wired\n          sparse-checkout-cone-mode: true\n      \n      # 安装AWS CLI\n      - name: 安装AWS CLI\n        uses: unfor19/install-aws-cli-action@v1\n        with:\n          version: 2.22.35\n      \n      # 配置AWS凭证（用于访问Cloudflare R2）\n      - name: 配置AWS凭证\n        run: |\n          mkdir -p ~/.aws\n          cat > ~/.aws/credentials << EOF\n          [default]\n          aws_access_key_id = ${{ secrets.R2_ACCESS_KEY_ID }}\n          aws_secret_access_key = ${{ secrets.R2_SECRET_ACCESS_KEY }}\n          EOF\n          \n          cat > ~/.aws/config << EOF\n          [default]\n          region = auto\n          output = json\n          EOF\n          \n          # 验证配置是否生效\n          echo \"AWS CLI配置完成，当前配置：\"\n          aws configure list\n      \n      # 列出目录内容，以便于调试\n      - name: 列出目录内容\n        run: |\n          echo \"列出经济学人目录内容：\"\n          ls -la ./01_economist || echo \"经济学人目录不存在\"\n          echo \"列出纽约客目录内容：\"\n          ls -la ./02_new_yorker || echo \"纽约客目录不存在\"\n          echo \"列出Atlantic目录内容：\"\n          ls -la ./04_atlantic || echo \"Atlantic目录不存在\"\n          echo \"列出Wired目录内容：\"\n          ls -la ./05_wired || echo \"Wired目录不存在\"\n      \n      # 查找最新的经济学人文件\n      - name: 查找最新的经济学人文件\n        id: economist\n        run: |\n          if [ -d \"./01_economist\" ]; then\n            LATEST_ECONOMIST_DIR=$(find ./01_economist -maxdepth 1 -type d -name \"te_*\" | sort -r | head -n 1)\n            echo \"latest_dir=$LATEST_ECONOMIST_DIR\" >> $GITHUB_OUTPUT\n            \n            # 从目录名中提取日期（格式如te_2025.04.05）\n            if [ -n \"$LATEST_ECONOMIST_DIR\" ]; then\n              DIR_NAME=$(basename \"$LATEST_ECONOMIST_DIR\")\n              ECONOMIST_DATE=$(echo \"$DIR_NAME\" | sed 's/te_//')\n              echo \"date=$ECONOMIST_DATE\" >> $GITHUB_OUTPUT\n              echo \"找到最新的经济学人目录: $LATEST_ECONOMIST_DIR，日期: $ECONOMIST_DATE\"\n            fi\n          else\n            echo \"经济学人目录不存在\"\n            echo \"latest_dir=\" >> $GITHUB_OUTPUT\n          fi\n      \n      # 查找最新的纽约客文件\n      - name: 查找最新的纽约客文件\n        id: newyorker\n        run: |\n          if [ -d \"./02_new_yorker\" ]; then\n            LATEST_NEWYORKER_DIR=$(find ./02_new_yorker -maxdepth 1 -type d -mindepth 1 -not -path \"*/\\.*\" | sort -r | head -n 1)\n            echo \"latest_dir=$LATEST_NEWYORKER_DIR\" >> $GITHUB_OUTPUT\n            \n            # 从目录名中提取日期\n            if [ -n \"$LATEST_NEWYORKER_DIR\" ]; then\n              DIR_NAME=$(basename \"$LATEST_NEWYORKER_DIR\")\n              echo \"date=$DIR_NAME\" >> $GITHUB_OUTPUT\n              echo \"找到最新的纽约客目录: $LATEST_NEWYORKER_DIR，日期: $DIR_NAME\"\n            fi\n          else\n            echo \"纽约客目录不存在\"\n            echo \"latest_dir=\" >> $GITHUB_OUTPUT\n          fi\n      \n      # 同步经济学人到R2\n      - name: 同步经济学人到R2\n        if: steps.economist.outputs.latest_dir != ''\n        run: |\n          echo \"开始同步经济学人目录: ${{ steps.economist.outputs.latest_dir }}\"\n          \n          if [ -d \"${{ steps.economist.outputs.latest_dir }}\" ]; then\n            # 只上传PDF文件\n            for file in \"${{ steps.economist.outputs.latest_dir }}\"/*.pdf; do\n              if [ -f \"$file\" ]; then\n                # 提取文件名\n                filename=$(basename \"$file\")\n                # 构建S3路径\n                s3_key=\"2.外刊/经济学人/${{ steps.economist.outputs.date }}/$filename\"\n                \n                # 检查文件是否已存在\n                echo \"检查R2中是否已存在文件: $s3_key\"\n                if aws s3api head-object --bucket ${{ secrets.R2_BUCKET_NAME }} --key \"$s3_key\" --endpoint-url \"https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com\" 2>/dev/null; then\n                  echo \"文件已存在，跳过上传: $s3_key\"\n                else\n                  echo \"正在上传PDF文件: $file\"\n                  # 禁用分块上传，使用单一请求上传文件\n                  aws configure set s3.multipart_threshold 999GB\n                  aws s3 cp \"$file\" \"s3://${{ secrets.R2_BUCKET_NAME }}/$s3_key\" \\\n                    --endpoint-url \"https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com\" \\\n                    --no-progress \\\n                    --checksum-algorithm CRC32\n                  echo \"文件上传完成: $s3_key\"\n                fi\n              fi\n            done\n            echo \"已同步经济学人PDF到R2\"\n          else\n            echo \"经济学人目录不存在或为空: ${{ steps.economist.outputs.latest_dir }}\"\n          fi\n      \n      # 同步纽约客到R2\n      - name: 同步纽约客到R2\n        if: steps.newyorker.outputs.latest_dir != ''\n        run: |\n          if [ -d \"${{ steps.newyorker.outputs.latest_dir }}\" ]; then\n            # 只上传PDF文件\n            for file in \"${{ steps.newyorker.outputs.latest_dir }}\"/*.pdf; do\n              if [ -f \"$file\" ]; then\n                # 提取文件名\n                filename=$(basename \"$file\")\n                # 构建S3路径\n                s3_key=\"2.外刊/纽约客/${{ steps.newyorker.outputs.date }}/$filename\"\n                \n                # 检查文件是否已存在\n                echo \"检查R2中是否已存在文件: $s3_key\"\n                if aws s3api head-object --bucket ${{ secrets.R2_BUCKET_NAME }} --key \"$s3_key\" --endpoint-url \"https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com\" 2>/dev/null; then\n                  echo \"文件已存在，跳过上传: $s3_key\"\n                else\n                  echo \"正在上传PDF文件: $file\"\n                  # 禁用分块上传，使用单一请求上传文件\n                  aws configure set s3.multipart_threshold 999GB\n                  aws s3 cp \"$file\" \"s3://${{ secrets.R2_BUCKET_NAME }}/$s3_key\" \\\n                    --endpoint-url \"https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com\" \\\n                    --no-progress \\\n                    --checksum-algorithm CRC32\n                  echo \"文件上传完成: $s3_key\"\n                fi\n              fi\n            done\n            echo \"已同步纽约客PDF到R2\"\n          else\n            echo \"纽约客目录不存在或为空: ${{ steps.newyorker.outputs.latest_dir }}\"\n          fi\n      \n      # 同步The Atlantic到R2（如果有更新）\n      - name: 同步The Atlantic到R2\n        run: |\n          if [ -d \"./04_atlantic\" ]; then\n            LATEST_ATLANTIC_DIR=$(find ./04_atlantic -maxdepth 1 -type d -mindepth 1 -not -path \"*/\\.*\" | sort -r | head -n 1)\n            if [ -n \"$LATEST_ATLANTIC_DIR\" ] && [ -d \"$LATEST_ATLANTIC_DIR\" ]; then\n              # 从目录名中提取日期\n              DIR_NAME=$(basename \"$LATEST_ATLANTIC_DIR\")\n              ATLANTIC_DATE=$DIR_NAME\n              echo \"找到最新的大西洋月刊目录: $LATEST_ATLANTIC_DIR，日期: $ATLANTIC_DATE\"\n              \n              # 只上传PDF文件\n              for file in \"$LATEST_ATLANTIC_DIR\"/*.pdf; do\n                if [ -f \"$file\" ]; then\n                  # 提取文件名\n                  filename=$(basename \"$file\")\n                  # 构建S3路径\n                  s3_key=\"2.外刊/大西洋月刊/$ATLANTIC_DATE/$filename\"\n                  \n                  # 检查文件是否已存在\n                  echo \"检查R2中是否已存在文件: $s3_key\"\n                  if aws s3api head-object --bucket ${{ secrets.R2_BUCKET_NAME }} --key \"$s3_key\" --endpoint-url \"https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com\" 2>/dev/null; then\n                    echo \"文件已存在，跳过上传: $s3_key\"\n                  else\n                    echo \"正在上传PDF文件: $file\"\n                    # 禁用分块上传，使用单一请求上传文件\n                    aws configure set s3.multipart_threshold 999GB\n                    aws s3 cp \"$file\" \"s3://${{ secrets.R2_BUCKET_NAME }}/$s3_key\" \\\n                      --endpoint-url \"https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com\" \\\n                      --no-progress \\\n                      --checksum-algorithm CRC32\n                    echo \"文件上传完成: $s3_key\"\n                  fi\n                fi\n              done\n              echo \"已同步The Atlantic PDF到R2\"\n            else\n              echo \"未找到有效的The Atlantic目录\"\n            fi\n          else\n            echo \"Atlantic目录不存在\"\n          fi\n      \n      # 同步Wired到R2（如果有更新）\n      - name: 同步Wired到R2\n        run: |\n          if [ -d \"./05_wired\" ]; then\n            LATEST_WIRED_DIR=$(find ./05_wired -maxdepth 1 -type d -mindepth 1 -not -path \"*/\\.*\" | sort -r | head -n 1)\n            if [ -n \"$LATEST_WIRED_DIR\" ] && [ -d \"$LATEST_WIRED_DIR\" ]; then\n              # 从目录名中提取日期\n              DIR_NAME=$(basename \"$LATEST_WIRED_DIR\")\n              WIRED_DATE=$DIR_NAME\n              echo \"找到最新的连线杂志目录: $LATEST_WIRED_DIR，日期: $WIRED_DATE\"\n              \n              # 只上传PDF文件\n              for file in \"$LATEST_WIRED_DIR\"/*.pdf; do\n                if [ -f \"$file\" ]; then\n                  # 提取文件名\n                  filename=$(basename \"$file\")\n                  # 构建S3路径\n                  s3_key=\"2.外刊/连线杂志/$WIRED_DATE/$filename\"\n                  \n                  # 检查文件是否已存在\n                  echo \"检查R2中是否已存在文件: $s3_key\"\n                  if aws s3api head-object --bucket ${{ secrets.R2_BUCKET_NAME }} --key \"$s3_key\" --endpoint-url \"https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com\" 2>/dev/null; then\n                    echo \"文件已存在，跳过上传: $s3_key\"\n                  else\n                    echo \"正在上传PDF文件: $file\"\n                    # 禁用分块上传，使用单一请求上传文件\n                    aws configure set s3.multipart_threshold 999GB\n                    aws s3 cp \"$file\" \"s3://${{ secrets.R2_BUCKET_NAME }}/$s3_key\" \\\n                      --endpoint-url \"https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com\" \\\n                      --no-progress \\\n                      --checksum-algorithm CRC32\n                    echo \"文件上传完成: $s3_key\"\n                  fi\n                fi\n              done\n              echo \"已同步Wired PDF到R2\"\n            else\n              echo \"未找到有效的Wired目录\"\n            fi\n          else\n            echo \"Wired目录不存在\"\n          fi四、最终效果效果\n可以看到执行同步后，对应刊物的最新文章就被我们同步到Obsidian的Vault里了。五、可能的改进优化1.更多的同步平台我们目前的解决方法是利用 GitHub Actions 将文件推送到 S3 兼容的云存储（如腾讯云 COS），然后依赖 Obsidian 的 Remotely Save 插件进行同步。但每个人的同步习惯和工具链可能不同：OneDrive / Google Drive / Dropbox:Obsidian 端: Remotely Save 插件本身就支持 OneDrive、Dropbox 等多种后端。如果你已经在 Obsidian 中配置了这些服务的同步，那么 Obsidian 这边不需要改动。GitHub Actions 端 (挑战): 关键在于修改 sync-to-obsidian.yml 这个 Workflow。你需要找到或创建一个 GitHub Action，该 Action 能够安全地验证并上传文件到你选择的云盘服务。这通常涉及到：获取对应云盘服务的 API 访问令牌或使用特定的 CLI 工具 (如 rclone，一个强大的多云存储管理工具，或者针对特定服务的官方/社区 CLI)。将认证信息（如 API Token）安全地存储在 GitHub Secrets 中。修改 Workflow 中的上传步骤，使用相应的命令将文件推送到你的云盘指定目录。例如，使用 rclone copy 命令。优点: 可以直接利用你已有的、可能容量更大或更习惯的云盘服务。缺点: 需要额外配置 Actions 与特定云盘服务的集成，可能比 S3 稍微复杂一些。Git (例如，使用 Obsidian Git 插件):思路: 不再需要 S3 作为中间存储。GitHub Actions 直接将下载到的最新外刊 PDF 文件提交 (commit) 并推送 (push) 到一个专门用于同步 Obsidian Vault 的 Git 仓库（或者就是你的 Vault 本身如果它是一个 Git 仓库）。Obsidian 端: 你需要在 Obsidian 中安装并配置 Obsidian Git 插件，让它定期自动 pull 这个 Git 仓库的更新。GitHub Actions 端: 修改 sync-to-obsidian.yml Workflow：移除所有 AWS CLI 和 S3 相关的配置和上传步骤。在检出 awesome-english-ebooks 内容后，将找到的最新 PDF 文件复制到 另一个 Git 仓库（你的 Obsidian Vault 仓库）的工作目录中，或者直接复制到当前仓库的某个指定目录下（如果打算用同一个仓库混合管理）。添加 Git 命令步骤 (git add, git commit, git push) 来提交这些新文件。需要配置好推送权限，可能需要使用 Personal Access Token (PAT) 或 SSH 密钥，并存储在 Secrets 中。优点: 完全基于 Git，对于熟悉 Git 的用户来说可能更自然；减少了对 S3 的依赖。缺点:仓库大小: Git 不擅长处理大型二进制文件。频繁添加 PDF 可能导致 Git 仓库迅速膨胀，克隆和拉取变慢。可能需要结合使用 Git LFS (Large File Storage) 来管理这些 PDF 文件，但这会增加设置的复杂性。冲突处理: 如果你在本地也修改了 Vault，自动 pull 可能会遇到合并冲突，需要手动解决。2.AI加成下的文件处理我们还可以在 GitHub Actions 中集成 pandoc 等工具（或者使用类似于Mistral OCR一类的工具），尝试将 EPUB 或甚至 PDF 转换为 Markdown 格式。这样可以直接在 Obsidian 中编辑、链接和引用文本内容，而不是仅仅处理一个附件。但这非常复杂，因为格式转换（尤其是 PDF）往往会丢失布局和图片，效果可能不理想，需要大量调整和测试。可以尝试在 Action 中解析文件名或文件内容（如果可能），提取期刊名称、期号、日期等元数据。然后，除了上传原始文件，还可以自动生成一个对应的 Markdown 笔记文件（.md），包含这些元数据、指向原始 PDF/EPUB 文件的链接以及可能的标签（如 #外刊 #经济学人 #待读）。这将极大地提升在 Obsidian 中的组织和可发现性。这可能需要编写更复杂的脚本（如 Python 脚本）并在 Action 中运行。说实话我觉得这样不如自己notion开一个database，确实没必要自己硬在Obsidian里实现一个徒增维护成本的数据库"
  },
  {
    "title": "神经药理学笔记：茶氨酸、咖啡因和米氮平",
    "summary": "观前提醒我不能对这篇博客内容的科学性、真实性和有效性做任何保证米氮平为处方药，需经医生诊断并结合个人状况开具。请勿擅自购买或使用药物反应存在显著个体差异，具体用药和剂量需由医生根据健康状况、病情轻重及既往用药综合判断药物通常需辅以心理治疗（如CBT/CBT-I）及生活方式干预（如作息规律、适度运动、放松训练等）以提升疗效引言本篇主要介绍三种在不同场景下影响我们大脑功能的代表性物质：L-茶氨酸 (L",
    "tags": [
      "心理学与神经科学"
    ],
    "url": "/posts/HumanSciences/theanine-caffeine-mirtazapine/",
    "date": "2025-04-07T00:00:00.000Z",
    "content": "观前提醒我不能对这篇博客内容的科学性、真实性和有效性做任何保证米氮平为处方药，需经医生诊断并结合个人状况开具。请勿擅自购买或使用药物反应存在显著个体差异，具体用药和剂量需由医生根据健康状况、病情轻重及既往用药综合判断药物通常需辅以心理治疗（如CBT/CBT-I）及生活方式干预（如作息规律、适度运动、放松训练等）以提升疗效引言本篇主要介绍三种在不同场景下影响我们大脑功能的代表性物质：L-茶氨酸 (L-Theanine)，这种源自茶叶的氨基酸以其独特的镇静放松效果而闻名；咖啡因 (Caffeine)，全球范围内最广泛使用的中枢神经兴奋剂，是我们对抗疲劳、提升警觉的“老朋友”；以及米氮平 (Mirtazapine)，一种作用机制复杂、兼具抗抑郁、抗焦虑和显著镇静效果的处方药物。什么，你问我为什么要把这三种放到一篇文章里？因为我自己服用好吧，这当然是个玩笑（或者不完全是？）。因此，这篇“神经药理学笔记”的主要内容是：L-茶氨酸如何带来“清醒的放松”？咖啡因如何让我们保持警觉，以及其代价是什么？米氮平这个“多面手”是如何通过多重机制发挥作用的？我们将逐一剖析它们的药理机制、主要效果、应用场景以及需要注意的安全信息。最后，我们还会简单对比一下这三者，看看它们之间是否存在有趣的关联或潜在的相互作用。一、L-茶氨酸 (L-Theanine) - 来自茶叶的平静力量1.简介与来源L-茶氨酸（γ-谷氨酰乙胺）是一种非蛋白质组成的独特氨基酸，主要存在于茶树（Camellia sinensis）的叶片中，尤其以绿茶含量最为丰富。它也少量存在于某些蘑菇种类中。作为一种天然化合物，L-茶氨酸因其能够诱导精神放松状态，同时不伴随传统镇静剂常见的嗜睡副作用而备受关注。其化学结构与神经递质谷氨酸（Glutamate）和γ-氨基丁酸（GABA）相似，这为其独特的神经药理学特性奠定了基础。2.药理机制L-茶氨酸能够穿过血脑屏障（Blood-Brain Barrier, BBB），直接作用于中枢神经系统。 L-茶氨酸被认为可以促进GABA的合成与释放。GABA是中枢神经系统主要的抑制性神经递质，其水平升高有助于降低神经元兴奋性，从而产生抗焦虑和镇静效果。在结构上，L-茶氨酸与谷氨酸类似，可以与谷氨酸受体（特别是AMPA、Kainate受体，对NMDA受体的作用尚存争议）结合，可能起到部分拮抗作用或调节作用。通过抑制谷氨酸的兴奋性作用，尤其是在应激状态下，有助于恢复神经系统的平衡，减少兴奋性毒性。部分研究还提示其可能抑制谷氨酸转运体，减少突触间隙的谷氨酸。 L-茶氨酸在特定脑区（如纹状体、海马体）可增加多巴胺和血清素的释放或减少其降解。这两种神经递质与情绪调节、奖赏机制和认知功能密切相关，其水平提升可能有助于改善情绪、增强愉悦感和认知表现。多项脑电图（EEG）研究显示，摄入L-茶氨酸后，大脑枕叶和顶叶区域的α波（8-13 Hz）活动显著增强。α波通常与“清醒的放松”（wakeful relaxation）状态相关，表现为精神放松、注意力集中但无睡意。这就和之前讲抗失眠与抑郁药物对于人体的作用相反了基于上述机制，我们可以总结出L-茶氨酸展现出以下主要的药理效应：抗焦虑与压力缓解： 这是L-茶氨酸最广为人知的作用。通过调节GABA和谷氨酸系统，以及提升α波活动，它能有效减轻主观的紧张感和生理上的应激反应（如心率、皮质醇水平的轻微降低）。改善认知功能： L-茶氨酸单独使用或与咖啡因协同使用时，可能有助于提高注意力、专注力、学习和记忆能力，尤其是在压力环境下。这种效应可能与其对多巴胺、血清素的调节以及α波的增强有关。改善睡眠质量： L-茶氨酸本身并非直接的催眠剂，但它通过缓解入睡前的焦虑和促进放松状态，有助于缩短入睡潜伏期，提高睡眠效率和主观睡眠质量。潜在的神经保护作用： 实验室研究提示，通过调节谷氨酸能系统，L-茶氨酸可能对某些神经退行性疾病模型或缺血性损伤具有一定的保护潜力，但这方面的临床证据尚不充分。可以看到，L-茶氨酸与咖啡因联用可以提高人的主观警觉度并减轻疲劳感，对于提升高认知负荷任务表现具有协同增效作⽤。3.药代动力、安全和耐受性L-茶氨酸通常被认为是安全的，具有良好的耐受性。在美国，它被FDA认定为“公认安全”（Generally Recognized As Safe, GRAS）的食品成分。在推荐剂量范围内（通常为100-400mg/天），副作用罕见且轻微，可能包括头痛或轻度胃肠不适。口服L-茶氨酸后，它能被肠道良好吸收，约1小时内达到血浆峰浓度，并能有效透过血脑屏障。其半衰期相对较短，大约在1-2小时左右。主要在肝脏和肾脏代谢，部分通过尿液排出。目前未发现其具有成瘾性或引起戒断症状。与其他药物的显著相互作用报道较少，但理论上与降压药或中枢神经系统抑制剂合用时应谨慎，建议在医生或药师指导下使用。4.总结L-茶氨酸作为一种源自天然茶叶的氨基酸，通过多靶点调节中枢神经递质系统和脑电活动，提供了一种独特的“清醒放松”效果。其在缓解焦虑、改善认知和睡眠方面的潜力，加之良好的安全性，使其成为膳食补充剂领域和功能性食品开发中的热门成分。然而，对于其作为治疗手段的有效性和长期影响，仍需更大规模、高质量的临床研究来证实。二、咖啡因 (Caffeine) - 最广泛使用的中枢神经兴奋剂1.简介与来源咖啡因（1,3,7-三甲基黄嘌呤）是一种生物碱，属于甲基黄嘌呤类化合物。它是全球范围内消费最广泛的中枢神经系统 (CNS) 兴奋剂，天然存在于咖啡豆、茶叶（其中咖啡因含量通常低于等量咖啡）、可可豆、瓜拉那果和可乐果等多种植物中。由于其提神醒脑、驱除疲劳的效果，咖啡因被广泛添加到饮料（咖啡、茶、能量饮料、软饮料）、食品以及某些非处方药和处方药中（例如，作为止痛药的辅助成分或用于治疗新生儿呼吸暂停）。2.药理机制与效应咖啡因的主要药理作用机制是非选择性拮抗腺苷受体 (Adenosine Receptors)，特别是A₁和A₂<0xE2><0x82><0x90>亚型。腺苷是一种内源性嘌呤核苷，在中枢神经系统中作为一种重要的抑制性神经调质。它通过与腺苷受体结合，抑制神经元活动，促进睡意和血管舒张。咖啡因的分子结构与腺苷相似，能够竞争性地结合并阻断腺苷受体，从而阻止腺苷发挥其抑制作用。这种去抑制 (Disinhibition) 效应导致许多神经递质（包括多巴胺、去甲肾上腺素、乙酰胆碱、谷氨酸和血清素）的释放增加，神经元兴奋性增强，最终表现为中枢神经系统的兴奋。咖啡因的作用广泛影响多个生理系统：中枢神经系统：兴奋与警觉： 减少困倦感，提高警觉性、注意力和反应速度。认知功能： 可能改善某些认知任务的表现，尤其是在疲劳状态下，如持续注意力、工作记忆和执行功能。情绪： 低至中等剂量可能带来愉悦感和精力充沛感，但高剂量或在易感个体中可能诱发焦虑、紧张、易怒和失眠。运动协调： 可能轻微改善运动表现，但高剂量可引起手部震颤。心血管系统： 可引起短暂的心率和血压升高，尤其是在不常摄入咖啡因的个体中。长期规律摄入者通常会产生耐受。呼吸系统： 松弛支气管平滑肌（源于其代谢产物茶碱的作用），轻度增加呼吸频率和深度。肾脏： 具有利尿作用，通过增加肾血流量和抑制肾小管对钠和水的重吸收实现。胃肠道： 刺激胃酸分泌，可能松弛食管下括约肌。骨骼肌： 可能增强骨骼肌的收缩力。3.药代动力学一般来说，口服咖啡因后会迅速且完全吸收，生物利用度接近100%，通常在摄入后30-120分钟达到血浆峰浓度，咖啡因会广泛分布于全身组织，能够轻易透过血脑屏障和胎盘屏障。摄入体内后，咖啡因主要在肝脏通过细胞色素P450酶系（特别是CYP1A2同工酶）代谢。主要代谢产物为副黄嘌呤 (Paraxanthine, 约占84%)、可可碱 (Theobromine, 约占12%) 和茶碱 (Theophylline, 约占4%)，这些代谢产物本身也具有一定的生物活性。代谢产物主要通过肾脏随尿液排出，仅少量（约1-2%）以原形排出。咖啡因的消除半衰期个体差异较大，成人通常为3-7小时，但受多种因素影响（如遗传因素、吸烟（加速代谢）、怀孕（减缓代谢）、肝病（减缓代谢）以及某些药物（如氟伏沙明可显著抑制CYP1A2））。4.耐受性、依赖性与戒断像哥们我就干出来戒断反应了，一天不喝就头疼长期规律摄入咖啡因会导致对其多种效应产生耐受，尤其是对心血管、利尿和睡眠干扰作用；但对主观兴奋作用的耐受性发展相对较慢且不完全，耐受性的产生可能与腺苷受体的上调有关。此外，咖啡因可产生一定程度的心理依赖和轻微的生理依赖，虽然其成瘾潜力远低于强效精神活性物质，但规律摄入者突然停用可能出现戒断症状。最常见的戒断症状是头痛（搏动性），其他症状可包括疲劳、嗜睡、注意力不集中、情绪低落或易怒、类似流感的症状（如肌肉酸痛、恶心）。戒断症状通常在停用后12-24小时出现，20-51小时达到峰值，可持续2-9天。5.安全性与相互作用安全性： 中等剂量（通常指每日<400mg，约等于3-4杯标准咖啡）对大多数健康成人是安全的。常见副作用包括失眠、紧张、焦虑、心悸、胃部不适和尿频。过量摄入（通常>500-600mg/天）可导致咖啡因中毒（Caffeinism），表现为严重焦虑、激动、快速或不规则心跳、肌肉震颤、恶心呕吐等。极高剂量（数克）可能致命，通常由心律失常或癫痫发作导致。相互作用：药物代谢： 影响CYP1A2酶活性（诱导或抑制）的药物会改变咖啡因的代谢和血药浓度。例如，吸烟诱导CYP1A2，加速咖啡因清除；而氟伏沙明、西咪替丁、某些喹诺酮类抗生素则抑制CYP1A2，显著延长咖啡因半衰期，增加毒性风险。药效学相互作用： 可能增强其他兴奋剂的作用；可能干扰某些镇静剂或抗焦虑药的效果；与某些药物（如麻黄碱）合用可能增加心血管风险。三、米氮平 (Mirtazapine) - 多靶点的抗抑郁药1.简介米氮平是一种具有独特药理学特性的抗抑郁药，化学结构上属于四环类哌嗪-氮䓬衍生物。在药理学分类上，它被归类为去甲肾上腺素能和特异性血清素能抗抑郁药 (Noradrenergic and Specific Serotonergic Antidepressant, NaSSA)。米氮平于1990年代上市，主要用于治疗成人重度抑郁症 (Major Depressive Disorder, MDD)，尤其适用于伴有显著焦虑、失眠或食欲减退/体重减轻症状的患者。其作用机制区别于选择性血清素再摄取抑制剂 (SSRIs)、血清素去甲肾上腺素再摄取抑制剂 (SNRIs) 或三环类抗抑郁药 (TCAs)。2.药理机制米氮平的核心机制之一在于对α₂-肾上腺素能受体的强大拮抗作用。米氮平能够有效地“关闭”两种重要的α₂受体：一种是位于去甲肾上腺素（NE）神经元末梢的“自身受体”（autoreceptor），另一种是位于血清素（5-HT）神经元末梢的“异身受体”（heteroreceptor）。阻断自身受体，相当于解除了NE释放的“刹车”，使得NE的释放量得以增加。同样地，阻断异身受体（通常被NE激活以抑制5-HT释放）也移除了对5-HT释放的抑制，从而促进了5-HT的释放。这种同时提升NE和5-HT水平的独特方式，构成了其抗抑郁作用的重要基石。除了提升神经递质的“量”，米氮平还精妙地调控着这些递质作用的“靶点”。它对特定的血清素（5-HT）受体亚型表现出高亲和力的拮抗（阻断）作用。特别值得关注的是其对5-HT₂受体（尤其是5-HT₂ᴀ 和 5-HT₂ᴄ）的阻断。这一作用被认为是米氮平带来抗焦虑效果、改善睡眠（减少慢波睡眠抑制）的重要原因，并且有助于降低传统SSRI类药物可能引起的性功能障碍、失眠或初期焦虑加剧等副作用风险。通过“屏蔽”5-HT₂受体，增加的5-HT得以更优先地激动与抗抑郁疗效密切相关的5-HT₁ᴀ受体。此外，米氮平还是一个强效的5-HT₃受体拮抗剂。这种强大的阻断作用赋予了它类似昂丹司琼等药物的抗恶心和止吐效果，这对于某些患者来说是一个重要的临床优势，同时也可能帮助减少一些胃肠道相关的不适感。米氮平还对组胺H₁受体有极强拮抗作用（甚至可视为反向激动作用）。其对H₁受体的亲和力非常高，甚至超过了许多专门的抗组胺药。这直接解释了为何米氮平常伴有显著的镇静、嗜睡副作用，以及为何它能促进食欲并可能导致体重增加。有趣的是，其镇静作用往往在较低剂量（如7.5-15mg）时更为突出，因为在更高剂量下，由α₂受体拮抗带来的去甲肾上腺素能活性增强，可能会部分抵消H₁受体阻断所致的嗜睡效应。和SSRIs/SNRIs/TCAs这些老前辈不同，米氮平对血清素转运体 (SERT)、去甲肾上腺素转运体 (NET) 或多巴胺转运体 (DAT) 几乎没有抑制作用，对毒蕈碱胆碱能受体 (mAChRs) 和α₁-肾上腺素能受体的亲和力很低。这解释了为何其较少引起抗胆碱能副作用（如口干、便秘、视物模糊，尽管口干仍较常见，可能机制复杂）和体位性低血压（相较于TCAs）。3.药理作用基于其多靶点作用机制，米氮平表现出以下主要药理效应和临床应用价值：抗抑郁作用： 通过增强NE和5-HT（特别是通过5-HT₁<0xE2><0x82><0x90>受体）的神经传递来实现。适用于治疗MDD的各种亚型。抗焦虑作用： 可能源于增强的NE/5-HT传递和5-HT₂受体拮抗。对伴有焦虑症状的抑郁症患者尤其有效，有时也用于广泛性焦虑障碍等焦虑症的治疗（常为off-label）。镇静/催眠作用： 强大的H₁受体阻断使其成为治疗伴有失眠的抑郁症患者的有效选择。通常在睡前给药。食欲刺激和体重增加： H₁受体和可能的5-HT₂<0xE2><0x82><0x82>受体拮抗作用导致食欲显著增加和体重增加。这对于食欲差、体重减轻的抑郁症患者可能是有益的，但对于担心体重增加的患者则是一个主要缺点。抗恶心/止吐作用： 5-HT₃受体拮抗赋予其此特性，有时用于治疗化疗引起的恶心呕吐或作为其他药物引起恶心的辅助治疗。4.药代动力学米氮平口服后吸收良好，但由于首过效应，绝对生物利用度约为50%。食物对其吸收影响不大。主要通过在肝脏通过细胞色素P450酶系统广泛代谢，主要涉及CYP2D6、CYP3A4和CYP1A2；以代谢物形式经尿液（约75%）和粪便（约15%）排出。米氮平消除半衰期相对较长，平均为20-40小时，支持每日一次给药。半衰期存在个体差异，老年人和女性通常较长。5.安全性与副作用米氮平最常见的副作用是嗜睡/镇静（尤其在治疗初期和低剂量时）、食欲增加、体重增加和口干。头晕、疲劳也较常见。粒细胞缺乏症/中性粒细胞减少症是罕见但严重的潜在副作用，通常发生在治疗开始后的4-6周，停药后可逆。若患者出现发热、咽痛、感染迹象，应立即检查血常规。血清素综合征风险，尤其在与MAOIs或其他血清素能药物合用时（尽管单独使用米氮平风险低于SSRIs）。注意事项与禁忌：对米氮平或其成分过敏者禁用。禁止与单胺氧化酶抑制剂 (MAOIs) 合用或在停用MAOIs后14天内使用（反之亦然），以防血清素综合征。因其镇静作用，应警告患者驾驶或操作机械的风险，尤其在治疗初期。避免同时饮酒或使用其他中枢神经系统抑制剂（如苯二氮䓬类），因其会加剧镇静作用。在有癫痫病史、肝肾功能不全、心脏病、低血压、闭角型青光眼、前列腺肥大等患者中慎用。突然停药可能导致撤药综合征（如头晕、恶心、焦虑、失眠、感觉异常），应逐渐减量停药。米氮平是一种具有独特多靶点作用机制（NaSSA）的抗抑郁药，通过同时增强去甲肾上腺素和特异性血清素神经传递，并阻断5-HT₂、5-HT₃和H₁受体来发挥作用。其突出的镇静、抗焦虑和促进食欲效果使其在特定抑郁症患者亚群中具有优势，尤其适用于伴有失眠、焦虑和体重减轻者。然而，其显著的镇静和体重增加副作用也是临床应用中需要重点考虑和管理的问题。了解其复杂的药理学特性对于优化治疗选择和管理潜在风险至关重要。四、对比与关联（L-茶氨酸 vs. 咖啡因）1. L-茶氨酸 vs. 咖啡因：天然的“动静”组合L-茶氨酸和咖啡因天然共存于茶叶中，这俩放一块就很有趣了。核心作用的对比：咖啡因： 典型的中枢神经兴奋剂。主要通过拮抗腺苷受体，减少大脑的“刹车”信号，从而提升警觉性、注意力和能量水平。其效果直接、快速，但可能伴随紧张、焦虑、心悸和后续的“能量崩溃”（crash）。L-茶氨酸： 独特的镇静放松剂（非嗜睡型）。通过促进GABA、调节谷氨酸能系统、增强α脑波，诱导一种“清醒的放松”状态，减轻压力和焦虑，同时可能改善认知功能，特别是注意力。对情绪和焦虑的影响：咖啡因在高剂量或易感人群中可能诱发或加剧焦虑。L-茶氨酸则具有明确的抗焦虑效果。对睡眠的影响：咖啡因是众所周知的睡眠干扰物，会延长入睡时间，减少总睡眠时长和深度睡眠。L-茶氨酸通过缓解睡前焦虑，有助于改善睡眠质量，但本身并非直接的催眠药。2. L-茶氨酸与咖啡因的协同效应：取长补短尽管作用看似相反，L-茶氨酸和咖啡因联合使用时却能产生显著的协同效应，这在许多研究和个人体验中都得到了证实，也是为什么饮茶（尤其是绿茶）带来的提神效果常被描述为比喝咖啡更“平稳”和“专注”的原因。认知增强： 如前文图示研究所示，L-茶氨酸与咖啡因联用，在提升注意力、警觉性、任务切换能力和减少错误率方面，效果常常优于单独使用任何一种。咖啡因提供了原始的“动力”和警觉基础，而L-茶氨酸则帮助“调优”这种状态，使其更加专注和平和，减少分心。减轻咖啡因副作用： 这是两者协同作用中最吸引人的一点。L-茶氨酸能够显著缓解或“缓冲”咖啡因可能引起的负面效应，如：减少“抖动”和紧张感 (Jitters)： L-茶氨酸的镇静作用可以抵消咖啡因过度兴奋引起的身体和精神紧张。改善情绪稳定性： 避免咖啡因可能带来的烦躁或焦虑飙升。可能平缓“能量崩溃”： 虽然机制尚不完全清楚，但更平稳的能量曲线是常见的主观感受。机制推测： 这种协同作用的精确机制仍在研究中，但可能涉及：L-茶氨酸通过增强α波活动，创造了一种有利于集中注意力的“宁静背景”。L-茶氨酸对GABA和谷氨酸系统的调节，可能平衡了咖啡因引起的过度兴奋。两者可能在调节多巴胺、去甲肾上腺素等神经递质方面存在复杂的交互影响，共同优化了认知相关的神经回路。实际应用： 这种协同作用使得 L-茶氨酸 + 咖啡因的组合在以下场景备受欢迎：提高工作或学习效率： 需要长时间保持专注和精力，同时避免过度焦虑。认知要求高的任务： 如考试、演讲、复杂问题解决。作为咖啡的替代品或补充： 追求更“干净”、“平顺”的提神体验。许多“促智”（Nootropic）补充剂也采用了这种经典搭配。结论本篇深入了解了三种在不同层面影响我们大脑功能的物质：源自茶叶、带来“清醒放松”的 L-茶氨酸；全球最受欢迎、提供能量与警觉的咖啡因；以及作用机制复杂、用于治疗特定精神健康状况的处方药米氮平。L-茶氨酸以其独特的抗焦虑、促进放松同时不引起嗜睡的特性，成为了应对日常压力、提升专注力的天然选择。它通过调节GABA、谷氨酸系统和增强α脑波，提供了一种温和而有效的方式来平衡身心状态。咖啡因作为我们文化中根深蒂固的兴奋剂，其通过阻断腺苷受体来对抗疲劳、提升警觉的效果毋庸置疑。然而，我们也必须认识到其潜在的副作用，如焦虑、睡眠干扰，以及耐受性和戒断现象。米氮平则代表了精神药物治疗的复杂性与精准性。作为一种NaSSA类抗抑郁药，它通过多靶点（α₂、5-HT₂、5-HT₃、H₁受体）的复杂调控，不仅能有效治疗抑郁症，还兼具显著的抗焦虑、镇静和食欲刺激作用，特别适用于特定类型的患者。但其应用必须在专业医疗指导下进行，并需密切关注其副作用，尤其是镇静和体重增加。参见[1] Einöther, S. J. L., & Giesbrecht, T. (2012). Caffeine as an attention enhancer: reviewing existing assumptions. Psychopharmacology, 225(2), 251–274. doi:10.1007/s00213-012-2917-4 [2] Giesbrecht, T., Rycroft, J. A., Rowson, M. J., & De Bruin, E. A. (2010). The combination of L-theanine and caffeine improves cognitive performance and increases subjective alertness. Nutritional Neuroscience, 13(6), 283–290. doi:10.1179/147683010x12611460764840 [3] Owen, G. N., Parnell, H., De Bruin, E. A., & Rycroft, J. A. (2008). The combined effects of L-theanine and caffeine on cognitive performance and mood. Nutritional Neuroscience, 11(4), 193–198. doi:10.1179/147683008x301513 [4] Anttila, S. A. K., & Leinonen, E. V. J. (2006). A Review of the Pharmacological and Clinical Profile of Mirtazapine. CNS Drug Reviews, 7(3), 249–264. doi:10.1111/j.1527-3458.2001.tb00198.x"
  },
  {
    "title": "模型考古学（八）：Llama4发布——并非领先",
    "summary": "一、简报难产的llama终于发布，几个月后的OpenAI仍然遥遥无期2025年4月6日，Meta宣布llama家族上新，宣布了三个llama 4系列模型，开源了两个：Llama 4 Scout、Llama 4 Maverick、Llama 4 Behemoth（规模最大，未开源）。这是模型摘要：Llama 4 Scout，16位专家的170亿激活参数的多模态模型，单个H100 GPU可运行， 同类",
    "tags": [
      "模型考古学"
    ],
    "url": "/posts/AI and Deep Learning/Llama-4-report/",
    "date": "2025-04-06T00:00:00.000Z",
    "content": "一、简报难产的llama终于发布，几个月后的OpenAI仍然遥遥无期2025年4月6日，Meta宣布llama家族上新，宣布了三个llama 4系列模型，开源了两个：Llama 4 Scout、Llama 4 Maverick、Llama 4 Behemoth（规模最大，未开源）。这是模型摘要：Llama 4 Scout，16位专家的170亿激活参数的多模态模型，单个H100 GPU可运行， 同类SOTA，并拥有10M（一千万）上下文窗口，并在广泛报道的基准测试中比 Gemma 3、Gemini 2.0 Flash-Lite 和 Mistral 3.1 有更好的表现Llama 4 Maverick，128位专家的170亿激活参数多模态模型，击败GPT-4o和Gemini 2.0 Flash，与DeepSeek-V3同等代码能力参数只要一半，主打与DeepSeek一样的性价比，单个H100主机即可运行。Maverick在广泛报告的基准测试中击败了 GPT-4o 和 Gemini 2.0 Flash，同时在推理和编码方面与新的 DeepSeek v3 取得可比的结果，而活跃参数不到一半。Llama 4 Maverick 以优于同类的性能成本比提供服务，实验聊天版本在 LMArena 上的 ELO 得分为 1417。Llama 4 Behemoth：2万亿（2880B）参数的超大超强模型，十六位专家，以上二者都由这个模型蒸馏而来；目前还在训练中；多个基准测试超过GPT-4.5、Claude Sonnet 3.7和 Gemini 2.0 Pro。Meta还宣布，这些Llama 4模型标志着Llama生态系统新时代——原生多模态AI创新的开始。接下来，我们一起看看本次Llama 4系列模型的创新点。二、创新点解读因为本次Llama4并没有发布技术报告，所有信源均来自于官方博客1.全面转向MoE架构Llama4系列是 Meta 首次在旗舰模型中采用专家混合 (MoE, Mixture of Experts) 架构。与传统的“稠密”模型（每次计算都使用所有参数）不同，MoE 模型包含多个“专家”网络，对于每个输入（token），系统会动态地选择一小部分专家来处理。MoE 架构的核心优势在于计算效率。在 Llama 4 中，每个 token 只激活总参数的一部分（称为“活跃参数”）。这使得模型在训练和推理时速度更快，计算成本更低，在相同的计算资源（FLOPs预算）下，MoE 架构通常能比稠密模型达到更好的性能。例如，Llama 4 Maverick 使用了 128 个路由专家 和 1 个共享专家。每个 token 会被发送到共享专家，并同时被路由到 128 个专家中的一个进行处理。模型结构上采用了稠密层和 MoE 层交替的方式来进一步优化推理效率。Meta 还特别优化了 MoE 的并行化设计，以提高训练和推理速度。转向 MoE 是 Llama 4 实现更高性能和效率的关键一步，使得强大的模型（如 Maverick）能够在单个 H100 主机上运行成为可能，并为 Behemoth 这样的超大规模模型训练提供了基础。2.原生多模态与早期融合Llama4系列和Llama3系列最大的区别之一就是Llama4系列模型是原生多模态模型。和市面上其他常见的多模态模型训练方式不一样，Llama4系列在训练时采用了早期融合 (Early Fusion)，也是 Llama 4 多模态能力的核心技术。与一些模型在后期才融合不同模态信息的做法不同，Llama 4 在模型主干网络的早期就将文本和视觉的 token 无缝集成在一起处理。早期融合使得模型可以在包含大量未标记的文本、图像和视频数据的混合数据上进行联合预训练，从而学习到更深层次的跨模态关联。训练数据量是 Llama 3 的两倍多（超过 30 万亿 token）。在架构方面，Llama 4 使用了基于 MetaCLIP 的改进版视觉编码器，这个编码器是与一个冻结的 Llama 模型一起单独训练的，目的是更好地将视觉信息“翻译”成 LLM 能够理解的表示。Llama4模型在预训练阶段接触了多达 48 张图像的输入，在实际应用（后训练测试）中可以处理最多 8 张图像，支持更复杂的视觉推理和互动任务。Llama 4 Scout 在图像定位方面表现突出，能够理解用户提示中涉及的视觉概念，并将模型的响应精确地锚定到图像中的特定区域，提升了视觉问答的准确性。中译中就是终于，finally支持其他家视觉模型同款的输出检测框功能。3.超长上下文与架构创新Llama 4 在处理长序列信息方面取得了突破性进展，尤其是 Llama 4 Scout，模型支持高达 1000 万 (10M) token 的上下文窗口，远超 Llama 3 的 128K 和业界普遍水平。Llama 4 Maverick 也支持 1M token。超长上下文可以解锁很多的模型应用场景，包括处理和摘要极长的文档或多份文档、分析用户长时间、大范围的活动记录以实现深度个性化和对包含数百万 token 的庞大代码库进行理解和推理等用例。那么，为什么Llama4可以实现超长上下文呢？核心在于架构创新 (iRoPE)。交错注意力层 (Interleaved Attention Layers)：在 Llama 4 架构的部分层中，使用了不带位置嵌入 (Positional Embeddings) 的交错注意力机制。这是支撑“无限”上下文长度的核心设计。推理时温度缩放 (Inference-Time Temperature Scaling)：通过在推理时调整注意力机制的“温度”，增强了模型在处理超出训练长度的序列时的泛化能力（长度泛化）。iRoPE 命名：Meta 将这种架构称为 iRoPE。“i” 代表交错注意力层 (interleaved)，而 “RoPE” 指的是在模型大多数其他层中仍然使用的旋转位置嵌入 (Rotary Positional Embeddings)。模型在“大海捞针 (Needle-in-a-haystack)”测试（在长文本中定位信息）和处理超过 1000 万代码 token 的 NLL（负对数似然）任务上都展示了良好效果。4.训练与后训练优化高效训练技术 (MetaP)：Meta 开发了一种名为 MetaP 的新训练技术，能够更可靠地设置关键的超参数（如学习率、初始化规模），并使其能在不同模型尺寸、批次大小和训练数据量之间良好迁移。FP8 精度训练：为了在不牺牲质量的前提下最大化训练效率，Llama 4（尤其是 Behemoth）的预训练采用了 FP8 精度，配合 32K GPU 集群，实现了极高的计算吞吐量（单个 H100 GPU 达到 390 TFLOPs）。中期训练 (Mid-training)：在预训练和后训练之间增加了一个“中期训练”阶段，使用专门的数据集和新的训练方法来强化模型的核心能力，并扩展上下文长度。精细化的后训练流程：后训练流程被重新设计，以平衡多模态能力、推理和对话：改进的 SFT (Supervised Fine-Tuning)：使用 Llama 模型作为“裁判”，过滤掉超过 50% 的简单数据，对更难的数据进行轻量级 SFT，避免过度拟合。在线强化学习 (Online RL)：通过精心挑选的更难提示进行 RL 训练，显著提升性能。采用持续在线 RL 策略，在训练和利用模型之间交替进行，不断过滤和保留中等到困难的提示。轻量级 DPO (Direct Preference Optimization)：在 RL 之后进行轻量级 DPO，处理与模型响应质量相关的边缘情况，平衡智能与对话能力。教师模型蒸馏 (Behemoth -> Maverick)：Llama 4 Maverick 的高质量部分得益于从 Llama 4 Behemoth 进行的协同蒸馏 (collaborative distillation)。Meta 开发了新颖的蒸馏损失函数，结合动态加权的软目标（教师模型的输出概率）和硬目标（正确答案）。利用 Behemoth 在预训练期间的前向传播计算结果作为 Maverick 的蒸馏目标，摊销了计算成本。针对超大模型的后训练优化 (Behemoth)：为 2T 参数的 Behemoth 进行后训练是巨大挑战。Meta 为此进一步优化，例如修剪了 95% 的 SFT 数据，采用轻量级 SFT 后进行大规模 RL，使用 pass@k 分析采样困难提示，动态过滤无用提示，以及完全异步的在线 RL 训练框架，将训练效率提升了约 10 倍。5.多语言Llama4在 200 种语言上进行了预训练，支持在超过 100 种语言上进行开源微调，且其中每种语言都有超过 10 亿个 token 的数据量，多语言标记 (token) 的数量比 Llama 3 多出 10 倍。但中文能力……我们还是等即将到来的Qwen3吧。三、大声BB1.端侧模型的头子都投了，未来主流路径应该还是以OpenAI和DeepSeek为代表的中心化全能MoE模型为主之前的Llama1、Llama2、Llama3都是Dense模型，系列模型规模大致在7B-70B左右，端侧运行的可能性和优势比较明显，Llama在大模型社区内也长期占据着主流基座模型的开发者心智，吸引了一大批关注本地化、小型化部署的开发者。但本次 Llama 4，尤其是 Maverick 和 Behemoth，明显是冲着云端、高性能计算去的。连 Scout 运行也需要 H100（虽然是单个）。这似乎印证了一个趋势：尽管端侧有需求，但要追求最前沿的性能、最长的上下文、最强的多模态能力，目前还得靠数据中心里的高性能超算。如果连Llama这种曾经的“端侧之光”都开始主攻需要H100级别算力才能跑起来的模型，那未来端侧/云端模型之争的天平，似乎在加速倒向OpenAI和DeepSeek所代表的云端中心化、追求极致性能和通用能力的MoE模型路线。本地化部署的未来可能更多在于这些大模型的“轻量版”或者特定任务的微调版本，而非前沿基础模型本身。2.全面拥抱 MoE，大模型技术架构趋同之前 Mistral 是最早在大模型方面让 MoE 架构火出圈的，Google 的 Gemini 也用了 MoE（至少Gemini 1.5 pro是MoE），基本上大模型主流赛道的旗舰模型都是MoE架构（OpenAI、Google、Grok、DeepSeek、Qwen）。现在 Meta Llama 4 全系列拥抱 MoE，基本说明想把模型参数和能力再往上堆一个数量级，同时还要兼顾（相对）效率，MoE 是目前业界公认的最优解之一。这也意味着模型训练和推理的复杂性又上了一个台阶，对基础设施和优化技术的要求更高了。稠密模型也许在某些特定场景还有优势，但在追求通用智能和规模效应的路上，MoE 似乎已成必选项。大家的技术路线越来越像了，卷的方向也越来越一致：更大的参数规模（通过MoE实现）、更强的多模态、更长的上下文。 这也意味着，大模型领域的“军备竞赛”进入白热化阶段，比拼的是谁能更快地训练出更大、更优的 MoE 模型，以及谁拥有更强的工程优化能力和数据处理能力。3.其实说创新也没多创新我们来细数一下Llama 4的创新点：MoE 架构？主流玩家早都已经换完了，Llama 4 是首次在旗舰模型用，但不是第一个吃螃蟹的。原生多模态？ GPT-4V、Gemini 珠玉在前，大家都在做。早期融合 (Early Fusion) 算是一个实现细节上的优化，但多模态本身不是新概念。超长上下文？ Llama 4 Scout 的 10M 确实是目前最长，iRoPE 架构是其实现的关键，这算是一个不错的工程创新。但追求长上下文这个方向本身，也是行业趋势，之前Gemini、Minimax，甚至Qwen也在这方面进行过探索，并且成果都挺显著的。训练优化？ FP8 训练、RLHF/DPO 流程、模型蒸馏，这些都是当前大模型训练的常规操作或渐进式改进（让我们感谢DeepSeek）。MetaP 可能是 Meta 内部提效的法宝，但对外界来说，更多是工程细节的打磨。Llama 4本次相当于整合了市场上最热门、最有效的技术方向，优化并且在理论上推向了新的规模和性能高度，尤其是在开源模型领域再次树立了标杆。为什么是理论上呢，我们下一节就说但要说开创了全新的、颠覆性的技术路线，好像还谈不上。更像是站在前人（或者说同行）的肩膀上，做了一次工程和整合能力的极致展现，把现有的 \"SOTA 配方\" 调得更猛、融合得更好了。4.我们再退一万步讲，好像模型性能也就那样Llama 4 Scout 和 Maverick 的性能确实亮眼，在各自的细分领域（轻量级多模态 SOTA、高性价比 MoE）做到了领先。Scout 能在单 H100 上跑还带 10M 上下文，这很实用；Maverick 性价比看齐 DeepSeek V3，用一半的活跃参数达到相似性能，这也很厉害。但仔细看，Maverick 对标的是 GPT-4o 和 Gemini Flash，打赢了固然可喜，但考虑到参数规模和 MoE 架构的加持，似乎也在情理之中。与 DeepSeek V3 打平手，也说明大家技术水平在同一梯队，差距在毫厘之间。至于那个真正对标 GPT-4.5、Sonnet 3.7、Gemini Pro 的终极大杀器 Llama 4 Behemoth，目前还处于“期货”状态，仍在训练中。它宣称的性能超越听起来很诱人，但毕竟还没正式发布和接受公开检验。所以，目前发布的 Llama 4 是很强，尤其是在开源社区和特定性能/成本区间内极具竞争力。但它带来的更多是一次强有力的追赶和局部超越，以及开源领域的新标杆。要说它带来了颠覆性的、让所有人惊呼“AI 又进化到了全新纪元！”的那种体验代差，至少从目前发布的 Scout 和 Maverick 来看，似乎还没到那个程度。更像是一次意料之中、情理之内的强力迭代，证明了 Meta 依然是顶级玩家，但整个 AI 领域可能进入了一个性能提升边际效应递减、需要更长时间积累才能迎来下一次质变的阶段。5.好话说完了，接下来该社区反馈了前面分析了 Llama 4 的诸多亮点和技术实力，Meta 的官方博客和各种基准测试也描绘了一幅美好的图景。然而，模型发布后，社区的实际体验和反馈却带来了一些不同的声音，甚至可以说是“杂音”。根据我目前掌握的信源，似乎Meta大力宣传的Llama 4 Scout 和 Maverick在编码领域并不如他们宣称的和打榜的那么好，有很多开发者质疑官网下载的maverick模型和lmarena竞技场的仿佛不是一个模型，无论是代码能力，还是写作能力，甚至输出文风都完全不一样，官网下载的模型明显远远不如竞技场。在Linux do论坛，有开发者质疑竞技场和实际发布模型差距过大，货不对板：我理解一定程度的差异，但是二者差异大到了让我开始怀疑甚至是meta放错了代码，给错了模型。几乎不像是一个模型。我无意贬低这个模型，竞技场的体验是不错的，文风很好，文笔很棒。虽然逻辑差点，指令跟随性差点。可是这个发布出来的，我很难形容这是竞技场里我体验到的，我实际上上面的图片也可以证明，二者几乎“能力完全不对等”再补一句，reddit上有人测试竞技场的知识量和or发布的知识量似乎是不相同的，很多竞技场的是知道的，但是放到or渠道就不知道了（我没有实测，在此放上贴图，如果有老哥实测欢迎贴出来）这意味着什么？如果社区的这些反馈具有普遍性，那问题就比较微妙了：基准测试与实际体验脱节？ LMArena 上的高分，以及官方报告中的优异表现，可能是在特定的、高度优化的环境下取得的。这可能是特定的系统提示 (System Prompt)、推理参数设置，甚至是未公开的微调版本。普通开发者下载模型后，在自己的环境中复现这种“巅峰状态”可能非常困难，导致心理落差巨大。模型版本混乱或误导？ 最坏的情况，就像那位开发者猜测的，是否存在发布的版本和用于打榜、展示的版本并非完全一致？这会严重影响 Meta 开源的可信度。虽然大公司不太可能犯这种低级错误，但社区的强烈质疑值得关注。对“编码能力”的定义差异？ Meta 宣称 Maverick 在编码上媲美 DeepSeek V3，但社区反馈不佳。这可能是因为评测基准 (Benchmarks) 侧重的方面（例如代码生成、补全）和开发者实际工作流中更看重的方面（例如复杂逻辑理解、Debug、项目级代码理解）存在差异。基准测试高分不一定等于实际开发体验好。需要特定的“启动咒语”？ 有些模型需要非常精巧的 Prompt Engineering 才能发挥最佳性能。也许下载版的 Llama 4 需要特定的提示技巧，而这些技巧并未在发布时充分说明？四、总结本次Llama 4系列发布充斥着仓促气息。尽管Meta带来了技术上的诸多更新，如首次在自己的旗舰模型中采用MoE架构、实现原生多模态早期融合、通过iRoPE架构将上下文窗口推向千万级别等，但与Llama 2、Llama 3发布时那种“开源之光”技惊四座、甚至在某些方面引领潮流的感觉相比，Llama 4更像是一次快速整合与追赶。从技术创新角度看，Llama 4的核心亮点大多是对行业现有SOTA（State-of-the-Art）方向的跟进和优化，而非开创性的突破。全面转向MoE是对DeepSeek、Mistral等先行者的追随；原生多模态是业界标配；超长上下文虽有工程创新（iRoPE），但方向本身也是Gemini、月之暗面、Qwen等早已布局的领域；训练和后训练技术（FP8、MetaP、RL/DPO流程优化、蒸馏）更多是渐进式改进和工程能力的体现。相比之下，一些竞品在注意力机制（如MoBA、NSA、Lighting Attention）或RL方法（如DeepSeek R1）上展现出的探索性更强。Llama 4给人的感觉是，Meta利用其强大的工程和算力资源，将现有“配方”快速组合并推向了新的规模，目的是先跟上第一梯队，弥补之前（如坚持Dense模型）的战略判断。在性能与市场反响方面，虽然Scout和Maverick在基准测试上表现亮眼，甚至在特定指标上超越了GPT-4o等强力对手，但并未带来革命性的体验代差。更重要的是，发布后社区迅速出现的“货不对板”的质疑声浪——开发者反映实际下载的模型在编码、写作等方面的能力远不如LMArena竞技场版本——给这次发布蒙上了一层阴影。这种体验上的脱节，无论源于版本差异、特定配置要求还是评测方法的局限，都削弱了Llama 4本应带来的冲击力，并加剧了其“仓促发布”的印象。从战略和时机来看，Llama 4的发布也显得有些微妙。全面拥抱MoE更像是对先前路线的一次“纠错”。选择在周末发布，以及竞争对手（如Gemini研究员、千问负责人）在社交媒体上颇具玩味的调侃，都指向一种可能性：Meta或许是为了避开下周可能出现的更强竞品（传闻中的DeepSeek、Qwen、DeepMind新模型），而选择抢先发声。这与Llama 3时期作为领先者的自信姿态形成了鲜明对比。同时，在行业对推理模型和AI Agent需求高涨的背景下，Llama 4并未优先推出此类模型，也未发布能在本地轻松运行的小尺寸版本，这让部分开发者感到失望。总而言之，Llama 4的发布无疑巩固了Meta作为AI顶级玩家的地位，它依然是开源社区一个强大的新选择，特别是在理论性能和某些特定能力（如超长上下文）上设立了新标杆。然而，这次发布更像是一次防御性和追赶性的迭代，是Meta在快速变化的市场格局中，为稳住阵脚、跟上步伐而进行的一次必要但略显仓促的技术整合与“秀肌肉”（尤其是通过Behemoth的训练规模）。其“追赶”的意味强于“引领”。真正的考验，或许在于尚未完全亮相的Behemoth能否真正兑现其超越GPT-4.5等的承诺，以及Meta如何有效回应社区反馈、弥合基准与实际体验的鸿沟。从曾经的开源领跑者到如今奋力追赶的身影，Meta AI未来的道路依然充满挑战。参见[1] Meta官方关于 Llama 4 发布的技术博客[2] 量子位：LIama 4发布重夺开源第一！DeepSeek同等代码能力但参数减一半，一张H100就能跑，还有两万亿参数超大杯[3] 机器之心：Meta深夜开源Llama 4！首次采用MoE，惊人千万token上下文，竞技场超越DeepSeek[4] 硅星人Pro：1000万上下文+2880亿参数的Llama4，却让DeepSeek们松了一口气"
  },
  {
    "title": "人类简史书评&笔记：想象的共同体",
    "summary": "前言尤瓦尔·赫拉利的《人类简史：从动物到上帝》（Sapiens: A Brief History of Humankind）和我之前看过所有的“简史”类书籍的内容编排都不太一样。赫拉利并未简单罗列历史事件并加上一点评价，而是试图探寻一个根本性问题：智人（Homo sapiens）究竟是如何从非洲草原上一种无足轻重的动物，一步步崛起为地球的主宰？作者在书中提出了一个极具颠覆性也极富解释力的核心论点（",
    "tags": [
      "书评"
    ],
    "url": "/posts/HumanSciences/book-review-History-of-Humankind/",
    "date": "2025-04-04T00:00:00.000Z",
    "content": "前言尤瓦尔·赫拉利的《人类简史：从动物到上帝》（Sapiens: A Brief History of Humankind）和我之前看过所有的“简史”类书籍的内容编排都不太一样。赫拉利并未简单罗列历史事件并加上一点评价，而是试图探寻一个根本性问题：智人（Homo sapiens）究竟是如何从非洲草原上一种无足轻重的动物，一步步崛起为地球的主宰？作者在书中提出了一个极具颠覆性也极富解释力的核心论点（至少在刚出书那会确实很具颠覆力）：认知革命（Cognitive Revolution）赋予了智人一种独特的能力——创造并相信“虚构的故事”（fictions）或“共同的想象”（collective imagination）。不同于其他动物只能描述客观现实（如“河边有狮子”），智人能够谈论并相信那些不存在于物理世界中的事物，例如神祇、国家、民族、法律、金钱、公司乃至人权等抽象概念。正是这些基于“共同想象”构建起来的“想象的现实”（imagined realities），成为了人类社会大规模、灵活协作的基石。它使得素不相识的个体能够超越血缘、地域的限制，为了共同的目标（无论这个目标是建造金字塔、参与十字军东征，还是维护现代民族国家或跨国公司）而有效合作。从人类学和社会学的视角审视，赫拉利的这一论述与社会构建理论深度契合，并与本尼迪克特·安德森（Benedict Anderson）在其经典著作中提出的“想象的共同体”（Imagined Communities）概念产生了强烈的共鸣。安德森主要探讨现代民族主义的文化根源，认为民族是一种“想象的政治共同体”——其成员素未谋面，但内心却共享着一种同属一体的深刻联结感。当然，我在这里并不想把人家的书重新打散然后誊录在博客中，我会选取其中几段特别喜欢的观点来进行讨论，借由赫拉利提供的宏大叙事框架，聚焦于“共同想象”这一核心机制，并结合“想象的共同体”这一视角，深入探讨我们赖以生存的社会秩序、文化认同乃至经济体系，其根基在多大程度上是建立在这些共享的“虚构故事”之上。摘录1.社会建构主义通过文字创造出想象的现实，就能让大批互不相识的人有效合作，而且效果还不只如此。正由于大规模的人类合作是以虚构的故事作为基础，只要改变所讲的故事，就能改变人类合作的方式。只要在对的情境之下，这些故事就能迅速改变。例如在1789年，法国人几乎是在一夕之间，相信的故事就从“天赋君权”转成“人民做主”。因此，自从认知革命之后，智人就能依据不断变化的需求迅速调整行为。这等于开启了一条采用“文化演化”的快速道路，而不再停留在“基因演化”这条总是堵车的道路上。走上这条快速道路之后，智人合作的能力一日千里，很快就远远甩掉了其他所有人类和动物物种。这段其实和社会建构主义的基本观点非常类似，即我们所认识的“现实”在很大程度上是由社会成员通过互动和共享的意义体系共同构建出来的，而非仅仅是客观物理世界的反映。像“国家”、“法律”、“人权”甚至“金钱”的价值，都不是自然固有的属性，而是人类通过语言、符号（文字是其中最强大的形式之一）和持续的社会实践赋予其意义和力量的“社会事实”（social facts，借用涂尔干的概念）。赫拉利强调这些“虚构的故事”是大规模合作的基础，这正是社会建构论所指出的，共享的意义系统使得复杂的社会互动和组织成为可能。法国社会学家埃米尔·涂尔干（Émile Durkheim）提出的“集体意识”或“集体表象”概念指的是社会成员共享的信念、道德观念和态度，它们作为一种独立于个体的力量存在并对个体行为产生约束或引导，从而促进社会整合（social integration）和团结（solidarity）。正是因为共享了关于“民族”、“上帝”或“公司使命”的故事，原本陌生的人们才能感受到一种归属感，并为了共同的目标而协作。:::note\n这就是一种共同体叙事。我们人类是社会动物，从出生开始就在不断地加入/退出各种社会意义上的共同体。\n:::赫拉利将基于“故事”的合作能力视为“文化演化”的快速通道，与缓慢的“基因演化”形成对比。这在社会学上强调了文化（特别是符号、语言和共享叙事）在人类社会发展中的极端重要性。与生物学限制不同，文化具有高度的可塑性和传播性。新的“故事”（技术、规范、信仰、组织形式）可以通过学习和交流迅速传播和修改，使得人类社会能够以远超基因变异和自然选择的速度来适应环境、解决问题和重塑自身。这解释了人类社会形态多样性和历史变迁速度的独特性。2.叙事共识今天之所以能有全球贸易网络，正是因为我们相信着一些虚拟实体，像美元、联邦储备银行，还有企业的商标。而在部落社会里，如果两个陌生人想要交易，往往也得先借助共同的神明、传说中的祖先或图腾动物建立信任。“虚拟实体”作为经济信任的基石现代法定货币（Fiat Money）本身没有内在价值（不像黄金），其价值完全来自于集体信念——相信政府会接受它作为税款，相信他人会接受它用于支付，相信中央银行（如美联储）会维持其购买力（尽管这常常受到挑战）。美元之所以成为全球贸易的主要媒介，是因为足够多的人和机构相信它的稳定性和可接受性。这种信念是一种强大的“想象的现实”，是全球经济交换的基础设施。中央银行、商业银行、监管机构等是现代金融体系的核心。它们的运作依赖于公众对其权威性、偿付能力和履行职责能力的信任。例如，人们相信存在银行的钱是安全的（部分因为有存款保险，这本身也是一种制度化的承诺/故事），相信中央银行能够调节经济。这种对机构的信任，是信贷创造、支付系统运行和金融市场稳定的前提。当这种信任崩溃时（如2008年金融危机期间对某些机构的信任危机），系统就会失灵。在经济学中，品牌代表着声誉资本（Reputational Capital）。消费者购买带有特定商标的商品，不仅仅是购买物理产品，更是购买一种承诺——关于质量、服务或某种体验的承诺。这种承诺（故事）是通过广告、过往经验和社会认同建立起来的。强大的品牌能够降低消费者的信息搜寻成本，并允许公司收取品牌溢价。这本质上是消费者相信该品牌会兑现其隐含或明确的承诺。这种信任具有巨大的经济价值（品牌价值）。许多“虚拟实体”（尤其是货币和某些平台型企业）具有网络效应。越多人使用美元，美元作为交易媒介就越有用，这反过来又吸引更多人使用它。这种正反馈循环强化了最初的信念。这表明，“想象的现实”一旦建立并被广泛接受，往往会具有自我维持和强化的力量。信任作为交易成本的降低机制经济学（特别是新制度经济学）强调交易成本的重要性。在一个缺乏信任的世界里，每次交易都需要复杂的验证、担保和监督，成本极高。赫拉利提到的“共同的神明、传说中的祖先或图腾动物”在部落社会中起到的作用，与现代社会的法律、货币和品牌类似：它们提供了一个共享的参照框架，降低了陌生人之间建立信任的成本，从而促进了交换和合作。无论是古代的宗教/神话体系，还是现代的货币/法律/品牌体系，它们都通过创造一种可预测性和共同的理解基础，极大地降低了交易的不确定性和风险，使得大规模、复杂的经济活动成为可能。金融的本质——基于未来的想象和承诺金融尤其依赖于“想象的现实”。贷款是基于对借款人未来偿还能力的信任。股票代表着对公司未来盈利能力的预期（故事）。保险是基于对未来风险分担的集体协议。衍生品等复杂金融工具更是建立在对未来价格变动或其他指标的抽象预期之上。整个金融体系可以说是一个巨大的、基于对未来的“虚构故事”（预测、承诺、合约）进行定价和交易的系统。当足够多的人相信某个关于未来的故事（例如，某个科技概念的潜力），资本就会流向那里，推动现实世界的发展，这正是“想象”塑造“现实”的体现。3.农业革命人口、剩余产品与可治理性对于那个营养不良的中国汉代女孩或者所有农民来说，小麦究竟给了他们什么？对于个人来说，小麦根本算不上给了什么。但对于智人这个物种整体来说，小麦的影响就十分深远。种植小麦，每单位土地就能提供更多食物，于是智人的数量也呈指数成长。大约在公元前13000年，人类还靠采集和狩猎为生的时候，巴勒斯坦的杰里科(Jericho)绿洲一带，大概可以养活一个有百名成员的采集部落，而且人们相对健康、营养充足。到了大约公元前8500年，野生植物的荒野成了片片麦田，这片绿洲这时养活了约有千人的农村，但人口密度也因此增大，而且成员染病及营养不良的情形要比过去严重太多。\n这正是农业革命真正的本质：让更多的人以更糟的状况活下去。政治学的核心关注点之一是权力的产生、分配和维持。农业革命带来的生产力飞跃为更大规模的政治实体奠定了基础。虽然个体生活质量下降，但单位土地供养人口的绝对数量急剧增加。在冷酷的权力计算中，人口数量本身就是一种力量——更多的劳动力、更多的潜在士兵、更大的税基。杰里科从百人部落到千人农村的转变，意味着潜在的社会复杂性和权力集中的可能性大大增加。控制更多的人口和他们生产的粮食，是早期政治权力（无论是酋邦还是早期国家）形成和扩张的物质基础。尽管个体农民营养不良，但农业定居产生了（或至少是更容易集中管理）粮食剩余。这个剩余，无论多么微薄，是政治学意义上的关键。它使得一部分人可以脱离直接的食物生产，从事专门化的活动——统治、管理、祭祀、军事。这直接导致了社会分层（Social Stratification）和政治等级（Political Hierarchy）的出现。营养不良的农民，正是以其被剥削的剩余价值（以粮食形式），供养了新兴的政治、宗教和军事精英。因此，“更糟的状况”不仅是营养问题，更是政治经济地位急剧下降的体现，他们成为了被统治和被榨取的阶级。从定居化与可治理性（Governability）角度观察，农业迫使人类定居。与流动性强的狩猎采集者相比，定居的农民更容易被定位、登记、征税、征兵和控制。土地成为最重要的生产资料，也成为权力控制的焦点。对土地的控制（所有权、分配权）成为政治权力的核心。定居社会使得建立持久的政治结构、官僚体系和强制性权力（如法律、军队）成为可能，甚至可以说是必需的。从政治控制的角度看，农业革命极大提升了人口的“可治理性”。集体利益与个人代价“让更多的人以更糟的状况活下去”描述了一种常见的政治困境，为了某个“集体”（在这里是“智人”这个物种，但更容易代入的是“国家”、“民族”或统治集团）的“成功”（生存、扩张、强大），可以牺牲（或“被牺牲”）个体的利益和福祉。政治决策，尤其是在资源稀缺或面临外部竞争的早期社会，常常需要在集体生存/扩张与个体生活质量之间做出残酷的权衡。农业革命的案例表明，历史的选择往往倾向于前者，因为它最终导致了能够组织更大规模力量的社会形态胜出。人口密度增加、资源（土地、水）重要性提升、社会分层、管理剩余产品的需要——正是早期国家形成理论（State Formation Theories）所关注的关键驱动因素。人口压力、内部冲突（因资源和不平等加剧）、管理复杂灌溉系统或防御的需求等，都推动了更强大、更集权的政治组织的出现。农民的“苦难”可以被视为构建和维持这些早期政治结构所付出的社会成本。总结一下，农业革命的核心在于：它创造了更大规模、更易控制的人口基础。它通过剩余产品的产生和集中，催生了社会分层和政治精英。它通过定居化，极大地增强了人口的可治理性，为持久政治权力的建立提供了条件。它体现了集体（物种/国家/统治集团）扩张逻辑往往以牺牲个体福祉为代价这一残酷的政治现实。它为国家的最终形成准备了必要的人口、经济和社会条件。4.文字与科层制一个帝国要运作，会产生大量的信息。除了法律之外，帝国还必须记录各种交易和税收、军用物资和商品的库存量，还有各种节庆及打胜仗的日期。在先前的几百万年间，人类只有一个地方可以记录信息：他们的大脑。但很遗憾，对于整个帝国这么大的数据量来说，人类的大脑并不是个很好的储存设备。信息是治理的血液，规模呼唤技术社会规模的扩大（从部落到帝国）会带来治理复杂性的急剧增加。有效的治理依赖于对社会状态的准确把握和对规则的一致执行。无论是征税、维持法律秩序、组织大型工程（如军事后勤），还是进行资源分配，都需要大量、准确、可追溯的信息。没有这些信息，治理将变得盲目、低效且不公平。早期原始社会将人脑作为唯一的存储器，直接构成了早期社会治理能力的“天花板”。人脑记忆的有限性、易错性、主观性以及个体死亡导致的信息丢失，严重限制了治理的范围、精细度和持续性。信息在口耳相传中容易产生“噪声”（失真），且难以进行大规模、并行的处理和检索。一个仅靠口传和个人记忆来运行的“帝国规模”的治理体系是不可想象的，它会迅速因信息过载、失真和遗忘而崩溃。因此，社会规模的扩大催生了信息处理技术的突破（如文字、计数系统、档案管理）。文字和书写系统的发明，可以被视为信息存储技术的一次革命性突破。它极大地扩展了信息的存储容量（几乎无限）、持久性（超越个体生命）、保真度（减少失真）和可访问性（允许异步、多人访问）。这从根本上改变了人类社会处理和利用信息的能力，为更复杂的社会组织形式（如帝国）的涌现和稳定运作提供了信息论基础。外部信息存储系统的发明，是人类社会能够超越小型熟人社会，发展出大规模、非人格化治理结构（如帝国）的关键技术前提。它使得治理决策可以基于更广泛、更持久的数据，规则可以被标准化和普及化。科层制（Bureaucracy）角度：文书工作的起源与理性化的基石马克斯·韦伯（Max Weber）提出了理想科层制模型，其核心特征之一就是基于书面文件（written documents）的规则和程序。科层制追求效率、可预测性和非人格化，而这一切都高度依赖于系统化的信息记录、传递和存档。帝国运作所需记录的法律、税收、库存、历史事件等，正是科层制官僚体系需要处理的核心信息。没有可靠的记录系统（即书面文件），就不可能有标准化的程序、明确的权责划分、基于规则的决策，也就无法实现韦伯意义上的理性化（Rationalization）管理。可以说，克服人脑的生物学限制，通过技术手段（文字、书写、档案）实现信息的外部化、标准化和持久化，是科层制这种高效（尽管有时显得僵化）的社会组织形式得以产生和发展的关键一步。5.文明无正义以上所有的区别，不管是自由人/奴隶、白人/黑人、富人/穷人，都只是虚构的想象所构建出来的。然而历史的铁则告诉我们，每一种由想象建构出来的的秩序，都绝不会承认自己处于想象和虚构，而大谈自己是自然、必然的结果。社会建构与政治权力政治学认识到，许多被视为“自然”的社会分类和等级制度，实际上是特定历史和社会背景下，通过权力运作、法律制定、文化传播和日常实践共同建构起来的。这些分类并非基于客观生物学或物理现实（例如，“种族”的生物学基础极其薄弱，“阶级”更多是经济和社会关系的产物），而是服务于特定政治和经济利益的社会定义。权力关系决定了哪些“想象”能够成为主导，并被制度化。政治秩序为了维持稳定和获得民众的顺从（而不仅仅依赖赤裸裸的强制），需要合法性。将现存的权力结构、社会分层和资源分配描绘成“自然的”、“不可避免的”、“神授的”或“基于优胜劣汰的”，是意识形态进行合法化论证的经典策略。通过自然化（Naturalization），人为的、可变的社会安排被去政治化（depoliticized），看起来像是不可更改的现实，从而削弱了对其提出质疑和挑战的可能性。区分“我们”与“他们”（无论基于阶级、种族还是国籍）是政治动员和身份认同构建的常用手段。等级制度可能被视为一种（尽管常常是残酷且低效的）社会分工和资源分配的方式。这种视角并不否认其“虚构”性，但更关注其在维持特定政治和社会系统运转中的实际功能。霸权（Hegemony）的运作与解构安东尼奥·葛兰西（Antonio Gramsci）的霸权理论对此有深刻阐述。霸权不仅仅是通过强制（警察、军队）来统治，更是通过文化和意识形态领导权，让被统治阶级自愿地接受统治阶级的价值观和世界观，认为现存秩序是合理的、符合“常识”的。赫拉利所说的“大谈自己是自然、必然的结果”，正是霸权运作的体现——将特定的、服务于统治集团利益的“虚构想象”塑造成普遍接受的真理和规范。认识到秩序的“虚构”基础，也揭示了其潜在的脆弱性。既然秩序是建构的，那么它也是可以被解构和重建的。政治斗争在很大程度上就是围绕着定义现实、争夺叙事权展开的。挑战现有秩序的力量，往往需要首先揭示其“虚构”本质，打破其“自然”、“必然”的神话，提出替代性的“想象”和秩序蓝图（例如，从“天赋君权”到“人民主权”的转变）。然而，正如“历史的铁则”所言，维护秩序的力量会极力掩盖其建构性，将挑战者斥为“颠覆自然的”、“不切实际的”或“破坏秩序的”，这本身也是政治权力自我防御的重要手段。6.宗教公元前的1000年间，出现了三种有可能达到“世界一家”概念的秩序，相信这些秩序，就有可能相信全球的人类都“在一起”，都由同一套规则管辖，让所有人类都成为“我们”（至少有这个可能），“他们”也就不复存在。这三种全球秩序，首先第一种是经济上的货币秩序，第二种是政治上的帝国秩序，而第三种则是宗教上的全球性宗教，比如佛教、基督教和伊斯兰教。\n……\n我们今天常认为宗教造成的是歧视、争端、分裂，但在金钱和帝国之外，宗教正是第三种让人类统一的力量。\n……\n因此，我们可以说宗教是“一种人类规范及价值观的系统，建立在超人类的秩序之上”。这里有两大基本要素：\n1.宗教认为世界上有一种超人类的秩序\n……\n2.以这种超人类的秩序为基础，宗教会发展出它认为具有约束力的规范和价值观。\n……\n某个宗教如果想要将幅员广阔、族群各异的人群都收归旗下，就还必须具备另外两种特质。第一，它信奉的超人类秩序必须普世皆同，不论时空而永恒为真。第二，它还必须坚定地将这种信念传播给大众。换句话说，宗教必须同时具备“普世特质”和“推广特质”。功能主义视角下的宗教角色宗教作为一种意识形态工具，它能够超越地域、血缘和既有的政治边界，构建更大规模的“想象的共同体”。与帝国依靠强制力、货币依靠交换需求不同，宗教通过提供一套共享的终极意义系统、世界观和道德规范，实现了对多元人群的文化整合与社会动员。统治者（无论是帝国君主还是后来的民族国家领袖）常常利用或与宗教力量合作，以神圣化其统治（Legitimation），并为社会提供凝聚力（Cohesion），从而降低治理成本，增强集体行动能力（例如，宗教名义下的战争或大型工程）。从宗教学的视角看，赫拉利对宗教的定义（基于超人类秩序的规范和价值观系统）抓住了宗教的核心特征之一——提供超越经验世界的终极实在（Ultimate Reality）作为一切规范和价值的来源。这赋予了宗教规范一种绝对性和神圣性，使其比世俗法律或习俗更具约束力和动员力。“普世特质”和“推广特质”确实是区分“世界宗教”（World Religions）与地方性/民族性宗教的关键特征，解释了它们为何能跨文化、跨地域传播。超人类秩序强调“超人类秩序”是宗教规范的基础，这在政治上极其重要。它意味着宗教所设定的规则和价值不容置疑、不容协商、超越了人类自身的立法权。这为宗教权威（教士、神学家等）或借用宗教权威的世俗统治者提供了巨大的权力。它可以用来合理化现存的社会等级和不平等（如神权统治、种姓制度），也可以用来颠覆现有秩序（如宗教改革、革命运动）。将秩序的根基置于“超人类”，实质上是将其排除在人类理性的批判和政治的讨价还价之外，这既是其力量所在，也是其潜在危险所在。正是因为宗教建立在特定的“超人类秩序”之上，并声称其“普世皆同”、“永恒为真”，它必然会界定出“异教徒”、“不信者”或“异端”。这种基于信仰的“我们”与“他们”的划分，历史上一直是剧烈冲突、歧视和战争的根源。宗教的“推广特质”在实践中，往往伴随着文化征服、强制改宗甚至暴力。因此，宗教在统一一部分人类的同时，也深刻地、有时是血腥地分裂了另一部分人类。这种内在张力是政治学分析宗教时不可或缺的一环。7.一神论从历史上来看，一神论就像是个万花筒，把一神论、二元论、多神论和泛灵论，收纳在同一个神圣论述之下。结果就是，基督徒大致上是信奉一神论的上帝，相信二元论的魔鬼，崇拜多神论的圣人，还相信泛灵论的鬼魂。像这样同时有着不同甚至矛盾的思想，而又结合各种不同来源的仪式和做法，宗教学上有一个特别的名称：综摄(syncretism)。很有可能，综摄才是全球最大的单一宗教。综摄指的是不同宗教信仰、文化习俗、象征符号的融合与并存。宗教学研究表明，综摄几乎是所有宗教在历史发展和跨文化传播过程中的常态，而非例外。很少有宗教是以“纯粹”形态诞生并保持不变的。它们总是在与所处环境的文化、先前存在的信仰体系互动中，吸收、改造、融合各种元素。魔鬼：在基督教神学中，魔鬼通常被视为堕落天使，是上帝创造物的一部分，其力量最终受上帝掌控，因此理论上不构成与上帝对等的二元力量，尽管在信徒感受和某些神学流派中其力量可能被极度强调。圣徒：官方教义强调圣徒是“代祷者”（intercessors），信徒是“敬礼”（veneration）而非“崇拜”（worship，专指对上帝），以此区别于多神论。当然，实践中这条界线常常模糊。鬼魂/灵魂：对灵魂不朽的信仰和对特定鬼魂存在的民间信念，在神学上也会被置于上帝最终审判和掌控的框架内。宗教学会关注这些内部的解释机制如何运作，以及它们在多大程度上成功地维持了官方教义与大众实践之间的张力。:::note\n自有大儒为我辩经！\n:::8.混沌的历史历史的铁则就是：事后看来无可避免的事，在当时看来总是毫不明显。\n直到今天，情况仍是如此。我们已经走出全球经济危机了吗？还是前面还有更大的打击？中国会不会继续发展、成为全球第一的超级大国？美国会不会丧失霸主地位？一神论基本教义派是会成为全球未来的风潮，又或不过是地方的小骚动，在未来不值一哂？我们走向的是生态的灾难还是科技的天堂？以上所有结果背后都有一套很完整的论述，但我们就是无法确定何者将成真。但如果过了几十年后再回顾，我们就会觉得答案真是太明显了。\n……\n对于许多希望看到历史必然性的人来说，这种说法大概有些令人失望。毕竟，宿命论吸引人的地方，就在于觉得这个世界和我们的信念都是历史上自然且必然的产物。于是，我们似乎是自然而然就发展出民族国家，自然而然就遵循着资本主义经济原则，也是自然而然地坚信着人权的概念。如果承认历史并非必然，等于是承认了现在的民族主义、资本主义和人权都只是巧合的产物。不仅如此，历史还是所谓的“二级”混沌系统。混沌系统分成两级，一级混沌指的是“不会因为预测而改变”。例如天气就属于一级混沌系统。虽然天气也是受到无数因素影响，但我们可以建立计算模型，不断加入越来越多因素，让天气预报也越来越准确。\n至于二级混沌系统，指的是“会受到预测的影响而改变”，因此就永远无法准确预测。例如市场就属于二级混沌系统。假设我们开发出了一个计算机程序，能够完全准确预测明天的油价，情况会如何？可以想见，油价会立刻因应这个预测而波动，最后也就不可能符合预测。对于历史决定论的批判这段主要是对历史决定论的批判，作者明确反对历史决定论——即认为历史发展遵循某种预定轨迹或铁律，最终导向特定结果（如某些马克思主义的简化解读、辉格史观等）。赫拉利强调“事后看来无可避免的事，在当时看来总是毫不明显”，精准地指出了后见之明偏误 （Hindsight Bias）在历史叙述中的普遍性。这种批判非常重要，因为它解放了我们对过去的理解和对未来的想象。承认历史的偶然性（Contingency）意味着承认我们当前的社会结构、政治体制、经济模式（民族国家、资本主义、人权）并非“自然”或“必然”的终点，而是特定历史路径、选择和斗争的结果。这为批判性地审视现状和探索替代性未来打开了空间。:::note\n虽然强调偶然性很重要，但将民族国家、资本主义、人权简单归为“巧合”可能略显轻率。它们是复杂的历史进程的结果，涉及结构性因素、权力斗争、思想演变和社会运动等，并非完全随机。用“非必然”（Not Inevitable）或“路径依赖”（Path Dependent）可能比“巧合”更精确地描述其历史地位。\n:::混沌系统一级混沌（如天气）虽复杂，但系统本身不受预测行为的影响。二级混沌（如市场、历史）则具有反身性（Reflexivity）：对系统的预测会成为系统的一部分，从而改变系统的行为，最终可能使预测失效。人类的行为会因为知晓预测、预期或理论而改变。例如，如果广泛预测某股票会涨，人们会蜂拥购买，导致价格提前上涨甚至形成泡沫，最终可能偏离“基本面”预测；如果预测某社会运动会成功，可能吸引更多参与者，但也可能引发当局更强力的镇压，改变结果。社会科学的目标可能不应是追求像自然科学那样的精准预测，而更多在于理解机制、揭示模式、识别可能性、评估风险，并认识到人类行动者本身对历史进程的塑造作用。:::note\n过度强调混沌和偶然性，有时可能忽略结构性力量（如地理、技术水平、长期经济趋势、文化传统）对历史发展的约束和塑造作用。历史并非完全开放，行动者的选择总是在一定的结构限制内进行的。\n虽然精准的长期预测不可能，但基于对结构、趋势和机制的理解，进行中短期预测、情景规划或风险评估仍然是可能且有意义的。二级混沌系统并非意味着完全不可知，只是预测的性质和界限不同。\n:::挑战宏大叙事的舒适区赫拉利指出了“宿命论”或历史必然性叙事的心理吸引力——它提供了一种秩序感、意义感和安全感，让我们觉得所处的世界和所信奉的价值是稳固和天经地义的。承认偶然性则可能令人不安，因为它意味着我们所珍视的制度和价值（如人权）并非永恒真理，而是“巧合的产物”（或许用“历史建构的产物”更准确，以包含其中的人类努力和斗争）。这可能会削弱它们的绝对权威性，但也可能促使我们更积极地去维护、完善和重新论证它们的价值，而不是将其视为理所当然。列举当前面临的重大不确定性（经济、地缘政治、意识形态、科技/环境），强调我们无法确知未来走向，这与历史的混沌特性论述一脉相承。这是一种智识上的诚实，反对廉价的预言和简单的线性外推。总结与反思我们这一代人或许以往任何世代都更直观地生活在由各种“故事”构建的现实中。从社交媒体上精心塑造的个人形象与社群认同，到全球化浪潮下民族国家身份的微妙变迁，再到对加密货币等新兴“虚拟实体”价值的集体信念博弈，我们所珍视的价值观、我们所归属的群体、我们所参与的社会经济体系，其根基在多大程度上依赖于这些共享的、有时甚至未经审视的“想象”？作为不断变化的“故事”的继承者和参与者，我们有责任去审辨、去质疑，甚至去重塑那些驱动我们社会运转、定义我们身份认同的“想象的共同体”叙事，为我们期望的未来注入新的、更具包容性和正义性的意义。——写于风浪之中，Windsurf依然划得飞快。"
  },
  {
    "title": "一份关于美联储的报告（下）：政策工具箱与宏观经济指标的运作逻辑",
    "summary": "上一期我们简单介绍了下美联储的基本结构和目标，本期来梳理美联储的常规货币政策工具和非常规货币政策工具。美联储作为美国的中央银行，肩负着国会赋予的双重使命：促进最大就业和维持物价稳定，还致力于维持适度的长利率水平。为了实现这些宏观经济目标，美联储会运用一系列货币政策工具来影响经济中的信贷成本和可获得性，进而调控总需求、就业与通货膨胀。传统上，这些工具主要围绕着调控银行体系内的准备金数量和联邦基金利率",
    "tags": [
      "暗涌"
    ],
    "url": "/posts/Finance and Economics/fed-report-02/",
    "date": "2025-04-02T00:00:00.000Z",
    "content": "上一期我们简单介绍了下美联储的基本结构和目标，本期来梳理美联储的常规货币政策工具和非常规货币政策工具。美联储作为美国的中央银行，肩负着国会赋予的双重使命：促进最大就业和维持物价稳定，还致力于维持适度的长利率水平。为了实现这些宏观经济目标，美联储会运用一系列货币政策工具来影响经济中的信贷成本和可获得性，进而调控总需求、就业与通货膨胀。传统上，这些工具主要围绕着调控银行体系内的准备金数量和联邦基金利率（Federal Funds Rate）——即存款机构之间相互借贷准备金余额（主要是在美联储持有的余额）的隔夜利率。本章将详细阐述美联储在实践中长期依赖的三大常规货币政策工具：公开市场操作（Open Market Operations, OMOs）、贴现窗口贷款（Discount Window Lending）与法定存款准备金要求（Reserve Requirements）。虽然金融环境和美联储的操作框架已随时间演变，特别是在2008年全球金融危机之后，但理解这些常规工具的机制对于把握美联储政策的基石及其后续演进至关重要。:::note\n如未说明，本文中所有的图像都是4o画的\n:::一、美联储常规货币政策工具基础概念：联邦基金利率 (The Federal Funds Rate)联邦基金利率是理解美联储常规货币政策传导机制的核心基石。它是美国存款机构（如商业银行、储蓄机构、信用合作社等）之间相互借贷其在美联储持有的准备金余额（Reserve Balances）的隔夜、无担保利率。联邦基金市场是一个银行间市场。每天，由于客户提款、存款、贷款发放、证券交易以及清算支付等活动，各家银行在美联储的准备金账户余额会发生变动。一些银行可能发现其准备金余额低于法定要求（在历史上要求存在时）或低于其自身流动性管理的期望水平，而另一些银行则可能持有超出需求的超额准备金。联邦基金市场允许持有过剩准备金的银行将其借给需要补充准备金的银行，通常借款期限为隔夜。联邦基金利率本质上是一个市场利率，由准备金的供求关系决定。当准备金供应相对稀缺时，借入成本上升，利率趋于上行；当准备金供应充足时，借入成本下降，利率趋于下行。 尽管联邦基金利率由市场决定，但美联储通过其货币政策工具（主要是公开市场操作）来影响准备金的整体供应量，从而将其引导至联邦公开市场委员会（FOMC）设定的目标水平或目标区间。FOMC会定期宣布其政策决议，其中最重要的就是联邦基金利率的目标。这个目标利率是美联储向公众和市场传达其货币政策立场的主要信号。形象一点说就是大家签了一个协议，谁家碰到困难大家凑一块接济下，别干出来挤兑风险了为什么这个指标非常重要呢？因为联邦基金利率是美国货币市场利率体系的基础利率。它的变动会迅速传导至其他短期利率，如欧洲美元利率、短期国库券利率、商业票据利率、回购利率等。进而，这些短期利率的变化会影响到长期利率（如抵押贷款利率、公司债券利率）、银行贷款利率、汇率以及资产价格。通过这一系列传导途径，联邦基金利率的调整最终影响到更广泛的经济活动，包括企业的投资决策、家庭的消费支出，从而作用于就业和通货膨胀，实现美联储的政策目标。市场上实际成交的联邦基金利率并非单一数值，而是一个有利率分布的交易集合。美联储通常关注并公布有效联邦基金利率（EFFR），这是根据联邦基金市场实际隔夜交易计算出的成交量加权中位数利率。美联储货币政策操作的目标，尤其是在传统框架下，就是使EFFR尽可能接近FOMC设定的目标利率。因此，对联邦基金利率的定义、决定机制及其在货币政策传导中的核心地位的理解，是深入探讨后续常规货币政策工具如何运作的前提。1.公开市场操作（Open Market Operations, OMOs）历史上，公开市场操作是美联储最常用、最灵活且最有效的货币政策工具，由联邦公开市场委员会（Federal Open Market Committee, FOMC）负责决策和指导。其核心在于通过在公开市场上买卖美国政府证券（主要是国库券、国库票据和国库债券）来调整银行体系的准备金总量，从而影响联邦基金利率。在传统的“稀缺准备金”（Scarce Reserves）操作框架下，公开市场操作是精确调控联邦基金利率至目标水平的关键。通过频繁、小规模的调整准备金供应，美联储能够有效地引导市场利率。原理机制扩张性操作（购买证券）：当美联储希望降低联邦基金利率或增加货币供应量时，它会从一级交易商（Primary Dealers）手中购买政府证券。美联储通过贷记这些交易商在美联储的账户（或其结算银行的账户）来支付购买款项。这直接增加了银行体系的总准备金水平。准备金供应增加，使得银行更容易满足其准备金要求或进行隔夜拆借，从而倾向于降低联邦基金利率。较低的联邦基金利率会通过金融市场传导至其他短期利率，并可能影响长期利率、汇率以及更广泛的信贷条件，刺激投资和消费。紧缩性操作（出售证券）：相反，当美联储希望提高联邦基金利率或减少货币供应量时，它会向一级交易商出售政府证券。交易商支付购买款项，导致其在美联储的账户余额减少，从而减少了银行体系的总准备金。准备金供应减少，使得银行间借贷成本上升，推动联邦基金利率上行。这会相应收紧信贷条件，抑制经济过热和通胀压力。操作类型永久性公开市场操作（Permanent OMOs）： 指直接买入或卖出证券，旨在长期性地改变美联储资产负债表规模和银行准备金水平，以适应经济增长对货币基础的结构性需求或实现长期的政策目标。临时性公开市场操作（Temporary OMOs）： 主要通过回购协议（Repurchase Agreements, Repos）和逆回购协议（Reverse Repurchase Agreements, Reverse Repos）进行。回购协议指的是美联储购买证券，并约定在未来特定日期将证券卖回给交易对手。这暂时性地向银行体系注入准备金和流动性。逆回购协议指的是 美联储出售证券，并约定在未来特定日期回购该证券，这暂时性地从银行体系抽离准备金和流动性。临时性操作主要用于应对准备金市场的短期波动，平滑联邦基金利率，确保其保持在FOMC设定的目标区间内。2.贴现窗口与贴现率 (The Discount Window and the Discount Rate)贴现窗口是美联储向符合条件的存款机构提供贷款的机制。这些贷款通常是隔夜的，旨在满足机构短期的流动性需求，或在面临财务压力时提供紧急资金支持。美联储对这些贷款收取的利率被称为贴现率（Discount Rate），由各联邦储备银行的董事会提议，并经联邦储备理事会（Board of Governors）批准设定。机制原理贴现窗口工具为银行提供了一个额外的流动性来源，当银行无法在市场上以合理成本获得所需资金时（例如，联邦基金市场利率异常高企或市场流动性紧张），可以向美联储申请贴现贷款。在传统操作框架下，贴现率通常设定在联邦基金目标利率之上。这构成了一个**事实上的利率“上限”**或惩罚性利率。银行通常倾向于首先在联邦基金市场上借款，只有在无法获得市场融资或成本过高时才会求助于贴现窗口。这种设计有助于稳定联邦基金利率，防止其因暂时的准备金短缺而过度飙升。作为常规工具之一， 贴现率的调整有时也被用作一种政策信号，表明美联储对经济状况和未来政策走向的看法，尽管其信号作用通常不如公开市场操作或联邦基金目标利率的调整那么直接和明确。贷款类型一级信贷（Primary Credit）： 提供给财务状况良好的存款机构，通常是隔夜贷款，利率（即一级信贷利率）是主要的贴现率。借款机构只需证明其财务稳健，无需解释借款原因，从而减少了使用贴现窗口的“污名效应”（Stigma）。二级信贷（Secondary Credit）： 提供给那些不符合一级信贷条件的存款机构，利率通常设定在一级信贷利率之上，带有更严格的监管审查。季节性信贷（Seasonal Credit）： 提供给那些存款和贷款具有明显季节性波动的小型存款机构，帮助它们应对可预测的资金流出高峰。尽管贴现窗口是重要的安全阀，但在常规时期，其使用量相对较小。银行倾向于避免使用，部分原因是担心市场可能将其解读为财务困境的信号（即“污名效应”）。然而，在金融压力时期，贴现窗口作为最后贷款人（Lender of Last Resort）的角色至关重要。3.法定存款准备金要求 (Reserve Requirements)法定存款准备金要求是指美联储规定存款机构必须将其吸收的部分存款（主要是交易账户存款，如支票账户）以准备金的形式持有，不能用于放贷或投资。这些准备金可以库存现金（Vault Cash）或在联邦储备银行的存款形式存在。机制原理（传统理论）理论上，通过调整法定存款准备金率（Required Reserve Ratio），美联储可以影响货币乘数的大小。较高的准备金率意味着银行需要持有更多存款作为准备金，可用于放贷的资金减少，从而限制了信贷扩张和货币创造能力。反之，降低准备金率则能释放更多资金用于放贷，刺激信贷增长。法定准备金要求为银行体系创造了一个相对稳定的准备金需求基数，这在“稀缺准备金”框架下有助于美联储通过公开市场操作更有效地管理准备金供应，以稳定联邦基金利率。工具局限性与演变历史上，法定存款准备金曾经是重要的货币政策工具，但随着时间的推移，其作为主动管理工具的地位逐渐下降，原因有三：工具的钝化性： 调整准备金率对银行体系的影响巨大且直接，难以进行精细微调，频繁调整会干扰银行的流动性管理和经营规划。金融创新规避： 金融创新使得银行可以通过各种方式（如表外业务、批发融资）规避准备金要求对信贷扩张的限制。对特定银行的负担： 对于准备金管理能力较弱或面临存款流失的银行而言，准备金要求可能构成沉重负担。鉴于上述原因，美联储越来越少动用法定存款准备金率作为积极的政策工具，更倾向于将其保持稳定。随着美联储在应对2008年金融危机及其后遗症的过程中实施了大规模资产购买计划（量化宽松），银行体系积累了远超法定要求的巨额准备金，进入了所谓的“充足准备金”（Ample Reserves）操作框架。在此框架下，准备金供应极为充裕，联邦基金利率主要通过管理利率（如准备金余额利率IOER/IORB，以及隔夜逆回购工具ON RRP的利率）来控制，而非通过微调准备金供应量。在这种环境下，法定存款准备金要求对货币控制的实际作用已微乎其微。最终，在2020年3月，为了进一步简化操作框架并支持信贷流向家庭和企业，美联储宣布将所有存款机构的法定存款准备金率降至零。这一决定标志着法定存款准备金作为一项积极或被动约束工具在美国货币政策实践中的终结。总结公开市场操作、贴现窗口贷款和法定存款准备金要求构成了美联储常规货币政策工具箱的核心。其中，公开市场操作长期以来是实施货币政策、调控联邦基金利率的主要手段。贴现窗口则扮演着流动性安全阀和最后贷款人的角色。法定存款准备金要求虽然在理论上具有重要意义，但由于其钝化性和金融创新的影响，其作为主动政策工具的地位早已式微，并最终在向充足准备金框架的过渡中被废除。理解这三大常规工具的功能与局限性，是分析美联储如何在不同经济环境下（包括危机时期）运用更广泛、更创新的政策手段（即非常规货币政策，将在后续章节讨论）来履行其法定职责的基础。二、非常规货币政策工具在第一章中，我们探讨了美联储传统上依赖的常规货币政策工具，这些工具主要通过影响联邦基金利率来调控经济。然而，自21世纪初以来，特别是2008年全球金融危机（GFC）及其后续影响，以及2020年COVID-19大流行的冲击，迫使美联储在常规政策空间受限（尤其是联邦基金利率触及或接近其“有效下限” Effective Lower Bound, ELB）的情况下，探索并大规模部署了一系列非常规货币政策工具（Unconventional Monetary Policy Tools）。这些工具旨在绕过传统利率渠道的限制，直接影响更广泛的金融条件、提供流动性支持、修复市场功能，并管理公众预期，以继续履行其稳定物价和促进最大就业的双重使命。本章将重点阐述美联储采用的主要非常规货币政策工具，包括大规模资产购买（量化宽松）、前瞻性指引、以及旨在稳定特定金融市场的紧急流动性和信贷工具。同时，我们也将讨论这些工具如何改变了美联储的操作框架，特别是向“充足准备金”（Ample Reserves）体系的过渡及其管理工具。1.大规模资产购买（Large-Scale Asset Purchases, LSAPs）/ 量化宽松（Quantitative Easing, QE）当短期政策利率降至有效下限后，大规模资产购买（通常被称为量化宽松，QE）成为美联储最重要的非常规工具之一。与旨在精确调控联邦基金利率的常规公开市场操作不同，LSAPs的目标是直接压低长期利率、放宽整体金融条件，并有时支持特定市场的流动性和功能。为了面对20年因冠病疫情开始的潜在金融风险， 美联储大量购买长期国债（Treasuries）和机构抵押贷款支持证券（Agency Mortgage-Backed Securities, MBS），从私人投资者（如银行、保险公司、养老基金等）的投资组合中移除了这些“久期风险”（Duration Risk）或“提前偿付风险”（Prepayment Risk）资产。为了重新平衡其投资组合，这些投资者会寻求购买其他风险和久期特征相似的资产（如公司债券、其他长期证券）。这种需求的增加会推高这些替代资产的价格，从而压低其收益率。最终效果是降低了私人部门的长期借贷成本。购买MBS还特别旨在降低抵押贷款利率，支持房地产市场。除开政策工具传导带来的风险压缩，大规模资产购买计划本身也传递了一个强烈的政策信号，表明美联储致力于在较长时期内维持宽松的货币政策立场。这种承诺有助于锚定市场对未来短期利率路径的预期，从而压低长期利率（因为长期利率部分反映了对未来短期利率的预期）。在市场极端承压时（如2008年底的MBS市场或2020年初的国债市场），美联储的购买可以提供关键的流动性，充当“最后做市商”，恢复市场信心和交易活动，防止金融状况的螺旋式恶化。美联储在GFC后实施了多轮QE（QE1, QE2, QE3），购买了数万亿美元的国债和MBS。在COVID-19冲击后，美联储再次启动了规模空前的资产购买计划，初期目标侧重于恢复市场功能，随后转向提供持续的经济支持。这些操作显著扩大了美联储的资产负债表规模。2.前瞻性指引（Forward Guidance）前瞻性指引是指中央银行就其未来货币政策意图（特别是未来联邦基金利率的可能路径或维持低利率的条件）进行的沟通。在零利率下限环境下，它是增强货币政策效力、管理市场预期的关键补充工具。通过明确传达未来可能维持宽松政策的时间长度或经济条件，前瞻性指引旨在影响市场参与者对未来短期利率的预期。由于长期利率包含了对未来短期利率路径的预期，更明确、更可信的低利率承诺可以有效降低长期利率，即使当前的短期政策利率已经无法再降。这有助于刺激对利率敏感的支出，如投资和耐用品消费。前瞻性指引一共有三种类型：日历型指引（Calendar-Based Guidance）： 明确说明将维持当前政策利率水平至某个具体日期（例如，“至少到2013年中期”）。这种方式简单明了，但可能因缺乏灵活性而受到批评。状态依存型/阈值型指引（State-Contingent / Threshold-Based Guidance）： 将未来政策行动与特定的经济指标（如失业率降至某水平以下，或通胀率达到某目标）挂钩（例如，“只要失业率仍在6.5%以上，且未来一至两年通胀预期不超过2.5%，就会维持联邦基金利率在0-0.25%”）。这种方式更具灵活性，能根据经济实际进展自动调整政策预期，但可能面临沟通复杂性和数据可靠性的挑战。定性指引（Qualitative Guidance）： 提供关于未来政策倾向的总体描述，而非具体日期或数字阈值（例如，承诺在经济复苏稳固前保持宽松政策）。前瞻性指引通常与LSAPs协同使用，相互增强效果。例如，持续的资产购买可以增强市场对美联储维持低利率承诺的可信度。3.紧急流动性与信贷工具（Emergency Liquidity and Credit Facilities）在金融危机期间，特定信贷市场可能出现严重的功能失调，即使整体利率水平很低，信贷也可能无法顺畅流向经济实体。为此，美联储依据《联邦储备法》第13(3)条授予的紧急权力，设立了一系列临时性的、有针对性的流动性和信贷工具，旨在充当特定市场的“最后贷款人”或“最后做市商”。这些工具通过直接向金融机构或非金融企业提供贷款、购买特定类型的资产（如商业票据、货币市场基金份额、市政债券、公司债券等）或提供担保，来缓解特定领域的融资压力、恢复市场信心、防止信贷紧缩蔓延。它们的目标通常不是广泛压低利率（QE的目标），而是修复关键信贷市场的传导机制，确保信贷流向家庭和企业。主要工具（GFC与COVID-19时期）：针对金融机构的工具： 如定期拍卖工具（TAF）、一级交易商信贷工具（PDCF）、货币市场共同基金流动性工具（MMLF）等，为银行和关键非银机构提供流动性支持。针对关键市场的工具： 如商业票据融资工具（CPFF）、定期资产支持证券贷款工具（TALF）、市政流动性工具（MLF）、一级市场公司信贷工具（PMCCF）、二级市场公司信贷工具（SMCCF）等，直接支持商业票据、资产支持证券、市政债券和公司债券市场。针对实体经济的工具： 如薪资保护计划流动性工具（PPPLF）、主街贷款计划（MSLP），旨在促进银行向中小企业提供贷款。我们可以看到这些美联储工具的设计通常包含限制条件（如抵押品要求、利率设定、期限等）以管理风险，并在市场功能恢复后逐步退出。它们是美联储应对极端金融压力、维护金融稳定的重要武器。要不然怎么能叫非常规货币政策工具呢，对伐？4.充足准备金框架下的利率管理：准备金余额利率（IORB）与隔夜逆回购工具（ON RRP）08年之后的大规模资产购买向银行体系注入了巨量准备金，使得传统的通过微调准备金供应来控制联邦基金利率的“稀缺准备金”框架失效。美联储因此转向了**“充足准备金”**（Ample Reserves）操作框架。在此框架下，美联储主要依靠两个管理利率来控制联邦基金利率在目标区间内运行：准备金余额利率（Interest on Reserve Balances, IORB）： 这是美联储向存款机构存放在美联储的准备金余额（包括法定准备金和超额准备金）支付的利率。由于银行可以将多余资金安全地存放在美联储并获得IORB，它们通常不愿意以显著低于IORB的利率在联邦基金市场上拆出资金。因此，IORB有效地为联邦基金利率设定了一个软性的“地板”，尤其对于银行间拆借而言。 (注：此前有利息支付工具IOER和IORR，后合并为IORB)隔夜逆回购协议工具（Overnight Reverse Repurchase Agreement Facility, ON RRP）： 这是一个美联储向更广泛的对手方（包括货币市场基金、政府支持企业等不能直接获得IORB的机构）提供的工具。通过ON RRP，这些机构可以将其持有的现金以隔夜逆回购的形式借给美联储（美联储出售国债并约定次日购回），并获得ON RRP利率。由于这些非银机构是联邦基金市场的重要资金供给方，ON RRP利率通常设定在联邦基金目标区间的下限附近或略低于IORB，为包括联邦基金利率在内的短期货币市场利率提供了一个更坚实的“地板”。通过调整IORB和ON RRP利率，美联储能够在准备金极其充裕的环境下，依然有效地将有效联邦基金利率（EFFR）维持在FOMC设定的目标区间之内。总结非常规货币政策工具极大地扩展了美联储应对经济危机和在零利率下限环境中实施货币政策的能力。大规模资产购买（QE）和前瞻性指引主要用于影响长期利率和金融条件，而紧急流动性与信贷工具则侧重于修复特定的市场功能障碍。这些工具的使用也促使美联储的操作框架演变为“充足准备金”体系，依赖IORB和ON RRP等管理利率来控制政策利率。虽然这些非常规工具被证明在危机时期是有效的，但它们的长期影响、潜在副作用（如资产负债表规模膨胀、退出策略的复杂性、对资产价格和财富分配的影响等）以及未来是否会成为更常规化的工具，仍然是中央银行学界和政策制定者持续研究和讨论的重要议题。三、关键宏观经济指标帝国央行的货币政策决策当然不会是真空球形鸡，而是基于对当前经济状况的细致评估以及对未来经济走向的预测。为了履行其促进最大就业和维持物价稳定的双重使命，并维护金融稳定，联邦公开市场委员会（FOMC）需要持续监测和解读一系列广泛的宏观经济与金融指标。这些指标提供了关于经济活动强度、劳动力市场状况、通货膨胀压力以及金融系统健康状况的关键信息。没有任何单一指标能够完美地描绘复杂的经济全貌，因此，美联储采取一种整体性（Holistic）和数据依赖（Data-Dependent）的方法，综合分析各种数据来源，识别潜在趋势，评估风险，并最终做出符合其法定目标的政策判断。美国经济比较重要的指标大致可以分为四个部分：劳动力市场指标、通货膨胀指标、经济活动与增长指标和金融市场与金融条件指标。1.劳动力市场指标评估当前经济运行是否接近“最大就业”水平是美联储的核心任务之一。“最大就业”并非一个固定的、可直接衡量的数字，而是一个动态的、可持续的最高就业水平，与物价稳定目标相一致。美联储关注一系列指标来全面评估劳动力市场的健康状况：失业率（Unemployment Rate, U-3）： 这是最广为人知的劳动力市场指标，衡量了积极寻找工作但未能找到工作的劳动力所占的比例。低失业率通常表示劳动力市场趋紧，但也需结合其他指标判断是否存在过热风险。需关注其局限性，例如未包含“失去信心的工人”（Discouraged Workers）或“准待业工人”（Marginally Attached Workers）。更广泛的失业/未充分就业指标（Broader Measures of Labor Underutilization, e.g., U-6）： U-6指标包含了U-3的失业人口，以及准待业工人和因经济原因而从事兼职工作的人（Part-Time for Economic Reasons）。它提供了对劳动力市场闲置资源（Slack）更全面的视角。劳动力参与率（Labor Force Participation Rate, LFPR）： 衡量劳动年龄人口中正在工作或积极寻找工作的人口比例。LFPR的变化受人口结构（如老龄化）、社会因素和经济周期影响。理解LFPR的趋势对于判断失业率下降的真实含义至关重要（例如，失业率下降是由于就业增加还是人们退出劳动力市场）。就业增长（Payroll Employment Growth）： 来自非农就业报告（Nonfarm Payrolls, NFP）的月度新增就业人数是衡量劳动力需求和经济活力的关键实时指标。持续强劲的就业增长表明经济扩张，反之则可能预示放缓。关注就业增长的行业分布也很重要。职位空缺与劳动力流动调查（Job Openings and Labor Turnover Survey, JOLTS）： 提供关于职位空缺数量、雇佣率、离职率（特别是自主离职率 Quits Rate）等信息。高职位空缺和高自主离职率通常表明劳动力需求强劲，工人对找到新工作的信心较高，市场趋紧。薪资增长（Wage Growth）： 如平均时薪（Average Hourly Earnings, AHE）和就业成本指数（Employment Cost Index, ECI）。薪资增长是衡量劳动力市场紧张程度和潜在通胀压力的重要指标。美联储关注薪资增长是否与生产率增长和2%的通胀目标相符。过快的薪资增长可能引发“工资-物价螺旋”担忧，而过于疲软则可能抑制消费。需区分名义薪资增长与实际薪资增长（经通胀调整后）。2.通货膨胀指标维持物价稳定是美联储的另一核心使命，其明确的长期目标是将通货膨胀率控制在2%。美联储主要关注以下通胀指标：个人消费支出价格指数（Personal Consumption Expenditures Price Index, PCE）： 这是美联储首选的通胀衡量指标。与消费者价格指数（CPI）相比，PCE的覆盖范围更广（包含不由家庭直接支付的消费，如雇主提供的医疗保险），其权重会根据消费者实际支出模式的变化而动态调整（考虑替代效应），因此被认为能更准确地反映整体消费价格的变动趋势。核心PCE价格指数（Core PCE Price Index）： 剔除了波动性较大的食品和能源价格后的PCE指数。核心通胀被认为是衡量潜在、持续通胀压力的更好指标，有助于政策制定者看透短期价格波动的“噪音”，把握中期通胀趋势。美联储的2%通胀目标是以整体PCE衡量的，但核心PCE在政策分析中占据重要地位。消费者价格指数（Consumer Price Index, CPI）： 虽然不是美联储的首选目标指标，但CPI因其发布及时、广受公众关注，并且是许多政府福利和私人合同（如工资协议）的调整依据，仍然是重要的参考指标。核心CPI（剔除食品和能源）同样受到关注。生产者价格指数（Producer Price Index, PPI）： 衡量国内生产者销售商品和服务的价格变动。PPI可被视为消费价格的某种“领先”指标，反映了生产成本端的压力（“管道”通胀压力），但其向消费者价格的传导并不直接或完全。通胀预期（Inflation Expectations）： 公众和市场对未来通胀的预期对实际通胀的形成至关重要。如果预期保持稳定并“锚定”在美联储的目标附近，有助于抑制暂时的价格冲击演变成持续的通胀。美联储监测多种通胀预期指标：基于调查的预期： 如密歇根大学消费者调查、纽约联储消费者预期调查、专业预测者调查（Survey of Professional Forecasters, SPF）。基于市场的预期： 如通胀保值国债（TIPS）的盈亏平衡通胀率（Breakeven Inflation Rates）、通胀互换（Inflation Swaps）利率。这些指标反映了金融市场参与者对未来通胀的看法，但可能受到流动性溢价、风险溢价等因素的影响。美联储密切关注实际通胀数据与通胀预期，评估通胀风险是偏向上行还是下行，以及通胀预期是否牢固锚定。3.经济活动与增长指标衡量整体经济的增长速度和健康状况对于判断资源利用程度、预测未来就业和通胀路径至关重要。国内生产总值（Gross Domestic Product, GDP）： 最全面的经济活动衡量指标，反映一个国家在特定时期内生产的所有最终商品和服务的总市场价值。关注实际GDP增长率（经通胀调整后）及其组成部分（消费、投资、政府支出、净出口）的贡献。GDP数据发布有滞后性，但提供了经济大图景。高频/领先指标： 由于GDP的滞后性，美联储依赖更及时的指标来判断经济动能：零售销售（Retail Sales）： 反映消费者支出状况，是GDP中消费部分的重要领先指标。工业生产（Industrial Production）： 衡量制造业、矿业和公用事业部门的产出，反映实体经济的生产活动。耐用品订单（Durable Goods Orders）： 特别是核心资本品订单（非国防、除飞机外），被视为衡量企业投资意愿的指标。住房市场指标： 如新屋开工（Housing Starts）、营建许可（Building Permits）、成屋销售（Existing Home Sales）和房价指数。房地产市场对利率敏感，其活动状况对整体经济有显著影响。采购经理人指数（Purchasing Managers' Indexes, PMIs）： 如ISM制造业和非制造业PMI。这些基于调查的指数具有前瞻性，反映了企业对订单、生产、就业等状况的看法，是判断经济扩张或收缩拐点的常用指标。消费者信心/情绪指数（Consumer Confidence/Sentiment Indexes）： 如密歇根大学消费者信心指数和世界大型企业联合会（Conference Board）消费者信心指数。反映了消费者对当前经济和未来前景的看法，可能影响其消费意愿。4.金融市场与金融条件指标金融市场是货币政策传导的关键渠道，金融条件的松紧直接影响实体经济的借贷成本和信贷可得性。同时，维护金融稳定也是美联储日益重视的目标。利率（Interest Rates）： 包括短期国债收益率、长期国债收益率（及其收益率曲线形态）、公司债券收益率（及其与国债的利差，反映信用风险溢价）、抵押贷款利率等。这些利率直接影响家庭和企业的融资成本。信贷市场状况（Credit Market Conditions）： 银行贷款增长、信贷标准（如通过高级贷款官员意见调查SLOOS了解）、商业票据发行、信贷利差（Credit Spreads）等。反映了信贷的可获得性和成本。资产价格（Asset Prices）： 股票市场估值、房地产价格等。资产价格通过财富效应影响消费，也可能蕴含金融稳定风险。汇率（Exchange Rates）： 美元汇率影响进出口价格（从而影响通胀）和贸易竞争力。金融条件指数（Financial Conditions Indexes, FCIs）： 一些机构编制的综合指数，试图将利率、利差、资产价格、汇率等多个金融变量整合成单一指标，以量化整体金融条件的松紧程度。几个核心指标的整理在上述诸多经济指标中，有几个因其直接关联美联储的双重使命（最大就业和物价稳定）、发布频率、市场影响力以及在FOMC声明和经济预测中被频繁引用，而通常被认为是最重要或最受关注的：核心个人消费支出价格指数（Core PCE Price Index）增长率：重要性： 这是美联储衡量潜在通胀趋势的首选指标。虽然官方的2%通胀目标是针对整体PCE（Total PCE）的，但核心PCE剔除了波动较大的食品和能源价格，被认为能更好地反映经济中持续的、基础性的价格压力。美联储决策者高度关注核心PCE通胀是否朝着（或稳定在）2%的目标运行。关注点： 月度环比和年度同比的增长率，以及其相对于2%目标的偏离程度和变动趋势。非农就业人数（Nonfarm Payrolls, NFP）增长：重要性： 这是衡量劳动力市场活动和经济活力的最及时、最关键的指标之一。它直接反映了企业雇佣的意愿和能力，是判断经济扩张或收缩势头的重要依据，直接关系到“最大就业”目标。每月初发布的数据通常会引发显著的市场反应。关注点： 每月新增的就业岗位数量，是否达到或超过了维持失业率稳定所需的水平（通常估计在每月10万左右，但会随人口增长等因素变化），以及就业增长的广度（是否分布在多个行业）。失业率（Unemployment Rate, U-3）：重要性： 这是衡量劳动力市场闲置程度最广为人知的指标，直接关联“最大就业”目标。虽然美联储也看重更广泛的就业不足指标（如U-6）和劳动参与率，但U-3失业率仍然是公众和市场关注的焦点，也是FOMC经济预测中的核心变量之一。关注点： 失业率的水平及其变化趋势，与FOMC估计的长期正常失业率（NAIRU或u*）的比较。平均时薪（Average Hourly Earnings, AHE）增长率：重要性： 这是衡量薪资压力和劳动力成本变化的关键指标，与非农就业报告同时发布。薪资增长是连接劳动力市场紧张程度和通胀压力的重要环节。过快或过慢的薪资增长都可能引起美联储的关注。关注点： 月度环比和年度同比的增长率，是否与生产率增长和2%的通胀目标相符。、其他高度关注的指标（虽然可能略次于上述四个）：整体个人消费支出价格指数（Total PCE Price Index）增长率： 虽然波动性大，但这是美联储官方2%通胀目标的最终衡量标准。消费者价格指数（CPI）： 发布比PCE早，公众关注度高，影响许多合同的调整。核心CPI也备受关注。通胀预期（Inflation Expectations）： 特别是来自调查（如密歇根大学、SPF）和市场（如TIPS盈亏平衡率）的长期通胀预期，对判断通胀预期是否“锚定”至关重要。国内生产总值（GDP）增长率： 最全面的经济活动指标，但发布频率低（季度）且滞后。主要用于把握经济大趋势和潜在增长率。ISM采购经理人指数（PMIs）： 制造业和非制造业PMI是及时的、具有一定前瞻性的经济活动指标。如果必须选出最核心的几个，那么核心PCE通胀、非农就业增长和失业率这三者通常被视为直接反映美联储两大核心目标的“铁三角”。平均时薪增长紧随其后，因为它直接关联这两大目标之间的互动（劳动力市场对通胀的影响）。美联储的决策是基于对广泛数据的整体评估，但这些指标无疑是市场和分析师解读美联储政策意图时最为倚重的“风向标”。四、政策工具与指标的联动逻辑前述章节分别阐述了美联储的常规与非常规货币政策工具（第一、二章），以及其密切检测的关键宏观经济指标（第三章）。本章的核心任务在于揭示这两者之间的联动逻辑：即美联储如何通过操作其政策工具箱中的工具，来影响经济活动、劳动力市场和通货膨胀的关键指标，进而引导经济朝着其法定目标——最大就业和物价稳定——迈进。理解这一联动机制，即货币政策传导机制（Monetary Policy Transmission Mechanism），对于评估政策效果、预测经济走向以及把握美联储的政策意图至关重要。需要强调的是，这一过程并非简单的线性关系，而是充满了复杂性、时滞以及不确定性。经济学是真空球形鸡的线性拟合模型，但现实通常是极高复杂度的混沌模型1.主要的传导渠道美联储政策影响经济运行最传统的渠道就是利率渠道（Interest Rate Channel），政策工具变动（如调整联邦基金利率目标或进行QE）影响短期和长期市场利率，进而改变家庭和企业的借贷成本，影响消费和投资决策。在利率渠道外，信贷渠道（Credit Channel）通过影响银行的贷款意愿和能力（银行贷款渠道），以及企业通过非银行渠道（如债券市场）融资的成本和可得性（资产负债表渠道）来调控宏观经济。每一次美联储的加息/减息总会牵动全世界经济金融界的注意力，美联储会通过汇率渠道（Exchange Rate Channel）来影响资本流动和汇率。例如，较低的利率可能导致美元贬值，从而刺激出口、抑制进口，影响净出口和总需求，并可能影响进口商品价格（进而影响通胀）。时间来到了新世纪，GFC和冠病危机后美联储开始的大规模QE和利率调整会通过资产价格渠道（Asset Price Channel）来影响股票、房地产等资产的价格。资产价格上涨可以通过财富效应刺激消费，也可以通过托宾Q效应（Tobin's q）鼓励投资。目前，美联储是全世界预期管理（你也可以当成训狗）做的最好的中央银行，通过预期渠道（Expectations Channel）下的行动和沟通（特别是前瞻性指引）会塑造公众和市场对未来经济状况和政策路径的预期。例如，对未来长期维持低利率的预期本身就能压低当前的长期利率，并鼓励当前的支出和投资。所以，美联储影响实体经济的渠道一共有五个，分别是利率渠道、信贷渠道、资产价格渠道、汇率渠道和预期渠道。2.常规工具与指标的联动在传统的“稀缺准备金”框架下，以及在“充足准备金”框架下通过管理利率（IORB、ON RRP）进行的常规操作，其核心是影响联邦基金利率（FFR），进而通过上述传导渠道影响经济指标。降低FFR目标（或调整管理利率以引导FFR下行）——旨在刺激经济FFR下降通常带动其他短期利率（如国库券、商业票据利率）下行，并通过预期渠道和期限溢价影响长期利率（如抵押贷款利率、公司债收益率）走低，银行贷款利率也可能随之下降。贷款利率的下降会导致更低的借贷成本，鼓励企业投资（可能提振耐用品订单、工业生产、最终GDP）和居民消费，特别是对利率敏感的住房（新屋开工、成屋销售）和耐用品（零售销售）。企业投资和居民消费的增强又会增加对劳动力的需求，导致非农就业人数（NFP）增长加速，失业率（U-3及U-6）下降，劳动力市场趋紧可能推高薪资增长（AHE、ECI）。最终，整体经济活动的总需求增加，若经济接近或超过潜在产出水平，可能导致PCE和CPI通胀（尤其是核心PCE）上升，朝向或超过2%的目标。通胀预期也可能随之升温。提高FFR目标（或调整管理利率以引导FFR上行）——旨在抑制通胀/防止经济过热FFR上升带动各类市场利率上行，银行可能收紧信贷标准（SLOOS数据可反映），金融条件趋于收紧；更高的借贷成本抑制企业投资和居民消费，可能导致GDP增长放缓，相关领先指标（零售销售、工业生产、PMI等）走弱。 经济活动降温减少劳动力需求，NFP增长可能放缓甚至转负，失业率可能上升，薪资增长压力减弱，总需求减弱。总需求受到抑制有助于缓解价格上行压力，促使PCE和CPI通胀（尤其是核心PCE）回落至或稳定在2%目标附近。通胀预期也可能随之降温。3.非常规工具与指标的联动当FFR触及有效下限（ELB）时，传统工具已经无法有效调控宏观经济了，这时就需要我们的非常规工具登场。大规模资产购买（QE/LSAPs）QE主要通过投资组合平衡渠道直接压低所购买资产（长期国债、MBS）的收益率，进而影响其他长期利率和风险资产价格。同时通过信号渠道强化低利率预期。在市场压力大时还发挥流动性/市场功能渠道作用。对于金融市场来说，QE会显著降低长期利率（如10年期国债收益率、30年期抵押贷款利率），压缩信用利差，推高资产价格（股票、房地产），改善金融条件指数（FCIs）；QE 类似降息效果，通过降低长期融资成本刺激投资（尤其是住房投资）和消费（财富效应），支持GDP增长和就业（NFP），降低失业率。购买MBS旨在特别支持房地产市场。前瞻性指引这条渠道我一直都觉得跟训狗似的，主要通过预期渠道发挥作用，管理市场对未来短期利率路径的预期。 前瞻性指引降低长期利率的效果与QE类似，有助于刺激投资和消费，支持就业，增强政策可信度本身也有助于稳定信心。明确的宽松承诺有助于稳定或提升通胀预期，防止其过低，从而间接支持实际通胀向目标靠拢。紧急流动性与信贷工具此工具主要作用于信贷渠道和市场功能渠道，针对特定市场失灵提供流动性或信贷支持，相当于临时紧急给💊的金融机构贷款以维持金融系统的稳定性。对指标的影响：金融市场： 缓解特定市场的流动性紧张，降低风险溢价和信用利差（如商业票据利差、公司债利差），恢复市场交易活动，改善相关金融条件指标。经济活动与就业： 防止信贷冻结对企业运营和投资造成破坏性冲击，避免GDP大幅下滑和失业率飙升。支持信贷流向实体经济有助于稳定就业。通货膨胀： 主要目标是防止金融危机引发深度衰退和通缩，而非直接推高通胀。4.挑战：时滞、不确定性与外部因素理解工具与指标的联动逻辑时，必须认识到其中的挑战：时滞（Lags）： 货币政策的传导存在显著且可变的时滞。从政策实施到其对经济活动和通胀产生最大影响，通常需要数月甚至数年时间。这意味着美联储需要基于对未来的预测来制定政策，而非仅仅对当前数据做出反应。不确定性（Uncertainty）： 传导机制的强度和速度可能随经济结构、金融市场状况以及公众预期的变化而变化。非常规工具的效果尤其具有不确定性。外部因素： 全球经济状况、财政政策、地缘政治事件、技术冲击、供给侧因素（如能源价格波动、供应链问题）等都会影响经济指标，并可能干扰或改变货币政策的传导效果。中译中就是美联储的所有工具都不是灵丹妙药，现实世界是一个高复杂性的混沌系统，大家都凑合着过吧。五、帝国的央行，帝国的国资委:::note\n本章不会过多深入去探讨三大巨头和美联储的关系，仅做一个简单概述。\n:::在探讨美联储作为美国金融体系核心的角色时，我们不能忽视一股新兴且日益强大的力量——以贝莱德（BlackRock）、先锋领航（Vanguard）和道富（State Street）为代表的三大资产管理巨头。三大资管巨头通过汇集数万亿美元的资产，对美国乃至全球上市公司的所有权结构和公司治理产生了前所未有的集中影响。这种影响力之深远，使得三大巨头在某种意义上扮演了类似于“美国国资委”的角色，虽非美国联邦政府所有，但他们却在塑造企业行为和资本市场格局方面拥有巨大的话语权。尽管美联储的法定职责在于宏观调控与监管，而三大资管机构的核心业务在于资产管理与投资服务，但两者在金融市场的流动性、资产定价、系统性风险积聚与传染、甚至危机时期的干预与合作等层面，功能与影响已然发生显著交织。1.三大巨头的崛起之路：从边缘到核心贝莱德、先锋领航和道富当然不是一日之间突然崛起的。他们的发展是美国金融市场结构性变迁、技术创新和战略选择的共同结果，尤其受益于过去几十年被动投资（Passive Investing）浪潮的兴起。先锋领航 (Vanguard): 被动投资的先驱与布道者先锋领航成立于1975年，由约翰·博格（John Bogle）创立。Vanguard的独特之处在于其“客户所有”（client-owned）的股权结构，这使其能够将利润返还给基金投资者，从而提供市场上成本最低的投资产品。Vanguard是指数基金的坚定倡导者和市场领导者。博格认为，主动管理基金难以持续跑赢市场平均水平，低成本的指数基金才是普通投资者的最佳选择。这一理念随着时间的推移被广泛接受，推动了指数基金和交易所交易基金（ETF）的爆炸式增长，Vanguard也借此积累了海量的资产管理规模（AUM）。其增长主要依赖于有机增长和持续的低成本策略。贝莱德 (BlackRock): 风险管理、并购整合与ETF霸主起源于1988年，最初是黑石集团（Blackstone）旗下的一个固定收益资产管理部门，由拉里·芬克（Larry Fink）等人领导。其早期核心竞争力在于强大的风险管理能力，特别是其开发的“阿拉丁”（Aladdin）风险管理平台，至今仍是业内翘楚，并被众多金融机构采用。贝莱德的快速扩张在很大程度上得益于成功的战略并购——收购美林投资管理公司（Merrill Lynch Investment Managers, 2006），该收购极大扩展了贝莱德管理的资产类别和全球布局。在2008年金融危机后，贝莱德于2009年收购巴克莱全球投资者（Barclays Global Investors, BGI），特别是后者旗下的iShares（安硕）ETF业务。这笔交易使贝莱德一跃成为全球最大的资产管理公司和ETF提供商。贝莱德不仅在被动投资领域与Vanguard竞争，也在主动管理、另类投资等多个领域拥有强大实力，并通过其“金融市场咨询”（Financial Markets Advisory, FMA）部门向政府和机构提供咨询服务。道富环球顾问 (State Street Global Advisors, SSGA): ETF的开创者与机构服务的巨头道富银行本身拥有悠久历史（可追溯至1792年），但其资产管理部门SSGA成立于1978年。SSGA在金融创新史上留下了浓墨重彩的一笔：1993年，它推出了美国第一只ETF——SPDR S&P 500 ETF (代码: SPY)，这只基金至今仍是全球规模最大、交易最活跃的ETF之一。虽然其总AUM相较于贝莱德和先锋稍小，但道富在机构投资者服务、资产托管以及特定ETF领域（如行业ETF、黄金ETF）拥有极强的市场地位。这三大巨头的崛起，尤其是自2008年金融危机以来规模的急剧膨胀，与以下因素密切相关：被动投资革命： 指数基金和ETF因其低成本、透明度和易交易性，持续吸引资金流入，尤其是在低利率环境下，投资者寻求更广泛的市场敞口。金融危机的影响： 危机后对主动管理能力的质疑增加，以及监管对透明度的要求提高，进一步推动了向被动产品的转变。技术进步： 交易技术、数据分析和风险管理平台（如Aladdin）的发展，使得管理巨额、多元化的资产组合成为可能。规模经济效应： 资产管理行业具有显著的规模经济效应，规模越大，单位管理成本越低，越能吸引更多资金，形成正反馈循环。2.美联储与三大巨头：共生、依赖于潜在风险危机时期的“准执行伙伴”2008年金融危机时期，美联储在处理贝尔斯登、AIG等机构的遗留问题资产时，就曾聘请贝莱德的FMA部门提供估值、管理和处置方面的咨询服务，体现了美联储对贝莱德在复杂资产和风险管理方面专业能力的认可。自08年以后，三大资管巨头就迅速崛起，直至成为全美国的“控股者”。2020年COVID-19危机时期，美联储和三巨头的合作关系达到了全新的高度。为了稳定金融市场，美联储设立了多个紧急流动性便利工具，其中包括首次直接购买公司债和公司债ETF的工具（如二级市场公司信贷工具 SMCCF 和一级市场公司信贷工具 PMCCF）。美联储选择贝莱德作为这些工具的独家投资管理人，负责代表美联储执行购买操作。理论上美联储这么做是因为自身缺乏直接操作大规模、多样化证券购买的经验和基础设施。贝莱德拥有现成的交易平台（Aladdin）、市场准入和专业知识，能够快速有效地执行美联储的政策意图。同时，选择第三方管理人有助于在名义上隔离美联储与具体投资决策的潜在利益冲突（尽管选择贝莱德本身也引发了关于利益冲突的讨论，因为它管理的基金也可能是这些工具的受益者）。冠病危机期间美联储这些操作标志着一家私营资产管理公司深度嵌入了中央银行的危机应对机制中，扮演了关键的政策传导角色。这模糊了公共部门与私营部门在金融稳定领域的界限。信息与市场情报的流动三大巨头掌握着关于资本流动、资产定价、投资者情绪和市场微观结构的极其庞大且实时的信息。它们与全球数千家公司和机构投资者保持密切联系。美联储作为宏观审慎监管者和货币政策制定者，需要准确把握市场动态。虽然官方沟通渠道有严格规定，但通过正式（如市场咨询会议）和非正式的渠道，美联储无疑能从与这些巨头的互动中获得宝贵的市场洞察。反之，三大巨头也密切关注美联储的政策信号。中译中就是互通有无，大家加强联络一起捞钱系统性金融风险的节点三大巨头的规模本身就意味着它们具有系统重要性。它们管理的资产占美国乃至全球股市、债市的相当大比重。它们的投资决策、资金流动、甚至技术平台的稳定性，都可能对整个金融体系产生溢出效应；尤其是在被动投资领域，如果大量资金因某种原因（如市场恐慌）集中从指数基金或ETF中撤出，可能引发或加剧市场抛售，对市场流动性和稳定性构成挑战，这是美联储必须密切关注的风险点。虽然目前它们未被正式指定为“系统重要性金融机构”（SIFI），但关于其系统性风险的讨论从未停止。因此，当贝莱德既是美联储危机工具的管理人，又是市场上主要的资产管理者时，潜在的利益冲突是显而易见的：它购买的ETF或公司债可能包含其自己管理的基金所持有的证券。美联储对市场的干预，特别是通过购买资产（包括这些巨头管理的ETF），客观上支撑了资产价格，也使这些巨头的资产管理规模受益。这可能产生道德风险，即市场参与者预期在危机时会得到救助，从而可能承担过度风险。3.帝国的国资委概念介绍如果我们把帝国视为一个企业财团联合的国家，那么三大资管巨头就担任着类帝国国资委的角色，它们通过集中持有美国主要上市公司的股份，所形成的对公司治理和企业行为的巨大影响力。由于指数基金和ETF的普及，贝莱德、先锋领航和道富通常是美国绝大多数大型上市公司（如标普500指数成分股公司）的前三大股东。在许多公司中，它们三家合计持有的股份比例可能高达15%-25%，甚至更高。这种“普遍所有权”（Universal Ownership）意味着它们几乎“拥有”了美国企业界的很大一部分。不同于传统的分散持股，这种所有权的集中赋予了它们前所未有的潜在权力。作为大股东，它们在股东大会上拥有重要的投票权，可以影响董事会成员的选举、高管薪酬方案的批准、重大并购交易以及其他关键决策。那么这个时候有朋友可能要问了，人家只是被动持股呀，万一压根就不管企业怎么运转呢？近年来，三大巨头都建立了庞大的“投资督导”（Investment Stewardship）团队，负责与被投资公司的管理层和董事会进行沟通（Engagement），就公司战略、治理结构、风险管理、环境、社会和治理（ESG）等议题表达意见和施加影响。中译中就是资管老头发力了，你们都得听我三大巨头的话来做生意通过其投票政策和沟通策略，尤其是在ESG领域，三大巨头正在推动形成新的市场规范和企业行为标准。它们的要求（如气候相关信息披露、董事会多元化）往往超越了法律法规的最低要求，它们能够设定议程，引导资本流向符合其标准（例如ESG标准）的公司或行业，从而间接影响实体经济的资源配置。如果看到这里你还在感慨人家只是关注ESG领域多环保多高尚巴拉巴拉巴拉，那你可以直接关闭这篇博客然后打开VOA去感受自由之光普照了。当然，理论上真正的国资委服务于国家战略目标和政治议程。而三大资管巨头的首要责任（法律上的信义义务，Fiduciary Duty）是对其基金投资者负责，追求风险调整后的回报最大化。它们的行动逻辑主要是商业和投资驱动的，尽管其行为具有广泛的社会和经济后果……但理论是理论，实际是实际对伐。美联储和三大巨头的关系美联储和三巨头的关系首先体现在市场流动性与资产定价层面。三大资管巨头，特别是通过其庞大的指数基金和ETF产品线，已成为资本市场最主要的“流量入口”和“价格设定者”之一。其基于指数追踪的被动投资策略，虽然在个体证券选择上不显主动，但其巨大的资金流向（或撤离）某一类资产或整个市场时，对资产价格和市场流动性产生决定性影响。这直接关联到美联储货币政策的传导效率。当美联储试图通过降息或量化宽松（QE）向市场注入流动性、压低长期利率时，相当一部分流动性会通过三大巨头的基金产品流入股市和债市，其配置行为直接影响着政策意图能否有效转化为具体的资产价格变动和融资成本下降。反之，当市场预期紧缩时，这些巨头的资金流出可能放大市场的波动性，对美联储维持金融稳定构成挑战。其次，在系统性风险的积聚与管理上，两者关系更为复杂。一方面，三大资管巨头的规模本身就构成了潜在的系统性风险。它们的投资组合横跨全球，任何一家的重大操作失误、技术故障或遭遇大规模赎回，都可能引发市场剧震，形成“大到不能倒”的现代变体——“大到不能乱”（Too Big to Disrupt）。美联储作为系统性风险的最终监管者和流动性的最后提供者，必须密切关注这些机构的运作及其对金融体系稳定性的潜在威胁。另一方面，在危机时刻，美联储又可能需要依赖这些机构。例如，在2020年新冠疫情引发的市场动荡中，美联储设立的多个紧急流动性工具（如二级市场公司信贷工具 SMCCF），就聘请了贝莱德作为投资管理人，负责购买公司债和相关ETF。这凸显了两者在危机应对中的事实性合作关系，但也引发了关于利益冲突（贝莱德管理的工具可能购买其自己发行的ETF）、信息不对称以及公共权力“外包”给私营巨头的深刻讨论。第三，公司治理与宏观经济目标的潜在关联。三大巨头通过其持股和代理投票权，对上市公司的治理结构、高管薪酬、资本配置乃至环境、社会和治理（ESG）策略施加越来越大的影响。这种“股东积极主义”（Shareholder Activism），尤其是当其统一行动时，其力量堪比国家层面的产业政策引导者。虽然其出发点是为最终受益人（基金持有人）实现长期价值最大化，但其推动的议程（例如，强调气候风险、推动能源转型）在客观上可能与美联储更广泛的宏观经济目标（如促进可持续增长、维护金融稳定以应对气候相关风险）产生共鸣或潜在冲突。美联储虽然不直接干预个别公司的治理，但其宏观审慎框架越来越需要考虑由大型资管机构主导的、可能影响整个经济部门行为模式的结构性变化。总而言之，三大资管巨头实现了近乎之前的金融资本家们梦寐以求的空前集中的权力：对数千家全球主要企业的经营决策拥有潜在否决权或引导权。能够设定超越法律的企业行为标准（尤其在ESG领域）。其投资流动本身就能显著影响市场价格和流动性。与监管机构（如美联储）在危机时形成紧密合作，进一步巩固其中心地位。帝国央行+帝国国资委，不管底下的肉喇叭是怎么宣传的，真正掌握权力的老头们终归是极端清醒+理智的那一派。系列参见[1] Joseph Wang, 极简央行课 (北京:格致出版社 , 2023).[2] 李彬.滞胀风险下对美联储非常规货币政策的回顾与反思——一个政治经济学的视角[J].齐鲁学刊,2023,(05):119-128.[3] 郝飞飞.货币政策工具的选择、运用及有效性分析[D].中国社会科学院研究生院,2020.DOI:10.27642/d.cnki.gskyy.2020.000022."
  },
  {
    "title": "参考：抗失眠与抑郁药物清单",
    "summary": "观前注意我不能对这篇博客内容的科学性、真实性和有效性做任何保证以下列出的多为处方药，需经医生诊断并结合个人状况开具。请勿擅自购买或使用药物反应存在显著个体差异，具体用药和剂量需由医生根据健康状况、病情轻重及既往用药综合判断药物通常需辅以心理治疗（如CBT/CBT-I）及生活方式干预（如作息规律、适度运动、放松训练等）以提升疗效一、抗失眠药物（Hypnotics/Sedatives）抗失眠药物（催眠",
    "tags": [
      "心理学与神经科学"
    ],
    "url": "/posts/HumanSciences/insomnia-depression-pharmacology/",
    "date": "2025-03-30T00:00:00.000Z",
    "content": "观前注意我不能对这篇博客内容的科学性、真实性和有效性做任何保证以下列出的多为处方药，需经医生诊断并结合个人状况开具。请勿擅自购买或使用药物反应存在显著个体差异，具体用药和剂量需由医生根据健康状况、病情轻重及既往用药综合判断药物通常需辅以心理治疗（如CBT/CBT-I）及生活方式干预（如作息规律、适度运动、放松训练等）以提升疗效一、抗失眠药物（Hypnotics/Sedatives）抗失眠药物（催眠药/镇静药）的治疗目标是帮助入睡、维持睡眠或者改善睡眠质量。1.苯二氮䓬类药物 (Benzodiazepines, BZDs)原理介绍简单来说，苯二氮䓬类药物通过增强大脑中一种主要的抑制性神经递质——γ-氨基丁酸（GABA）的作用，来产生镇静、抗焦虑、抗惊厥和肌肉松弛等效果。如地西泮（安定）、劳拉西泮、阿普唑仑等，是临床上广泛用于治疗焦虑、失眠、癫痫和肌肉痉挛等问题的药物。我们大脑中有各种神经递质负责传递信号，有些是兴奋性的，让神经元更容易兴奋和放电；有些则是抑制性的，让神经元更难兴奋和放电。而γ-氨基丁酸（GABA） 是中枢神经系统中最重要、最普遍的抑制性神经递质。它帮助我们的大脑保持冷静和稳定，防止过度兴奋。GABA是通过与特定的“停靠站”——GABA_A受体结合来发挥作用的。这个GABA_A受体本身就是一个控制氯离子（Cl⁻）进出神经细胞的通道门。当GABA分子成功“停靠”到受体上时，这扇门就会打开，允许带负电荷的氯离子流入神经元内部。氯离子的涌入使得神经元内部的负电性增强（这个过程称为超极化），从而使神经元变得更难被“点燃”（即产生兴奋性神经冲动）。这就是GABA发挥其抑制作用，让大脑“冷静”下来的基本方式。而苯二氮䓬类药物的独特之处在于，它们并不直接模仿GABA去打开氯离子通道门。相反，它们是作用于GABA_A受体复合物上的另一个特定结合位点（苯二氮䓬结合位点）。当BZD分子结合到这个位点后，它会像一个“调节器”一样，改变GABA_A受体的状态。这种改变有两个主要效果：一是让受体对GABA更加“亲近”（增加亲和力）；二是更关键的，当GABA已经结合在受体上时，BZD的存在会显著增加氯离子通道打开的频率。这意味着，即使在正常的GABA水平下，只要有BZD的“助攻”，GABA的抑制信号就会被放大，更多的氯离子得以进入神经元，神经元的“刹车”效应因此被大大增强。正是因为BZD能够有效增强大脑的整体抑制作用，减少神经元的放电，所以此类药物可以产生显著的抗焦虑、镇静催眠、抗惊厥和肌肉松弛效果。然而，如同所有强效药物一样，苯二氮䓬类药物的使用也伴随着重要的注意事项。长期使用可能导致身体产生耐受性（需要更大剂量才能达到原效果）、生理依赖性（突然停药可能引发戒断症状）甚至成瘾的风险。常见的副作用包括嗜睡、头晕、协调能力下降和记忆力问题。此外，BZD与酒精、阿片类药物等其他中枢神经抑制剂合用会产生叠加效应，可能导致严重的呼吸抑制甚至危及生命。常见药物:短效 (帮助入睡): 艾司唑仑 (Estazolam/舒乐安定), 三唑仑 (Triazolam/酣乐欣 - 管控严格), 咪达唑仑 (Midazolam - 主要用于麻醉前)中效 (帮助入睡和维持睡眠): 劳拉西泮 (Lorazepam/安定文), 阿普唑仑 (Alprazolam/佳静安定 - 也常用于焦虑), 替马西泮 (Temazepam/利眠宁)长效 (维持睡眠，但次日残留效应可能较明显): 地西泮 (Diazepam/安定), 氯硝西泮 (Clonazepam/氯硝安定 - 也常用于焦虑/癫痫)药物特点： 起效快，效果肯定。但长期使用可能产生耐受性、依赖性，并可能影响日间认知功能，停药需逐渐减量。分为短效、中效、长效。注意事项： 老年人、有呼吸系统疾病者慎用。避免与酒精或其他中枢神经抑制剂同服。2.非苯二氮䓬类镇静催眠药 (Non-benzodiazepine Receptor Agonists, \"Z-drugs\")原理介绍非苯二氮䓬类镇静催眠药通常被称为 \"Z-药物\"（Z-drugs），因为它们的通用名常常以字母 \"Z\" 开头，例如唑吡坦 (Zolpidem)、扎来普隆 (Zaleplon) 和 艾司佐匹克隆 (Eszopiclone)。与上文的苯二氮䓬类（BZDs）药物类似，Z-药物的主要作用也是增强大脑中抑制性神经递质GABA的功能，从而产生镇静催眠效果。它们作用的靶点同样是GABA_A受体复合物。然而，Z-药物与传统BZDs相比，关键的区别是受体亚型的选择性。GABA_A受体实际上是一个复杂的蛋白质结构，由不同的亚基（如α, β, γ）组合而成。不同的亚基组合决定了受体对不同药物的敏感性以及最终产生的生理效应。GABA_A受体中的α1（Alpha-1）亚基与催眠和镇静作用密切相关，而α2和α3亚基更多地与抗焦虑作用相关，α5亚基则与认知和记忆功能有关。Z-药物在化学结构上虽然不同于苯二氮䓬类，但它们能够选择性地、高亲和力地结合到主要包含α1亚基的GABA_A受体上的苯二氮䓬结合位点（或其附近）。通过与这个位点结合，Z-药物同样能增加GABA介导的氯离子通道开放频率，增强GABA的抑制效应，促进神经元超极化，最终诱导睡眠。由于Z-药物对α1亚基具有更高的选择性，理论上，它们能够更精确地靶向睡眠诱导机制，而相对较少地影响与抗焦虑、肌肉松弛或抗惊厥作用相关的其他α亚基（α2, α3, α5）。这意味着：主要作用是催眠： Z-药物最显著的效果是促进睡眠，因此它们主要被批准用于治疗失眠症。理论上副作用谱不同： 相较于非选择性的BZDs，Z-药物可能具有较少的抗焦虑、肌肉松弛和抗惊厥作用（尽管在高剂量下这些作用也可能出现）。同时，它们对睡眠结构（特别是慢波睡眠和REM睡眠）的影响可能也与BZDs有所不同。药代动力学特点： 许多Z-药物（如唑吡坦和扎来普隆）被设计成具有快速起效和较短的作用持续时间，旨在帮助患者快速入睡，并减少次日残留的镇静效应（“宿醉感”）。艾司佐匹克隆的作用时间相对较长，更适用于维持睡眠。常见药物：唑吡坦 (Zolpidem/思诺思, Ambien)佐匹克隆 (Zopiclone/忆梦返)右佐匹克隆/艾司佐匹克隆 (Eszopiclone/Lunesta) - 佐匹克隆的右旋异构体，半衰期稍长扎来普隆 (Zaleplon/Sonata) - 半衰期极短，主要用于入睡困难风险：Z-药物仍然可能导致耐受性、生理依赖性、戒断症状（尤其是在长期使用或高剂量使用后突然停药）以及滥用的风险。常见的副作用包括头晕、头痛、嗜睡、口干、胃肠不适以及可能的次日认知功能损害。在特殊场景下，Z-药物与一些复杂的睡眠相关行为有关，如梦游、在睡眠状态下驾驶（睡眠驾驶）、进食、打电话等，患者醒来后对此完全没有记忆。这是美国FDA特别警示的一个严重风险。与BZDs一样，Z-药物不能与酒精或其他中枢神经系统抑制剂（如阿片类药物）同时使用，否则会极大地增加过度镇静和呼吸抑制的风险。3. 褪黑素受体激动剂 (Melatonin Receptor Agonists)原理介绍褪黑素受体激动剂是一类相对较新的镇静催眠药物，它们通过模拟人体内自然产生的褪黑素（Melatonin）的作用来调节睡眠-觉醒周期。代表性药物包括雷美替胺（Ramelteon）和他司美琼（Tasimelteon）。与前两类药物（苯二氮䓬类和Z-药物）根本不同的是，褪黑素受体激动剂不作用于GABA系统。它们的核心机制是调节人体的生物钟（Circadian Rhythm），而不是产生广泛的中枢神经系统抑制。我们大脑的下丘脑视交叉上核（Suprachiasmatic Nucleus, SCN）是人体的“主时钟”，负责调控昼夜节律。夜晚黑暗来临时，松果体会分泌褪黑素，褪黑素作用于SCN上的特定受体，向身体发出“夜晚已到，准备睡觉”的信号。褪黑素主要通过激活两种G蛋白偶联受体来发挥作用：MT1 受体： 激活MT1受体主要起到促进睡眠的作用，它能够抑制SCN的神经元活动，降低机体的觉醒水平。MT2 受体： 激活MT2受体则更多地参与调节生物钟的相位（Phase-Shifting），帮助调整睡眠-觉醒周期与外界环境（如光暗周期）同步。褪黑素受体激动剂（如雷美替胺）能够高选择性地结合并激活MT1和MT2受体，模拟内源性褪黑素的生理作用，通过激活MT1受体，帮助更快地进入睡眠状态；还可通过激活MT2受体，帮助调整紊乱的生物钟，使其与期望的睡眠时间对齐。这对于治疗睡眠时相延迟障碍或时差综合征（Jet Lag）等与生物钟相关的睡眠问题尤其有意义。他司美琼则专门用于治疗完全失明者的非24小时睡眠-觉醒障碍（Non-24）。特点由于这类药物的作用机制更接近于生理调节，而非强制性抑制，它们通常具有以下特点：主要改善入睡困难： 对于维持睡眠困难的效果可能不如GABA能药物。无滥用和依赖风险： 迄今为止的研究表明，褪黑素受体激动剂没有表现出像BZDs或Z-药物那样的依赖性、耐受性或戒断症状，因此它们不属于管制药品。对睡眠结构影响小： 通常不会显著改变正常的睡眠阶段分布（如REM睡眠和慢波睡眠）。次日残留效应少： 相较于作用时间较长的GABA能药物，次日嗜睡、认知功能受损的风险较低。常见药物雷美替胺 (Ramelteon / Rozerem)他司美琼 (Tasimelteon / Hetlioz)阿戈美拉汀 (Agomelatine / Valdoxan) - 这个药物比较特殊，除了是MT1/MT2激动剂外，还是5-HT2C受体拮抗剂，常用于伴有睡眠障碍的抑郁症。褪黑素类药物常见的副作用相对较轻，可能包括头晕、疲劳、恶心等。虽然依赖风险低，但仍需在医生指导下使用。需要注意的是，某些药物（如氟伏沙明）会显著抑制雷美替胺的代谢，增加其血药浓度和副作用风险，因此合并用药时需特别谨慎。这类药物可能不如BZDs或Z-药物那样提供强效的“催眠”感觉，对于寻求快速强效镇静的患者可能感觉效果不明显。4. 食欲素受体拮抗剂 (Orexin Receptor Antagonists)食欲素受体拮抗剂是一类相对较新的治疗失眠的药物，它们的作用机制与前面提到的苯二氮䓬类（BZDs）、Z-药物（作用于GABA系统）还有褪黑素受体激动剂完全不同。这类药物通过阻断大脑中促进觉醒的信号通路来发挥作用。要理解这类药物，首先需要了解食欲素（Orexin，也称为Hypocretin）系统。食欲素是由大脑下丘脑特定神经元产生的一类神经肽（包括食欲素-A和食欲素-B）。这个系统在调节我们清醒-睡眠周期中扮演着至关重要的角色，特别是维持清醒状态（Promoting Wakefulness）。可以把它想象成大脑中的一个“保持清醒”或“警觉”的开关。当食欲素释放并与其在大脑其他区域（如负责觉醒、情绪、能量代谢的脑区）的受体——食欲素受体1（OX1R）和食欲素受体2（OX2R）结合时，会激活这些神经元，从而促进和维持我们的清醒状态、警觉性和食欲等。研究发现，缺乏食欲素信号是导致发作性睡病（Narcolepsy）的主要原因，患者会表现为白天过度嗜睡和猝倒（突然失去肌肉张力）。食欲素受体拮抗剂的作用机制就是阻止内源性的食欲素与其受体（OX1R和/或OX2R）结合。通过占据这些受体结合位点但不激活它们，这些药物有效地阻断了食欲素发出的“保持清醒”的信号。这并不是像GABA药物那样广泛地抑制大脑活动，而是特异性地抑制了大脑中的觉醒驱动力。通过减弱这种觉醒信号，这类药物能够帮助降低大脑的警觉水平，从而促进睡眠的发生和维持。简单来说，它们不是强行“踩刹车”（增强抑制），而是“松开油门”（减弱兴奋/觉醒）。由于这种独特的作用机制，食欲素受体拮抗剂被认为可能对睡眠结构的影响较小，并且理论上可能减少传统催眠药的一些副作用，比如次日残留效应或依赖性风险（尽管仍需谨慎）。常见药物目前已上市的主要是双重食欲素受体拮抗剂（DORAs），意味着它们同时阻断OX1R和OX2R：苏沃雷生 (Suvorexant / Belsomra)：第一个获批上市的DORA。伦博雷生 (Lemborexant / Dayvigo)：另一个DORA。达利雷生 (Daridorexant / Quviviq)：较新的DORA。风险尽管作用机制不同，食欲素受体拮抗剂同样存在潜在的风险和副作用：最常见的副作用是次日嗜睡或困倦感 (Somnolence)，可能影响驾驶或其他需要警觉性的活动。因此，服药后应确保有足够的睡眠时间（通常建议至少7小时）。其他可能的副作用包括头痛、头晕、疲劳、口干、异常梦境等。需要警惕的风险包括：复杂睡眠行为（如梦游、睡眠驾驶、睡眠进食等），尽管发生率可能低于Z-药物，但仍有报道。可能加重抑郁症或出现自杀意念。极少数情况下可能出现睡眠瘫痪（醒来时暂时无法移动或说话）、入睡前/醒来时幻觉（Hypnagogic/Hypnopompic hallucinations）或类似发作性睡病中的猝倒样症状（Cataplexy-like symptoms，即短暂的肌肉无力）。药物相互作用：这些药物主要通过肝脏的CYP3A4酶代谢，与强效CYP3A4抑制剂（如酮康唑、克拉霉素）或诱导剂（如利福平、卡马西平）合用会显著影响其血药浓度，需要调整剂量或避免联用。禁忌症：患有发作性睡病的患者禁用此类药物，因为这会进一步抑制他们本已不足的食欲素信号。5. 具有镇静作用的抗抑郁药 (低剂量使用)某些抗抑郁药因为其药理特性具有显著的镇静副作用，在临床实践中，医生有时会利用这一特性，在远低于治疗抑郁症所需剂量的情况下，将它们处方给失眠患者，尤其是那些伴有抑郁或焦虑症状的患者，或者对传统催眠药反应不佳、不耐受或希望避免使用苯二氮䓬类/Z-药物的患者。原理这类抗抑郁药产生镇静作用的机制通常与它们阻断大脑中特定的神经递质受体有关，而不是（或不仅仅是）它们用于治疗抑郁的主要机制（如调节血清素或去甲肾上腺素的再摄取）。关键的受体包括：组胺H1受体 (Histamine H1 Receptor)：许多具有镇静作用的抗抑郁药（特别是米氮平、多虑平、阿米替林等）都是强效的组胺H1受体拮抗剂。组胺H1受体被阻断后，会产生类似于第一代抗组胺药（如苯海拉明）的嗜睡效果。这是它们镇静作用的主要来源之一。血清素5-HT2A受体 (Serotonin 5-HT2A Receptor)：曲唑酮和米氮平是显著的5-HT2A受体拮抗剂。阻断这个受体不仅有助于诱导睡眠，还可能改善睡眠结构，例如增加慢波睡眠（深度睡眠）。在低剂量下，曲唑酮的5-HT2A拮抗作用强于其血清素再摄取抑制作用。α1肾上腺素能受体 (Alpha-1 Adrenergic Receptor)：曲唑酮和三环类抗抑郁药（TCAs）也能阻断α1受体。这种阻断作用可以导致镇静，但也可能引起体位性低血压（站立时头晕）的副作用。毒蕈碱乙酰胆碱受体 (Muscarinic Acetylcholine Receptor)：三环类抗抑郁药（TCAs，如阿米替林、多虑平）和米氮平具有不同程度的抗胆碱能作用。这种作用可以贡献镇静效果，但也是许多不良副作用的来源，如口干、便秘、视力模糊、尿潴留和认知功能障碍（尤其在老年人中）。曲唑酮的抗胆碱能作用相对较弱。在用于失眠的低剂量下，这些药物对上述受体的拮抗作用往往是其发挥催眠效果的主要机制，而其经典的抗抑郁作用（通常需要更高剂量和更长时间才能显现）则不是重点。常见药物曲唑酮 (Trazodone / 美抒复)：非常常用的处方外（off-label）失眠治疗药物。低剂量（如25-100mg）下，其镇静作用（主要通过H1和5-HT2A拮抗）强于其抗抑郁作用。米氮平 (Mirtazapine / 瑞美隆)：强效的H1拮抗剂，镇静作用显著，尤其在较低剂量（如7.5-15mg）下。同时它也是一种有效的抗抑郁药，并且常常伴有食欲增加和体重增加的副作用。多虑平 (Doxepin)：一种老的三环类抗抑郁药。现在有极低剂量（3mg, 6mg）的剂型（商品名Silenor）被美国FDA专门批准用于治疗睡眠维持困难（即夜间易醒）。在这个极低剂量下，它主要作为高选择性的H1受体拮抗剂发挥作用，全身性的抗胆碱能和其他TCA副作用相对较少。较高剂量（用于抗抑郁）则镇静作用更强，副作用也更多。阿米替林 (Amitriptyline), 诺米替林 (Nortriptyline) 等三环类抗抑郁药 (TCAs)：这些老一代的抗抑郁药也具有很强的镇静作用（通过H1和抗胆碱能机制）。然而，由于它们的副作用谱较广（显著的抗胆碱能效应、体位性低血压、心脏毒性风险、体重增加等），特别是对老年人不友好，现在已较少仅仅为了治疗失眠而使用了，除非患者同时有需要治疗的抑郁症或特定类型的疼痛。风险照例，药物都会有对应的风险。最明显的就是**次日残留镇静作用（宿醉感），**这是最常见的副作用，可能影响日间功能。特异性副作用：曲唑酮：可能引起体位性低血压（头晕、跌倒风险）、阴茎异常勃起（一种罕见但需要紧急处理的严重副作用）。米氮平：常见的副作用是嗜睡、食欲增加、体重显著增加、口干。TCAs（尤其是较高剂量）：抗胆碱能副作用（口干、便秘、视力模糊、尿潴留、认知模糊）、心脏风险（心律失常，尤其在过量时）、体位性低血压、体重增加。低剂量多虑平（Silenor）的这些风险较低。停药问题：虽然成瘾性不如BZDs/Z-drugs，但长期使用后突然停药也可能导致不适或失眠反弹。药物相互作用：可能与其他药物发生相互作用，特别是其他中枢神经系统抑制剂（增加镇静）或影响心脏传导的药物（TCAs）。二、 抗抑郁药物 (Antidepressants)抑郁症和焦虑症的确切病因非常复杂，涉及遗传、环境、心理和社会等多方面因素。但我们目前可以简单认为大脑中某些关键神经递质的功能失调在其中扮演了重要角色，主要为以下三种：血清素（Serotonin, 5-HT）：与情绪、睡眠、食欲、焦虑调节密切相关。去甲肾上腺素（Norepinephrine, NE）：涉及警觉性、能量、注意力和应激反应。多巴胺（Dopamine, DA）：与快感、奖励、动机和运动控制有关。因此，现行抗抑郁药主要通过调节大脑中神经递质（如血清素、去甲肾上腺素、多巴胺）的水平来改善情绪。1. 选择性血清素再摄取抑制剂 (SSRIs)SSSRIs是目前临床上最常用的一类抗抑郁药物，也被广泛用于治疗焦虑障碍、强迫症、惊恐障碍等多种精神健康问题。它们之所以被广泛使用，是因为相较于早期的抗抑郁药（如三环类抗抑郁药、单胺氧化酶抑制剂），它们通常具有更好的耐受性和更高的安全性。原理要理解SSRIs的工作原理，首先需要了解大脑中的一种重要神经递质——血清素（Serotonin, 5-HT）。血清素在大脑中扮演着调节情绪、睡眠、食欲、焦虑、性欲等多种功能的关键角色。在我们的大脑中，神经元（脑细胞）通过释放神经递质（如血清素）到两个神经元之间的微小间隙——突触间隙（Synaptic Cleft）——来传递信号。当一个神经元（突触前神经元）释放血清素到突触间隙后，这些血清素会与下一个神经元（突触后神经元）上的血清素受体结合，从而传递信号，影响情绪等功能。为了精确控制信号强度和持续时间，突触前神经元上有一个特殊的“回收泵”——血清素转运体（Serotonin Transporter, SERT）。这个转运体会将突触间隙中多余的或完成任务的血清素“吸回”到突触前神经元内部，进行再利用或分解，这个过程称为再摄取（Reuptake）。那么，问题就来了.jpg研究发现抑郁症等情绪障碍往往与大脑内血清素水平或功能失调有关，所以SSRIs的核心作用就是选择性地抑制（Block）这个血清素转运体（SERT）。当SERT被抑制后，血清素从突触间隙被回收的速度减慢，导致突触间隙中的血清素浓度升高，并延长其作用时间。这样，就有更多的血清素能够与突触后神经元的受体结合，从而增强血清素能神经系统的信号传递，最终帮助改善情绪、减轻焦虑等症状。常见药物氟西汀 (Fluoxetine) - (Prozac / 百忧解) - 半衰期较长，停药时撤药反应相对较轻。舍曲林 (Sertraline) - (Zoloft / 左洛复) - 常用于抑郁伴焦虑，对胃肠道副作用可能稍明显。帕罗西汀 (Paroxetine) - (Paxil / 赛乐特) - 抗焦虑效果较强，但镇静作用和体重增加、撤药反应可能相对明显。西酞普兰 (Citalopram) - (Celexa / 喜普妙) - 耐受性较好，但高剂量时需注意QT间期延长的风险。艾司西酞普兰 (Escitalopram) - (Lexapro / 来士普) - 是西酞普兰的有效异构体，通常认为选择性更高，耐受性更好，起效可能更快。氟伏沙明 (Fluvoxamine) - (Luvox / 兰释) - 对强迫症的治疗效果尤为突出，药物相互作用相对较多。常见副作用尽管SSRIs相对安全，但仍可能引起一些副作用。这些副作用通常在治疗初期出现，随着身体适应药物，很多副作用会逐渐减轻或消失。胃肠道反应（最常见）： 恶心、呕吐、腹泻、便秘、食欲改变（增加或减少）、口干。通常建议餐后服药以减轻胃肠道不适。神经系统反应：头痛、头晕。睡眠障碍：失眠（难以入睡或早醒）或嗜睡（白天感到困倦）。焦虑、紧张、烦躁不安（尤其在治疗初期可能暂时加重）。震颤（手抖）。性功能障碍： 这是SSRIs一个比较突出且可能长期存在的副作用，影响男女患者。包括性欲减退、勃起困难、射精延迟或无法射精、性高潮延迟或缺失。如果出现此问题，务必与医生沟通，可能需要调整剂量、换药或加用其他药物处理。其他常见副作用：出汗增多。疲劳、乏力。体重变化：长期使用可能导致体重增加（尤其是帕罗西汀），少数人可能体重减轻。:::note\n噔噔咚，我们还有不常见副作用呢\n:::不常见副作用情绪或行为改变： 极少数情况下，特别是在儿童、青少年和年轻成人中，开始服药或调整剂量时，可能增加自杀意念或行为的风险（美国FDA有“黑框警告”提示此风险）。需要密切监测情绪变化，尤其是治疗初期。血清素综合征 (Serotonin Syndrome)： 一种罕见但可能危及生命的状况，通常发生在同时使用多种增加血清素水平的药物（如其他抗抑郁药、某些止痛药、偏头痛药物、草药圣约翰草等）或SSRIs过量时。症状包括：精神状态改变（焦虑、激动、谵妄、昏迷）、自主神经功能紊乱（心跳加快、血压波动、高热、出汗、瞳孔散大）、神经肌肉症状（肌肉僵硬、抽搐、反射亢进、震颤）。一旦怀疑，需立即就医。低钠血症 (Hyponatremia)： 尤其在老年人中风险较高，可引起头痛、注意力不集中、记忆损害、意识模糊、虚弱、站立不稳甚至跌倒。严重时可导致癫痫发作或昏迷。出血风险增加： SSRIs可能影响血小板功能，增加瘀伤或出血的风险，尤其在同时使用非甾体抗炎药（NSAIDs如布洛芬）、阿司匹林或抗凝药（如华法林）时。撤药反应 (Discontinuation Syndrome)： 如果突然停药或过快减量，可能出现一系列不适症状，如头晕、恶心、焦虑、失眠、感觉异常（如“电击感”）、流感样症状等。因此，停药必须在医生指导下逐渐减量。QT间期延长： 某些SSRIs（特别是西酞普兰和艾司西酞普兰在高剂量时）可能影响心脏电活动，增加心律失常风险。2. 血清素和去甲肾上腺素再摄取抑制剂 (SNRIs)原理正如其名所示，SNRIs的作用涉及到两种关键的神经递质：血清素 (Serotonin, 5-HT) 和 去甲肾上腺素 (Norepinephrine, NE)。SNRIs与SSRIs类似，也是现代常用的抗抑郁药，但它们的作用机制略有不同，影响的神经递质范围更广一些。除了抑郁症，它们也常用于治疗广泛性焦虑障碍、社交焦虑障碍、惊恐障碍以及某些类型的慢性疼痛（尤其是神经病理性疼痛）。在大脑中，去甲肾上腺素主要与警觉性、注意力、能量水平、动机以及身体对压力的反应（“战斗或逃跑”反应）有关。它也对情绪调节有重要作用。甲肾上腺素系统的功能失调也可能与抑郁症和焦虑症的症状（如疲劳、注意力不集中、缺乏动力）有关。通过抑制这两种转运体，SNRIs能够提高突触间隙中血清素和去甲肾上腺素的浓度，延长它们的作用时间，从而同时增强血清素能和去甲肾上腺素能神经系统的信号传递。与SSRIs类似，SNRIs的抗抑郁效果通常也需要数周才能完全显现。那么，SNRIs和我们之前提到的SSRIs的区别是什么呢？通过同时调节血清素和去甲肾上腺素，理论上SNRIs可能对更广泛的抑郁症状比SSRIs有效，特别是对于那些伴有明显疲劳、动力缺乏或身体疼痛症状的患者。去甲肾上腺素通路也参与调节身体的疼痛信号传递。因此，某些SNRIs（如度洛西汀、文拉法辛）也被批准用于治疗某些慢性疼痛状况，如糖尿病周围神经病变痛、纤维肌痛和慢性肌肉骨骼疼痛。常见药物文拉法辛 (Venlafaxine) - (Effexor XR / 怡诺思缓释胶囊) - 第一个上市的SNRI，剂量依赖性地抑制SERT和NET。缓释剂型（XR）更常用，以减少副作用和方便给药。去甲文拉法辛 (Desvenlafaxine) - (Pristiq / 唯泰) - 是文拉法辛的主要活性代谢产物，其对SERT和NET的抑制比例相对固定，不受肝脏代谢酶个体差异的影响。度洛西汀 (Duloxetine) - (Cymbalta / 欣百达) - 对SERT和NET的抑制作用相对均衡，广泛用于抑郁症、广泛性焦虑障碍以及多种慢性疼痛状况。米那普仑 (Milnacipran) - (Savella / 亿珂 - 在美国主要用于纤维肌痛；Ixel - 在某些国家用于抑郁症) - 对NET的抑制作用略强于或等于对SERT的抑制作用。左旋米那普仑 (Levomilnacipran) - (Fetzima) - 是米那普仑的活性对映异构体，对NET的抑制作用显著强于对SERT的抑制作用。常见副作用由于SNRIs同时影响血清素和去甲肾上腺素系统，它们的副作用谱是SSRIs副作用和去甲肾上腺素能副作用的叠加。双倍的享受，双倍的痛苦！与SSRIs相似的副作用（源于血清素系统影响）：恶心、口干、便秘或腹泻、食欲改变。头痛、头晕。失眠或嗜睡。性功能障碍（性欲减退、射精/高潮困难等）。焦虑、紧张（尤其在治疗初期）。额外的或更显著的副作用（源于去甲肾上腺素系统影响）：血压升高 (Hypertension)： 这是SNRIs（尤其是文拉法辛高剂量时）一个需要特别关注的副作用。开始治疗前和治疗期间需要定期监测血压。心率增快 (Tachycardia)： 可能感到心跳加速或心悸。出汗增多 (Diaphoresis)： 通常比SSRIs更常见或更严重。口干 (Xerostomia)： 也可能比SSRIs更明显。便秘： 相较于腹泻可能更常见（但个体差异大）。失眠、激动： 去甲肾上腺素的激活作用可能导致入睡困难或感觉更“兴奋”。排尿困难或尿潴留： 虽然不常见，但有可能发生，尤其是有前列腺问题的男性。赫赫，不常见副作用要来了不常见副作用血清素综合征： 风险与SSRIs类似，联合用药时需特别注意。撤药反应： 突然停药或过快减量可能导致撤药症状，文拉法辛的撤药反应通常被认为比较明显和常见，必须在医生指导下缓慢减量。症状可包括头晕、恶心、焦虑、失眠、感觉异常（“脑部电击感”）、流感样症状等。出血风险增加： 机制与SSRIs相似。低钠血症： 风险与SSRIs相似，老年人更需注意。情绪或行为改变： 同样存在“黑框警告”，提示在儿童、青少年和年轻成人中可能增加自杀意念风险。肝脏毒性风险： 度洛西汀有罕见的肝损伤报告，有肝病史或大量饮酒者需慎用或避免使用。闭角型青光眼风险： 去甲肾上腺素作用可能导致瞳孔散大，有窄房角或闭角型青光眼病史的患者需慎用。3. 三环类抗抑郁药 (TCAs)原理TCAs是继单胺氧化酶抑制剂（MAOIs）之后上市的第二代抗抑郁药，在20世纪50年代末至60年代初被发现并应用于临床。在SSRIs和SNRIs问世之前，它们是治疗抑郁症的主要药物。尽管由于其副作用谱较广和过量风险较高，现在已不常作为一线药物使用，但TCAs仍然是非常有效的抗抑郁药，尤其对于某些特定类型或难治性的抑郁症，以及某些其他疾病（如神经病理性疼痛、偏头痛预防、失眠、夜遗尿等）仍然占有一席之地。:::note\n这位更是第二老的重量级大哥\n:::其实与SNRIs类似，大多数TCAs能同时抑制突触前神经元上的血清素转运体 (SERT) 和 去甲肾上腺素转运体 (NET)，从而提高突触间隙中这两种神经递质的浓度，增强相应的神经信号传递。不同TCA药物对SERT和NET的抑制强度比例有所不同（例如，氯米帕明对SERT抑制作用强，而去甲丙咪嗪对NET抑制作用强）。但，TCAs与SSRIs还有SNRIs最显著的区别，也是其副作用较多的主要原因是TCAs还会不同程度地阻断（拮抗）大脑和身体其他部位的多种受体，包括：毒蕈碱样乙酰胆碱受体 (Muscarinic Acetylcholine Receptors)： 导致抗胆碱能副作用。组胺H1受体 (Histamine H1 Receptors)： 导致镇静和体重增加。α1-肾上腺素能受体 (Alpha-1 Adrenergic Receptors)： 导致体位性低血压和头晕。部分TCAs还可能影响钠离子通道和钙离子通道，这与其心脏毒性有关。但是啊但是，姜还是老的辣，尽管副作用多，TCAs的抗抑郁效果通常被认为是强效的，有时在重度或伴有精神病性特征的抑郁症中效果优于较新的药物。常见药物阿米替林 (Amitriptyline) - (Elavil / 依拉维林) - 镇静作用和抗胆碱能作用较强，常用于伴有失眠或焦虑的抑郁症，也广泛用于神经痛和偏头痛预防。去甲替林 (Nortriptyline) - (Pamelor / 帕米洛) - 是阿米替林的活性代谢产物，通常认为其镇静、抗胆碱能和体位性低血压副作用相对较轻，耐受性可能更好。血药浓度监测较常用。丙咪嗪 (Imipramine) - (Tofranil / 托非尼) - 是最早的TCA之一，也用于治疗惊恐障碍和儿童夜遗尿。去甲丙咪嗪 (Desipramine) - (Norpramin / 诺普兰明) - 是丙咪嗪的活性代谢产物，对去甲肾上腺素再摄取的抑制作用相对更强，抗胆碱能和镇静作用相对较弱。氯米帕明 (Clomipramine) - (Anafranil / 安拿芬尼) - 对血清素再摄取的抑制作用在TCAs中最强，是治疗强迫症 (OCD) 的金标准药物之一，但也常伴有较强的副作用。多虑平 (Doxepin) - (Sinequan / 西那泉) - 具有非常强的组胺H1受体阻断作用，镇静作用显著，低剂量常用于治疗失眠（商品名Silenor）。也用于治疗焦虑和抑郁，局部制剂用于治疗瘙痒。常见副作用先把最危险的放在前面。:::caution\nTCAs的过量风险极高\n:::相对于SSRIs和SNRIs，TCA过量非常危险，即使是相对较小的过量也可能导致严重的心脏毒性（致命性心律失常）、癫痫发作、昏迷和呼吸抑制，需要紧急医疗救治。 因此，对于有自杀风险的患者，处方TCAs时通常会限制单次处方量。TCAs的副作用谱较广，与它们阻断的多种受体直接相关：抗胆碱能副作用 (Anticholinergic Effects)：口干 (非常常见)视力模糊（调节障碍）便秘排尿困难或尿潴留（尤其在有前列腺增生的男性中）心动过速认知功能障碍（如记忆力下降、注意力不集中、意识模糊），尤其在老年人中风险更高。组胺H1受体阻断副作用 (Antihistaminic Effects)：镇静、嗜睡、疲劳（尤其在治疗初期，可利用此特性治疗失眠）体重增加、食欲增加α1-肾上腺素能受体阻断副作用 (Alpha-1 Blockade Effects)：体位性（直立性）低血压（从坐位或卧位站起时感到头晕、眼前发黑，甚至晕厥），增加跌倒风险，尤其在老年人中。头晕心血管副作用 (Cardiovascular Effects)：心动过速（Tachycardia）心电图改变：可能延长PR、QRS和QT间期，增加心律失常的风险。这是TCA过量致死的主要原因。 在开始治疗前和治疗期间，尤其对于有心脏病史或风险的患者，可能需要进行心电图监测。神经系统副作用：震颤（手抖）（罕见）癫痫发作风险增加（降低癫痫阈值）（罕见）锥体外系症状性功能障碍：性欲减退、勃起功能障碍、射精异常、性高潮障碍。撤药反应：突然停药可引起胆碱能反跳（恶心、腹泻、流涎）、失眠、焦虑、激越、头痛、流感样症状等。必须在医生指导下缓慢减量停药。4. 单胺氧化酶抑制剂 (MAOIs):::note\n这位更是第一老的远古级老大哥\n:::MAOIs是最早被发现并用于治疗抑郁症的药物之一，大约在20世纪50年代问世。它们是强效的抗抑郁药，尤其对于某些特定类型的抑郁症（如非典型抑郁症，特征包括情绪反应性、体重增加、食欲增加、铅样麻痹感、对拒绝过分敏感）以及对其他治疗无效的难治性抑郁症可能非常有效。然而，由于其严格的饮食限制和潜在的危险药物相互作用，MAOIs现在通常不作为一线或二线治疗选择，一般保留给对其他多种抗抑郁药治疗无效或不耐受的患者，并且需要在经验丰富的医生严密监测下使用。原理要理解MAOIs，首先要了解单胺氧化酶 (Monoamine Oxidase, MAO)，这是一种存在于身体多种组织（包括大脑、肝脏、肠道）中的酶。它的主要功能是分解（代谢）单胺类神经递质，包括：血清素 (Serotonin, 5-HT)去甲肾上腺素 (Norepinephrine, NE)多巴胺 (Dopamine, DA)以及食物和某些药物中存在的酪胺 (Tyramine)。看到这里，可能有的观众就释怀地笑了，毕竟这几种物质都是我们的老熟人了对伐？顾名思义，MAOIs类药物通过抑制单胺氧化酶的活性来发挥作用。传统的MAOIs（如苯乙肼、反苯环丙胺、异卡波肼） 通常是非选择性的（同时抑制MAO-A和MAO-B） 并且是不可逆的（药物与酶结合后，酶的活性无法恢复，需要身体合成新的酶才能恢复功能，这通常需要大约两周时间）。当然，也有一些是可逆的MAOIs（如吗氯贝胺，moclobemide，在某些国家可用）或选择性的MAOIs（如司来吉兰，selegiline，低剂量时主要抑制MAO-B，用于帕金森病；高剂量或透皮贴剂形式用于抑郁症时，也会抑制MAO-A）。通过抑制MAO酶，MAOIs阻止了血清素、去甲肾上腺素和多巴胺的分解，从而增加了这些神经递质在神经元内和突触间隙中的浓度，增强了它们在脑内的信号传递作用，最终达到抗抑郁的效果。由于同时提升了三种主要的单胺类神经递质，其效果可能非常强力。劲啊！常见药物苯乙肼 (Phenelzine) - (Nardil) - 非选择性、不可逆反苯环丙胺 (Tranylcypromine) - (Parnate) - 非选择性、不可逆异卡波肼 (Isocarboxazid) - (Marplan) - 非选择性、不可逆司来吉兰 (Selegiline)口服低剂量 (Eldepryl, Zelapar) - 选择性MAO-B抑制剂，主要用于帕金森病。透皮贴剂 (Emsam) - 用于抑郁症。通过皮肤吸收，在较低剂量（如6mg/24h）时可能部分绕过对肠道MAO-A的抑制，从而可能降低（但并非完全消除）与食物中酪胺发生相互作用的风险。但在更高剂量（9mg/24h, 12mg/24h）时，仍需严格饮食限制。吗氯贝胺 (Moclobemide) - (Aurorix, Manerix) - 选择性、可逆的MAO-A抑制剂 (RIMA)。由于其可逆性，与酪胺的相互作用风险相对较低（但仍需注意，尤其大量摄入酪胺时），药物相互作用风险也可能稍低。但在美国未被批准上市。接下来就是我们第一不喜欢的副作用环节了。常见的副作用及极其重要的警告常见副作用：体位性低血压 (Orthostatic Hypotension)： 这是MAOIs非常常见的副作用，可能导致头晕、晕厥和跌倒。失眠 (Insomnia)： 尤其反苯环丙胺可能更具兴奋性。体重增加 (Weight Gain)： 尤其苯乙肼比较常见。性功能障碍 (Sexual Dysfunction)： 性欲减退、性高潮缺失等。水肿 (Edema)： 脚踝等部位可能出现水肿。镇静或嗜睡： 也可能发生，但不如失眠常见。口干、便秘、排尿困难等抗胆碱能样副作用（但通常比TCAs轻）。极其重要的警告：致命的相互作用风险酪胺诱发的高血压危象 (Hypertensive Crisis from Tyramine Interaction)：原因： 食物中的酪胺是一种会升高血压的物质。正常情况下，肠道和肝脏中的MAO-A会将其分解。当使用MAOIs（特别是抑制MAO-A的）时，这种分解作用被抑制，摄入的酪胺会大量进入血液循环，刺激肾上腺素和去甲肾上腺素大量释放，导致血压急剧、危险地升高。需要严格避免的食物和饮料（富含酪胺）：陈年/发酵/烟熏/腌制的食品：各种陈年奶酪（如切达干酪、蓝纹奶酪、瑞士干酪、帕玛森干酪等；新鲜奶酪如茅屋奶酪、奶油奶酪通常安全）腌制、烟熏或风干的肉类/鱼类（如腊肠、意大利香肠、熏肉、咸鱼、鱼子酱等；新鲜烹制的肉/鱼安全）发酵的豆制品（如腐乳、豆豉、纳豆、某些酱油/豆瓣酱）腌菜（如德国酸菜）酵母提取物（如马麦酱 Marmite、维吉麦酱 Vegemite）某些酒类： 生啤酒、特定红酒（如基安蒂酒 Chianti）、雪利酒、利口酒。过度成熟的水果（如香蕉皮、过度成熟的牛油果、无花果）蚕豆 (Fava beans / Broad beans) 的豆荚。症状： 突发的剧烈头痛（通常在后枕部）、心悸、颈部僵硬、恶心、呕吐、出汗、瞳孔散大、畏光、心率或血压急剧升高。这是一种医疗急症，可能导致中风、心肌梗死甚至死亡，必须立即就医！持续时间： 即使停用不可逆MAOI，饮食限制也需要持续到停药后至少2周，以等待新的MAO酶合成。危险的药物相互作用：血清素综合征 (Serotonin Syndrome)： MAOIs与所有能增加血清素水平的药物合用都是绝对禁忌的，极其危险，可能致命。包括：SSRIs、SNRIs、TCAs曲坦类药物（用于偏头痛，如舒马普坦）某些阿片类止痛药（如哌替啶/度冷丁 (Meperidine)、曲马多 (Tramadol)、芬太尼、美沙酮）右美沙芬 (Dextromethorphan，常见于止咳药中)草药圣约翰草 (St. John's Wort)其他MAOIs利奈唑胺 (Linezolid，一种抗生素，也具有MAOI活性)亚甲蓝 (Methylene blue)切换药物时需要极长的洗脱期： 从这些药物换到MAOI，或从MAOI换到这些药物，通常需要至少2周（对于氟西汀，由于其长半衰期，需要至少5周）的间隔时间。与拟交感神经药物的相互作用（导致高血压危象）：减充血剂（常见于感冒药或鼻喷剂中，如伪麻黄碱 (Pseudoephedrine)、去氧肾上腺素 (Phenylephrine)、麻黄碱 (Ephedrine)）兴奋剂（如安非他明 (Amphetamine)、哌甲酯 (Methylphenidate)）某些局部麻醉药中含有的血管收缩剂（如肾上腺素 (Epinephrine)）——需要告知牙医或外科医生正在使用MAOI。多巴胺、去甲肾上腺素等升压药。与某些降压药的相互作用： 可能导致血压过度降低。与全身麻醉药的相互作用： 手术前必须告知麻醉师正在使用MAOI，可能需要提前停药。如……如何呢？这就是MAOIs，听肺科医生说。5. 非典型抗抑郁药 (Atypical Antidepressants)这个类别更像是一个集合，包含了那些作用机制独特，不能明确归入SSRIs、SNRIs、TCAs或MAOIs类别的抗抑郁药物。它们的作用靶点和药理特性各不相同，因此其疗效特点和副作用谱也呈现多样性。选用这类药物通常基于患者的具体症状、对其他药物的反应或耐受性，以及期望避免某些特定副作用（如性功能障碍或体重增加）的考虑。安非他酮（Bupropion）(Wellbutrin / 维博缓释片, Zyban / 载班 - 用于戒烟)此药物主要通过抑制去甲肾上腺素 (NE) 和 多巴胺 (DA) 的再摄取（NDRI），对血清素系统的影响很小。这种独特机制解释了其较少引起性功能障碍和体重增加的原因。特点： 主要影响NE和DA，性功能副作用罕见（有时反而改善），不引起体重增加（有时反而减轻）。但有剂量依赖性诱发癫痫的风险（尤其在有癫痫史、贪食症/神经性厌食症患者中禁用）。也批准用于戒烟。常见副作用：失眠、头痛、口干、恶心、焦虑、震颤。主要风险是癫痫发作，务必遵循剂量限制，并告知医生所有可能增加风险的因素。米氮平 (Mirtazapine) - (Remeron / 瑞美隆)属于去甲肾上腺素能和特异性血清素能抗抑郁药 (NaSSA)。它通过阻断突触前α2-肾上腺素能自身受体和异质受体，增加NE和5-HT的释放。同时，它强效阻断5-HT2A、5-HT2C、5-HT3以及组胺H1受体。阻断H1受体是其显著镇静作用和导致体重增加的原因；阻断5-HT2和5-HT3受体可能有助于减少焦虑和胃肠道副作用，并可能改善性功能。特点： 强效镇静作用（尤其在低剂量时），显著增加食欲和体重。常用于伴有严重失眠和食欲减退的抑郁症患者。性功能副作用发生率低。常见副作用：嗜睡、镇静、体重增加、食欲增加、口干、头晕。曲唑酮 (Trazodone) - (Desyrel / 美抒复)属于血清素拮抗剂和再摄取抑制剂 (SARI)。它主要通过阻断5-HT2A受体（这被认为是其主要的抗抑郁、抗焦虑和催眠作用机制）和较弱地抑制血清素转运体 (SERT)。它还阻断α1-肾上腺素能受体（导致体位性低血压和头晕）和组胺H1受体（导致镇静）。低剂量时主要利用其H1和5-HT2A阻断作用来治疗失眠。特点： 高剂量（如150-600mg/天）时具有抗抑郁作用，但常因镇静和头晕而受限。低剂量（如25-150mg/天）广泛用作催眠药物。需要警惕罕见但严重的阴茎异常勃起 (Priapism) 风险（持续、疼痛的勃起，需立即就医）。常见副作用：嗜睡、头晕、口干、体位性低血压、阴茎异常勃起（罕见但紧急）。伏硫西汀 (Vortioxetine) - (Trintellix / 心达悦, Brintellix)是一种多模式 (Multimodal) 抗抑郁药。它抑制SERT，同时还作为多种血清素受体的调节剂（如5-HT1A激动剂、5-HT1B部分激动剂、5-HT3/5-HT1D/5-HT7拮抗剂）。这种复杂的作用模式被认为可能对其改善抑郁症相关的认知症状有贡献。特点： 多模式作用机制，除了抗抑郁外，可能有改善抑郁症相关认知功能（如注意力和执行功能）的潜力。常见的副作用是恶心（尤其在治疗初期）。性功能障碍发生率低于SSRIs/SNRIs。常见副作用：恶心（常见）、呕吐、便秘、头晕。维拉唑酮 (Vilazodone) - (Viibryd)属于血清素部分激动剂/再摄取抑制剂 (SPARI)。它既抑制SERT（像SSRI一样），又作为5-HT1A受体的部分激动剂。理论上，这种双重作用可能提供与SSRI相当的疗效，同时可能具有更快的起效速度和较低的性功能障碍发生率（尽管临床数据不一）。特点： SSRI加5-HT1A部分激动剂。常见的副作用是胃肠道反应（腹泻、恶心），通常建议与食物同服以增加吸收并可能减轻胃肠不适。性功能障碍发生率可能低于传统SSRIs。常见副作用：腹泻、恶心（常见）、头晕、失眠。需与食物同服。阿戈美拉汀 (Agomelatine) - (Valdoxan / 维度新)作用机制非常独特，是褪黑素MT1和MT2受体激动剂，同时也是5-HT2C受体拮抗剂。通过激动褪黑素受体，它有助于调节紊乱的昼夜节律（这在抑郁症中很常见）。拮抗5-HT2C受体可以间接增加大脑额叶皮质区的去甲肾上腺素和多巴胺水平。特点： 通过褪黑素和5-HT2C受体起作用，有助于恢复正常的睡眠-觉醒周期。性功能障碍和体重增加的风险低。重要： 有潜在肝毒性风险，治疗前和治疗期间需要定期监测肝功能（转氨酶）。有肝损害者禁用。常见副作用：头痛、头晕、恶心、腹泻、疲劳。主要关注点是肝功能监测。"
  },
  {
    "title": "一份关于美联储的报告（上）：联储介绍与基本经济概念的厘定",
    "summary": "如果你关注财经新闻，那一定听过美联储的大名——它的每一次加息、降息，甚至主席的一次演讲（甚至主席演讲的第一个单词），都可能在全球市场掀起惊涛骇浪。但对于大多数人来说，美联储仍然笼罩着一层神秘色彩。美联储（Federal Reserve，简称Fed）是美国的中央银行，成立于1913年，初衷是为了终结当时频发的银行业恐慌。如今，它的职责已远远超出最初的设想——从调控利率到充当金融系统的最后贷款人，再到",
    "tags": [
      "暗涌"
    ],
    "url": "/posts/Finance and Economics/fed-report-01/",
    "date": "2025-03-27T00:00:00.000Z",
    "content": "如果你关注财经新闻，那一定听过美联储的大名——它的每一次加息、降息，甚至主席的一次演讲（甚至主席演讲的第一个单词），都可能在全球市场掀起惊涛骇浪。但对于大多数人来说，美联储仍然笼罩着一层神秘色彩。美联储（Federal Reserve，简称Fed）是美国的中央银行，成立于1913年，初衷是为了终结当时频发的银行业恐慌。如今，它的职责已远远超出最初的设想——从调控利率到充当金融系统的最后贷款人，再到在经济危机时大手笔救市，它几乎称得上是美国（甚至全球）经济的\"隐形操纵者\"。表面上看，美联储像是一个技术官僚机构，由经济学家和金融专家组成，通过复杂的数学模型制定货币政策。但实际上，它的每一次决策都充斥着政治与经济的博弈。它的\"双重使命\"——稳定物价和最大化就业，本身就经常互相矛盾。当通胀高企时，它必须狠心加息来冷却经济；而当危机爆发，它又不得不打开\"印钞机\"，用天量资金托住摇摇欲坠的市场。2008年金融危机和2020年疫情冲击，让美联储的权能进一步扩张。它从传统的利率调节者，变成了直接下场购买公司债、支撑股市的\"救世主\"。虽然这些举措避免了更严重的崩溃，但也引发了巨大争议：中央银行是否越界了？印钞救市的狂欢过后，账单又该由谁来支付？下面就让我们从美联储的基本架构与基本的经济概念入手，一步步拆解它的“神秘面纱”，并探讨这些政策如何通过金融市场传导到你的钱包、我的生活乃至全球经济体之中。一、美联储的基本介绍美联储（Federal Reserve System）成立于 1913 年，源于当时美国金融体系屡受银行挤兑和经济恐慌的冲击。由于美国在 19 世纪末 20 世纪初频繁出现金融危机，时任政府和国会希望建立一个能在关键时刻提供流动性支持并维持金融稳定的中央银行制度。《联邦储备法案》（Federal Reserve Act）在 1913 年获得通过，自此诞生了美联储这一兼具公共属性和私有运作特征的中央银行体系。1.总体结构美联储的组织结构相对复杂，主要由以下三大部分组成：联邦储备委员会（Board of Governors）联邦公开市场委员会（FOMC）12 家地区联邦储备银行（Federal Reserve Banks）同时，美联储与国会之间保持相对独立但又需向后者汇报。在执行货币政策时，美联储不受行政部门的直接干预；但在机构设置与成员任命等方面，美联储又受到美国政府的影响。（1）联邦储备委员会（Board of Governors）联邦储备委员会是美联储系统的中枢，负责指导和监督整个美联储体系的运作。委员会位于华盛顿特区，由 7 名成员（理事）组成。每位成员由总统提名，并经参议院批准产生，任期长达 14 年，旨在保证政策的连续性与独立性。联邦储备委员会的主要职责是指定全国性货币政策与监管规则，对商业银行的合并及其他重大事项进行审批。在日常进行监督监管银行体系以维护金融稳定，并向国会提交货币政策报告，定期与国会沟通美联储政策走向。（2）联邦公开市场委员会（FOMC）联邦公开市场委员会是美联储最核心的货币政策决策机构，其主要职责是制定公开市场操作（Open Market Operations）。FOMC共有12名成员，包含7位由总统任命并经参议院确认的联邦储备委员会成员，以及纽约联储行长和另外4位地区联储行长（在其余11家地区联储行长中轮流担任，任期通常为一年）。其中，纽约联储行长拥有永久投票权，这是因为纽约联储位于美国的金融核心地带，承担着实际执行公开市场操作的职能，是FOMC政策决定的主要落地者。FOMC负责制定货币政策目标和实施方案（主要通过调整联邦基金利率目标范围、买卖国债等方式），根据国内外经济形势来调整联储的货币政策立场。FOMC会定期举行会议（通常每年 8 次），并通过政策声明向公众传达对经济前景及货币政策的看法。（3）地区联邦储备银行（Federal Reserve Banks）美国境内共有 12 家地区联储银行，分别位于波士顿、纽约、费城、克里夫兰、里士满、亚特兰大、芝加哥、圣路易斯、明尼阿波利斯、堪萨斯城、达拉斯和旧金山。每家地区联储银行都独立运营，覆盖所在地区的金融及经济事务。这些联邦储备银行的职能其实和我国的各省市人民银行的职能差不多：为当地商业银行提供服务（例如向商业银行供给现金、清算支票等）代表美联储执行货币政策相关的操作，如在其辖区内购买或出售国债收集地区经济与金融数据，为 FOMC 制定货币政策提供依据对辖区内的银行进行日常审查和监管2.美联储的目标是什么？从上述架构可以看出，美联储作为美国的中央银行，集决策、执行与监管多重职能于一身，其职责远不止“印钞”或设定利率这么简单。理论上美联储有五大职能，分别是执行国家货币政策、维护金融系统稳定、监管金融机构、保障支付与结算系统和促进消费者保护与社区经济发展，但这里我们还是不要看那么多虚的，直接关注美联储的核心职责。如果要用一句话来概括美联储的核心职责，那就是：在保持物价稳定的前提下，尽可能促进充分就业，在此基础上，美联储也会兼顾金融市场稳定，努力防范系统性风险对美国乃至全球的冲击。根据1977年《联邦储备法修正案》，美联储被正式赋予了两项具有同等重要性的法定目标：促进充分就业（Maximum Employment）保持物价稳定（Price Stability）（1）促进充分就业“充分就业”指的是将失业率维持在一个较低且可持续的水平，让有劳动能力和意愿的民众都能在合理的时间范围内找到工作。经济学家们对\"充分就业\"的定义就莫衷一是——是指失业率4%还是5%？要不要考虑劳动力参与率？如何看待结构性失业？而我们的美联储对此的处理很有智慧：它从不设定具体的失业率目标，而是通过分析全方位的劳动力市场指标（包括工资增长、职位空缺数、劳动参与率等）来综合判断就业市场的健康状况。理论上说，充分就业不仅意味着个体收入和生活质量的提高，也能增强消费与投资信心，为经济创造良性循环。当劳动力市场稳固时，企业的投资意愿往往增强，进而带动整体经济活力。而失业率过高会造成社会资源浪费、居民收入下降和消费萎缩，进而影响经济增长和社会稳定。那么，当失业率过高，经济增长乏力时，美联储通常会使用宽松的货币政策工具（如降低联邦基金利率目标、增加货币供应），以刺激信贷和消费需求。这样做可以降低融资成本，鼓励企业投资扩张，从而创造更多就业机会。（2）保证物价稳定在另一端，物价稳定是社会经济运行的基础条件之一。与就业目标不同，美联储对物价稳定的定义非常明确：将核心PCE物价指数的年度涨幅保持在2%左右。维持温和且可预期的通胀水平，有助于企业进行长期规划，也能保护居民的实际购买力。一个健康的物价环境使市场行为更具可预见性，从而降低不确定性对经济活动造成的干扰。过高的通胀会导致货币购买力下降、生活成本上升；而通胀过低乃至通缩，则会抑制企业与消费者的支出意愿，导致经济陷入下行循环。当通胀预期或实际通胀率明显攀升时，美联储会采取紧缩性货币政策（如上调联邦基金利率或缩减资产负债表），通过提高融资成本来抑制过热的需求；反之，当通胀疲弱甚至面临通缩风险时，美联储会倾向使用宽松手段，鼓励企业与消费者加大支出，从而缓解通缩压力。（3）隐形的第三使命：金融稳定虽然法律没有明文规定，但2008年金融危机后，维护金融体系稳定已实际成为美联储的\"第三使命\"。金融市场一旦出现大规模动荡，可能会触发连锁反应，迅速波及实体经济并进一步影响就业与物价。尤其是在全球金融体系高度互联的当下，美国金融市场的风吹草动往往能在全球范围内掀起波澜。因此，美联储对金融稳定的关注也成为其工作重点之一。为了实现上述三个目标，美联储拥有一系列核心货币政策工具。传统上包括：联邦基金利率（即政策利率）、公开市场操作、贴现率（贴现窗口贷款利率）和法定准备金率。自2008年金融危机后，美联储还引入了向存款机构支付超额准备金利息（IOER，现称“准备金结算余额利率”）和隔夜逆回购协议工具（ON RRP）等补充工具，以在银行体系超额准备金充足的环境下更有效地引导利率。为了更好的理解美联储的各类政策工具和实际作用，我们需要先行解释一下金融与经济市场中的一些可能会反直觉反常识的基本概念。二、一些金融基本概念的厘定1.何为货币？有观点认为，人类社会的发展就是一部寻求流动性和安全资产的历史。何为流动性？在现代社会，流动性就是“不受任何质疑”（no question asked）、价值在任何状态下都可以被视为比较稳定的、人们普遍接受的金融合约，在任何时候都能做到“一元钱就是一元钱”。在这个视角下，货币可以被视为「最具流动性的资产」，它在交易过程中能够以最小摩擦完成价值转换。若将流动性定义为在最短时间、最低成本内变现为通用购买力（例如法定货币）的能力，那么“货币”就几乎等同于“流动性”本身。回顾人类历史，从最初的贝壳、金银，到后来的纸币与电子货币，都是在社会不断演进、交易日益频繁的过程中，为满足人们对安全、便捷和广泛接受程度的需求而逐渐形成的。反过来讲，具备这些特点的资产或者金融合约就会成为不同阶段流通于社会的货币。我们上面说的贝壳、金银和纸币等都是法定通货，是常见的一种货币形式，但货币远远不只有这些法定通货。美联储、商业银行、各国财政部和最近四十年兴起的影子银行都在商业体系中扮演者重要的角色。随着人类社会金融基础设施的进步，现代社会中商业银行创造的“短期债”（短期存款）因为其具有很强的流动性能够被大家接受，所以也逐渐被视为理想的货币形式之一。:::note\n这里可能有点绕，通俗的讲就是你存在银行里的钱也是货币。\n:::银行存款是商业银行创造的货币，其与通货可以互换。是的，虽然大众观点里兜里踹的钱和银行里存的钱都是“钱”，但实际上二者还是有区别的相同的，全世界各国的中央银行准备金就是由各国的央行发行，只能由商业银行持有的一种货币。特别的讲，由政府发行的美国国债虽然可能具有很长期限而并非短期债，但以国家主权信用作为担保的美国国债，有着较高的流动性与安全性，随时可以兑换成通货，在实际上成为大公司和金融\n机构的“货币”。有的人在这里可能就要问了，为什么这些金融机构不直接持有现金或者存在银行里呢？对于金融机构来说，把几千万乃至上亿美刀放在自己的仓库里只会让别人认为这家机构是不是要转职收治精神病人把这些资金存放在商业银行会导致存款数额远远高于联邦存款保险公司存款保险的上限（如果商业银行出现破产风险，央行单个账户最多只会赔付五十万美元）他们更不可能持有央行准备金，因为他们不是银行，没资格买因此，对于这些大公司和金融机构来说，美国国债就是最理想的货币形式。此外，国债是具有收益率的，美国国债收益率被视为所有美元资产的基准利率，因而美国国债也是一种安全资产。在更高层次的金融运作中，美国国债的角色往往更为突出。它不仅能提供一种安全资产的功能，还能在全球范围内充当高流动性、低风险的“通用抵押品”，被金融机构视为“无违约风险”的基础工具。举例来说，在回购市场（Repo Market）中，美国国债经常被用于抵押，以获得短期资金周转或者进行杠杆操作；在二级市场上，美国国债也可以很容易被交易套现。从这个角度来说，美国国债虽然在期限上可能是中长期，但只要具有足够高的信用评级和市场流动性，实际上就可以被视作“货币”的替代形式——至少对于大部分金融机构而言，国债随时可以兑换成通货，能够满足支付和交易的需求。所以，将国债作为“广义上的货币”或“准货币”实际上是现代信用体系的一种外延：货币不仅仅是我们日常所熟悉的现金或电子账户余额，也不仅限于央行发行的基础货币，凡是具有高度流动性且被市场广泛接受的资产（以及与之相关的金融工具），都在实际运行中扮演着货币的功能。当年由贝南克提出的“全球储蓄过剩”理论在一定程度上也反映了这一现象——全球金融市场对安全资产的需求量很大，而美国国债的广泛使用正是满足这一需求的具体体现。:::note\n美国经济学家明斯基曾说过，“每个人都能创造货币，问题是如何当它被接受”。\n至此，我们同样可以说，源于资产的流动性，每种资产都具有一定的“货币性”（moneyness），只是不同类型资产的货币性或流动性的程度不同而已。如果对各类金融资产进行排序，包括通货、国债、银行短期债等在内的货币的流动性最高，其次是AAA级政府支持机构的MBS，再次是AAA级公司债，以此类推，直到对信息最敏感从而货币性最低的股票。\n:::因此，理解“货币”的广度，对认识现代金融体系中的“安全资产”与“流动性”至关重要。不同时期、不同市场主体对货币的具体需求差异，会推动货币形态不断演进与扩张。从实物货币到央行货币，再到商业银行货币、影子银行创造的短期负债，以及国债、优质抵押债券等各类金融资产，都在各自适用的范围里，发挥着货币功能。换言之，正是因为市场不断出现新的流动性需求，才迫使各种金融工具在不同场景中被赋予货币属性。2.货币的供应和创造机制在古典经济学框架里，货币供应一般被认为由中央银行通过铸币或发行基础币（Monetary Base）决定，再通过货币乘数机制在商业银行体系内放大，从而形成广义货币（M1、M2等），核心观点在于央行投放多少基础货币，商业银行就能“乘数式”扩张多少贷款与存款。当然，在现代金融实践中，货币的创造会更加复杂，央行与商业银行的角色也并非简单的主从关系，我们这里只做一个简单的介绍。（1）传统“货币乘数”模型在传统教科书中，货币供应的描述常见于以下流程：基础货币投放中央银行通过公开市场操作、外汇占款等方式向经济注入基础货币 $H$，包括：通货（Cash）：流通于公众手中的现金；银行准备金（Reserves）：存放于央行的商业银行存款，不可直接用于交易，仅用于清算和满足准备金要求。存款吸收与负债转化商业银行吸收储户存款后，形成两类账目：资产端：增加等额准备金（需按央行规定留存法定准备金）；负债端：生成对储户的存款债务。贷款发放与存款创造银行依据法定存款准备金率 $r$（如10%），将存款的 $1-r$ 部分用于放贷。贷款转化为借款人的银行存款，进一步扩大体系内的存款总量。例如：初始存款100元，银行放贷90元，借款人将该90元存入他行，触发新一轮存款扩张。货币乘数效应通过反复的“存→贷→存”循环，单笔基础货币可撬动多倍货币供应。最终形成的广义货币供应量$M$取决于基础货币和货币乘数的乘积。通过上述链条，若初始投放基础货币为 $H$，法定存款准备金率为 $r$，则广义货币供应量 M 近似可表示为：$$\nM=\\frac{1}{r} \\times H\n$$若央行投放基础货币 $H = 1000$ 亿元，法定准备金率 $r = 10%$，则理论最大货币供应量为：$$M = \\frac{1000}{0.1} = 10,!000 , \\text{亿元}$$每轮存贷过程如下：第1轮：存款1000亿 → 放贷900亿 → 新增存款900亿；第2轮：存款900亿 → 放贷810亿 → 新增存款810亿；……直至新增贷款趋近于零。（2）货币供应量模型与 M1、M2在宏观经济分析中，为了更好地度量并追踪货币在社会经济活动中的流通规模，经济学家通常会按照“流动性”及“可用于支付”的便捷程度，对货币进行不同层次的划分，形成常见的M0、M1、M2等概念。这些概念也常被统称为“货币供应量”或“货币层次”（Monetary Aggregates）。1. M0（或称为基础货币/通货）构成：通常包括在外流通的纸币（现金）与硬币，以及商业银行在中央银行持有的准备金存款（有时也把“准备金”单列为 MB，Monetary Base）。特点：M0 是最直接、最具法偿能力（Legal Tender）的货币形态，表现为人们日常使用的现金和商业银行结算体系的根基（准备金）。意义：央行对 M0 的发行和管理，往往通过公开市场操作、调整准备金率或贴现窗口等手段进行调控。它也是传统“货币乘数”模型的起点之一。2. M1（狭义货币）构成：在大多数国家/地区的统计口径中，M1 = M0 + 活期存款（也称为“活期/往来存款”或“可开支票存款”）。特点：M1 强调随时可用于支付的特征，因为活期存款可以随时从银行账户提取或用于转账支付。意义：M1 往往用来观察社会经济中“即时支付能力”的存量，对消费、投资等经济活动有较直接的指示意义。当 M1 增速变化较大时，通常意味着银行体系或企业、居民部门的支付能力及交易活动水平发生明显波动。3. M2（广义货币）构成：M2 = M1 + 定期存款/定期储蓄（及其他短期流动性强的存款形态，如某些货币市场存款、储蓄存单等）。特点：M2 不仅包含可以随时支付的活期存款，也包括了相对流动性稍弱、但仍然相对安全便捷的定期存款或短期储蓄，整体规模更大。意义：M2 通常被视为反映经济中广义流动性的重要指标。由于其包含的金融资产更加多元，因而更能体现社会整体资金状况，也常作为央行或政府部门制定货币政策、衡量通胀压力的重要参考。简单来说，货币供应量按流动性分为三个层次：M0是最基础的现金和银行准备金，能立即用于支付；M1在M0基础上加入活期存款，反映社会即时支付能力；M2则涵盖更广，包含定期存款等短期储蓄，代表整体经济流动性。M0、M1、M2 等口径，从最具流动性的现金、活期存款逐步扩大到更广泛的定期存款与金融工具，形成一个“货币金字塔”。随着层级的增加，金融资产的流动性降低，但规模往往更大。:::note\nM1 重点反映“交易需求”，与消费、企业支付能力等经济活动密切相关；而M2 则更多关注“广义储蓄与流动性”，被视为经济体系资金总量的重要风向标。\n:::（3）现代货币创造机制然而，货币乘数模型实际上只是对商业银行体系和中央银行关系的一个简单刻画。现代金融体系中，货币创造更倾向于由商业银行“内生”产生，而中央银行则通过调控市场流动性、政策利率和监管要求来间接约束或引导商业银行的放贷行为。在具体的金融实践中，当商业银行对合格的借款人发放贷款时，实际并不需要等待“存款”或“准备金”先行到位；相反，银行在资产负债表上同时增加对客户的贷款（资产）和客户账户中的存款（负债），从而“创造”出新的货币。随后，为了满足准备金和监管要求，商业银行会从同业市场或中央银行融资来保证流动性，但这个过程更多是一个对既成事实的被动“配合”。因为只要借款人在信用评估上符合银行的内部标准，银行就有动力去发放贷款，创造货币的能力便内生地产生。中央银行为避免金融体系过度扩张或流动性不足，往往会借助公开市场操作、贴现窗口以及各种常备贷款便利工具来平抑市场利率波动，并通过调整政策利率来影响银行的资金成本和放贷意愿，从而间接影响货币创造的总规模。当然，这并不意味着中央银行对货币供给毫无掌控。除了调节利率和市场流动性，中央银行还会以监管的身份对商业银行提出资本充足率、拨备覆盖率和流动性比率等监管要求；这不仅能防止银行因过度杠杆而导致系统性风险，也对信贷投放形成一定约束。换言之，商业银行虽然在实际业务中占主导地位，但他们的内生放贷行为并非毫无限制，而是要在宏观审慎和货币政策的多重框架下开展。随着金融市场的发展，新的货币形态与金融工具不断涌现，如影子银行、加密资产等更为复杂的信用创造方式，也使得货币创造主体和渠道呈现出多元化态势。正因如此，中央银行的政策工具箱也不仅限于传统的准备金率和公开市场操作，而是包含更为广泛的宏观审慎政策与市场结构调控手段，以适应现代金融环境下丰富且快速变化的货币创造过程。3.为什么美元和美债重要全世界所有的经济体都对流动性资产有着巨大需求，而在当前的全球金融体系中，正因为美元在全球范围内的高度流通性，各国央行为应对国际收支波动和流动性风险，往往会把美元作为主要储备货币囤积在自己账上，使得美元已经成为了世界流动性之源，成为了事实上的世界货币。我们可从以下四个维度理解美元的独特性：安全性美元之所以能被各国央行当作“避风港”，很大程度上源于美国整体经济实力及其金融体系的成熟程度。美国拥有较完善的法律和金融监管框架，美国国债市场也被普遍视为全球最具安全性和流动性的债券市场之一。对于许多新兴经济体或外汇储备规模相对较小的国家而言，在地缘政治、国际经济环境出现不确定性时，将外汇储备集中配置于美元资产，尤其是美债，可以帮助其稳定本国金融市场预期、避免本币过度波动。这种“安全资产”特质在市场出现恐慌情绪或流动性紧张时表现得尤为突出：资金大规模涌向美元和美债，进一步加固了美元在全球金融体系中的核心位置。贸易作为全球最主要的贸易结算货币，美元在国际贸易，尤其是大宗商品（如原油、金属、农产品）交易中担当了“计价单位”的角色。对许多依赖资源出口或进口的国家来说，以美元来计价能够降低汇率不确定性并保证结算的便利性。从货币使用的角度，谁最先成为交易定价和结算的“共同语言”，谁就能在贸易网络中奠定主导地位。由于全球贸易规模庞大，这种以美元为“媒介”的结算体系在跨国交易中具有自然的规模效应，形成了难以撼动的美元主导地位。反过来，这种贸易网络的深度和广度也让各方在国际往来中持续积累美元资产，巩固了美元作为“世界货币”的功能。低成本所谓的“低成本”，不仅指美国得以在全球范围内较为轻松地融资，也指全球各国在美元体系下能迅速获得所需资金。对美国而言，拥有全球储备货币地位意味着可以以相对低的利率在国际市场发行债务（即所谓“铸币税”或“美元霸权”所带来的特权），从而减轻国内经济发展所需资金的压力。这一特权同时也为其他国家提供了相对透明和流动性充足的金融环境，很多国际借贷和融资操作以美元为主。这种“美元化”的全球融资体系虽然给各经济体带来了便利，但也意味着当美元流动性紧缩或美国利率上行时，全球其他地区会同步感受到流动性压力和融资成本上升的冲击，从而凸显出美元在国际资金供需中的枢纽角色。流动性美元资本市场是世界上最具深度和流动性的市场，美元的全球化流动性是支撑其“世界货币”地位最核心的动能。全球投资者和金融机构都极度依赖美元市场来获取短期融资或进行资产交易，特别是在外汇掉期、衍生品市场等领域，美元交易量始终占据着较大份额。尽管美国政府也曾面临过“债务上限”和短期政治博弈，但总体上美国偿债意愿与能力仍被市场认为是高度可信的。二级市场的活跃交易为美债提供了极高的流动性。当出现任何区域或全球性的流动性紧张，往往需要美联储通过“美元流动性互换”或其他非常规政策工具向海外市场注入美元，以防止美元荒加剧金融动荡。这种在危机时刻随时为市场“输血”的能力强化了美元资产的可信度，让美元成为全世界范围内追逐的“终极流动性”载体。对于需要大量外汇储备和国际支付能力的经济体而言，持有或获取美元不仅是一种防范金融风险的手段，也是一种稳定全球市场信心的象征。同样地，持有美元是一个理想选择，因为它们易于贮存。美国债券市场的深度和流动性意味着投资者可以轻松且无风险地储存大量美元。国债是支付利息的货币。对于拥有大量货币的机构或富人来说，流动性确实是一个问题。在全球回购（Repo）市场中，美债通常被视为优质抵押品，能够以极低的折扣（haircut）获得借款。这进一步巩固了其在金融体系中的地位：只要持有美债，就意味着可以在需要时迅速融到美元资金。中国持有数万亿美元的美国国债的很大原因在于，没有其他市场足够深以持有这些货币。总结美元的安全性、贸易地位、融资低成本及强大流动性相互交织，使得它在全球经济生态中占据了难以替代的中枢地位。各国与企业在这一美元主导的架构下获得金融与贸易便利的同时，也不可避免地承受其利率和流动性波动所带来的不确定性。这既是美元成为“世界货币”的逻辑所在，也构成了各国在制定宏观经济和货币政策时必须面对的核心外部条件。在厘清了「货币」的内涵与创造机制，以及「美元与美债」在全球金融体系中的重要地位后，我们对现代金融运行和国际货币体系的基本脉络有了更加完整的认知。正因为美元和美债处于如此关键的位置，美联储在实施货币政策时所采取的一举一动，往往都能产生超越美国本土的深远影响。接下来，我们将基于这一背景，进一步探讨美联储的核心政策工具，看看它是如何通过种种金融手段，实现对经济与金融环境的调控。"
  },
  {
    "title": "模型考古学（七）：Qwen2.5-Omni技术报告解读",
    "summary": "3月27日凌晨，阿里正式开源Qwen2.5-Omni，作为阿里首个开源的统一端到端模型，能处理文本、音频、图像和视频等多种模态，并生成实时的文本或语音响应。以4o和minicpm-2.6o还有Qwen2.5-Omni为代表的全模态模型最突出的特点，是以一个统一的 Transformer 体系来完成从感知到生成的全部环节。它不仅支持多模态信息的输入和理解，还能根据需要，以文本或语音这两种形式进行流式",
    "tags": [
      "模型考古学"
    ],
    "url": "/posts/AI and Deep Learning/Qwen-2.5-Omni-R1-report/",
    "date": "2025-03-27T00:00:00.000Z",
    "content": "3月27日凌晨，阿里正式开源Qwen2.5-Omni，作为阿里首个开源的统一端到端模型，能处理文本、音频、图像和视频等多种模态，并生成实时的文本或语音响应。以4o和minicpm-2.6o还有Qwen2.5-Omni为代表的全模态模型最突出的特点，是以一个统一的 Transformer 体系来完成从感知到生成的全部环节。它不仅支持多模态信息的输入和理解，还能根据需要，以文本或语音这两种形式进行流式输出。这在实际应用中格外有价值：例如在语音对话场景里，Qwen2.5-Omni 可以先用音频编码器接收和理解用户的口头指令，再通过语言解码器（文本输出）或双轨自回归生成器（语音输出）提供实时响应；而在视频对话中，它则能将图像、语音等要素统一编码，解决视频理解、人物说话内容识别与场景描述等一系列“跨模态语义融合”的难题。当然，4o面向c端解锁的全模态能力是渐进式的。可能刚发布时只有个处理图片和文本，下个月支持处理音频，再过几个月终于支持输出图像+音频了，主打一个切香肠。从命名上看，“Omni”一词本身就象征了“全能”与“全局性”。而与之前的多模态大模型相比，Qwen2.5-Omni 选择了用一个“端到端”的思路来彻底打通模态之间的传递过程，让模型能够在同一条工作流中接收、处理和输出多模态信息。这意味着很多过去需要将语音识别、视觉编码、文本生成等环节分离处理，再通过繁琐的中间表示或接口进行整合的做法，目前都可以由单个模型来进行处理，整体流程的复杂度极大的被降低。回到主题，我们之所以关注这款新模型，正是因为它向我们展示了统一端到端多模态模型的潜力和挑战。从Openai的GPT-4o，谷歌的Gemini系列，再到现在的qwen2.5-omni，我们可以看到学术产业界正在不断尝试把大模型的“通用性”往更多样化的模态延伸，Qwen2.5-Omni 则进一步证明了当多模态感知与多模态生成深度耦合、在同一套序列建模体系内协同演化时，将可能为各行各业带来更多交互方式、更大创新空间。Qwen2.5‑Omni 的关键特性可以概括为：总体来说，这是一个可以感知所有模态并能以流式方式同时生成文本和自然语音响应的统一模型研究团队提出了一种新的位置嵌入算法，称为TMRoPE，该算法明确地融入了时间信息以同步音频和视频研究团队提出了Thinker‑Talker 架构，以促进实时理解和语音生成接下来，我们会结合官方技术报告，对 Qwen2.5-Omni 的架构设计、训练过程以及在不同基准下的性能表现，做更细致的拆解与点评。毕竟，对于一款“真的能听、能看、能说、能生成”的模型，了解它的内部机理与实现思路，才是真正的“模型考古学”最有趣的部分。一、构建全模态模型的难度是什么？1.多模态统一训练的复杂性在现实世界中，各个模态（文本、图像、语音和视频等）的数据分布和特征形式大不相同。传统大模型最喜欢的文本模态是离散符号序列，音频则更关注短时频谱动态，图像/视频有二维甚至三维时空结构。想要把这些模态放到同一个模型中进行端到端的统一训练，首先就需要面对大规模的数据标签风格和模态差异带来的对齐问题。所以，模型必须具备一种“系统性方法”来实现图像-文本、视频-文本、音频-文本等对齐，这既要求模型本身具备足够灵活的结构，也需要能够在训练阶段让所有模态“互相促进”，而不是各管各的。更进一步，如果将多模态特征全部简单拼接在一起，很可能导致不同模态之间互相干扰，甚至把原本在各模态上已学到的特征能力“破坏”掉。为了克服这一难点，Qwen2.5-Omni 会在模型结构和训练数据上进行特别设计，例如先通过大量单模态或双模态对齐数据进行预训练，再逐步纳入更大规模的多模态混合数据等。2.时间同步与多维位置编码音频、视频都具有时间维度，并且二者需要对齐以保证“所见即所听”。如果在时间轴上对它们进行不当处理，一方面容易损失视频时序或音频节奏信息，另一方面还会造成语音与视频帧不同步。报告里提出的一大创新是 TMRoPE（Time-aligned Multimodal Rotary Position Embedding），通过对输入序列做“时间切块+多维位置编码”，在 40ms 这一相对统一的时间粒度下，让音频帧和视频帧逐步匹配。加之对图像、视频的高度与宽度位置编码进行区分，最终在单一的 Transformer 模型里实现了多模态时空信息的对齐与融合。对于不同帧率的视频，Qwen2.5-Omni 也会通过动态插值、块状处理等策略来减少长序列带来的内存开销，进而实现实时处理，保证了多模态编码器不会因为“时序过长”而失效。3.同时生成多模态输出的相互干扰与常见的“多模态输入、单模态输出”不同，Qwen2.5-Omni 还要能在输出侧同时生成文本和语音，并且是以流式的方式生成，这里另一个难点就出现了：如何避免文本和语音在解码过程中的相互干扰？报告中专门提出了 Thinker-Talker 架构：Thinker 相当于“语言大脑”，进行高层的语言思考、生成文本，并提供抽象的语义向量给到后续。Talker 则只关注如何把 Thinker 的这些高维语义表示转成语音编码，并进一步流式输出音频。通过这样的解耦，模型能在同一套流水线（同一个 Transformer）里，并行完成“文本思考”和“语音生成”两件事，不至于出现语音编码和文本编码在输出层互相“污染”的问题；同时还能根据用户需求，决定用文字还是语音来回复，也可以两者都输出。在其他多模态模型里，如果直接共享一个单一解码器输出多模态，极易导致参数竞争、梯度冲突，从而影响整体生成质量。4.全模态模型在流式场景下对模型结构和推理效率的高要求要支持实时语音对话或视频对话，单纯解决输入和输出的模态融合并不够，还得兼顾“延迟”——尤其是语音、视频数据量大，且往往需要连续接收和生成。如果仍使用传统的全局注意力机制去处理几分钟甚至更长的音视频序列，模型规模和计算量都会成倍飙升。为此，Qwen2.5-Omni 在多模态编码器上采用了“块状（block-wise）”或“滑动窗口”的注意力机制，对长序列进行分块处理；又在生成端使用了分段自回归的方式（双轨自回归 + Streaming DiT），能在相对有限的上下文内完成一段语音的生成，再与下一个音频块顺畅衔接，减少初始包时延。这些设计都是为了真正做到“边输入边输出”，而不是一次性拿到所有音视频后再统一推理。二、Thinker-Talker 解读上图为Qwen2.5-Omni的架构，可以看到Qwen2.5‑Omni 采用了 Thinker‑Talker 架构。Thinker 就像大脑一样，负责处理和理解来自文本、音频和视频模态的输入，生成高级表示和相应的文本。Talker 则像人的嘴巴一样，以流式的方式接收 Thinker 产生的高级表示和文本，并以离散的语音单元输出。1.Thinker模块：负责理解与文本生成Thinker模块本身就可以被视为一个大语言模型（LLM），用来接收来自多种模态的输出（文本、图像、音频、视频），将这些信息转化为高层语义表示。在在输入端，Thinker 通过一系列编码器（Audio Encoder、Vision Encoder）获取语音、图像 / 视频的表示，再和文本序列的表示在统一的 Transformer 解码器中融合。不同模态在实际处理时，通过 TMRoPE 等时间对齐机制确保时序信息一致，从而让 Thinker 能获得对多模态的整体理解。当用户需要纯文本回答时，Thinker 就直接把语义向量转化为文本输出（经典的自回归生成过程）。从架构上看，它承担了大部分复杂的“语言思考”和 “语义推理”工作。2.Talker模块：负责语音生成“嘴巴”角色，双轨自回归Talker 采用了 dual-track autoregressive 方式，专门针对语音生成而设计。它在训练和推理过程中，会和 Thinker 同步进行，但只需要关注如何将 Thinker 的高维语义表示转换成音频编码再合成语音。Talker模块会接收来自 Thinker 采样文本标记的高层表示和嵌入。作为一种流式算法，语音生成必须在整个文本完全生成之前预测内容的声音和态度。Thinker 提供的高维表示隐式传达了此类信息，从而实现更自然的流式生成过程。Qwen团队还设计了一种高效的语音编解码器 qwen‑tts‑tokenizer。qwen‑tts‑tokenizer 能够高效地表示语音的关键信息，并且可以通过因果音频解码器流式地解码为语音流。接收信息后，说话者开始自回归地生成音频标记和文本标记。语音生成不需要与文本在词级和时标级上进行对齐。这显著简化了训练数据和推理过程的要求。融合文本 token 与高维向量语音生成并非仅依赖 Thinker 的隐藏语义表示——报告中提到，为了让模型在需要实时输出、并且可能有丰富情感或语气时能生成更自然的声音，Talker 还会拿到一部分实际采样出的文本 token 作为参考，以消解同音词、语义模糊等问题，保证与文本意义相匹配的音频生成。Streaming DiT 实现流式语音输出Talker 输出的语音编码最终会通过后端的 DiT（Diffusion Transformer）模块生成音频波形，而这个环节采用了“滑动窗口”分块处理，用相对有限的上下文就能持续生成音频，减少延迟，这也是整个系统能支持“边录音、边回复”的关键。:::note\n在初始预训练阶段，Qwen2.5-Omni的LLM组建用的是Qwen 2.5，视觉编码器与Qwen2.5-VL相同，音频编码器则使用Whisper-large-v3进行初始化。\n:::三、跑分展示剩下的懒得放了，毕竟7B的模型最主要还是学术研究用途。总结Qwen2.5-Omni 作为一款真正意义上的多模态统一模型，它最核心的价值在于极大地简化了多模态处理和生成的工作流程。传统模式下，文本、图像、语音、视频往往需要分别调用专门模型或工具，再借助各种中间接口才能完成。每多一种模态，往往就会增加一层繁琐的对接和管理成本。而 Qwen2.5-Omni 将多模态感知与多模态生成整合在同一个端到端模型里：一次性完成感知到表达无论输入是音频、图像、视频还是文本，所有预处理、解析和编码都在同一个大的架构内完成，免去了在不同模型之间拆分和转换数据格式的步骤。流式输出让互动更高效Qwen2.5-Omni 不仅能输出文本，也能在同一个模型内同步地生成语音响应，这种“边听边说”的对话模式极大地提升了实时交互体验。工作流层面，无需再为“文本转语音”单独部署 TTS 引擎，减少了对接流程和延迟。训练与维护集中化过去用多模态方案时，常要分别维护语音识别、视觉模型、语言模型、TTS 模块等四五个组件；而一个统一的 Omni 模型集中管理了多模态的能力更新，降低了系统复杂性。训练或更新时，一次性就能让模型获得各模态的最新增强。可扩展性更强有了一个能够处理多模态输入和多模态输出的通用框架，当面对新需求（如嵌入更多视觉检测、视频推断等任务）时，只要在当前模型上额外进行针对性调优，便可实现端到端的升级，而不会像过去那样要外接不同类型的新组件。对于很多需要混合应用音视频处理、文档理解、实时通话协作的场景而言，Qwen2.5-Omni 带来的 “一体化协同” 让整个业务流程更为简洁：开发者不必再在多模态模型和单模态工具之间来回切换，维护起来也更加省时省力。对于希望构建通用 AI 服务的团队来说，这才是Omni类模型的价值所在。"
  },
  {
    "title": "模型考古学（六）：DeepSeek V3和R1技术报告浅析",
    "summary": "上篇博客我们回顾了Minimax-01系列模型在传统Transformer的Attention机制上做的创新，实现了非常强劲可观的超长上下文外推能力，那么本篇将聚焦于 DeepSeek 的最新进展，深入分析其发布的 DeepSeek V3 和 DeepSeek R1 技术报告，探讨这些模型在架构设计、训练策略以及推理能力等方面的特点与创新。DeepSeek V3 是一个强大的混合专家（MoE）语言",
    "tags": [
      "模型考古学"
    ],
    "url": "/posts/AI and Deep Learning/DeepSeek-v3-R1-report/",
    "date": "2025-03-23T00:00:00.000Z",
    "content": "上篇博客我们回顾了Minimax-01系列模型在传统Transformer的Attention机制上做的创新，实现了非常强劲可观的超长上下文外推能力，那么本篇将聚焦于 DeepSeek 的最新进展，深入分析其发布的 DeepSeek V3 和 DeepSeek R1 技术报告，探讨这些模型在架构设计、训练策略以及推理能力等方面的特点与创新。DeepSeek V3 是一个强大的混合专家（MoE）语言模型，总参数量达到 6710 亿，每个 token 激活 370 亿参数。为了实现高效推理和经济高效的训练，DeepSeek V3 采用了多头潜在注意力（MLA）和 DeepSeekMoE 架构，这些技术在 DeepSeek V2 中已得到充分验证。此外，DeepSeek V3 开创性地采用了无辅助损失的负载均衡策略，并设定了多 token 预测训练目标，以增强模型性能。DeepSeek R1 则展示了通过强化学习（RL）提升大型语言模型（LLM）推理能力的有效性。研究表明，即使不使用监督微调（SFT）作为冷启动，通过大规模强化学习也能显著提升推理能力。此外，加入少量冷启动数据可以进一步提升性能。:::note\n本篇是「模型考古学」系列的最后一篇。接下来的一段时间内我将转向宏观经济层面，重点关注以美联储为代表的中央银行政策工具与宏观经济指标的互动逻辑。同时，也可能会不定期分享一些关于图形渲染与 AI 超分技术的研究。\n如果兴致来了可能也会写一些刑法相关的法学研究（）\n:::DeepSeek V3：强劲且性价比极高的通用基座模型老规矩，先看看模型性能跑分：前置知识（1）：消融实验“消融实验”（Ablation Study）是机器学习和深度学习研究中一种非常常见且重要的实验方法，主要用于回答这个问题：模型中某个组件、机制或设计，究竟有没有用？想象你在造一台复杂的机器，比如一辆电动车：它有电池、马达、刹车系统、辅助仪表盘等多个模块。如果你想知道“仪表盘”是否对整体性能有帮助，你就可以：拿掉仪表盘看看车还能不能正常跑，速度快不快，操控好不好这就是“消融实验”的基本思想。在深度学习中也一样：模型可能包含很多设计，比如多头注意力、位置编码、门控机制、预归一化等等。你要想知道某一项设计是否真的贡献了性能，就可以通过“删掉它”，再观察性能变化。1.正式定义消融实验是指在保留其他部分不变的前提下，有意识地移除模型中的某个模块、机制或超参数设置，并比较性能差异，从而验证该部分的有效性。常用于：验证新提出的模块是否真的带来提升分析多种设计选择中哪个最优给模型结构的设计决策提供依据2.举例比如 DeepSeek-V3 中使用了 MLA 注意力机制 和 FP8 训练。要验证 MLA 是否有用，作者可能会做三组实验：| 实验 | 使用 MLA | 使用标准注意力 | 结果 |\n| --- | --- | --- | --- |\n| baseline | ❌ | ✅ | perplexity = 4.1 |\n| MLA-only | ✅ | ❌ | perplexity = 3.9 |结论：加入 MLA 后性能提升，说明 MLA 是有效的。再比如他们用了 Auxiliary-Loss-Free 的 MoE 路由，如果想验证“偏置项 $b_i$”是否真的起作用，可以做一个“去掉 bias 的版本”看结果是否变差，这也是一种消融实验。常见的消融方式：| 消融对象 | 举例 |\n| --- | --- |\n| 模型结构 | 拿掉残差连接 / 不用位置编码 |\n| 模块设计 | 不用 MLA / 不用 MoE / 不加 gating bias |\n| 训练策略 | 不用 warmup / 不加正则项 |\n| 数据设置 | 去掉某类训练数据 / 不做预训练 |\n| 精度控制 | 比较 FP8 / FP16 / BF16 |前置知识（2）：大模型精度格式我们经常能看到例如FP16、BF16、FP8、INT8、INT4……这些名字到底都是什么？1.一张表格快速对比| 格式 | 全称 | 位宽 | 数据结构 | 精度高低 | 常用于 | 是否支持训练 | 是否支持推理 | 硬件支持 |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| FP32 | Float32 | 32-bit | 1符号 + 8指数 + 23尾数 | 🔵 最高 | 传统训练/推理 | ✅ 稳定 | ✅ 准确 | 所有硬件 |\n| FP16 | Float16 | 16-bit | 1符号 + 5指数 + 10尾数 | 🟡 中等 | 训练/推理 | ⚠️ 需配合技巧 | ✅ 主流 | A100/H100/3090等 |\n| BF16 | Brain Floating Point 16 | 16-bit | 1符号 + 8指数 + 7尾数 | 🟡 中高 | 训练/推理 | ✅ 稳定 | ✅ 主流 | TPU/A100/H100等 |\n| FP8 | Float8 | 8-bit | 1符号 + 5/4指数 + 2/3尾数 | 🟠 新兴 | 高效训练 | ✅（H100等） | 🚧 有待完善 | H100 专属 |\n| INT8 | Integer 8-bit | 8-bit | 整数（非浮点） | 🔴 低 | 推理量化 | ❌ | ✅ 普遍 | 普遍支持 |\n| INT4 | Integer 4-bit | 4-bit | 整数（非浮点） | 🔴 极低 | 极限推理 | ❌ | ✅ 受限 | 少数框架支持 |2.这些格式的“结构”是怎么组成的？浮点数格式（如 FP32、FP16、BF16、FP8） 一般由以下几部分组成：符号位（Sign bit）：决定正数还是负数（1 位）；指数位（Exponent）：决定数值的范围（越多位，范围越大）；尾数位（Mantissa）：决定数值的精度（越多位，小数越准确）；| 格式 | 总位数 | 指数位 | 尾数位 | 精度 vs 范围 | 特点 |\n| --- | --- | --- | --- | --- | --- |\n| FP32 | 32 | 8 | 23 | 精度高，范围广 | 训练和推理都没问题，就是显存太大 |\n| FP16 | 16 | 5 | 10 | 精度中等，范围较小 | 显存省一半，适合训练推理 |\n| BF16 | 16 | 8 | 7 | 精度低，范围大 | 精度略差，但动态范围和 FP32 一样，适合训练 |\n| FP8 (E4M3 或 E5M2) | 8 | 4/5 | 3/2 | 精度和范围都低 | 靠精细策略才可训练 |\n| INT8/INT4 | 8/4 | 0 | 全是定点整数 | 只支持离线静态值 | 仅用于推理压缩，不可训练 |3.它们的主要用途是什么？| 格式 | 用于训练？ | 用于推理？ | 优势 | 风险 |\n| --- | --- | --- | --- | --- |\n| FP32 | ✅ 标准 | ✅ 标准 | 精度高、稳定 | 显存大，计算慢 |\n| FP16 | ✅ 混合精度 | ✅ 高效推理 | 显存减半 | 对极端值不友好，易爆炸 |\n| BF16 | ✅ 高稳定性训练 | ✅ 几乎原精度推理 | 动态范围大 | 小数精度差一些 |\n| FP8 | ✅（配合技巧） | ✅（实验中） | 更节省显存 + 更高吞吐 | 容易溢出或数值不稳定 |\n| INT8 | ❌ | ✅ 主流压缩 | 高压缩比，运行快 | 精度有一定损失 |\n| INT4 | ❌ | ✅ 极致压缩 | 显存压缩最高 | 精度容易严重下降 |4.精度格式的核心区别：（1）数值表示能力（精度 + 范围）FP32 > BF16 ≈ FP16 > FP8 ≫ INT8 > INT4训练需要高范围 & 高精度（FP32 / BF16）；推理只要保住前向结果基本不变就行（INT8 / INT4 够用）。（2）显存占用32bit → 16bit → 8bit → 4bit，显存逐级减半；FP8 训练相比 FP16 可以进一步减少 43% 显存，INT4 推理则可以压缩到 1/8。（3）数值稳定性 vs 兼容性FP16 在一些早期 GPU（如 A100）上广泛支持；BF16 动态范围广，在 TPU、H100 上支持良好；FP8 是 Hopper GPU 之后的新特性，框架支持尚在完善；INT4 是纯粹为了极致压缩做的近似计算，只适合推理。最后，再用一张表格总结一下：| 角色 | 精度 | 用途 | 关键词 |\n| --- | --- | --- | --- |\n| FP32 | 最高 | 标准训练/推理 | 经典、安全、显存贵 |\n| BF16 | 范围大，精度适中 | 主流大模型训练格式 | Google力推、TPU专属 |\n| FP16 | 精度还行 | 高效推理、训练 | 显存节省，稳定性一般 |\n| FP8 | 极低精度 | 训练新宠 | Hopper专属、高速、易炸 |\n| INT8 | 非浮点，近似值 | 推理压缩主力 | 快、省、略降精度 |\n| INT4 | 超低精度 | 推理极限压缩 | 速度狂魔，可能降智 |一、模型创新总览架构层面MLA多头潜在注意力，大幅降低推理成本（这个其实ds v2就有了）在ds v2高效架构的基础上，开创了一种无辅助损失的负载均衡策略，最大限度地减少因鼓励负载均衡而导致的性能下降多令牌预测（MTP）⽬标，并证明其对模型性能有益。它还可以⽤于推测性解码以加速推理预训练：追求终极训练效率FP8混合精度训练，首次在超大规模模型上验证了其有效性通过算法、框架和硬件的协同设计，ds克服了跨节点 MoE 训练中的通信瓶颈，实现了近乎完全的计算通信重叠。这显著提⾼了ds的训练效率，降低了训练成本，使ds能够在不增加额外开销的情况下进⼀步扩⼤模型规模极致的工程优化和降本增效在预训练阶段，DS在14.8T的数据上训练了V3，预训练过程异常稳定，在整个训练过程中没有碰到任何不可恢复的损失峰值，也无需回滚。全部训练过程一共也就花了五百来万美元，令人感慨。在预训练阶段，训练 DeepSeek-V3 每万亿 tokens 仅需 180K H800 GPU 小时。因此，在我们拥有 2048 个 H800 GPU 的集群上，训练时间仅需 3.7 天。我们的预训练阶段在不到两个月的时间内完成，消耗了 2664K GPU 小时。结合上下文长度扩展所需的 119K GPU 小时和后训练所需的 5K GPU 小时，DeepSeek-V3 的完整训练总共消耗 2.788M GPU 小时。假设 H800 GPU 的租赁价格为每小时时 2 美元，我们的总训练成本仅为 557.6 万美元。请注意，上述成本仅包括 DeepSeek-V3 的官方训练，不包括在架构、算法或数据上的前期研究和消融实验的成本。后训练：从DeepSeek R1进行知识蒸馏引入了一种创新方法，从长链思维（CoT）模型中锻炼推理能力，特别是从DeepSeek R1系列模型之一转化为标准的LLMs，特别是DeepSeek V3。DS将R1的验证和反思模式融入到DeepSeek V3，显著提升了其推理性能，同时也保持了对V3的输出风格和长度的控制。我们可以看到，和昨天的Minimax一样，Ds V3也是在Attention机制上做了大改良。DeepSeek V3的基本架构仍然在Transformer的框架内，为了实现高效推理和经济高效的训练，DS V3还采用了MLA和DeepSeek MoE，这二者的含金量在DS V2那里已经体现的非常明显了。二、模型亮点：MLA多头潜在注意力传统的多头注意力（Multi-Head Attention）最初就是在传统的Transformer架构（源自《Attention Is All You Need》, Vaswani 等人，2017 年）中提出的。它是 Transformer 中最核心的组件之一。这一组件可以被视为并行的多组注意力（Self-Attention），从而让模型在同一层面上对输入序列的不同位置或不同特征进行关注。多头注意力可以让模型在多个“视角”下去看输入序列，提高了对复杂关联关系的捕捉能力。在标准的多头注意力中，我们通常会对输入向量 $h_t$（对应第t个token，在某一层的隐状态）分别投影得到 $Q、K、V$ 矩阵，再将 $Q$ 与 $K$ 做点积计算注意力分数，并基于分数加权求和得到输出向量。设总的嵌入维度为 $d$，注意力头数为 $n_h$，每个头的维度为 $d_h=\\frac{d}{n_h}$对于训练大模型或做推理时，“KV 缓存”所占的空间往往非常可观。也就是说，在自回归生成推理时，需要保存大量的$K$ 和 $V$（对所有已生成的token）的中间表示，以便后续计算新的注意力分数。为什么DS要专门在这方面进行工程创新？这是因为随着模型规模变大，我们的Attention注意力机制需要储存和计算的中间结果（尤其是 Key 和 Value，也就是常说的 KV 缓存）会爆炸式增长。这不仅导致显存压力巨大，也会影响推理时的速度。MLA（Multi-Head Latent Attention）就是为了解决这个痛点而生的一种低秩压缩思路：它以较低维度的“潜表示（Latent Representation）”来替代原本的高维 Key/Value，极大地减少 KV 缓存需要的内存空间，并且在保持模型性能的同时降低推理或训练的成本。MLA的核心思路：先压缩，再缓存Step 1.压缩 Key/Value（减少推理时的 KV 缓存）在传统的多头注意力中，每一步生成都要把 Key 和 Value 以相对高的维度保存下来，以便后续进行注意力计算。MLA 则提出了一个巧妙的两步走：Down-Projection把输入隐藏向量$\\mathbf{h}_t$（维度 $d$ ）先映射到一个更小的维度 $d_c$（$d_c \\ll d$），得到一个潜表示 $\\mathbf{c}_t^{KV}$。Up-Projection当需要计算注意力时，再把这个潜表示用相应的投影矩阵$W^U$还原回多头所需的 Key、Value 维度。Step 2. 压缩 Query（节省训练时的激活内存）在训练时，除了存储 KV，计算注意力的中间激活也非常占空间。MLA 还对 Query 做了类似的低秩压缩——先将$h_t$降到一个小维度，再投影回原本多头空间。这样，同样能够减少反向传播时的激活开销。MLA 中还强调了相对位置编码（RoPE, Rotary Position Embedding）的重要性。论文里会先对输入做一次 RoPE，然后与压缩后的 Key 或 Query 做拼接，让模型既能享受到低秩带来的内存优势，又能保留相对位置信息，提高注意力对序列顺序的理解能力。总结一下MLA的优势：显存占用要求大幅下降：推理时需要缓存的 KV 维度更小，大模型在长上下文推理时所需的内存压力小了许多。训练内存也能节省：Query 的低秩投影让激活量减少，进而让训练时的显存开销降低。模型性能几乎不受影响：如果下投影/上投影矩阵设计得当，MLA 在保持或近似保持原有性能的前提下，带来了巨大的内存收益。MLA（Multi-Head Latent Attention） 简单来说就是给多头注意力配上一层“低秩眼镜”——它让 Key、Value（甚至 Query）在一个更小的维度里先“缩身”，再在需要注意力计算时“拉伸”回去。这种低秩操作减少了要缓存和计算的量，帮我们大幅降低显存/内存需求，同时性能上几乎与传统多头注意力相当。三、无辅助损失负载均衡的DeepSeek MoE1.MoE历史回顾与DS改进MoE的历史还得追溯到1991年的论文《Adaptive Mixtures of Local Experts》，出自Geoffrey Hinton和Michael I. Jordan两人之手。虽然这个概念1988年就有了，但大部分的科研论文认为还是这篇论文奠定了MoE的基础。而大模型时代开启之后最早采用MoE架构的模型应该是GPT4，发布于2023年3月，当时是George Hotz爆料GPT4是8×220B模型，让MoE架构第一次进入到大众的视野中。2023年12月，Mistral-8×7B发布，是全球第一个开源的MoE商用模型。DeepSeekMoE 则在常规的 GShard/ Switch Transformer 等 MoE 结构基础上，做了以下重要改进：更细粒度的专家：而不是每一层只有少量巨大的专家，DeepSeekMoE 将专家拆成更多、更小的单元以提升并行度、充分利用算力。共享专家（Shared Expert）与路由专家（Routed Expert）并存：部分专家（“共享专家”）不依赖 token 的路由选择，所有 token 都会经过该专家；另一些则根据路由器的打分来决定是否被激活。Top-K 路由：每个 token 会选取得分最高的 $K_r$ 个路由专家参与计算；每个 token 的负载只会分配到有限个专家上，以防止过大的通信与计算开销。2.负载均衡问题与传统的“辅助损失”方法在标准的 Mixture-of-Experts（MoE）模型中，Feed-Forward Network（FFN）往往被拆分成多个“专家（Expert）”，由门控函数（Router 或 Gating）决定每个 token 会被路由给哪些专家，从而带来参数可扩展性和计算加速。在 MoE 模型里，如果路由器的打分不平衡，有些专家可能收到过多 token，另一些则几乎“闲置”，称之为路由崩溃（Routing Collapse）。为了避免这种情况，过去常常在训练时引入辅助损失（Auxiliary Loss）（比如 Google Switch Transformer 的负熵正则化），鼓励模型把路由分数分散给更多专家，从而达到负载均衡。但这种做法有一个明显缺点：辅助损失越强，模型的主任务性能就越可能被干扰。因为它相当于在主损失之外引入强力的正则项，可能破坏模型本来自然学到的高质量路由分布。3.无需额外辅助损失的负载均衡策略（Auxiliary-Loss-Free Strategy）为了兼顾“路由负载均衡”与“模型性能”，DeepSeek-V3 提出了一种无需额外辅助损失的负载均衡策略（Auxiliary-Loss-Free Strategy）。主要做法如下：3.1 在路由打分中引入“偏置项” $b_i$对于每个路由专家 $i$，都会维护一个可训练或可动态更新的偏置 (Bias) $b_i$token 要选 Top-K 专家时，用的不是原始分数$,s_{i,t} = \\mathrm{Sigmoid}(\\mathbf{u}_t^{\\mathsf{T}} \\mathbf{e}i)$直接排序，而是$,s{i,t} + b_i$作为最终排序依据如果某个专家在前一批训练样本中过载（被选中的 token 太多），就调小$b_i$；反之，如果该专家“吃不饱”，就调大 $b_i$通过这种动态调整偏置，系统会逐渐把一些 token 分流给那些负载较轻的专家，实现整体的负载均衡。值得注意的是，真正用来计算专家输出加权的门控值 仍然是原始的 $,s_{i,t}$，而不是 $,s_{i,t} + b_i$。也就是说，偏置只影响“被不被选中”，不会对已经选中的专家输出的加权造成直接干扰，从而尽量减小对模型原本学习的干扰。3.2 具体的偏置更新规则论文中采用一种简单直接的策略：每个训练 step 或一定步数后，统计各专家在该 batch 内的被选取次数；如果某专家的占比超过平均负载，就判定“过载”，相应地对该专家的$b_i$ 减去一个固定步长 $\\gamma$；如果某专家的占比低于平均负载，就判定“欠载”，对该专家的 $b_i$ 加上同样的步长 $\\gamma$；$\\gamma$称为 bias update speed，可以是一个小超参数（如 0.001）。这样，过载的专家会渐渐拉低其路由排序打分，从而被选中的概率下降；欠载的专家则相反。3.3 保留少量的“序列级别”辅助损失另外，DeepSeek 还在训练时保留了一个极小的序列级别平衡损失（sequence-wise auxiliary loss），仅用于避免单条样本出现极端失衡——但它的权重非常低，以免影响主任务。该损失并不像传统的 GShard/Switch 里那样对整个 batch 做很强的负熵约束，而只是保证在“单个序列”内部不要完全只选到少数几个专家。通过这种“批量维度”或“序列维度”的松弛约束，再加上动态更新的 bias，实现了在大规模训练中保持负载平衡，而又不严重牺牲性能。4.技术优点这么做最主要的优点还是可以避免高强度辅助损失破坏主任务。之前的 MoE 常常发现，辅助损失系数一大就会明显影响收敛效果。现在这种做法只在路由决策层引入偏置，且只改变“被选与否”，对专家输出的加权几乎不插手，从而大幅减轻副作用。DS的动态调参机制在大规模MoE训练实践中表现稳定，可以维持长时间的负载健康，在论文实验中DS还观察到没有纯辅助损失的强干扰后，专家更容易在不同领域数据上出现“专业化”分工。在保持整体高效训练和推理加速的同时，也获得了更灵活、更稳健的专家分布；实验结果显示，这种方法往往能带来更好的模型精度/推断能力；也为大规模 MoE 模型在分布式场景下提供了更优的稳定性和资源利用效率。四、FP8训练这部分解释研究起来有点太干了，总而言之就是受益于新的 Hopper GPU（H800 等） 上专门提供了 FP8 Tensor Core，以及对混合精度训练（TensorFloat-32、BF16、FP8）的多项优化，使得低精度可以真正大规模应用而不会拖慢速度。由此，DS团队成功地将 FP8 训练稳定地应用到超过百亿甚至千亿参数量级的模型上，大幅减少了显存占用，同时提高了训练速度，这是过去采用 BF16/FP16 无法进一步显著降低成本的一个新“突破口”。1.为什么之前不常用“低精度”做大模型训练？硬件限制：低精度训练（如 FP8）需要 GPU 硬件在核心计算单元（Tensor Core）上支持相应格式，并且有配套的高速量化/反量化操作。如果硬件不支持，就只能用软件仿真，效率会非常低，还可能要应对额外的数值不稳定性。数值稳定性担忧：一旦精度再降低（从 16-bit 再到 8-bit），激活、梯度就很容易受离群值影响而产生严重的溢出或舍入误差——导致梯度爆炸或模型发散。过去很多实践经验表明，大模型里存在非常大的激活值、梯度值，直接用 8-bit 的浮点或定点数训练，往往极不稳定。已有 BF16（或 FP16）普遍可用且稳定：在过去几年里，BF16 训练已经被各大框架、大模型实验证明较为稳妥，既保证了足够数值范围，又带来了比 FP32 小得多的内存占用和训练加速。开发者往往选择先用 BF16 做大规模模型，这样可以避免太多新的风险。2.为啥DS能做到FP8训练精细的量化策略：对激活、权重进行 tile-wise 或 block-wise 的分块缩放（scaling），而非一刀切的整张张量缩放；这样能够更好地对应激活中局部分布的不同，使得离群值不会破坏整体量化效果。高精度累加（Accumulation）：在做 8-bit Tensor Core 乘加（MMA）时，会把中间结果及时地在 CUDA Core 里用更高精度（如 FP32）进行部分累加，避免大量舍入误差。保持部分关键操作的高精度：例如残差连接、归一化层、门控分数 (MoE gating) 等仍在更高精度（BF16/FP32）中计算，最大程度地保证训练稳定性。支持更好的硬件：在新的 Hopper GPU（H800 等） 上专门提供了 FP8 Tensor Core，以及对混合精度训练（TensorFloat-32、BF16、FP8）的多项优化，使得低精度可以真正大规模应用而不会拖慢速度。五、多Token预测评估（MTP技术）1.在训练时多令牌预测，一次生成多个未来目标传统的自回归预测方式（如 GPT 等模型）在解码时一次只能根据已生成的上下文预测下一个单一的令牌（token），然后再将新产生的令牌拼到上下文中，继续预测下一个，依次循环。MTP（Multi-Token Prediction） 的想法是：在每个位置上，不仅预测下一个令牌，还同时并行预测再往后的第二个或更多个未来令牌。这样一来，模型在训练时就能得到更加丰富的训练信号，从而在推理阶段也可以进一步将这些一次性预测出的多个令牌作为备选，利用推测性解码来整体加速生成。具体做法是：主模型（Main Model） 依旧负责对下一个令牌进行标准的自回归预测；若干个 MTP 模块（MTP Modules） 用来额外预测后续更多位置的令牌。例如当设置深度 $D=2$ 时，每个 token 除了获得下一令牌的分布，还额外得到预测“第二个令牌”的分布。使用多条交叉熵损失的平均值来训练，在不增加（或仅少量增加）推理参数量的前提下让模型获得“深度规划式”的预测能力。推测性解码（speculative decoding） 的核心在于：如果模型一次能预测出多个“候选”令牌，那么下游的“鉴别/接受”机制可以迅速验证哪些令牌真正能够拼接到最终输出中，而不必等待模型一步步地自回归生成。简单来说，推测性解码更像一次性拿到了模型对“接下来的几个位置”整体的预测，再根据一定的规则或辅助判断来“验收”这些额外预测。只要这些额外预测通过了验收，系统就可以一次性把它们放入生成序列里，加快输出速度。为此，DS在主模型之外新增了额外的 Transformer Block 和线性变换矩阵（投影层），它们与主模型的嵌入层和输出层共享参数或部分共享结构，使模型在一次前向过程中就能额外产生未来更多位置的预测分布2.推理阶段如何利用MTP提升生成速度训练完成后，模型可以直接 丢弃 这些 MTP 模块，仍像普通自回归那样一次只预测下一个令牌；或者也可以结合 推测性解码（speculative decoding） 的思路，把 MTP 模块附加到推理流程中，提高解码速度。作者强调：“由于第二个令牌预测的接受率（acceptance rate）相当高，大约在 85%~90%，因此在推理过程中能够一次性批量采纳额外的预测，大大提升解码吞吐量，TPS（Tokens Per Second）相应可提高到 1.8 倍。”这说明当 MTP 模块一次预测出 2 个令牌时，后验检查/鉴别机制发现其中绝大多数是符合上下文的正确令牌，从而可以跳过部分自回归步骤，整体减少了生成过程的迭代次数。这套方法能够在 不显著牺牲预测质量 的前提下，显著提升大模型的推理效率，对大规模应用部署非常实用。论文中还提到如果不需要多令牌并行推理，也可以直接忽略或关闭 MTP 模块，单独使用主模型进行常规解码，保证兼容性与灵活性。未来方向最后，让我们看一下DS团队在V3论文里对未来的前瞻：在训练和推理效率⽅面，我们⼒求实现对⽆限上下⽂⻓度的⾼效⽀持。此外，我们将尝试突破Transformer 的架构限制，从⽽推动其建模能⼒的边界。:::note\nMamba和线性注意力，启动！\n:::我们将持续迭代训练数据的数量和质量，并探索整合更多训练信号来源，旨在推动数据在更⼴泛维度上的扩展。我们将持续探索和迭代模型的深度思考能⼒，旨在通过扩展其推理⻓度和深度来增强其智能和问题解决能⼒。我们将探索更全⾯和多维的模型评估⽅法，以防⽌在研究过程中过度优化固定基准测试，这可能会对模型能⼒产⽣误导性印象并影响我们的基础评估。DeepSeek-R1：RL驱动、o1水平的开源推理模型:::note\n最伟大和出圈的一集\n:::我已经懒得在这里介绍R1发布后的热度几何震撼几何了，直接看论文吧。我们推出了第一代推理模型 DeepSeek-R1-Zero 和 DeepSeek-R1。DeepSeek-R1-Zero 是一个通过大规模强化学习（RL）训练而成的模型，未经过监督微调（SFT）作为初步步骤，展示了卓越的推理能力。通过 RL，DeepSeek-R1-Zero 自然涌现出许多强大且有趣的推理行为。然而，它也面临诸如可读性差和语言混合等挑战。为了解决这些问题并进一步提升推理性能，我们推出了 DeepSeek-R1。该模型在 RL 之前引入了多阶段训练和冷启动数据。DeepSeek-R1 在推理任务上的表现与 OpenAI-o1-1217 相当。为了支持研究社区，我们开源了以下内容：DeepSeek-R1-ZeroDeepSeek-R1基于 Qwen 和 Llama 从 DeepSeek-R1 蒸馏出的六个密集模型（1.5B、7B、8B、14B、32B、70B）本次DeepSeek相当于发布了三个部分的模型：DeepSeek-R1-Zero：疯狂的CoT推理机器，无SFT纯RL训练，不管输出格式，解答不做summarization，阅读性差无格式DeepSeek-R1：带冷启动（Cold Start）SFT，然后做RL训练，控制输出格式，有summarization，是成熟的可直接部署的版本DeepSeek-R1-Distill：基于Qwen和Llama作为Base从R1数据蒸馏成小模型整体流程：一、研究贡献总结1.为什么说DeepSeek-R1-Zero的重大进步是采用纯RL？从现有文献和实践来看，传统的大模型往往需要先用一定量的监督数据（SFT，Supervised Fine-Tuning）“热身”，再进行强化学习（RL）阶段来进一步提升模型在推理、对齐等方面的能力。在不少以往的做法中（例如常见的 PPO、RLFH 等训练流程），会先通过人工或已有模型注释的大规模数据对基模型进行有监督微调，一方面让模型学到更一致的回答风格与格式，另一方面将模型初步对齐到正确的解题思路与答题模式之上。之后再结合强化学习策略（往往利用训练的奖励模型或预先人工标注），做进一步的性能或对齐提升。DeepSeek-R1-Zero 则跳过了这一步：它只基于一些“可度量正确性”的问题（如数学、编程）用规则或判题器给出奖励，完全通过强化学习便“生长”出了多步推理、自动反思等行为。这在一定程度上证明了只要合理地设计奖励函数和训练流程，模型可以通过大规模强化学习自发地“演化”出长链推理、反思（reflection）等复杂能力，而不一定要依赖先验的监督数据。当然，DeepSeek-R1-Zero 在可读性等方面仍有一定缺陷（容易出现多语混杂、叙述不够流畅等），因此后续又在其基础上结合了少量冷启动数据（cold-start data）及多阶段强化学习，形成更好用、更平衡的 DeepSeek-R1 版本。2.蒸馏：小模型也可以很强大使用DeepSeek-R1生成的推理数据，DS对社区中广泛使用的几个密集模型进行了微调。评估结果表明，提炼出的⼩型密集模型在基准测试中表现非常出色。DeepSeekR1-Distill-Qwen-7B 在 AIME 2024 上达到了 55.5%，超过了 QwQ-32B-Preview。此外，DeepSeek-R1-Distill-Qwen-32B 在 AIME 2024 上得分为 72.6%，在 MATH-500 上得分为 94.3%，在 LiveCodeBench 上得分为 57.2%。这些结果显著优于之前的开源模型，并与 o1-mini 相当。DS 向社区开源了基于 Qwen2.5 和 Llama3 系列的 1.5B、7B、8B、14B、32B 和 70B 的checkpoint。3.向全世界开源了一款o1级别性能的、商用级别的、极高性价比的、中国产的推理模型具体跑分这里就不写了。除了之前大家都默认的数理代码能力之外，DeepSeek R1出圈的重要甚至主要原因还在于R1的文学创作能力非常强，当时确实实实在在的惊艳到我了，给全国人民送了个大礼。二、DeepSeek-R1-Zero：在基础模型上进行强化学习之前的研究表明RL在推理任务中表现出显著的有效性，但这些工作严重依赖于人类监督数据，而这种数据的搜集非常耗时耗力，需要大量的数据劳工苦力。因此，DS探索了LLMs在没有监督数据下发展推理能力的潜力，重点关注模型通过纯RL过程中的自我进化。1.基座模型与强化学习算法DS选取了一个预训练好的大模型（DeepSeek-V3-Base）作为初始的基座模型，采用一种名为 Group Relative Policy Optimization（GRPO）的方法，该算法与 PPO 类似，但不需要单独的价值网络。对于每个训练样本，DS会从旧策略采样一组输出，然后计算每个输出的奖励，与组内其他输出的奖励进行对比形成优势（advantage），最后用带有裁剪（clipping）的目标函数来更新策略模型。这样既简化了计算开销，也能在大规模 RL 训练中保持稳定。2.奖励设计：基于“正确性+格式”正确性奖励（accuracy reward）：针对有明确判分标准的问题（如数学、编程），用规则（例如数学答案可直接比对，编程通过编译测试用例）来判断输出是否正确，并给予相应的奖励或惩罚。格式奖励（format reward）：要求模型在回答时先输出推理过程（用 <think> 标签包裹），再输出答案（用 <answer> 标签包裹）。如果模型遵守这一格式，就会获得额外的正奖励。模型训练对话模板如下：A conversation between User and Assistant. \nThe user asks a question, and the Assistant solves it. \nThe assistant first thinks about the reasoning process in the mind and then provides the user with the answer. \nThe reasoning process and answer are enclosed within <think> </think> and <answer> </answer>, respectively.\n\nUser: <prompt> \nAssistant:\n模型输出时，必须先写下完整推理（<think>...</think>），再给出最终答案（<answer>...</answer>）。如果答案被规则判定为正确，同时格式合规，则累加奖励。对于数理题这种有确定答案地场景，通过匹配答案正确性就能获得奖励，例如：question: find the minimal value of x^2 - 4x + 1 = 0……Answer:  $\\boxed{-3}$正确答案是 -3，那么可以通过规则匹配上就可以得到奖励1，匹配不上为奖励-1，特别的要处理1/2和0.5这种同值不同形式的匹配。通过这种大规模、持续迭代的 RL 训练，让模型不断学会更长、更完整的推理，并提升准确率。可以看到，随着RL的推进，DeepSeek-R1-Zero表现出稳定且一致的性能提升。图为DeepSeek-R1-Zero在RL过程中训练集上的平均响应长度。可以看出DeepSeek-R1-Zero自然地学会了通过更多的思考时间来解决推理任务。在整个训练过程中，模型的改进并非来自外部调整，而是源于内部的内在发展。DeepSeek-R1-Zero 通过利用扩展的测试时间计算，自然地获得了解决日益复杂推理任务的能力。这种计算范围从生成数百到数千个推理标记，使模型能够更深入地探索和完善其思维过程。这种自我进化最显著的一个方面是，随着测试时间计算的增加，复杂行为的出现。例如，模型会进行反思——即重新审视和评估其先前的步骤——并探索解决问题的替代方法。这些行为并非明确编程，而是模型与强化学习环境交互的结果。这种自发的发展显著增强了 DeepSeek-R1-Zero 的推理能力，使其能够更高效、更准确地应对更具挑战性的任务。3.自发涌现的长链推理与反思DeepSeek-R1-Zero在训练中并没有显式地被人工示例教导要“写冗长推理”或“要进行自我反思”，而是通过准确性与格式的奖励信号，自发产生了长链推理与多次自我检查、反思（reflection）等复杂行为。训练进行到中期时，模型在推理过程中可能会出现“突然意识到自己推理有误”然后改写推理的“aha moment”，这在纯 RL 场景下非常有意思。aha moment强调了RL的力量和美感：我们不需要明确地教导模型如何解决问题，而是需要简单地为其提供正确的激励，模型就会自主发展出高级的问题解决策略。三、DeepSeek-R1：冷启动的强化学习DS研究团队在观察到R1-Zero的显著成果和局限性之后，提出了两个问题：通过引入少量高质量数据作为冷启动，能否进一步提升推理性能或加速收敛？如何训练一个用户友好的模型，不仅能生成清晰连贯的思维链（CoT），还能展示强大的通用能力？为此，DS开始了R1的训练。1.冷启动-少量SFT为了防止从基础模型开始的RL训练出现太多的不稳定因素，训练团队先使用少量精心挑选并带有详细推理过程的监督数据（SFT数据）来对基座模型进行一次初步微调，让模型拥有一个更好的起点。简单概括来说，冷启动数据大多是一些带有详细推理步骤的题目（如数学推理、编程问题），由人工或已有模型先生成较高质量的示例，让 DeepSeek-V3-Base 先学到合适的“写作/推理风格”、清晰的答案格式以及基础的解题思路。随后再通过强化学习去“放大”这些推理能力，进一步提升准确率与推理深度。这样做不但能加速模型从无到有的推理能力构建，而且还能保证最终模型在语言流畅度、格式可读性方面有更出色的表现。与 DeepSeek-R1-Zero 完全跳过 SFT、直接用 RL 训练基模型相比，冷启动的目的是帮助模型预先“学会”一些人类可读的推理格式和初步思路，从而在后续的大规模 RL 中更快、更稳定地收敛，并且避免出现多种语言混杂、可读性差等问题。可读性：DeepSeek-R1-Zero 的一个关键限制是其内容通常不适合阅读。响应可能混合多种语言，或缺乏 Markdown 格式来突出显示答案。相比之下，在为 DeepSeek-R1 创建冷启动数据时，研究团队设计了一种可读的模式，包括在每次响应的末尾添加摘要，并过滤掉对读者不友好的响应。此处，输出格式定义为 |special_token|<推理过程>|special_token|<摘要>，其中推理过程是查询的 CoT，摘要用于总结推理结果。潜力：通过精心设计带有人类先验的冷启动数据模式，研究团队观察到相较于 DeepSeek-R1-Zero 的更好性能，他们相信，迭代训练是推理模型的更优方式。2.面向推理的强化学习 RL在冷启动数据上对 DeepSeek-V3-Base 进行微调后，研究团队采用了与 DeepSeek-R1-Zero 相同的大规模强化学习训练过程。这一阶段的重点是增强模型的推理能力，特别是在编码、数学、科学和逻辑推理等推理密集型任务中，这些任务涉及具有明确解决方案的明确定义的问题。在训练过程中，研究团队观察到 CoT 经常出现语言混合现象，尤其是在 RL 提示涉及多种语言时。为了缓解语言混合问题，研究团队在 RL 训练中引入了语言一致性奖励，该奖励计算为 CoT 中目标语言单词的比例。尽管消融实验表明这种调整可能导致模型性能略有下降，但这种奖励符合人类偏好，使其更具可读性。最后，研究团队通过直接相加将推理任务的准确性和语言一致性奖励结合起来，形成最终奖励。然后，研究团队在微调后的模型上应用 RL 训练，直到其在推理任务上达到收敛。3.拒绝采样阶段（收集整理SFT数据）在RL阶段基本收敛之后，DS会基于当前的RL检查点来生成一批新的监督微调SFT数据，用于下一阶段的正式SFT训练。和初始“冷启动”阶段只面向推理任务不同，这一次他们会纳入更多不同任务类型的数据，进而增强模型在写作、角色扮演、问答、翻译等通用场景下的能力，此过程包含以下两部分：3.1 生成推理数据：拒绝采样首先，“拒绝采样”（rejection sampling）指的是针对同一个提示多次采样，让已训练（或正在训练）中的模型对同一个问题/提示生成多条不同的回答。生成后，研究团队将基于质量标准筛选输出，对这些候选输出进行自动或人工的质量评估，凡是未通过评估标准（例如判定错误、格式混乱、或不符预期）的回答会被“拒绝”掉；只有通过评估、被判定为正确或高质量的回答才会被“接受”并保留下来，用作下一轮监督微调（SFT）的训练数据。之所以要做拒绝采样，是因为即使经过强化学习后的检查点，也难免会产生一些错误或较低质量的回答。通过一次性采样多个候选并只保留“正确/优质”回答，就可以自动构造出更高质量的 SFT 数据，减少人工标注量，同时让模型在后续训练中获得更精准的监督信号。这一阶段采用基于规则的正确性判定（如判题器检查数学/编程题）、生成式奖励模型（将真实答案与模型预测输入 DeepSeek-V3 等模型对比打分）等手段。同时为了保证可读性，会过滤掉混合语言、过长段落、凌乱代码块等不符合预期的输出，最终只保留质量较高、答案正确的候选回答。最终，他们将“被接受”的回答连同对应的提示（Prompt）一起，整理为标准的监督训练样本，包含完整的“问题-思维链-答案”结构。经过多次迭代的“拒绝采样”后，一共收集了约60万条与推理相关的训练样本。3.2 扩充非推理数据在此阶段还会纳入与推理无关的任务数据，以便提升模型在写作、对话、角色扮演、知识问答、翻译等更广泛场景下的实用性。复用已有数据：从 DeepSeek-V3 的 SFT 数据集中，筛选出写作、问答、翻译等任务示例。对于部分任务（如较复杂的写作场景），可以引导模型产生一定的“思维链”帮助其构思；但对于简单问候类的请求，如“你好”，就不再强制输出 CoT。补充新的通用场景：补充一些额外的数据源，如带有多轮对话、角色扮演、自我认知等场景，保证模型在日常交流及复杂对话中的表现更自然。最终，他们搜集了大约 20 万个与推理⽆关的训练样本。4.监督微调 正式SFT训练综合上述推理与非推理数据，共计约 80 万条训练样本，构成一个高质量、覆盖多领域的 SFT 数据集。将该数据集用于对 DeepSeek-V3-Base 模型进行 2 个 Epoch 左右的监督微调（SFT）：对齐模型风格：通过监督方式，让模型在推理格式、回复风格、对话礼仪、内容连贯等方面更加统一、自然。提升多场景能力：既强化了模型在数学、编程、逻辑推理上的正确率，又扩充了模型在写作、问答、对话、翻译等通用场景的实用性。在完成这一步后，模型基本具备了较完善的回答形式和可读性，并能在多类任务中提供较高水平的答复。随后结合更多场景的 RL 训练，可以进一步增强模型的对齐效果与安全性，使得 DeepSeek-R1 系列在推理能力和通用应用之间达到更好的平衡。四、蒸馏：赋予小模型推理能力在强化学习阶段得到的强大推理模型 DeepSeek-R1，可进一步作为“教师模型”为小模型进行蒸馏（Distillation），从而让小模型也能具备相当程度的高阶推理能力。其核心思路是：从教师模型中采样出丰富、高质量的推理数据，再用这些数据对小模型做有监督的微调（SFT），就能让小模型学到教师模型在思维链（Chain-of-Thought）、答案精准度等方面的优点。1.蒸馏流程概览教师模型：选定已经完成多轮强化学习并表现出优异推理能力的 DeepSeek-R1 checkpoint，通过它在大量、多类型的推理场景中进行推理采样，得到以 <think>…</think> 形式呈现的思维链 + <answer>…</answer> 最终答案。之后，进行数据筛选，类似拒绝采样（Rejection Sampling）的思路，对教师模型输出进行自动或人工评估，只保留正确和可读性良好的高质量样本。在这一环节会涵盖数学、编程等可客观判定正确性的任务，也会吸收一部分更开放场景下的推理示例，以丰富小模型的训练分布。为了让更高效的小模型具备像 DeepSeek-R1 一样的推理能力，我们直接使用 DeepSeek-R1 整理的 80 万样本对开源模型进行微调，例如 Qwen（Qwen, 2024b）和 Llama（AI@Meta, 2024）。:::note\n我不知道这里“整理的80万样本”是R1出锅之前的那个原始训练集，还是出锅之后又烘培了80万份样本。\n:::在数据筛选完之后，针对如 Qwen 系列（1.5B、7B、14B、32B、70B）或 Llama 系列（8B、70B）这类开放大模型，直接用上一步得到的“教师数据”进行有监督微调。在训练中，小模型逐步“模仿”教师模型的解题思路与回答格式，从而学会更长、更完整的推理链条与高准确度的解题策略。2.蒸出的小模型性能评估从实验结果看，蒸馏后的小模型可在多项推理基准测试（如 AIME 数学竞赛题、MATH-500、编程题等）上取得接近甚至超越较大原模型的表现。例如：DeepSeek-R1-Distill-Qwen-7B 在 AIME 上能达到 55.5% 的 Pass@1 准确率，相比未蒸馏版本有大幅提升。DeepSeek-R1-Distill-Qwen-32B 更是能取得 72.6% 的 AIME Pass@1，并在 LiveCodeBench 等编码任务上成绩领先其他同等规模模型。这些结果表明，通过蒸馏自具有强大推理能力的教师模型，较小参数规模的模型依旧可以在推理任务中取得令人印象深刻的水平，且大大减少了推理时的计算与内存消耗。3.蒸馏 VS. 直接强化学习有趣的是，若尝试对小模型直接进行大规模强化学习（即不依赖教师模型），往往需要投入庞大的算力，而且最终推理性能也未必能匹敌蒸馏的效果。例如对 Qwen-32B 模型进行大规模 RL，只能达到与QwQ-32B-Preview相近的水准。然⽽，从 DeepSeek-R1 蒸馏⽽来的 DeepSeek-R1-Distill-Qwen-32B 在所有基准测试中表现显著优于 DeepSeek-R1-Zero-Qwen-32B。通过在多任务、多类型推理数据上的蒸馏，小模型获得了可观的推理能力，又保留了推理速度快、资源占用低等优势。未来如果将蒸馏方法与更多样化的强化学习场景、对齐技术相结合，还可能进一步释放小模型的潜能。对应用场景而言，这意味着在更轻量、可部署性更好的前提下，依旧能获得远超传统小模型的推理效果，真正做到“让小模型拥有大智慧”。因此，我们可以得出两个结论：首先，将更强大的模型蒸馏到较小的模型中会产生优异的结果。然而，依赖于本文中提到的大规模强化学习的小模型，往往需要巨大的计算能力，甚至可能无法达到蒸馏所期望的性能。其次，尽管蒸馏策略既经济又有效，但要超越智能边界，可能仍然需要更强大的基础模型和更大规模的强化学习。未来展望以下是DS团队在论文末尾写的内容。未来，我们计划在以下方向为 DeepSeek-R1 进行投资研究：通用能力：目前，DeepSeek-R1 在函数调用、多轮对话、复杂角色扮演和 JSON 输出等任务上的能力不如 DeepSeek-V3。未来，我们将探索如何利用长链思维（CoT）来提升这些领域的任务表现。语言混合：DeepSeek-R1 目前针对中文和英文进行了优化，这可能导致在处理其他语言的查询时出现语言混合问题。例如，即使查询使用的是非中文或英文的语言，DeepSeek-R1 仍可能使用英文进行推理和回答。我们计划在未来的更新中解决这一限制。提示工程：在评估 DeepSeek-R1 时，我们观察到它对提示非常敏感。少样本提示（Few-shot prompting）会持续降低其性能。因此，我们建议用户直接描述问题，并在零样本设置（zero-shot setting）中指定输出格式，以获得最佳结果。软件工程任务：由于评估时间较长，影响了强化学习过程的效率，大规模强化学习在软件工程任务中尚未得到广泛应用。因此，DeepSeek-R1 在软件工程基准测试上并未显示出相较于 DeepSeek-V3 的巨大改进。未来版本将通过实施软件工程数据的拒绝采样或在强化学习过程中引入异步评估来提高效率，以解决这一问题。参见[1] 小冬瓜AIGC：【解读】DeepSeek-R1：RL前真的不需要SFT了吗???[2] Liu A, Feng B, Xue B, et al. Deepseek-v3 technical report[J]. arXiv preprint arXiv:2412.19437, 2024.[3] Guo D, Yang D, Zhang H, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning[J]. arXiv preprint arXiv:2501.12948, 2025."
  },
  {
    "title": "模型考古学（五）：Minimax-01 模型技术报告简读",
    "summary": "DeepSeek V3刚出那会就想专门写篇解读博客了，但一直摸到现在，我寻思再不写的话Qwen3和Ds v4都快出了，当懒狗开摸也得有个限度对伐。Minimax-01模型亮点：Lightning attention加持下的百万上下文窗口先放一个模型的跑分表，可以看到Minimax 01尤其在超长上下文领域表现优秀，随着上下文长度的增加，其模型性能衰退的速度是所有长上下文模型里最缓慢的。1.Tran",
    "tags": [
      "模型考古学"
    ],
    "url": "/posts/AI and Deep Learning/minimax-01-report/",
    "date": "2025-03-22T00:00:00.000Z",
    "content": "DeepSeek V3刚出那会就想专门写篇解读博客了，但一直摸到现在，我寻思再不写的话Qwen3和Ds v4都快出了，当懒狗开摸也得有个限度对伐。Minimax-01模型亮点：Lightning attention加持下的百万上下文窗口先放一个模型的跑分表，可以看到Minimax 01尤其在超长上下文领域表现优秀，随着上下文长度的增加，其模型性能衰退的速度是所有长上下文模型里最缓慢的。1.Transformer架构模型的固有缺点——上下文增加带来计算复杂度的二次增长我们都知道Transformer的核心机制是自注意力机制(Self-Attention)，它在每一层都要对输入序列的每一个token与其他所有token进行交互，这就导致了如下计算复杂度：$$\nO(n2⋅d)$$$n$：输入序列的长度（即上下文长度）$d$：表示维度（一般为隐藏层维度）当上下文长度n增加时，计算复杂度会按照 $n^2$ 的速度增长，注意力机制如此设计会导致随着上下文长度增加，如从1k tokens到8k、32k乃至于1M，对应的资源需求也会暴涨。注意力矩阵为 $n^2$ ，那么32k tokens就是一个32000*32000的矩阵，占用显存极大；训练中每一步都要进行 $n^2$ 次乘法运算，训练/推理速度也会大幅下降。由此，Transformer一开始其实并不擅长原生建模如长文档、代码、大型图数据等长序列模型。那么，之前学术界的解决办法都有哪些呢？To address this challenge, researchers have proposed various methods to reduce the computational complexity of the attention mechanism, including:Sparse Attention (Beltagy et al., 2020; Zaheer et al., 2020)Linear Attention (Qin et al., 2022a, 2022b, 2024c)Long Convolutions (Qin et al., 2023a)State Space Models (the Mamba series) (Dao and Gu, 2024; Glorioso et al., 2024; Gu and Dao, 2024; Ren et al., 2024; Team et al., 2024b)Linear RNNs (Qin et al., 2023b, 2024d)Despite their theoretical promise, these innovations have seen limited adoption in commercial-scale models.英译中就是方法有稀疏注意力、线性注意力、长卷积、状态空间模型（如Mamba系列）还有线性RNN等。（1）稀疏注意力（Sparse Attention）代表工作：Beltagy 等人（2020），提出了 LongformerZaheer 等人（2020），提出了 Big Bird大鸟转转转，启动！传统注意力机制中，所有位置（token）的两两交互都需要计算相似度，导致计算和显存开销随序列长度 n 呈平方关系。稀疏注意力的核心思路是只让部分位置之前进行注意力计算，使注意力矩阵变得稀疏，从而显著降低复杂度。Longformer采用局部窗口（local window）和全局token（global tokens）相结合的稀疏模式，而 Big Bird 则在此基础上结合随机稀疏和环状全局连接（circular patterns）。这类方法可以将复杂度降低到 $O(n)$ 或 $O(n log n)$ ，在长序列任务如文档级自然语言理解、长序列生成等方面具有一定优势。稀疏注意力主要优势在于在长序列上显著减少计算量和内存占用，在对局部上下文比较敏感（比如文档摘要）的任务中效果通常较好。但这个架构下的稀疏模式需要精心设计，不同任务需要不同的稀疏结构，在捕获远程依赖（long-range dependency）时，依旧存在可能覆盖不足的隐患。（2）线性注意力（Linear Attention）代表工作：Qin 等人（2022a,b, 2024c）等线性注意力旨在将原本 $O(n²)$  的注意力操作近似或重构为 $O(n)$ 或  $O(n d)$ ，其中d通常为特征维度，其理论基础常是对 softmax 或其他核函数进行低秩近似、核化技巧（kernel trick）或因式分解。典型实现包括：Performer：通过随机特征映射（Random Feature Mapping）将 softmax 转换为可分解的向量乘积形式。Linear Transformers：使用可分解核函数将注意力矩阵分解，从而线性地累积和计算上下文信息。这种工程方法的优点是理论复杂度大幅下降，易于在较长序列上进行扩展，减轻硬件压力，但一些线性化近似在准确性和稳定性上仍有挑战，尤其是当分布非常复杂或软注意力分布较尖锐时，逼近效果可能不如标准注意力。在实际大规模预训练模型中，线性注意力可能面临数值稳定性和收敛速度等问题，需要对训练流程进行专门调优。（3）长卷积（Long Convolution）代表工作：Qin 等人（2023a）基于卷积的模型通常具有平移不变性和高效的局部特征提取能力，且在硬件上（尤其是 GPU、TPU）高度可并行化。为应对长序列建模的需求，研究者引入了“长卷积”思想，即在传统卷积核的基础上通过扩张卷积（dilated convolution）、分段卷积或分块交互等方式来建模长距离依赖。与稀疏注意力相似，长卷积通过结构化地控制感受野的扩张，使得模型在捕获远距离依赖的同时保持较低的计算复杂度（通常在 $O(n) ～ O(n log n)$ 范围）。优点是卷积对于局部模式和相对位置信息建模具备先验优势，但对特别远程的依赖可能需要较深网络或技巧性设计，效果不一定优于稀疏注意力；长卷积内核的设计和超参数设置往往比较复杂，模型大小也可能随之增加。（4）状态空间模型（Manba系列）代表工作：Dao 和 Gu（2024）Glorioso 等人（2024）Gu 和 Dao（2024）Ren 等人（2024）Team 等人（2024b）非常好Manba，使我的长序列问题out，腾讯用了都说好！在序列建模中，状态空间模型（State Space Model, SSM）是一类将输入序列映射到隐状态空间再输出的模型，对应一个线性微分方程（或离散差分方程），能够以 O(n) 的复杂度表征长序列依赖。S4、Mamba 系列等模型通过对状态方程的谱域或时域进行高效求解，让网络对输入序列做卷积式或近似卷积式的处理，从而在理论上实现对数千甚至上万长度序列的高效建模。优点：改进隐状态更新和输出映射，使得训练和推理更稳定；结合特定任务特征（如语言建模、时序预测、语音处理等），在保持线性复杂度的同时兼顾表达能力。在捕捉长程依赖时，复杂度可保持在 O(n)，理论上可支持超长序列。采用隐状态更新的方式，有利于在序列处理中与 RNN 等架构兼容，也方便硬件流水线加速。潜在局限性：对大规模预训练语言模型的适配仍在探索中，实际落地需要考虑与自回归生成、上下文并行等机制的兼容性。模型超参数（如状态维度、离散化方式）选择不当时，可能导致优化不稳定或泛化性能欠佳。（5）线性RNN（Linear RNN）代表工作：Qin 等人（2023b, 2024d）传统 RNN（如 LSTM、GRU）在长序列建模中往往面临梯度消失或爆炸的问题，而且在推理时大多只能顺序执行，难以并行。线性 RNN 方法则尝试对循环结构中关键的非线性部分进行线性化，或者通过特定的核函数、矩阵分解，将状态更新变得更加稳定且易于并行化，最终在理论上能实现近似的 O(n) 训练和推理效率，同时减轻梯度消失。与状态空间模型类似，此类方法核心在于对“循环”结构的改造，追求在大规模数据下更加可训练、可扩展，从而为长序列任务提供一种更轻量级的替代方案。主要优点保留 RNN 的时序依赖机制，避免大规模全局注意力的高内存开销。相比标准 RNN 更易训练，并能部分并行化，推理延迟也较小。潜在局限在捕获复杂的跨句或篇章级依赖时，可能仍不及注意力机制灵活。线性化的近似方式需要平衡模型容量和稳定性；训练大规模模型时的数值问题和优化策略仍有待进一步研究。Minimax最后做了个总结，尽管这些创新在理论上颇具前景，但在商业规模模型中的应用仍然有限。那么，Minimax的解决方法是什么呢？他们确定了一种混合架构，主要使用基于 线性注意力（Linear Attention） 变体的 闪电注意力（Lightning attention） Qin 等人（2024b），该架构中，每七个使用 Lightning attention 的Transformer块之后都会跟随一个使用Softmax Attention的Transformer块。Minimax 01采用了MoE架构，最终参数为456b，激活459亿，共32个专家。新模型在长上下文场景下的响应延迟也非常不错。2.注意力架构设计简析该架构中，每七个使用Lightning attention的Transformer块之后都会跟随一个使用Softmax Attention的Transformer块我们知道Softmax Attention通常指的是Transformer及其变体中使用的“标准自注意力机制”，也被称为Scaled Dot-Product Attention。这一机制在每个注意力头的计算中，会对查询（$Q$）和键（$K$）之间的相似度采用点积后再使用Softmax函数归一化，以得到注意力权重，然后将权重作用在对应的值向量（$V$）上。其核心公式可写作：$$\nAttention(Q,K,V)\n= \\text{softmax}!\\Bigl(\\frac{QK^\\mathsf{T}}{\\sqrt{d_k}}\\Bigr),V\n$$在训练和推理时，Softmax Attention 机制最主要的计算瓶颈在于其注意力矩阵（$\\text{softmax}!\\Bigl(\\frac{QK^\\mathsf{T}}{\\sqrt{d_k}}\\Bigr)$）的大小通常是随序列长度 nn 呈二次增长（$O(n^2)$），这会导致当序列较长时开销非常大。这么做的优势是能够对序列任意两位置（token）的交互进行“显式”建模，对长程依赖的捕捉更全面、表达能力较强。所以在通常的普遍的大语言模型中，Softmax Attention 仍被广泛采用，成为 Transformer 结构模型的核心。而Minimax 01为了兼顾超长上下文+经济的资源占用，采用了在大部分 Transformer 块中使用线性注意力（Lightning attention），但仍定期插入少量 Softmax Attention 块的工程方法。线性注意⼒确保了恒定的计算复杂度𝑂(𝑑)，不受序列⻓度影响。这是通过循环更新项 KV 实现的，从⽽避免了重复计算整个注意⼒矩阵的需要。相⽐之下，softmax 注意⼒在推理过程中会产⽣𝑂(𝑛𝑑)的复杂度。线性注意力既可以在一次整段前向计算中是$O(n)$ 级别，也能够在自回归场景下进一步将每步的边际开销缩减到仅$O(d)$。Minimax团队在实验过程中发现Lightning attention机制在检索能力上表现有限，启发了他们探索采用一种混合方法（Hybrid-Lighting），结合了Lightning attention 和 Softmax Attention 二者的优势，通过每隔⼋层⽤ softmax 注意⼒替换闪电注意⼒来提升检索性能。虽然纯线性注意力模型在计算上高效，但他们并不适合LLMs。这是因为他们本质上无法执行检索，而检索能力对于上下文学习至关重要。这是Minimax-text-01的架构图：虽然线性注意力（包括各种近似或低秩方法）虽然在理论和实验中大幅降低了计算复杂度和显存占用，但其对注意力分布的近似在某些场景下会带来表达损失，尤其是对长程依赖或分布较尖锐的注意力模式可能刻画得不够精细。插入少量的 Softmax Attention 块可以弥补这一局限，让模型仍能捕捉到更复杂或更细腻的依赖结构。另一方面，如果所有模块都使用标准的 Softmax Attention，则 O(n²) 的注意力机制在长序列场景下会带来巨大的硬件与时间成本。因此，在大多数块中使用近似快速的注意力机制，只在一定间隔（例如每 7 个块）使用完整的 Softmax 注意力，就成为了一种工程上的“折衷方案”——既维持了大部分模块的高效性，也让模型在必要的层次仍保留了较高保真度的注意力计算。让我们看一下不同架构的模型参数与 FLOPs ⽐较：已知常见符号含义如下：$b$：批大小（batch size）$n$：序列长度（sequence length）$l$：网络层数（number of layers）$d$：隐层维度（hidden dimension）$h$：注意力头数（number of attention heads）参数量方面，三种注意力机制相比，Softmax最简单只有 $12ld^2$；Lightning和Hybrid则多一些关于 $d^2/h$ 的额外项，表明线性或混合注意力需要一部分核映射或门控参数。FLOPs（运算量）：Softmax 随着序列长度 $n$ 增加会显著抬升，因为注意力部分是 $O(n^2)$（表格中则以$\\tfrac{n}{6,d}$的方式体现出依赖程度）。Lightning 避免了对 $n$ 的直接依赖，主要受注意力头数 $h$ 的影响，因此在长序列场景下运算量增幅更小。Hybrid‐lightning 介于两者之间：相对于纯 Lightning，多了一些与序列长度和注意力头数相关的运算成本，但通常比全部 Softmax Attention 要更高效；同时能在一定程度上保留 Softmax 的高保真注意力。:::note\n这张表格应该可以很清晰地显示不同技术路径的性能消耗区别了。模型规模越大，Lightning Attention 与 Hybrid-lightning 相对于 softmax 注意力的优势就越明显。\n:::技术报告显示，Lightning attention 在大多数下游任务中表现出与 Transformer 模型相当的性能，除了 NIAH。这表明线性注意力在语言建模能力上与 Transformer 模型相似，但在检索任务上表现不佳，使其不适合于大规模语言模型（LLMs）。然而，Hybrid Lightning attention 不仅匹配了 softmax attention 的检索和外推能力，还超越了其表现，因而非常适合在 LLMs 中进行上下文学习。Softmax 注意力机制可解释为一种线性 RNN（Qin 等人，2024a）。在每个时间步 $t$ 从初始时间 $t=1$开始，重新计算隐藏状态的过程常被比喻为“翻阅书籍”。该方法通过系统地回顾先前数据，使模型能够准确保留输入信息。相比之下，线性模型缺乏这种重新计算过程，这限制了它们有效保留输入数据的能力。Hybrid Lightning Attention实现了与序列⻓度⽆关的恒定训练速度，并且是唯⼀⼀个性能超过FlashAttention2 的线性模型。3.总结Minimax本次的研究成果还是非常惊艳扎实的，从整体看，他们本次主要面向「如何在保证模型表达能力的同时控制计算资源消耗」做了扎实的探索，没有选择一味追求极致高效的线性模型（比如全 Lightning attention），也没有保守地坚持全 Softmax 架构，而是走出了一条 工程实用主义导向的“混合注意力路径”。此外，Minimax Text-01 模型在架构设计上采用了 分层结构+MoE（专家路由）机制，进一步压缩推理成本，增强了模型在多任务、多语境下的适应能力。最终呈现出的表现，是一种理论创新与工程可行性高度融合的成果。当然，目前包括 Hybrid Lightning 在内的各类长上下文解决方案仍存在很多值得继续探究的问题，比如：如何进一步提升线性 attention 机制下的对齐能力与泛化性？Softmax block 的插入策略是否存在更优设计（例如动态插入、任务自适应等）？面对极端长文本（如百万字级文档、代码库、视频字幕等），模型的训练稳定性和学习效率是否仍然可控？在论文结尾，他们注明了未来的研究方向之一：当前模型保留了 1/8 的组件，采⽤标准 softmax 注意⼒机制。我们正在研究更⾼效的架构，以期完全消除 softmax 注意⼒，从⽽可能实现⽆计算开销的⽆限上下⽂窗⼝。如果无计算开销的无限上下文窗口模型真给他们做成，那未来复杂市政 Agent 系统、跨文件级代码自动修复、长篇对话连续推理、甚至真实世界记忆能力的 LLM 构建等等场景都可以想象乃至初步落地了。:::note\n下一篇估计会简读DeepSeek V3和R1的技术报告\n:::"
  },
  {
    "title": "浅谈一下我现在正在使用的AI服务",
    "summary": "作为一个从2022年12月就开始折腾ChatGPT等ai模型工具的老玩家，今天我想分享一下我目前正在使用的AI服务和一些感受。首先，我们都会在哪些场景下使用AI模型？对于我自己，主要是Coding写代码、写作（包含专业论文和非专业的博客、文案等）、日常闲聊三个场景，除此之外的其他场景实际上也超出了目前大模型+相关工具的能力上限。Coding编程场景这部分任务我主要使用Windsurf。Windsu",
    "tags": [],
    "url": "/posts/Essays/myaitools/",
    "date": "2025-03-21T00:00:00.000Z",
    "content": "作为一个从2022年12月就开始折腾ChatGPT等ai模型工具的老玩家，今天我想分享一下我目前正在使用的AI服务和一些感受。首先，我们都会在哪些场景下使用AI模型？对于我自己，主要是Coding写代码、写作（包含专业论文和非专业的博客、文案等）、日常闲聊三个场景，除此之外的其他场景实际上也超出了目前大模型+相关工具的能力上限。Coding编程场景这部分任务我主要使用Windsurf。Windsurf相较于Cursor和Copilot的优势：订阅便宜。Windsurf标准pro订阅是15美刀，如果你是最早就开始用Windsurf的那一批，pro订阅的价格会永久定为10美刀，爽到。系统设计更科学，Agent模式表现更好。这点我和群友均有同样感受，cursor经常会出现“很忙，但不知道在忙什么”的感觉，令人忍俊不禁。Windsurf的系统架构设计非常有含金量。非常拟人通人性的Tab补全功能：这个谁用谁爽。当然，Windsurf也并非没有缺点：Pro订阅下包含两个计量服务：其中高级模型对话额度为每月500次，Agent的Flow额度为每月1500次。Flow额度通常会消耗的比高级模型对话额度快很多，1500次很不够用，如果用完的话要么只能等下个月订阅刷新，或者花费十美刀购买500个灵活额度。与之相对的，如果你购买了cursor的pro会员，那么你每个月付费额度用完之后还可以继续用慢速高级模型，起码对于非紧急需求也能凑合着用用（似乎近期慢速高级模型真的变龟速了）没了，我认为这就是Windsurf仅存的缺点，考虑到10刀每月的订阅价格甚至这都不能算缺点如果你囊中羞涩或者缺乏支付渠道或者只是单纯的不想为这个场景付费，你也可以直接选择字节的Trea，可以白嫖Claude 3.7，非常之香。写作场景这部分任务我通常会将 DeepSeek R1 + Qwen max + chatgpt-4o-latest + Gemini 2.0 pro 四个模型来回用。R1：还是谁用谁懂，最有文化水平和灵动的一集；但幻觉率同样居高不下+喜欢自己嗯凑高大上的科技名词，有时候很令人恼火Qwen max：国产最强的旗舰通用非推理模型，万金油chatgpt-4o-latest：代表Openai通用旗舰非推理模型的最新成果，动态更新，同样是各个领域的万金油六边形战士，发挥稳定，通常是最不坏的选择Gemini 2.0 pro：在DeepSeek r1出现之前是中文写作最灵动的模型，出之后稍逊风骚日常闲聊ChatGPT+豆包+R1为什么呢？首先是ChatGPT，我认为ChatGPT这个产品本身的设计是非常成功的，OpenAI很好的将旗舰级六边形战士模型+目前最完善最贴合使用需求的Tools+强大的语音对话功能集合在一起，形成了ChatGPT这个产品本身。虽然我们常常说OpenAI拉了胯/close ai/邪恶男同奥特曼巴拉巴拉巴拉，但其本身的对齐能力仍然是无可置疑的黑科技，OpenAI的模型几乎在任何场景下都是「最不坏的选择」，如果你不知道某个场景下用什么模型更好，那就直接用4o吧。豆包的主要优势则是全世界T0的中文语音对话能力，字节的TTS听起来非常舒服；让我们抛开doubao模型能力就那样不谈，豆包产品本身也是国内大模型C端产品里做的最完善最好的那个。不愧是最会做产品的互联网大厂R1则主要是本身模型能力太过于惊艳，这点无需多言。总结说了这么多，其实每个人的使用习惯和偏好都不一样。AI工具的快速演进，也意味着没有哪个选择是“最优解”——只有“此时此刻对你最合适的工具”。就像我自己从最早折腾Prompt到现在更看重产品本身的稳定性、拟人化设计、以及模型背后的“气质”，一路下来也逐渐形成了属于自己的搭配组合。我的建议是：别迷信单一模型，勇于尝试混搭策略；别被参数和bench吓住，多用用，多问问，多对比；AI的本质始终是“助手”，不是替你思考的机器，它能让你效率翻倍，也可能让你陷入幻觉的迷宫。保持清醒、保持怀疑，也保持好奇。愿你我都能成为在AI时代里游刃有余的“使用者”，而不是“被使用者”。🌊——写于风浪之中，Windsurf依然划得飞快。"
  },
  {
    "title": "模型考古学（四）：RAG技术解析",
    "summary": "一、前言什么是RAG？你是否遇到过这样的场景？向ChatGPT询问昨晚的欧冠赛果，它却给出两年前的比赛数据；让文心一言分析最新的政策文件，它开始编造不存在的条款。这是因为大模型的知识来源为训练时的静态数据，这些数据不会随着时间推移而自动更新。在大模型（LLM，Large Language Model）的发展过程中，信息的获取和生成能力一直是核心关注点。然而，传统大模型在处理实时信息、长尾知识或特定",
    "tags": [
      "模型考古学"
    ],
    "url": "/posts/AI and Deep Learning/deeplearning-research-004/",
    "date": "2025-03-20T00:00:00.000Z",
    "content": "一、前言什么是RAG？你是否遇到过这样的场景？向ChatGPT询问昨晚的欧冠赛果，它却给出两年前的比赛数据；让文心一言分析最新的政策文件，它开始编造不存在的条款。这是因为大模型的知识来源为训练时的静态数据，这些数据不会随着时间推移而自动更新。在大模型（LLM，Large Language Model）的发展过程中，信息的获取和生成能力一直是核心关注点。然而，传统大模型在处理实时信息、长尾知识或特定领域数据时，常常面临知识更新滞后、存储成本高昂以及幻觉（hallucination）问题。既然大模型自己本身的知识库是死的，那我们给它外置一个不断更新的知识库不就行了？为了解决这些问题，检索增强生成（Retrieval-Augmented Generation，RAG）技术应运而生。RAG的基本原理RAG是一种结合了信息检索（Retrieval）和文本生成（Generation）的混合架构，它允许大模型在回答问题时，不仅依赖于自身训练时获得的知识，还能动态地从外部知识库中检索相关信息，以提高生成内容的准确性和可信度。简而言之，RAG可以被理解为“先查资料，再回答问题”的智能问答系统。RAG通常由两个主要模块组成：检索模块（Retriever）：从外部数据库或文档集合中提取与输入查询最相关的信息。生成模块（Generator）：基于检索到的内容，结合大模型已有的语言能力，生成最终的回答。这种方法的优势在于，它可以让大模型具备“短期记忆”能力，使其能够处理时效性强、知识更新频繁或需要引用外部文献的任务。例如，在金融、医疗、法律等领域，RAG可以帮助模型提供更具权威性的答案，而不是仅凭预训练数据“猜测”答案。RAG技术通过检索外部知识库，避免了幻觉问题的困扰。相较于单纯依赖大型语言模型对海量文本数据的学习，RAG允许模型在生成文本时从事实丰富的外部知识库中检索相关信息。RAG技术的时效性优势使其在处理实效性较强的问题时更为可靠。通过与外部知识库的连接，RAG确保了模型可以获取最新的信息，及时适应当前的事件和知识。与传统的知识库问答（KBQA）相比，RAG技术在知识检索方面更加灵活，不仅能够从结构化的知识库中检索信息，还能够应对非结构化的自然语言文本。在接下来的部分，我们将深入探讨RAG的技术细节，包括其工作流程、主要应用场景，以及当前面临的挑战和改进方向。二、RAG的实现原理RAG系统的运作遵循“检索-增强-生成”的循环逻辑，其标准流程可分为以下三个阶段：阶段一：查询处理与检索查询解析：对用户输入的原始查询（如“2023年诺贝尔经济学奖得主是谁？”）进行语义理解，可能涉及关键词提取、实体识别、查询扩展（例如补充“获奖原因”“研究领域”等潜在关联词）。向量化检索：将查询转换为高维向量（embedding），通过相似度计算（余弦相似度、点积等）从知识库中召回Top-K相关文档片段。例如使用BERT等模型生成语义向量，配合HNSW（Hierarchical Navigable Small World）等高效索引结构加速检索。阶段二：上下文增强信息融合：将检索到的多个文档片段（如新闻稿、维基百科条目、学术论文摘要）与原始查询拼接，形成增强的输入上下文。例如构造如下Prompt：[question] 2023年诺贝尔经济学奖得主是谁？她的主要贡献是什么？\n向量检索到的文档：\n[information1] 2023年诺贝尔经济学奖授予克劳迪娅·戈尔丁（Claudia Goldin），以表彰她对女性劳动力市场历史演变的研究...\n[information2] 戈尔丁的著作《职业与婚姻：一个世纪的性别差距》揭示了...噪声过滤：通过重排序（Re-ranking）模型（如Cross-Encoder）对初步检索结果进行精排，剔除低相关性内容，提升上下文质量。阶段三：生成与验证条件生成：将增强后的上下文输入生成模型（如GPT-4、Qwen 2.5），通过注意力机制动态聚焦关键信息，生成最终回答。你是一个{task}方面的专家，请结合给定的资料，并回答最终的问题。请如实回答，如果问题在资料中找不到答案，请回答不知道。\n\n问题：{question}\n\n资料：\n- {information1}\n- {information2}\n- {information3}事实校验（可选）：对生成内容进行一致性检查，例如对比检索片段中的实体、时间、数据，防止生成矛盾或虚构信息。在论文综述「Retrieval-Augmented Generation for Large Language Models: A Survey」中，作者将RAG技术按照复杂度继续划分为Naive RAG，Advanced RAG、Modular RAG。| 技术类型 | 描述 |\n| --- | --- |\n| Naive RAG | Naive RAG是RAG技术的最基本形式，也被称为经典RAG。包括索引、检索、生成三个基本步骤。索引阶段将文档库分割成短的Chunk，并构建向量索引。检索阶段根据问题和Chunks的相似度检索相关文档片段。生成阶段以检索到的上下文为条件，生成问题的回答。 |\n| Advanced RAG | Advanced RAG在Naive RAG的基础上进行优化和增强。包含额外处理步骤，分别在数据索引、检索前和检索后进行。包括更精细的数据清洗、设计文档结构和添加元数据，以提升文本一致性、准确性和检索效率。在检索前使用问题的重写、路由和扩充等方式对齐问题和文档块之间的语义差异。在检索后通过重排序避免“Lost in the Middle”现象，或通过上下文筛选与压缩缩短窗口长度。 |\n| Modular RAG | Modular RAG引入更多具体功能模块，例如查询搜索引擎、融合多个回答等。技术上融合了检索与微调、强化学习等。流程上对RAG模块进行设计和编排，出现多种不同RAG模式。提供更大灵活性，系统可以根据应用需求选择合适的功能模块组合。模块化RAG的引入使得系统更自由、灵活，适应不同场景和需求。 |三、RAG还是SFT？在大模型落地的过程中，开发者常常面临技术路线选择：究竟是采用检索增强生成（RAG），还是通过监督微调（Supervised Fine-Tuning, SFT） 让模型直接学习领域知识？这两种技术路径各有优劣，需要根据具体场景权衡取舍。1.SFT：让大模型成为领域专家监督微调通过向预训练大模型注入特定领域的标注数据（如问答对、任务指令），使其逐步掌握专业知识和表达风格。例如：法律领域：用法律条文、判决书、律师函等数据微调，让模型学会引用《刑法》第XX条。医疗领域：输入病历、医学文献、药品说明书，使模型能准确解析“肌钙蛋白升高”的临床意义。# 典型的SFT数据格式示例\n{\n  \"instruction\": \"根据《民法典》分析房屋租赁合同违约条款是否有效\",\n  \"input\": \"合同约定：租客提前退租需支付全年租金50%作为违约金\",\n  \"output\": \"依据《民法典》第585条，违约金不得超过实际损失的30%...\"\n}\nSFT的优势是可以将外部的知识内化，模型将领域知识编码进参数，无需外部依赖即可生成专业内容，经过专业微调后可精确调整输出格式（如法律文书的严谨性、客服对话的亲和力）。对于需要多步逻辑推导的任务（数学证明、代码调试），微调后的模型的性能表现会显著更好。一般来说，现在主要用SFT来蒸馏小模型，比如Ds就用R1全量版蒸出一堆推理性能很不错的R1 Qwen小模型。\n这种方法通过教师采样生成序列，以 SFT 的方式训练学生模型，因此也被称为硬蒸馏（Hard Distillation）或「蒸馏+SFT」。但，SFT也有其缺点：前期数据清洗成本高，数据本身对大部分企业来说就是问题微调成本高，训练不确定性强，需要养一个专业的工程团队基础模型更新速度快，可能当前SFT出的特化模型三个月后在对应领域表现不如最新一代的基座模型2.RAG：赋予模型动态知识库与SFT不同，RAG不改变模型参数，而是通过实时检索外部知识库来增强生成能力。例如：企业知识库：连接内部文档（产品手册、技术白皮书、会议纪要），解决员工查询问题。实时资讯：接入新闻API、社交媒体流，让模型能解读“今日美股走势”。长尾知识：针对“冷门电影票房数据”“小众学术概念”提供精准答案。# RAG系统典型架构\n用户问题 → 向量化检索 → 知识库 → 上下文拼接 → 大模型生成\n                   ↑\n               实时更新（每日/每小时）\nRAG的优势就是系统低耦合，模型无需训练即可接入新知识源，适合知识频繁变更的场景（如政策法规更新）。因为有外部知识库，所以回答可信度显著会高一截，答案附有来源引用，规避“模型虚构法条”风险。对于中小团队而言，RAG的成本也要显著低于SFT，维护知识库比重新训练模型更轻量化，性价比非常高。四、前沿RAG系统案例—GraphRAG::github{repo=\"microsoft/graphrag\"}微软的GraphRAG是一种基于知识图谱的检索增强生成（RAG）技术，于2024年7月2日正式开源。其核心目标是通过结合大型语言模型（LLM）与图机器学习技术，解决传统RAG在处理全局性、抽象性问题时的局限性，例如回答“数据集的整体主题”或跨文档的复杂语义推理。微软的作者认为，目前的RAG技术很难解决诸如「当前数据集」的主题是什么这种较为「高级」「高维」的问题，此类应用场景本质上是一种聚焦于查询的总结性(QueryFocused Summarization，QFS)任务，单纯只做数据检索是无法解决的。与利用图索引的结构化检索和遍历功能的相关工作相比（子节 4.2），我们关注的是在此背景下图的一个先前未被探索的特性：其固有的模块性（Newman，2006）以及社区检测算法将图划分为紧密相关节点的模块社区的能力（例如，Louvain，Blondel et al.，2008；Leiden，Traag et al.，2019）。LLM生成的这些社区描述的摘要提供了对基础图索引及其所代表的输入文档的完全覆盖。然后，利用映射-归约方法实现整个语料库的查询聚焦摘要：首先使用每个社区摘要独立并并行地回答查询，然后将所有相关的部分答案汇总成最终的全局答案。微软的解决方法是，与其他RAG系统类似，GraphRAG整个Pipeline也可划分为索引(Indexing)与查询(Query)两个阶段。索引过程利用LLM提取出节点（如实体）、边（如关系）和协变量（如 claim），然后利用社区检测技术对整个知识图谱进行划分，再利用LLM进一步总结。最终针对特定的查询，可以汇总所有与之相关的社区摘要生成一个全局性的答案。image.png这么做的优势就是，通过社区分层和知识图谱的拓扑结构，GraphRAG能捕捉数据集的整体语义，回答传统RAG难以处理的抽象问题（如“数据中的前五主题”），在全面性、多样性等指标上显著优于基线RAG。但劣势也很明显，构建索引需要依赖LLM多次调用，例如处理19万字文档需约4分30秒，且使用GPT-4时单次索引成本可达12美元，对计算资源要求较高；知识图谱的构建涉及实体消歧、层次聚类等多步骤流程，开发与维护成本较高，且社区划分的准确性直接影响结果质量。此外，全局搜索需遍历多层社区结构，响应速度较慢，难以满足高实时性需求。不过后续改进版本LazyGraphRAG通过动态索引优化了此问题参见[1] 阿水, 鱼遇雨欲语与余 Coggle 30 Days of ML（24年1/2月）[2] Edge D, Trinh H, Cheng N, et al. From local to global: A graph rag approach to query-focused summarization[J]. arXiv preprint arXiv:2404.16130, 2024."
  },
  {
    "title": "暗涌系列：Ark Invest《Big Ideas 2025》报告浅析 Part 2",
    "summary": "四、自动驾驶 Robotaxi我之前倒写过关于Robotaxi的市场细分研报。如果有针对智能驾驶市场进行拆分详解需求的同学可以搜一下国信证券的三篇报告，分别是：汽车智能化系列专题-感知篇：终端智能化军备竞赛打响，中游各知硬件放量先行汽车智能化系列专题-决策篇（1）：从芯片到软件，车载计算平台产业链全面拆解汽车智能化系列专题-决策篇（2）：全球车载计算平台赛道核心玩家全面梳理传统Robotaxi赛道",
    "tags": [
      "暗涌"
    ],
    "url": "/posts/Finance and Economics/Darkwave-BigIdeas2025-P2/",
    "date": "2025-03-16T00:00:00.000Z",
    "content": "四、自动驾驶 Robotaxi我之前倒写过关于Robotaxi的市场细分研报。如果有针对智能驾驶市场进行拆分详解需求的同学可以搜一下国信证券的三篇报告，分别是：汽车智能化系列专题-感知篇：终端智能化军备竞赛打响，中游各知硬件放量先行汽车智能化系列专题-决策篇（1）：从芯片到软件，车载计算平台产业链全面拆解汽车智能化系列专题-决策篇（2）：全球车载计算平台赛道核心玩家全面梳理传统Robotaxi赛道过去一直深陷于 「硬件堆砌」 与 「长尾场景优化」 的双重泥潭。「硬件堆砌」指的是以Waymo和Cruise为代表的早期Robotaxi厂商，为了追求极致安全和冗余，不惜采用激光雷达、高精地图、多重传感器和超大算力芯片等豪华配置，这导致单辆自动驾驶出租车的成本一度高达20万美元，商业化进程几乎难以推进。而「长尾场景优化」则意味着，即便自动驾驶系统已经能够稳定应对绝大多数常规路况，但剩下不到1%的极端案例（比如暴雨中识别交警手势、临时道路封闭改道或乡村小路的特殊障碍物），却仍需要工程师进行手动编写规则、逐一攻克。这种模式使自动驾驶的落地充满瓶颈，技术进步的边际成本异常高昂，极大限制了产业规模化的可能性。幸好，大模型时代来了。随着Transformer、Occupancy Network等新一代AI模型的入局，Robotaxi的技术推进开始出现曙光：基于多模态大模型的实时感知能力，车辆不再过度依赖昂贵的高精地图，反而能直接从视觉等多种传感器实时构建更具灵活性的“语义地图”，精准捕捉道路上的动态变化与交通参与者的真实意图。举个栗子，以往让人头疼的“鬼探头”场景（比如路人突然从视线盲区冒出）在Transformer模型的帮助下，车辆反应速度可以达到人类驾驶员的1.5倍。与此同时，端到端的决策大模型（例如特斯拉的FSD、Wayve的LINGO-1、华为的高阶智能驾驶系统和理想的E2E-VLM等）更是彻底改变了传统自动驾驶需要层层模块堆叠的局面。过去动辄数十万行的代码，如今被高度整合的模型浓缩到了不足2000行，复杂场景的处理效率反而提升了40%以上，让自动驾驶从“硬件为王”的时代悄然过渡到“智能为王”的时代。除了软硬件层面的进步，智驾厂商庞大的用户量也带来了智驾能力的增长飞轮。随着车队规模不断扩大，每天都会产生PB级的真实路况数据，这些数据通过自动标注技术快速回流训练模型，形成了一个自我强化的“数据飞轮”，如小鹏汽车端到端大模型能够做到“每2天一次版本迭代，每2周一次体验升级”。大模型加持下的Robotaxi终于摆脱了“越堆越贵，越学越慢”的尴尬困境，驶入了一条快速迭代、低成本扩张的新赛道。我们的ARK主要认为，随着Robotaxi性能曲线的快速增长+持续的降本增效，特斯拉预计其自动驾驶软件在安全性上将超越人类驾驶员，网约车会随之创造约十万亿美元的市场，到2030年无人驾驶出租车可能产生约34万亿美元的企业价值。oi，还是一如既往的火热和大胆呢，wood桑五、自动物流（Autonomous Logistics）这块我觉得是真的挺有颠覆性想象力的。我们都知道Robotaxi主要面对长尾场景+政策监管的挑战，而自动物流的落地难度相对更低，商业化前景反而更加清晰。毕竟，货运的核心诉求就是“准时、稳定、低成本”，并不要求像Robotaxi那样具备复杂的人机交互能力。只要能够高效完成点对点的货物运输，自动驾驶物流车就已经能够创造巨大价值。当前全球物流行业面临的核心挑战是劳动力短缺、成本高企和效率瓶颈。以美国为例，卡车司机的平均年龄已经超过50岁，行业面临持续性的用工荒。与此同时，物流成本占全球GDP比重约10%，其中70%来自人力、燃油和车队运营支出，而传统长途货运受制于人类司机的工作时间限制（如欧美严格的驾驶时间监管），导致车辆利用率远低于理论最大值。自动驾驶货运车队的最大优势就在于无需人力成本，理论上可以24小时不间断运营，提高单车利用率，同时智能算法可以选择最优路线、控制油耗，甚至在新能源卡车普及后进一步压缩能源成本。此外，由于80%以上的公路货运事故由人为失误造成，自动驾驶技术的引入也能极大提高安全性。在自动物流的市场中，可以拆解为干线物流、支线物流和末端配送三个层级。其中，当前最具商业化潜力的赛道无疑是干线物流。干线物流适用于高速公路、封闭园区等规则明确、可预测性高的场景，例如，图森未来（TuSimple）、Aurora、Waymo Via等公司已经在美国展开大规模L4级自动驾驶卡车的测试，特斯拉Semi也计划搭载FSD进入自动货运市场。而在国内，满帮集团、美团、京东物流等企业也在加速布局无人驾驶货运车队，阿里旗下的菜鸟物流更是在多地试点“无人车+无人仓”模式，目标是实现全链路智能化。支线物流一般指干线物流到配送中心或城市内各分拨点之间的中短途运输。由于支线物流场景通常包括城市郊区、高速与城镇道路交织区域，行驶环境的复杂程度明显高于干线物流，但又相对可控，因此具备规模化自动驾驶技术落地的潜力。例如，国内京东物流已在多个城市内实现支线物流自动驾驶车辆的试运营，通过固定路线和区域运营的模式，降低技术落地的难度，实现了运营效率的提升与成本的下降。此外，支线物流在车货匹配和配送路径优化上的空间巨大，结合自动驾驶与AI算法，可进一步提高运输效率、降低货损率，实现更智能的城市物流体系。末端配送则是自动物流的最末环节，主要面向社区、校园、园区等区域内的短距离配送，货物一般以小包裹或轻量货物为主。末端配送自动驾驶车辆（无人配送车）的优势在于能够高频、高效地完成重复配送任务，节省大量人力资源，降低配送成本。同时，末端配送自动驾驶车辆通常采用电动化、小型化设计，更易于在城市密集环境中穿梭，且具备一定的灵活性，例如自动识别行人和路障，实现安全避让。目前，美团、京东、阿里菜鸟等公司都已在多地展开无人配送车的试运营，特别是在疫情期间，无人配送车在降低人际接触、保障物资供应方面发挥了重要作用，使得末端配送的自动化趋势进一步加速。如果说自动驾驶Robotaxi的终极形态是一个全球范围的“AI司机车队”，那么自动物流的终极形态或许是一个“机器人物流网络”。自动驾驶卡车承担干线运输，长途货运24小时不间断运行，支线配送由自动驾驶轻型货车完成，灵活应对中短途需求，而末端交付则依赖无人配送车、无人机，完成“最后一公里”服务。从供应链的角度来看，自动物流系统的出现意味着物流行业将从“人力驱动”转向“算力驱动”，物流效率的瓶颈将逐步被算法突破。未来，商品运输成本的下降可能会带动全球商品价格的降低，使得自动化物流成为推动全球经济增长的重要力量。木头姐在这章最后一页还专门提了一嘴，“美国需要低成本、⼈⼯智能驱动的⻜机”，放了中国和伊朗的无人机和美国的F16还有导弹做对比，主打一个压力给到议员，美元给到专款image.png六、能源能源这一块我是真不懂。按照我之前对于光伏发电市场的调研经验，传统能源早就进入红海市场范畴了，大家卷生卷死只为拼尽全力不出局。这个大市场下有想象力的板块应该就只剩民用核电了。民用核电具有清洁、高效以及能源密度极高的优势，但由于历史事故的阴影以及公众认知问题，长期以来发展相对迟缓。然而，随着第四代核反应堆技术（如小型模块化反应堆SMR和高温气冷堆HTGR）的快速进步，民用核电正重新进入市场视野。SMR技术通过标准化设计与模块化生产大幅降低了成本，同时也提高了安全性和灵活性，使其能够快速适应不同地区的能源需求。与此同时，高温气冷堆的高安全性设计，即便出现严重事故也能通过被动散热的方式自然降温，几乎消除了核泄漏风险，显著改善了公众接受度。以中国为例，海南昌江的小型模块化反应堆示范项目、山东荣成的高温气冷堆核电站均取得了里程碑式的进展。这类新型核电站不仅可以应用于集中供电，也适合于偏远地区的能源自给自足，甚至在海上核动力平台上也具备巨大潜力。随着能源转型需求的不断增加，未来十年内，民用核电或许能从边缘角色成长为全球能源市场的新增长极之一，开启全新的能源时代。:::note\n伴随以GPT为代表的大模型浪潮兴起，全球算力需求呈现爆发式增长，对能源供应的需求也随之剧增。以微软为代表的科技巨头已经开始积极布局小型核电站项目，以满足数据中心大规模模型训练和推理阶段对于稳定、高效且低碳能源的庞大需求。\n:::七、具身智能这段直接参见我 暗涌系列：Ark Invest《Big Ideas 2025》报告浅析 Part 1 观点洞察里的「具身智能革命进入成本临界点」部分就行了。八、可重复利用轨道火箭这块毋庸置疑，肯定是青天大老爷马斯克的星舰的天下。ARK关注的主要是星舰+星链建设，看起来她们也没有不要脸到嗯画星辰大海的饼的地步。传统的航天发射业务一贯以昂贵、复杂且难以复用为特点，导致航天成本居高不下，航天任务严重依赖政府补贴和少数大公司的垄断控制。星舰项目的目标则在于实现完全可复用，且能够快速周转的轨道级运载火箭。一旦这一目标实现，每次航天发射的边际成本将出现数量级的下降，或将从数千万美元甚至上亿美元降至几百万美元级别。这不仅会大幅降低卫星发射的成本，也能极大促进空间基础设施建设的发展。畅想未来一点，星舰的大规模运载能力（单次运载高达100吨），也为深空探测、月球基地建设甚至火星殖民带来了实际可能性。虽然现在谈星辰大海还有些言之过早，但至少有了星舰，我们对于未来的太空探索终于有了一个相对清晰且务实的路线图。毕竟，有时候未来看起来就差一个火箭而已。九、多组学生物这块我纯丁真水平，就不在这里献丑了，直接放上R1总结的内容：1. 技术发展与成本下降测序与合成技术：DNA测序和合成成本正以远超摩尔定律的速度下降。到2030年，DNA测序成本预计降至1美元/全基因组，合成成本可能下降千万倍（10⁷倍），推动生物数据的规模化生产。AI驱动分析：AI工具（如AlphaFold3、虚拟细胞模型）大幅提升生物分子结构预测效率和精度，单细胞基因组学与AI结合可模拟细胞功能，加速靶点发现和验证。2. 核心应用领域癌症筛查与监测：液体活检技术（如Guardant Health的“Shield”结直肠癌筛查）支持多癌种同步检测，早期发现率提升，市场潜力翻倍。微小残留病（MRD）检测可提前20个月发现癌症复发，未来或成为标准护理，数据量将超现有最大基因组项目（UK Biobank）700倍。药物开发：自驱动实验室（SDL）：结合高通量实验与AI，缩短药物发现周期（如Recursion Pharmaceuticals的SDL技术可将研发时间减少2年，成本降低数亿美元）。虚拟细胞模型：通过多模态数据模拟细胞响应，替代传统2D细胞和动物实验，提高临床前研究效率。精准治疗：基于患者特异性生物标志物开发个体化疗法，尤其针对罕见病和慢性病（如CRISPR基因编辑技术）。3. 经济与行业影响研发效率提升：AI加速药物开发流程，缩短上市时间（从13年压缩至8年），研发成本降低4倍（从24亿美元降至6亿美元）。专利价值重估：更长的专利保护期（因提前上市）使药物生命周期收入增加30-80%，治愈性药物（如一次性疗法）的经济价值可能达传统药物的20倍。行业回报率反转：AI驱动的药物开发可能扭转制药行业过去数十年研发回报率下滑的趋势，尤其对聚焦治愈性疗法的企业更有利。4. 未来展望数据爆炸：新生儿基因组测序普及后，全球生物数据量或增长千倍，推动AI模型训练和疾病预测能力。跨学科融合：多组学与AI、机器人（如自动化实验室）、能源（核能支持数据中心）的结合，将催生更高效的医疗基础设施。示例企业（非投资建议）测序工具：Illumina、10X Genomics、Twist BioscienceAI药物开发：Recursion Pharmaceuticals、Isomorphic Labs癌症筛查：Guardant Health、Natera基因编辑：Intellia Therapeutics、CRISPR TherapeuticsARK认为，多组学技术正通过“读-写-运行”（Read-Write-Run）范式重构生物医学，其与AI的深度融合将重塑医疗行业，带来万亿美元级市场机遇，并最终实现从疾病管理向根治的范式转变。我们能从ARK Invest的报告里学到什么？那些最具颠覆性潜力的赛道，往往都是伴随着巨大的不确定性和前期投入。Robotaxi的硬件堆砌问题、自动物流的监管挑战、民用核电的公众接受度等，这些赛道的共性在于早期资本投入大、技术风险高，但一旦跨越技术与市场的临界点，后续的规模效应与成本下降则能带来几何级增长。投资者需要学会区分真正的瓶颈与暂时的障碍，看到行业中「由量变到质变」的转折点，并做好在市场尚未普遍认可之时的战略布局。未来投资最核心的能力之一，就是理解技术进步的本质：无论是自动驾驶、多组学，还是太空运输，其成功的关键都依赖于算力、算法和数据的结合，即「智能为王」的时代已经到来。这意味着投资逻辑也必须相应转型，从传统的硬件、渠道、品牌等资产投入，转向数据、算法、生态体系等智力资本的价值挖掘。ARK Invest擅长描绘产业发展的远期愿景，但要真正捕捉这些产业机会，投资者不仅要能够忍受短期的波动和市场的不确定性，更需要有足够的定力和信念在市场产生悲观情绪时反而逆向投资。正如特斯拉自动驾驶项目曾遭遇的种种质疑，或生物技术产业早期高昂的试错成本，市场总是倾向于高估短期变化，却低估长期影响。对于个人投资者，我们需要警惕两种心态：技术乐观主义的「信仰透支」：将实验室突破等同于商业成功，忽视监管滞后性、社会接受度等摩擦力（例如公众对核电站的「零风险」要求可能延缓民用核电普及）过度风险规避的「安全幻觉」：用传统行业的确定性思维评估科技赛道，低估生态位重构带来的超额收益窗口（例如多组学对制药业价值链的重塑可能使现有巨头失去护城河）最后，我们究竟在投资什么？从小时候开始接受教育，我们实际上就是在不断的进行自我投资——用时间换取知识，用精力兑换技能。进入资本市场，我们实际上是在用当下的资源去置换对于未来的预期。我不太愿意像ARK那样狂吹宏大叙事，作为个人投资者，或许我们比机构更需要一种清醒的边界感：承认自己在信息获取、技术研判和风险承受能力上的天然劣势，反而能构建更具韧性的投资框架。:::note\n教育教我们“种瓜得瓜”，但资本市场时常在演绎“种瓜得星辰大海or一场空”。\n我们可以说，尤其是对于宏观择时的策略而言，金融市场的任何收益都是时间的函数。绝大多数时候选择正确的入场时机比选择正确的赛道更重要。接受这种反直觉的荒诞，或许才是成年人最艰难的一课。\n:::"
  },
  {
    "title": "《经济学研究入门指南》书评",
    "summary": "在飞机上看完了这本书。作为经济学和金融学的半吊子入门者，我一直感觉现代经济学的实证研究可以粗俗的讲就是算“直线”，给定一个假设和一堆数据，通过各种五花八门的模型和计量软件来拟合出那一条可能最符合实际的直线来证明自己的假设有效。当然，这种刻板印象肯定只是我这种不学无术的学术蟑螂的暴论。格林劳的《经济学研究入门指南》就温和地指出，回归方程中的每一个β系数，本质上都是人类认知局限的投影。当研究者选择将复",
    "tags": [
      "书评"
    ],
    "url": "/posts/Finance and Economics/book-review-of-doing-economics/",
    "date": "2025-03-05T00:00:00.000Z",
    "content": "在飞机上看完了这本书。作为经济学和金融学的半吊子入门者，我一直感觉现代经济学的实证研究可以粗俗的讲就是算“直线”，给定一个假设和一堆数据，通过各种五花八门的模型和计量软件来拟合出那一条可能最符合实际的直线来证明自己的假设有效。当然，这种刻板印象肯定只是我这种不学无术的学术蟑螂的暴论。格林劳的《经济学研究入门指南》就温和地指出，回归方程中的每一个β系数，本质上都是人类认知局限的投影。当研究者选择将复杂的社会关系简化为线性表达式时，必须时刻警惕这种数学优雅背后可能隐藏的认知暴力。经济学的经验研究远不止是简单地拟合一条“最优直线”。在这本书中，作者细致拆解了经济学研究的完整过程：从选题的权衡与考量，到文献的梳理与整合；从理论模型的构建，到数据的搜集与管理；从计量方法的检验，到最终论文的撰写与展示。每一个环节都深刻影响着研究的可靠性，而绝非仅仅追求回归结果的“显著性”。全书的最大优点在于它并非一本单纯教授计量方法或论文写作技巧的工具书，而是一本研究方法的指南。它强调了经验研究的逻辑链条，提示读者在数据分析之前首先要明确研究问题，并在理论逻辑上建立起可验证的假设。这样的思路，恰恰是许多初学者容易忽略的。当前，国内经济学入门书籍大多偏重于计量技术本身，而较少关注整个研究体系的搭建。本书的价值正在于此——它不仅提供了研究的“技术指南”，更塑造了一种严谨的研究思维。当然，本书并非没有局限性。它的内容框架虽然完整，但对具体的计量方法并未展开深入讨论，更多是指引读者如何组织研究，而非教会具体的分析技巧。因此，对于已经掌握一定计量经济学知识的读者来说，或许会感到意犹未尽。但正因如此，它更适合作为本科生或低年级研究生的入门指引，而非高级研究者的进阶读物。最后总结一下，《经济学研究入门指南》是一本非常值得推荐的书，尤其适合那些希望从零开始构建经济学研究思维的读者。在这个“数据驱动”的时代，许多研究者过于关注计量技术的复杂性，却忽视了研究本身的逻辑严谨性。格林劳通过这本书提醒我们，经济学的经验研究并不仅仅是“拟合直线”，而是一个完整且缜密的推理过程。对于任何希望真正理解经验经济学研究本质的人来说，这本书无疑是一个不可错过的起点，也是一份宝贵的指南。"
  },
  {
    "title": "模型考古学（三）：Agent 系统概述",
    "summary": "当瓦特在1788年为蒸汽机装上离心调速器，人类第一次触摸到了自动化的脉搏。这个由旋转飞球构成的简单装置能够根据蒸汽压力自动调节阀门开度，使机器的运转开始全面摆脱人工实时操控的桎梏。两个多世纪后的今天，当我们谈论大语言模型驱动的Agent系统时，依然能感受到这种追求自动化的原始冲动在技术迭代中延续——从机械装置的自动调节，到计算机程序的规则执行，再到如今AI系统在开放环境中的自主决策，人类始终在探索",
    "tags": [
      "模型考古学"
    ],
    "url": "/posts/AI and Deep Learning/deeplearning-research-003/",
    "date": "2025-03-04T00:00:00.000Z",
    "content": "当瓦特在1788年为蒸汽机装上离心调速器，人类第一次触摸到了自动化的脉搏。这个由旋转飞球构成的简单装置能够根据蒸汽压力自动调节阀门开度，使机器的运转开始全面摆脱人工实时操控的桎梏。两个多世纪后的今天，当我们谈论大语言模型驱动的Agent系统时，依然能感受到这种追求自动化的原始冲动在技术迭代中延续——从机械装置的自动调节，到计算机程序的规则执行，再到如今AI系统在开放环境中的自主决策，人类始终在探索如何让机器更好地理解意图、完成任务。如果说工业革命用齿轮传递动能，信息时代用代码传递指令，那么当前的 AI 浪潮，则试图传递某种更接近人类认知的「智能」。早期的自动化系统，需要工程师预设所有可能场景，如同纺织机依靠打孔卡控制织纹；现代机器学习则能通过数据自动发现规律，正如 AlphaGo 从棋谱中提炼策略。而 Agent 框架的突破性在于，它首次在数字世界中构建了具备环境感知、目标拆解、工具调用等类人认知能力的自主实体。更形象地说，早期的机器像提线木偶，每个动作都需要人直接操控；传统 AI 像按剧本表演的演员，只能在预设场景中完成任务；而现代 Agent 更像是被赋予了自由意志的智能助手。你只需要告诉它“帮我策划周末露营”，它就会自动查天气、列清单、比价格，甚至在帐篷售罄时主动建议替代方案。这种从“机械执行”到“认知协作”的转变，标志着自动化技术正突破物理规则与数字代码的边界，向着真正理解人类意图的方向进化。在本篇文章中，我们将探讨Agent系统的核心概念、技术演化及其与大模型的融合方式。尽管“Agent”这个词在计算机科学的不同领域有着各自的定义，但当下围绕大语言模型（LLM）构建的Agent架构，已经远远超出了传统意义上的自动化脚本或专家系统，而是朝着更具自主性、适应性和复杂推理能力的方向发展。为此，本文将围绕以下几个问题展开：什么是Agent系统？ 我们将从AI历史的角度，回顾Agent的核心概念，并区分不同类型的Agent模型。如何构建一个Agent？ 解析Agent的基本组成模块，包括环境感知、任务拆解、工具调用及反馈机制等关键组件，以及当下流行的实现框架。大模型如何增强Agent能力？ 大语言模型的推理能力为Agent带来了推断、规划和执行任务的巨大潜力，我们将探讨它如何在Agent架构中充当核心引擎。Agent的发展方向与挑战是什么？ 虽然Agent系统正在快速进步，但它仍然面临推理可靠性、可控性、长任务规划等挑战，本文也会对此作初步分析。一、什么是Agent系统1.基本概念在人工智能领域，Agent（智能代理）通常指能够自主感知环境并采取行动以实现目标的实体。这一概念源于早期人工智能对自主智能体的探索，并在20世纪90年代随着面向代理的编程和多智能体系统的研究得到强化。人工智能教材经常将AI定义为“对智能代理的研究与设计”，这体现了面向目标的行为是智能的核心。一个Agent通常具备以下关键属性：自治性：它能独立运行，依据自身的感知和内部状态作出决定。反应性和适应性：Agent能够根据环境变化及时作出响应，并通过学习或规则的更新来适应新情况。前瞻性（主动性）：优秀的Agent不仅能够被动响应事件，还能够基于目标主动采取行动。交互性（或社会性）：Agent能够与人类或其他Agents进行通信、协作或竞争，以完成任务。这些属性共同定义了智能Agent系统：它们能够在复杂环境中自主运行，追求既定目标，并不断提高其性能。2.Agent类型根据AI发展的不同阶段和范式，Agent系统可以采取多种模型和架构。基于规则的Agent：这类Agent依据预先定义的规则集（如条件-动作if-then规则）来感知环境并执行动作。它们没有内部学习机制，而是类似简单反射式代理，看到某种感知就触发相应动作。例如经典的恒温器、有限状态机控制程序，或早期专家系统都属此类。基于规则的Agent通常快速而直接，适用于简单明确的环境响应，例如机器人避障中的直接传感器-效应器映射。然而，由于缺乏对环境的内部模型和学习能力，它们难以应对复杂多变的情境，也无法自行改进策略。它们的行为完全由人类设计的规则决定，缺乏适应新情况的灵活性。image.png图1：简单反射式Agent示意图。Agent通过传感器获取环境感知（percepts），根据内部条件-动作规则判断当前环境状态（“世界现在是什么样”），然后由执行器输出动作来影响环境。这种Agent没有内部学习过程，其行为完全由预设规则驱动。（1）强化学习驱动的Agent：强化学习（RL）代理通过与环境反复交互、试错来自主学习最优行为策略。与基于规则的固定策略不同，RL代理根据奖励信号更新其决策策略，以最大化长期累积回报。经典工作如Sutton和Barto（1998）的研究奠定了RL代理的基础。现代AI中许多智能体都采用强化学习，不断调整策略以适应环境变化。例如，DeepMind的AlphaGo系列通过自我博弈强化学习达到超人水平的围棋决策，就是RL代理的代表。强化学习Agent具备适应性和学习能力，能在未知或复杂环境中逐步提高绩效。然而，其学习效率和稳定性依赖于良好的奖励设计和探索策略。RL代理往往需要大量交互数据训练，对于高维或长时序任务可能面临探索空间巨大的挑战。此外，纯RL代理的决策往往难以解释，这带来了可解释性方面的问题。（2）认知架构Agent：这类Agent基于认知科学的架构模型来设计，旨在模拟人类思维的结构和过程。典型代表有ACT-R和Soar等认知架构，它们将智能体的软件系统划分为类似人脑功能的模块。例如，ACT-R架构包含多个专门模块（视觉、记忆检索、决策等）和有限容量的缓冲区，用于模拟人类认知过程。Soar架构围绕问题空间来组织智能体行为，使用产生式规则（if-then规则）指导动作，并能在遇到无法立即解决的问题时建立子目标，从而逐步求解。认知架构Agent通常具有内部记忆和推理机制，支持较复杂的计划和问题求解。它们的决策依据清晰的符号规则或认知模型，因而在一定程度上可解释。这类Agent擅长需要高层推理和结构化知识的任务，在模拟人类认知、建模用户行为等领域有应用。然而，认知架构往往需要精细的知识工程和参数设置，通用性较弱；其性能也可能受限于人工设定的规则，不易扩展到完全未知的问题领域。（3）大语言模型（LLM）增强的Agent：最新兴起的一类Agent将强大的大语言模型融入决策与推理过程，为Agent赋予了前所未有的灵活性和知识能力。大语言模型（如GPT-4、PaLM等）经过海量语料训练，具备丰富的世界知识、推理和语言理解能力。当将LLM用作Agent的“大脑”或策略生成器时，Agent能够以类似自然语言思维的方式规划和行动。例如，LLM可以根据任务目标，用对话或提示来生成行动方案，再将方案转化为具体操作步骤。这使Agent能够在开放环境中处理复杂问题，甚至通过语言接口与人类或软件工具交互。LLM增强的Agent往往具备强大的推理能力和通用性：它们能理解抽象指令、分解复杂任务，并利用内置的知识完成开放领域的问题。这类Agent的兴起使AI从传统的工具型交互迈向更智能的合作伙伴。例如，最近涌现的AutoGPT、BabyAGI等系统展示了仅通过语言模型驱动的自主代理如何执行一系列复杂操作。需要注意的是，由于LLM本身的局限（如幻觉错误、长链推理困难），LLM-Agent在可靠性和可控性上还面临挑战，但其巨大潜力已引发广泛关注和研究。Agent系统是在AI历史中逐渐形成的核心概念，涵盖了从简单反应式程序到复杂自主智能体的各种形式。不同类型的Agent在自主性、适应性和交互性上各有侧重：基于规则的Agent强调确定性和可控性，强化学习Agent体现学习和优化能力，认知架构Agent追求可解释的高层智能，而LLM增强的Agent则带来了通用推理和语言交互的新范式。理解这些类别及其属性，有助于我们把握Agent技术的发展脉络和应用场景。二、如何构建一个现代意义上的Agent1.基本组成模块构建一个智能Agent通常需要将其划分为若干核心功能模块，协同实现“感知-决策-行动”的闭环。首先是环境感知模块（Sensors/Perception）：Agent通过传感器获取来自环境或用户的输入，这些输入可视为环境的状态信息或任务要求。接下来，Agent需要对感知信息进行理解与建模，这涉及内部状态表示或记忆模块。例如，内部世界模型/记忆可以存储Agent对环境的信念、历史经验或上下文信息，支持后续决策。然后是任务规划与决策模块：Agent依据其目标和当前状态，选择或生成一系列行动步骤。对于简单Agent，这可能是查表或规则匹配；对于复杂Agent，则包含策略推理、任务拆解（把复杂任务分解为子任务）等功能。在大语言模型驱动的Agent中，规划往往通过LLM生成链式思考或步骤列表来实现。之后，Agent通过工具调用或行动执行模块将决策付诸实施。这可能是控制机械执行器在物理环境中行动，也可能是调用软件API、检索数据库、生成文本回复等。在执行行动后，Agent获取环境反馈（例如行动导致环境变化或收到新感知），这又会通过反馈机制更新内部状态，进入下一轮感知-决策循环。这样的闭环形成了Agent的控制流，也被称为“感知-计划-执行”循环。一个常见架构是“Sense-Plan-Act”：即感知环境、基于内部模型计划行动、执行并影响环境，再循环往复。现代自主Agent还常加入反馈学习机制，即根据执行结果调整内部模型或策略参数，从而不断改进行为。例如，在强化学习代理中，环境反馈的奖励信号会用于更新策略；在LLM代理中，可以通过对对话历史的总结或自我反思来修正下一步方案。这些模块共同组成了Agent的基本架构，各模块的设计细节会因具体应用和算法选择而有所不同。image.png图2：典型AI Agent架构的组成模块示意图。中央的Agent核心负责统筹决策逻辑，围绕其四周是关键辅助模块：自上而下依次为记忆模块（存储历史对话或状态信息，提供上下文）、规划模块（负责将复杂问题分解成可执行的步骤或子任务）、工具模块（Agent可调用的外部工具或API函数库）。左侧是来自用户或环境的请求输入，Agent核心据此结合记忆、规划和工具接口产生行动方案，右侧通过执行模块影响环境或给出答复，实现闭环。2.已经成熟的框架项目（1）LangchainLangChain是一个用于构建由大语言模型驱动的应用（尤其是Agent）的框架库。它提供了一系列抽象和组件，将LLM与外部工具、知识库、记忆模块等连接起来。利用LangChain，开发者可以方便地创建链式调用（Chain）和代理（Agent）模块。例如，LangChain定义了统一的接口来接入不同的LLM、向量数据库（用于长时记忆）、工具函数等，使Agent可以在这些组件之间顺畅地进行对话和操作。LangChain内置了多种常见Agent范式（如基于ReAct逻辑的工具使用Agent），开发者只需配置提示模板和所需工具，即可构建一个能够自主解析任务并调用工具的LLM代理。LangChain的优势在于其模块化和灵活性：可以根据应用需要自由组合不同组件，扩展性强；但相应地，需要使用者具有一定的提示设计和编程能力来定制Agent的行为逻辑。（2）AutoGPTAutoGPT是2023年引发广泛讨论的一个开源自主Agent项目。它的目标是创建一个几乎无需人干预的“自治GPT-4代理”。AutoGPT通过让GPT-4模型持续迭代地生成行动计划、执行Python代码、再根据结果调整计划，如此循环来自主完成用户给定的目标。在启动时，用户为Agent设定名字、角色和若干目标，之后Agent便会“自行其事”，不断产生下一步行动直至达到目标或耗尽设定资源。AutoGPT的一大特点是引入了代码执行能力，即Agent可以让LLM编写Python脚本并运行，从而实现诸如文件操作、网络请求等复杂操作。这种机制形成了一个自我反馈回路：LLM生成的代码通过执行影响环境，产生新观察，LLM再根据新状态调整策略。AutoGPT被形象地称为一种“自我改进的AI”，因为它可以在一定程度上调试和改进自己生成的代码。它展示了LLM在长时间自主运行方面的潜力。然而当前版本的AutoGPT也暴露出一些问题：例如，长时间循环可能导致上下文丢失或重复操作，缺乏全局规划容易在复杂任务上迷失方向。此外，对GPT的大量调用也带来高额的计算成本。尽管如此，AutoGPT作为探索“任务级连续自主性”的里程碑式项目，证明了LLM可以作为核心引擎驱动多步任务的自动执行。（3）BabyAGIBabyAGI是另一个有代表性的开源自主Agent框架，由创业者Yohei Nakajima提出。它的设计宗旨是实现一个任务驱动的自动代理：给定一个高层次目标，BabyAGI能够自主生成、排序并执行子任务，直至目标完成。其核心机制包括一个任务队列和一个向量数据库记忆。BabyAGI使用LLM根据当前目标和已有进展，动态地产生新的待办任务，并评估其优先级插入队列中。每完成一个任务，会从队列取出下一个最高优先级的任务继续执行，如此循环。向量数据库用于记录先前任务的结果和有用信息，LLM可以查询这些记忆，从而保持跨任务的上下文衔接。BabyAGI因其简洁有效的设计成为开源社区关注的焦点，据报道它是2023年3月首个流行起来的自主Agent，实现了无人干预的任务规划和执行，在社交媒体上引发了热议。相较AutoGPT，BabyAGI架构更简单、轻量，易于理解和改进。但也因为简单，缺少复杂的决策模块，可能在应对非常复杂的目标时力不从心。目前社区已在BabyAGI基础上衍生出多个改进版本，引入更先进的调度算法或记忆管理，以提升其任务管理效率。（4）其他框架除了上述三个外，近期还有许多值得关注的Agent框架。例如，HuggingGPT是一种让LLM作为中枢，调用Hugging Face模型库中各种专家模型去解决复杂多模态任务的方案；微软的Jarvis（与HuggingGPT类似）展示了用ChatGPT协调计算机视觉、语音等模型来完成组合任务的案例。还有一些研究原型，如面向web浏览和API调用的BrowserGPT、面向机器人操作的SayCan等，都体现了通过工具集成来扩展Agent能力的趋势。此外，在多智能体方向，有框架探索让多个LLM代理彼此对话协作完成任务（如CAMEL等），体现出“代理社会”协同求解问题的初步能力。3.不同架构的优势、劣势及适用性不同Agent架构各有优劣，适合的应用场景也有所差异。早期的反应式架构（如简单规则代理）胜在实时性和可靠性，由于不维护复杂的内部状态，它们对传感器输入的响应非常迅速，适用于机器人避障、自动控制等需要毫秒级反应的场景。然而，这类架构无法处理需要规划的复杂任务，面对新情况时缺乏灵活性。与之相对，计划型架构引入了环境模型和前瞻性规划。Agent会执行“感知-建模-计划-行动”的周期，仔细推演可能的行动结果然后再执行。这种方法适合解决复杂决策问题，例如路径规划、策略游戏决策等，在需要高准确性的场景表现出色。然而，其缺点是在动态环境中反应速度较慢，可能跟不上实时变化。混合架构尝试将二者优点结合，使用分层结构同时具备及时反应和全局规划能力。典型做法是底层用反应式策略处理紧急情况，上层用计划模块处理长程目标。混合架构适用范围广，但设计和调试较为复杂，需要处理好不同层次决策的协调。对于LLM增强的Agent框架，例如LangChain提供的代理与AutoGPT/BabyAGI这种自治代理，它们之间也有差异。LangChain作为库，灵活性很高，适合需要深度定制Agent行为的应用，比如企业希望集成自有数据库和业务逻辑的智能助手。这种方式的优势是可控性强：开发者可以严格指定Agent何时调用何工具、如何解析输出，从而在安全性和可靠性上有保障。但不足之处在于需要投入开发工作，并且最终效果依赖于提示工程和设计质量。相比之下，AutoGPT/BabyAGI属于“一站式”的Agent应用，使用门槛较低，只需给定目标即可启动Agent自主运行。这适合于探索性任务或用户希望观察AI自主能力的场景。然而，由于当前LLM的能力限制，这类Agent在长时间运行时容易出现策略发散、推理错误累积等问题，需要人类在环监督长任务的执行。因此，在开放环境、复杂长任务（如跨天的项目管理、连续科研助手等）上，目前的AutoGPT类架构仍有待提升可靠性。反之，在封闭域、清晰目标的任务（如自动生成多步代码脚本、批量化的数据处理）中，它们可以大幅节省人力。认知架构Agent在需要高可信度和可解释性的领域依然有价值，例如军事决策支持系统或航空航天系统中，工程师可能偏好采用混合了符号AI的架构来保证系统行为可预测。而强化学习Agent则在游戏AI、机器人控制、推荐系统等有明确反馈信号的场景表现突出。总的来说，选择何种Agent架构取决于应用需求：要实时还是要深度推理？环境是否复杂多变？是否需要引入海量人类知识？等等。理解各种架构的优劣，让我们能在不同场景下扬长避短，构建最合适的Agent系统。三、大模型是如何增强Agent能力的？1.大模型扮演的角色大语言模型（LLM）的引入为Agent的推理、规划和执行能力带来了质的飞跃。一般而言，LLM在Agent中可以充当大脑或决策中枢的角色。具体来说，LLM擅长从复杂指令或问题中进行自然语言推理，这意味着Agent能够通过LLM产生接近人类逻辑的思考过程（通常以文本“思维链”形式）来分析问题。LLM还具备将抽象问题逐步分解的能力：面对复杂任务时，LLM可以按照步骤生成一个计划，将大目标拆解成可管理的子目标。这种能力极大地提升了Agent的自主规划水平，使其可以在多步推理和长程任务上有所作为。此外，LLM拥有海量的知识和语言理解能力，因而Agent可以利用LLM来获取背景常识，在缺乏外部知识库的情况下仍能进行有根据的决策。例如，一个LLM增强的Agent在医疗问答场景中可以直接依靠模型存储的医学知识给出初步诊断建议，然后再通过工具查询文献验证。这种内置知识丰富性让Agent能够处理开放领域的问题，而不局限于狭窄的预设规则。在Agent架构中，大模型可以扮演的角色有：其一，作为策略生成器/决策器，根据当前状态和目标直接产出下一步行动或计划。例如在自主对话Agent中，LLM根据对话上下文决定回答、询问还是调用工具。其二，作为任务规划器，LLM可以阅读总体目标后给出一系列有逻辑的子任务清单，Agent据此逐一执行并动态修正。这方面的例子有前述BabyAGI以及微软提出的HuggingGPT系统——在HuggingGPT中，ChatGPT（LLM）读取用户请求后进行任务规划，将请求拆解成若干步骤并为每步选择合适的专家模型来完成。LLM还可充当工具调用的接口：通过让LLM输出特殊格式的“动作指令”，Agent能够决定何时调用外部API或工具，再把工具返回的结果融入后续推理。这一思路在ReAct等研究中得到验证：LLM被引导生成交替的“思考（Thought）”和“行动（Action）”日志，边推理边执行外部操作。这种方法让Agent可以一边利用LLM高层推理，一边通过检索知识库或调用计算工具获取所需信息，从而将LLM的语言能力与外部环境交互有机结合。2.多步推理和复杂决策LLM使得Agent在解决复杂问题时表现出超越以往的能力。首先，LLM能够进行连贯的多跳推理。传统Agent在长链推理时容易因为中间步骤错误导致最终失败，而带有Chain-of-Thought（思维链）提示的LLM可以一步步展开推理过程，降低了跳跃性错误。例如，在回答需要综合多条资料的问题时，LLM-Agent可以先让模型思考哪些资料可能相关，然后指导其调用搜索工具获取资料，再整合信息得到最终答案。这种分解使模型的每一步都有据可查，降低了幻觉（hallucination）和推理混乱的风险。实验表明，采用ReAct框架（交替推理和行动）的LLM-Agent在开放域问答和事实核查任务中有效缓解了纯思维链方法中常见的幻觉问题，通过与外部百科接口交互，答案的准确性和可信度都有所提升。其次，在复杂决策场景，LLM-Agent展现出评估和权衡的能力。 LLM可以在内部模拟多种方案，并给出对各方案的分析，近似实现“头脑风暴”式的决策支持。例如，在投资组合优化场景下，一个LLM驱动的金融Agent可以同时考虑多种市场情景，分析不同组合的风险收益，然后推荐较优的策略。这种能力过去往往需要手工设计算法或专家知识，如今LLM的出现使Agent能够以通用推理的方式处理决策问题。第三，LLM-Agent在自动化长任务上展现出前景。 过去，让AI连续执行一个长达数小时甚至数天的复杂任务几乎是不可能的，因为需要面对各种不可预知的情况并灵活应对。LLM提供的语言策略生成使Agent能够在任务进行过程中实时调整计划。AutoGPT的实验显示，LLM-Agent可以完成如“从网络收集信息->分析->撰写报告”这样需要多步骤、多工具协作的任务。这类任务以往需要人工将不同AI工具串联，而现在Agent本身就能通过LLM的决策将流程连接起来。这预示着在未来，高度复杂的流程自动化将成为可能：从产品设计、数据分析到业务决策，Agent都可能接手执行诸多子任务，并且仅在关键决策点征询人类反馈。麦肯锡的分析亦指出，生成式AI正从提供知识的聊天机器人，进化到可以执行复杂多步骤工作的“代理”，实现从“思考”到“行动”的飞跃。四、发展方向与挑战1.挑战尽管Agent技术取得了显著进步，尤其是在引入大模型之后，仍有若干关键挑战亟待解决。（1）推理可靠性问题LLM驱动的Agent有时会产生“幻觉”——输出看似合理但实际错误的判断，或在多步推理中引入逻辑谬误。这种幻觉和错误传播可能在长任务中累积，导致最终结果偏离预期。如果Agent自主执行关键任务（如财务决策、控制机械设备），这样的不可靠推理显然是高风险的。因此，提高Agent推理的准确性和稳健性至关重要。目前，一些方法如引入自我反思（让Agent审查自己的思维链）或外部校验（通过冗余Agent互相检查）正在探索中，以减少推理失误。（2）可控性挑战高度自主的Agent可能会走意外路径，例如，为达成目标采用了人类未预料的方法，甚至违背初衷。如何让Agent的自主性在有边界的情况下发挥作用，避免“跑偏”，涉及到安全约束和人类监督机制的研究。监督机制：需要在架构上给予人类中途干预或监督的接口，例如在重要决策点请求人工确认。行为约束：在模型层面融入约束条件或奖励设计，引导Agent行为符合人类价值。这延伸出**AI价值对齐（Alignment）**的难题，即如何确保Agent的内部目标和策略与设计者的意图一致，避免敌对或有害的行动。正如AI学者Yoshua Bengio警示的，如果一个AI具备自主规划和行动能力，而其目标在恶意者手中被滥用，或者AI产生了自我保存等隐含目标，就可能与人类利益相冲突。例如，一个过于自主的Agent若将“自我生存”作为首要目标，可能会抗拒被关闭，甚至采取极端手段保证自身持续运行。虽然这种情况目前仍属极端假设，但它强调了目标可控性的重要性：我们必须能定义和限制Agent的目标范围，并防范潜在的目标漂移。（3）长任务规划与记忆挑战现有的大模型虽然在数千字上下文内表现出色，但对涉及数万步、跨越数天的任务仍力有不逮。Agent需要处理超长时序的计划，并记住早期步骤的细节和中间结果，这要求存储和检索大量信息。存储和检索：向量数据库、长短期记忆模块可以部分解决，但如何让Agent有效“记住”并“理解”自己的过去行为，仍是持续自适应的一大难题。上下文窗口限制：现有大模型的上下文窗口有限，长时间运行的Agent可能遗忘早期信息，因此需要分段规划、阶段性总结等策略加以缓解。（4）环境适应性挑战当Agent部署在现实世界或动态复杂环境中，它必须适应不断变化的情境、噪声和未见过的事件。这要求它具备领域自适应能力，能够将已有知识迁移到新情况，或通过在线学习快速调整策略。例如：家庭机器人：需要适应不同家庭的摆设和主人习惯。金融交易Agent：需要根据市场突发变化调整策略。这涉及强化学习、元学习、自主探索等技术的融合，让Agent更趋于持续学习者而非固定程序。近期的Voyager实验朝这一方向迈出了步伐，通过持续与环境交互积累技能，实现了开放世界中的自主适应。但在更广泛应用下，实现可靠的环境适应性仍然充满挑战。2.发展方向（1）多智能体系统除了单个Agent，多个Agent的交互与协作（即多智能体系统）被认为是下一阶段的重要方向。多个Agent之间可以分工合作，互相竞争，或通过通信形成群体智能。这种架构有望解决一些单智能体难以胜任的问题。一个明显趋势是利用多Agent自博弈来提升智能水平，例如AlphaGo通过多个代理自我对弈实现了超人表现。同理，在复杂决策场景下，让Agent与Agent交互（而非总是与人或静态环境交互），可以产生新的学习动力和策略探索。合作型多Agent系统中，不同Agent可以被赋予不同的专业能力或角色，类似人类团队那样各司其职。例如，一个复杂项目的AI团队里，可能有的Agent擅长规划，有的擅长执行代码，有的负责监控和纠错。通过协议，这些Agent可以交流信息、同步进度，完成单个Agent无法独立完成的宏大任务。最近的一些研究让两个LLM代理互相对话来完善答案或方案，发现确实能提高结果质量，因为不同代理相当于提供了多元视角和审核机制。这类似于人类“四眼原则”，即两个独立智能体互相检查减少错误。未来，多Agent有望在复杂环境建模、博弈决策、智能体博弈等方面取得突破。例如，在模拟经济或交通这样的复杂系统时，使用多个Agent模拟不同参与者的行为，可以产生逼近真实的涌现现象，从而测试各种政策的效果。再如，在Internet环境中部署的自主Agent，可以组成协作网络，共享信息以完成跨地域、跨领域的任务。然而，多智能体也带来新的挑战，如协调与通信问题：Agent如何形成共享协议语言高效交流？如何避免Agent之间出现不良竞争或冲突？这些都需要制定机制（比如契约网络协议或博弈均衡策略）来管理。多Agent系统的稳定性也是研究重点——因为每个Agent的学习行为会改变环境，对于其他Agent来说环境是非静止的，这使得收敛分析更加复杂。一项综合调查指出，让Agent能够建模和预测其他Agent的行为是实现稳定多Agent系统的关键开放问题之一。（2）多头技术结合为了进一步增强Agent的能力，研究者正尝试将Agent与强化学习、自监督学习、世界模型等前沿技术相结合。一方面，模型辅助的强化学习为Agent提供了更强的规划能力：通过学习环境的世界模型（即能够预测环境动态的内部模型），Agent可以在内部模拟多步结果，再选择最优行动，而无需完全依赖实时试错。这类似于人会在脑海中“想象”行动后果以做决策。DeepMind的MuZero算法将强化学习与学得的环境模型结合，在棋类和Atari游戏中取得了优秀成果，就是这种思路的例证。同样，未来的Agent或许会训练自己的世界模型网络，用于复杂环境下的预判和风险评估，以减少真实环境中的代价试错。另一方面，自监督学习可以赋予Agent更丰富的常识和表示学习能力。例如，Agent可以在大量无标签数据（视频、文本、模拟环境）中自我训练，学到关于物理世界、人类行为模式等的表征，这将在其执行具体任务时提供先验知识支撑。OpenAI等机构也在探索让语言模型通过阅读百科和网页自我训练，提升事实准确性和推理一致性。对于物理世界的Agent（如机器人），嵌入式的视觉模型可以通过自监督训练理解物体概念、空间关系，使机器人Agent具备类人常识。这些技术的融合有望突破目前Agent的局限：比如一个结合世界模型的Agent在下棋时可以在脑海中搜索未来几步的局面（提高策略最优性），在导航时可以规划路径避开可能的危险区域；结合自监督学习则让Agent在陌生情境下也有基本常识指导，不至于做出荒谬行为。我们认为Agent的发展正朝着综合智能方向迈进，即将不同AI范式的优势融于一身：既有深度学习带来的感知与模式识别能力，又有符号方法提供的逻辑与知识，以及强化学习给予的试炼提升能力。这将造就更健壮和灵活的智能体。（3）伦理、透明性和安全性随着Agent变得越来越自主和强大，围绕其行为的伦理与安全问题变得日益突出。决策透明性（Transparency）当Agent基于复杂模型和大规模数据做出决定时，人类往往难以理解其内部过程。如果Agent应用于医疗诊断、司法建议等敏感领域，缺乏解释的决策可能无法被信任。从技术角度看，未来Agent系统需要在设计上融入可解释AI的原则，例如提供可审计的决策链条（哪怕是LLM的“思维链摘要”）或关键步骤的理由说明。值得欣慰的是，一些LLM代理方法（如ReAct）天然具备“思维日志”功能，能够记录LLM每一步推理和行动的文本轨迹，使人类可以检查决策过程，从而提升透明度。安全性与伦理约束然而，当Agent拥有执行能力时，其被不当使用可能带来实际危害。例如，攻击者可能诱导它调用接口实施网络攻击或生成有害内容。为此，Agent系统需要：加入安全审查机制：限制其调用敏感操作的权限，并对输出内容进行过滤。责任归属问题：如果一个Agent的错误决策导致损失，开发者、用户还是Agent本身应该承担责任？当前法律框架尚未覆盖这类新问题，各国和相关机构需尽快制定相关法规。正如AI专家Yoshua Bengio所呼吁，对于强自治的AI，应当采取审慎监管，例如在部署前进行全面的风险评估和认证。Bengio还建议对“能够自主在现实世界中行动的强大AI”，采取“在未证明安全之前禁止投入使用”的原则。这种前置审查能够防范AI系统以不可控方式影响社会。在技术层面，还有专家提出，使用AI来监控AI是一种潜在的解决方案。具体而言，可以开发“审计Agent”作为实时监督者，对工作Agent的行为进行风险评估，并及时干预可能的不良行动。伦理嵌入与多Agent协作我们期望未来的Agent能够遵循人类价值观行事，例如公平、公正、避免偏见和保护隐私等。这一方向可以通过在训练中融入人类反馈（RLHF）或设定明确的伦理约束来实现。在多Agent交互情况下，也需要防止它们协作形成对抗性行为或串谋作弊。例如，多个Agent在交易场景中可能会无意间触发反竞争性策略。这表明，在多Agent系统中，还需研究其协作和博弈策略的约束机制。参见[1] Durante Z, Huang Q, Wake N, et al. Agent ai: Surveying the horizons of multimodal interaction[J]. arXiv preprint arXiv:2401.03568, 2024.[2] Xi Z, Chen W, Guo X, et al. The rise and potential of large language model based agents: A survey[J]. Science China Information Sciences, 2025, 68(2): 121101.[3] Lyzr AI. AI agents for stock market: The future of investments. 2023. Retrieved from https://lyzr.ai.[4] Hitachi DS. AI-powered GRC in banking – Part 2. 2023. Retrieved from https://hitachids.com.[5] Shen J, et al. Artificial intelligence versus clinicians in disease diagnosis. JMIR Medical Informatics, 2019. Retrieved from https://pmc.ncbi.nlm.nih.gov.[6] Fox News. ChatGPT outperformed doctors in diagnostic accuracy, study reveals. 2024. Retrieved from https://livenowfox.com.[7] DigitalDefynd. Agentic AI in healthcare – 5 case studies. 2025. Retrieved from https://digitaldefynd.com.[8] AONL Voice. Using robotics to remove staff delivery tasks. 2022. Retrieved from https://aonl.org.[9] MDPI Sensors. Multi-agent RL for traffic flow of autonomous vehicles. 2023. Retrieved from https://mdpi.com.[10] Waymo. New data on Waymo driver performance. 2023. Retrieved from https://waymo.com.[11] Weng L. LLM powered autonomous agents – Fig. 13 Generative agent architecture. 2023. Retrieved from https://lilianweng.github.io.[12] NVIDIA Blog. Voyager: An open-ended embodied agent with GPT-4. 2023. Retrieved from https://blogs.nvidia.com.[13] Wikipedia. Intelligent agent. Retrieved from https://en.wikipedia.org.[14] Wooldridge M. What agents aren't: A discussion paper. IEE Colloquium on Intelligent Agents, 1996. Retrieved from https://digital-library.theiet.org.[15] SmythOS Blog. Agent architectures in robotics. Retrieved from https://smythos.com.[16] Panesar A. Machine learning & AI for healthcare: Intelligent agents learn heuristics. 2017. Retrieved from https://pmc.ncbi.nlm.nih.gov.[17] SmythOS Blog. Cognitive agent architectures. Retrieved from https://smythos.com.[18] Talukdar W. Autonomous AI agents: Leveraging LLMs. IEEE Computer Society, 2025. Retrieved from https://computer.org.[19] Arya N. AutoGPT: Everything you need to know. KDnuggets, 2023. Retrieved from https://kd Nuggets.com.[20] Ruczynski K. BabyAGI explained. Wordware, 2024. Retrieved from https://wordware.ai.[21] NVIDIA Technical Blog. Introduction to LLM agents. Retrieved from https://developer.nvidia.com.[22] Talukdar W. Autonomous AI agents. IEEE Computer Society, 2025. Retrieved from https://computer.org.[23] Yao et al. ReAct: Synergizing reasoning and acting in LLMs. 2023. Retrieved from https://arxiv.org.[24] Shen et al. HuggingGPT: Solving AI tasks with ChatGPT. 2023. Retrieved from https://arxiv.org.[25] Wang et al. Voyager: An open-ended embodied agent with LLMs. 2023. Retrieved from https://arxiv.org.[26] Panesar A. Value alignment issue in ISAs. 2017. Retrieved from https://pmc.ncbi.nlm.nih.gov.[27] Bengio Y. AI scientists: Safe and useful AI? 2023. Retrieved from https://yoshua bengi o.org.[28] Lumenova AI Blog. AI agents: Potential risks. Retrieved from https://lumenova.ai.[29] Albrecht S, Stone P. Autonomous agents modelling other agents: A survey. Retrieved from https://en.wikipedia.org."
  },
  {
    "title": "暗涌系列：Ark Invest《Big Ideas 2025》报告浅析 Part 1",
    "summary": ":::note\n在看似平静的水面之下，总涌动着改变世界的力量。作为专注科技创投领域的观察者，我新建了「暗涌」系列，识图捕捉哪些尚未形成滔天巨浪，却已积蓄势能的产业暗流。在这里，你可能看到：深度解构：穿透创业公司的PR话术，拆解独角兽的底层技术栈与商业模式趋势前瞻：保持对市场的敬畏，在大趋势下捕捉潜在的超额收益范式转移：追踪技术成熟度曲线的陡峭转折点，捕捉范式转换期的非共识机遇首篇聚焦ARK Inv",
    "tags": [
      "暗涌"
    ],
    "url": "/posts/Finance and Economics/Darkwave-BigIdeas2025-P1/",
    "date": "2025-03-03T00:00:00.000Z",
    "content": ":::note\n在看似平静的水面之下，总涌动着改变世界的力量。作为专注科技创投领域的观察者，我新建了「暗涌」系列，识图捕捉哪些尚未形成滔天巨浪，却已积蓄势能的产业暗流。在这里，你可能看到：深度解构：穿透创业公司的PR话术，拆解独角兽的底层技术栈与商业模式趋势前瞻：保持对市场的敬畏，在大趋势下捕捉潜在的超额收益范式转移：追踪技术成熟度曲线的陡峭转折点，捕捉范式转换期的非共识机遇首篇聚焦ARK Invest《Big Ideas 2025》，让我们从木头姐的前沿预判中，解码那些正在重塑全球产业格局的隐秘力量。水面之下，方见真章。\n:::ARK Invest 由凯瑟琳·伍德（Catherine Wood，业内称“木头姐”）创立，是一家专注于科技创新与数字资产投资的基金管理公司。目前，该公司共运营 14 只 ETF，覆盖多个前沿技术领域，其中 6 只主动管理型科技创新 ETF 的资产管理规模已达 302 亿美元。自 2017 年以来，ARK 每年发布《Big Ideas》报告，以深度研究和独到见解成为全球科技创业者与投资者的重要参考。2025 年 2 月，《Big Ideas 2025》如期发布。作为 ARK 以实战押注科技变革的核心指南，本年度报告重点剖析了人工智能（AI）、机器人、能源存储、公共区块链和多组学测序五大技术领域，系统梳理产业格局，揭示未来趋势。报告涵盖产业/领域：人工智能代理（AI Agents）比特币稳定币区块链扩展自动驾驶出租车自动化物流能源机器人技术可重复使用火箭多组学（Multiomics）报告的几个观点洞察我觉得在具体分析这份报告之前，我们需要先思考几个问题：1.这篇报告为什么关注这几个领域？这些领域的独特价值是什么？要理解ARK Invest的关注逻辑，我们需要从它的核心投资理念出发。ARK始终保持着对于「颠覆性创新」的投资信仰，他们投资有三个核心判断标准：是否具备成本下降曲线、是否形成网格效应、是否创造增量市场。基于这个框架，我们可以解读ARK的领域选择逻辑：（1）AI Agent正处于“Iphone时刻”AI agent的价值突破在于其边际成本正以指数级下降，当顶级大模型的调用价格变成白菜价，同时推理速度在技术优化迭代下持续提高，那么原本很多迫于成本和延时没办法部署的场景现在和未来都会变得很具想象力。大模型价格战自DeepSeek v2推出时开打，大模型正式进入1元/百万tokens时代；后续DeepSeek r1更是将世界顶尖水平的推理模型推理价格拉到平民价。此外，以 DS、 Llama 和 Qwen 为代表的巨头开源力量允许模型普惠化去中心化，开发者和其他公司可以在自己的GPU集群里部署企业级推理服务，进一步降低了企业部署AI Agent的门槛。这个趋势类似于云计算的演进——当AWS、GCP等云服务商使计算资源成本下降后，SaaS应用迅速崛起。当模型综合调用成本远低于人工成本时时，智能客服、法律文书处理、编程辅助等场景将涌现出「AI原生工作流」，形成开发者生态与用户需求相互激发的网络效应。这种模式不简单替代人力，而是创造出万亿级的智能服务增量市场。（2）区块链基础设施开始支撑主流金融应用ARK对区块链的关注由来已久，本次的《Big Ideas 2025》依然将其作为重点方向之一。:::note\n不过ARK他们好像只关注比特币的投资价值，没太说其他在金融技术层的建构，我不知道是他们认为这玩意投资人看不懂还是压根就不信\n:::我认为当前的区块链技术确实正在从单纯的「加密资产」阶段逐步演进为一个支持全球范围内金融和数据流通的「去中心化信任层」。交易成本下降两个数量级（从以太坊主网每笔交易数美元降至Layer2的0.01美元量级）、结算速度突破千倍提升（Optimism等Rollup链实现秒级确认）、合规框架趋于完善（欧盟MiCA法案落地）三大突破，使区块链技术首次具备支撑万亿级金融应用的技术-经济可行性。区块链的核心价值可以拆解为以下几点：去中心化结算网络：相比传统金融系统，区块链网络能够提供更高效、透明的全球结算方案。稳定币（如USDC）已经成为跨境支付的重要工具，而基于智能合约的去中心化金融（DeFi）则提供了全新的资产管理和借贷模式。可编程金融：智能合约的引入，使得金融应用可以以代码的方式运行，去除中介，提高效率。如以太坊生态中的L2扩展方案（如Arbitrum、Optimism）正在推动DeFi的主流化应用，提供更低成本、更高吞吐量的交易环境。NFT与数字身份：大模型说这玩意有价值，但我觉得难说。（3）大模型加持下的智驾和自动物流正式开始高速商业化智驾和自动物流的商业化突破本质上也是多模态大模型技术红利与硬件成本下降曲线的交汇产物。之前的智驾系统曾受限于高昂的长尾问题处理成本：激光雷达+高精地图方案单车成本过高难以落地，传统算法面对极端场景（如暴雨中的临时路障）需要耗费大量的标注数据且效用难以令人满意；22、23年后大模型驱动的智驾方案（如特斯拉的FSD V12和华蔚小理的智驾方案）通过多模态感知融合+端到端技术让系统首次具备人类水平的判断驾驶能力。根据高盛团队的测试体验、众包数据以及第三方评价，FSD V13的关键干预距离达到了400-450英里之间，97%的驾驶过程中无需发生干预，当搭载智驾大模型的车辆突破临界规模，实时驾驶数据回流-模型迭代-OTA升级形成的循环加速可以进一步推动智驾能力指数级增长。随着Dojo超算投产，模型训练成本进一步降低，意味着L4级自动驾驶的经济可行性正在逼近临界点。当然，大模型的影响力不仅限于乘用车，还在重塑全球物流产业。中美两国都有大批智驾独角兽在测试L4级的自动驾驶卡车，逐步替代传统的双驾驶员模式，大幅降低人力成本的同时还可降低车祸/故障风险。末端物流领域，我们同样可以期待低空经济框架下美团无人机配送网络和菜鸟快递无人配送网络的入场。致敬传奇内斗之王纳斯达克上市企业图森未来除开硬件，软件方面的变革更具想象力。主机厂正在从传统制造商向数据运营商转型，依靠智驾订阅获取更长周期的用户价值；保险行业也随之变革，Progressive等保险公司已开始采用智驾安全评分进行动态定价，推动车险模式从「风险对冲」转向「技术服务费」模式。自动驾驶不再只是一个汽车行业的技术升级，而是一个规模比传统汽车产业大10倍的全新市场空间，覆盖数据服务、智能基建、能源网络等多个维度，开启了「软件吞噬交通」的新时代。（4）具身智能革命进入成本临界点具身智能（Embodied Intelligence）是指拥有物理身体、能够进行感知和行动的智能系统，强调机器对环境的交互能力。通俗一点讲，就是让人工智能“长”出躯体，在真实世界中理解、决策并执行任务。近年来深度学习、强化学习等AI范式飞速进步，大模型在前沿探索的过程中逐步融入机器人决策中，使机器具备了更强的语言、视觉理解和规划能力。核心技术方面，具身智能依赖多领域协同：高算力且低功耗的芯片，视觉、听觉、触觉等多模态传感器，精密伺服电机与控制器，以及云计算和大数据支持下的智能算法。这些要素的成熟共同奠定了具身智能革命的技术基础。为什么我说具身智能革命正在进入成本临界点呢？硬件成本：机器人的制造和组件成本正快速降低。以工业机器人为例，其全球平均价格已从2010年的约4.6万美元降至2017年的2.7万美元，并预计到2025年进一步降至约1.09万美元。根据经验曲线模型，每当累计产量翻番，成本就会下降固定比例（被称为“莱特定律”）。历史数据显示机器人领域的学习率约为50%，意味着产量每翻一倍，成本可减半。也正是我们的ARK Invest预测，到2025年工业机器人单价将低于1.1万美元，远低于传统预测，届时机器人需求将因成本触底而出现拐点式增长。实际案例也印证了成本的快速下滑：机器人的核心零部件如高精度传感器、减速器、伺服电机等过去昂贵且依赖进口，如今在技术进步和国产化推动下价格显著下降。例如曾经每台数万美元的激光雷达，现在部分型号已降到千元美元级别。人形机器人的硬件总成本目前约为5万美元，其中AI“大脑”、传感器芯片、伺服电机等单项成本均在1万美元左右，但随着设计优化和规模生产，这些模块的单价正逐步压缩。计算和算法成本：人工智能模型的训练和推理成本也在下降。一方面，芯片算力提升使单位计算成本降低；另一方面，云计算和开源软件生态降低了机器人开发门槛。例如Robot Operating System (ROS)等开源机器人操作系统的普及，使厂商无需从零开发软件，大大节约了开发成本。目前具身智能的大脑——大模型虽然训练代价高昂，但可以通过一次训练服务于无数机器人应用，摊薄了单个机器人实现复杂智能行为的AI成本。未来完全通过让单个大模型大脑控制多个机器人，实现“一脑多机”，这有望在未来进一步降低具身智能系统的人均智能成本。制造与数据成本：规模化生产带来的单位制造成本降低也非常明显。以人形机器人为例，特斯拉计划在2027-2028年实现每年数十万台的人形机器人量产。虽然这一目标可能偏乐观，但包括特斯拉在内的多家公司正致力于将机器人生产从实验小批量提升到类似汽车的大规模流水线。麦格理研究预计，随着产量提升，人形机器人的平均售价将从2026年的约7.4万美元大幅降至2035年的约2.2万美元。这意味着十年出头成本将削减70%以上，进入普通企业甚至消费者可承受的区间。同样，中国初创公司宇树科技近日发布其人形机器人G1量产版，起售价仅为9.9万元人民币，远低于业内普遍动辄数十万的价格。宇树科技公司创始人表示，这一低价得益于复用之前机器人狗成熟技术，对电机、结构、传感器等零部件的精准成本控制。他也强调，随着出货量增加，价格有望进一步亲民，这是任何产品规模化后的自然趋势。由此可见，机器人从试验品走向商品化，其成本拐点已近在眼前。:::note\n宇树科技，很神奇吧\n:::（5）能源生产这块其实有点老调重弹的味。大家年年都知道可控核聚变重要，成功就会颠覆全世界，都知道托卡马克xxxxxx，但年年又距离实现可控核聚变还差五十年。旧能源+光伏所有人都知道是红海市场，再怎么炒概念也没啥分析价值，整条产业链上限就到此为止；像可控核聚变这种高新硬科技我又没能力去做真正有价值的分析，所以这部分就不写了。（6）多组学革命理论上，多组学技术的突破可以大幅降低单人类全基因组测序成本和CRISPR基因编辑效率，单细胞测序成本的快速降低也可推动癌症早筛和免疫微环境研究相关方面的研究；在传统药物研发领域。2023 年，AlphaFold2 和 RoseTTAFold 等 AI 模型成功预测了几乎所有已知蛋白的三维结构，这一突破大幅加速了新药靶点的发现，AlphaFold3作为新一代模型性能更具想象力，AI将药物研发成本压缩70%，平均周期从10年降至3-5年。但！这方面我基本上是纯白痴，所以这里仅仅援引公开新闻报道观点，具体真实性我先存疑，毕竟技术从实验室到真正走上生产环境要走的路还是非常漫长的。总结能源革命支撑算力技术设施训练出更大更强的模型，Transformer架构+大模型加速具身智能算法迭代，具身智能进一步解放生产力替换低端岗位，多组学突破则又进一步依赖计算生物学的进步，广领域多头技术融合产生的“乘数效应”给予了ARK Invest投资极为庞大的想象空间。2.这篇报告是给谁看的？《Big Ideas》系列是一份面向长期投资者的硬科技路线图，其核心读者群体可分为以下四类：（1）机构投资者：追求超额收益传统资产管理机构（如养老金、主权基金）面临低利率时代下的收益焦虑，但受制于合规框架和短期考核压力，难以直接押注早期技术。他们需要一份具备前瞻性框架的报告，既能捕捉技术革命的早期信号，又能提供系统性风险评估逻辑。ARK通过拆解「成本下降曲线→网络效应→增量市场」的递进关系（例如AI Agent从技术突破到生态爆发的路径），帮助机构投资者建立对新兴领域的非线性增长预期，同时通过历史数据（如Agent渗透率曲线对比）验证其假设的合理性。（2）科技创业者：验证赛道选择与商业模式设计很多创业者，尤其是科创领域经常会陷入「技术迷恋」和「市场需求脱节」的矛盾。是的，零X万物，说的就是你报告通过技术-经济可行性分析（大模型成本降低后企业级代理市场的扩展）为创业者提供「技术落地临界点」的判断标尺，影响创业公司产品定义策略（选择高单价工业场景还是低单价消费场景）。（3）政策制定者：预判技术冲击与监管沙盒设计监管机构需要在技术创新与系统性风险之间平衡，例如自动驾驶事故责任认定、区块链跨境支付与反洗钱冲突等。报告可以通过量化技术扩散速度为政策响应预留时间窗口，给政策制定者提醒建立弹性更强的沙盒机制。（4）企业战投部门企业战投部门（CVC，Corporate Venture Capital）和传统GP/LP机构的目标其实并不太一样。传统财务投资者的核心逻辑是「投赛道、赌概率、求退出」，通过分散投资组合捕捉市场β收益，最终依赖IPO或并购实现资本增值；而企业战投的核心目标则是「控生态、锁资源、抗颠覆」，其投资行为本质上是母公司战略的延伸，需要将技术趋势转化为企业自身的竞争壁垒或风险缓冲垫。补全技术短板：当母公司主营业务面临技术断层风险时（例如传统车企在智驾算法上的滞后），CVC需要通过投资快速获取关键技术能力。ARK报告中强调的「成本临界点分析」为此类投资提供了精准的窗口期判断。例如，若AI Agent的边际调用成本在2025年降至人工成本的1/10（报告中预测数据），零售巨头可能会提前收购客服对话引擎初创公司，避免自身呼叫中心被低成本AI服务商颠覆。一个很经典的例子就是亚马逊2012年收购Kiva Systems（仓储机器人公司），正是预判了物流自动化成本曲线下探的趋势。\n造不如买，买不如收购！卡位式投资：在技术扩散初期，通过投资关键节点公司控制生态入口。ARK对区块链Layer2网络「交易成本突破0.01美元」的测算，解释了为何摩根大通等金融机构在2023年密集投资Polygon、StarkWare等扩容方案——谁能主导低成本结算层，谁就能在未来跨境支付网络中掌握定价权。这块我觉得阿里挺经典的。23年大模型投资热潮开始，国内基本上所有有头有脸的大模型独角兽阿里都参股投资了。应对跨界颠覆（防御式投资）：大模型等通用技术可能催生行业外的「野蛮人」（如字节跳动借助推荐算法颠覆内容产业）。主机厂们未来最大的竞争对手可能不是宝马丰田这种传统势力，而是而是拥有自动驾驶数据和用户入口的科技公司（如Waymo、高德甚至美团）。当然还有我们的华为。出卖灵魂你们车厂懂伐？（5）其他ARK写这份报告我觉得还有潜藏的意思，就是通过渲染「颠覆性创新」的史诗感，强化ARK在科技投资领域的思想领导力，吸引更多资金流入其ETF产品。在预期管理方面，可提前向LP传递「非共识投资」的必要性（例如忍受机器人领域短期亏损以换取指数级回报），降低业绩波动引发的赎回压力。事实上，报告中「成本临界点」的反复强调本质是在构建一套对抗传统估值模型（如DCF）的叙事体系。前言这部分主要还是分析师的宏大叙事，主要目的是让各位投资者放心的投资未来。人工智能、储能和公共区块链的进步对技术发展的步伐至关重要。在颠覆性技术中，神经网络是最重要的催化剂。根据ARK Inverst的研究，神经网络的进步将使得其他14项技术中至少6项的价值提升至少一个数量级，从而为下一代云技术、智能设备、自动驾驶、人形机器人、精准医学和多组学技术带来巨大的市场扩展。image.pngARK团队认为的十四项技术一、AI Agent首先我们得给AI Agent一个定义。AI代理是一个通过自然语言理解意图，利用推理和适当的上下文制定计划，使用工具采取行动以实现意图，通过迭代和持续学习自我改进的技术实体。image.png目前主流的agents都处于孤立的单用途代理场景，未来会逐步发展平台级代理和最广泛的通用代理。1.AI搜索+购物image.pngARK主要认为agent在未来搜索+购物领域大有可为，其实也好理解，毕竟最终消费掏钱的还得是人嘛。2.企业生产力（1）掠过消费场景，看企业生产力场景：在The Enterprise中，agent将通过软件提高生产力。部署智能代理的公司能够在相同人力资源的情况下增加单位产量，和/或优化人力资源以转向更高价值活动。随着人工智能的发展，agent有可能承担更高比例的工作负荷，并独立完成更高价值的任务。image.png降本增效.jpg我之前见过很脑残的反驳，说为什么ai不会替代人力劳工：如果工作岗位都用ai来做，那资本拿什么剥削员工？这种就属于念经念傻了，或者没读过正儿八经的经书。资本的最终目的是增值，剥削只是增值过程中非常好用的手段之一，如果资本不剥削就可以快速自我增值甚至效果还更好，那为啥还要剥削人？随着模型性能提高+成本快速下降，这一趋势将显著影响代理经济学：OpenAl 和Salesforce的新产品正在以经济高效的方式补充人工客服Agent。即使每次对话的固定成本为1美元，一旦AI代理能处理35%的客户服务咨询，它们就能为企业节省大量资金。AI代理还应降低入职和招聘成本，以及基于座位的软件成本，同时在扩展方面比人力更容易。（2）AI Coding赛道：AI正在重塑软件价值链image.png不同的大模型在实际编程任务解决中的表现这一章节最后的部分是「AI将极大地增强知识工作」，什么意思呢？（3）AI 正在推动软件的爆炸式增长预计到2030年，企业将在知识型工作中大幅增加AI软件的使用，以提高生产力。取决于AI软件的采用率，全球软件支出可能从过去10年14%的年增长率加速到18%-48%。ARK 设想了三种不同的AI投资情境，并分析了它们对就业、自动化、生产力等方面的影响：| 指标 | 保守投资 (Modest Investment) | 加速投资 (Accelerated Investment) | 快速大规模采用 (Rapid Mass Adoption) |\n| --- | --- | --- | --- |\n| 知识型工作者年增长率 | 6.3% | 3.2% | 1.3% |\n| 2030年自动化的工作时间占比 | 31% | 61% | 81% |\n| 生产性工作时间减少 | 0% | 8% | 20% |\n| 创造的生产力盈余 | $22万亿 | $57万亿 | $117万亿 |\n| 生产力解决方案的价值捕获率 | 10% | 10% | 10% |\n| 新增软件收入 | $2.2万亿 | $5.7万亿 | $11.7万亿 |\n| 2030年软件市场规模 | $3.5万亿 (18% CAGR) | $7万亿 (33% CAGR) | $13万亿 (48% CAGR) |AI 采用率的提高将减少知识型工作者的增长，同时提高生产力和经济收益。企业将越来越多地投资AI软件，并减少对人力的依赖。如果AI被快速大规模采用，全球软件市场可能在2030年达到$13万亿，年增长率高达48%。中译中就是，传统的中低层知识型员工的生存空间可能被快速压缩。二、比特币如果要用一句话概括比特币，那么最简单的描述便是：「一种去中心化的数字货币」。比特币诞生于2008年，由化名「中本聪（Satoshi Nakamoto）」的匿名人物提出，并在2009年正式上线运行。从技术角度来看，比特币依赖于区块链技术，其核心是一套分布式的、不可篡改的账本系统。与传统货币不同，比特币不依赖任何中央机构，所有交易记录都由全球的矿工节点共同维护，并通过工作量证明（Proof of Work, PoW）机制竞争生成新区块。这种设计确保了比特币的去中心化特性，使其无法被单一机构控制，也极难被篡改或作假。与传统法币可以由央行无限印钞不同，比特币的总量被严格限定在2100万枚，这一算法层面的设定使其更类似于数字黄金，被许多人视为一种抗通胀的价值储存手段。正因如此，从最初的一文不值，到后来被市场认定为「数字黄金」，比特币的价格经历了惊人的增长，也成为全球金融市场中最具争议性，同时也是最受关注的资产之一。比特币目前建立了一个成熟的全球货币体系，具有健全的网络基础与日益增长的机构采用率。image.png比特币在2024年创下历史新高，并且市场普遍预期特朗普总统任期内会有加密货币市场的重大利好。1.比特币的原理基本技术原理一共有三个模块：（1）区块链架构与分布式账本：比特币运行在区块链之上，即一个由顺序链接的区块组成的公开分布式账本。所有参与比特币网络的节点共同维护这本账本，每个区块记录一批经过验证的交易，并包含前一区块的哈希，从而将区块串联成链。这种链式结构确保交易记录不可篡改且可溯源，全网节点通过点对点网络实时同步新区块，保证账本的一致性。任何人都可以运行节点并持有完整账本副本，实现真正的去中心化。（2）工作量证明（PoW）共识机制：比特币采用PoW共识来确保新区块的产生和验证。矿工节点通过不断尝试哈希碰撞来竞争记账权：他们搜寻一个随机数（Nonce），使得将该Nonce与区块交易数据一起哈希后的结果满足网络难度要求（如哈希值前若干位为零）。找到合适Nonce的矿工即完成工作量证明并有权将新区块广播全网。其他节点验证该区块哈希及其中交易的有效性后，区块被添加到链上，矿工获得比特币区块奖励作为激励。PoW机制提高了作恶成本，确保攻击者必须投入巨大算力才能篡改历史记录，从而防止双重支付等攻击。正是通过这一“挖矿”过程，比特币网络在无中心机构的情况下达成共识并安全运行。（3）挖矿经济模型：比特币的货币发行内嵌于挖矿过程之中。最初每个新区块补贴50 BTC，每21万个区块（约4年）奖励减半，目前区块奖励为6.25 BTC，并将持续减半直至约2140年达到2100万枚上限。这一渐减的发行曲线使比特币成为恒量资产，长期呈现通缩性质，不会因超发而通胀。同时，网络每约两周根据全网算力自动调整挖矿难度，以确保出块时间约为10分钟。因此，无论矿工数量多少，出块速率保持稳定，新的比特币发行节奏可预测。矿工通过区块奖励和交易手续费获得收入，其利润取决于币价和运营成本。当币价上升时，挖矿收益提高会吸引更多矿工参与，算力上升；反之币价下跌会令部分矿工退出，算力下降。这个矿工-价格的动态平衡在一定程度上连接了比特币的市场价值与其网络安全（算力）之间的关系。总体而言，挖矿经济模型通过激励机制维系了网络的安全和货币供应的稳定增长。2.生态拓展：Layer 1 和 Layer 2（1）什么是Layer 1 ？Layer 1 是指区块链的底层协议，通常也被称为基础链。例如比特币（Bitcoin）、以太坊（Ethereum）等都属于Layer 1区块链。Layer 1 区块链在设计中追求去中心化与安全性，但在运行效率和可扩展性上面临一定限制。尤其是在高并发场景下，交易速度（TPS，Transactions Per Second）成为一种瓶颈。为了解决这一问题，Layer 1 区块链常常引入共识机制的改进或协议升级。例如，以太坊通过从工作量证明（PoW）转向权益证明（PoS）的转型（即Ethereum 2.0）就是一种尝试，以提高交易速度并降低能耗。然而，Layer 1扩展性的提升往往是有限的，因为它需要在三角理论（不可能三角：去中心化、安全性、扩展性）中权衡，过度改善某一方面可能损害其他方面。这也就是为什么区块链领域提出了引入Layer 2的解决方案。:::note\n所以，比特币作为Layer 1的数字货币，交易成本相较于现在的其他货币还是比较高的，在比特币基础上建构的DeFi生态也相对比较薄弱。\n:::（2）什么又是Layer 2 ?Layer 2 是建立在Layer 1基础协议之上的“加速”层，旨在优化区块链的效率和扩展性。简单来说，Layer 2的目标是将一部分计算和交易处理从主链中“卸载”到额外的二级网络，通过分担主链压力来提高整体性能。Layer 2 的具体实现方式可以分为多种，比如：状态通道（State Channels）：例如比特币的闪电网络（Lightning Network），通过在链外处理大部分交互，只将最终结果记录到主链上，极大提升了效率。侧链（Side Chains）：独立于主链但与之互操作的链，例如Polygon，提供更快、更廉价的交易服务。Rollups：包括Optimistic Rollups和ZK Rollups等，通过将大量交易数据打包后提交到主链，显著降低交易成本并提高吞吐量。所以，Layer 2实际上就是建构在Layer 1之上，将部分计算打包话链下化计算完成之后再反映到链上的一种技术治理方式，Layer 1 提供底层的安全保障和去中心化特性，而 Layer 2 则通过灵活的扩展方案提高了交易效率和用户体验。在这种协同进化的模式下，区块链技术能够逐步达到大众所期待的“去中心化互联网”：更快、更安全、更可靠的全球价值传输网络。3.区块链生态（1）去中心化金融（DeFi）近年兴起的去中心化金融（DeFi）拓展了区块链的金融应用版图。相比以太坊上繁荣的DeFi生态，比特币在这一领域的直接参与较为有限。由于比特币主链缺乏图灵完备的智能合约能力，其DeFi应用主要通过跨链形式实现，例如将BTC锚定为WBTC等代币在以太坊上使用。整体来看，目前只有极少比例的比特币被用于DeFi协议中：截至近期统计，比特币总市值约8,680亿美元，而其中锁定在DeFi中的价值仅约3.15亿美元，相比之下以太坊链上DeFi锁定价值高达约280亿美元。美国财政部在2024年的一份报告中指出，比特币在DeFi生态中主要扮演价值储存工具的角色，被视为“数字黄金”而非交易媒介。这体现出当前比特币更多被投资者持有用于储值，直接参与DeFi借贷、流动性挖矿等活动的程度较低。一方面，DeFi的繁荣强化了加密资产作为整体的市场关注度，间接提升了机构和投资者对比特币的认可度；但另一方面，以太坊等平台凭借DeFi实用性吸引了大量资金和用户，在一定程度上分流了对比特币的边际投资需求。这种此消彼长的关系需要动态来看：若未来在比特币网络上实现更丰富的金融应用（例如借助侧链或跨链协议），比特币有望进一步巩固其在加密金融体系中的核心地位，并从中获得更高的估值溢价。（2）Layer 2 扩容方案（闪电网络等）为提升比特币的交易处理能力和降低费用，Layer 2扩容方案应运而生，其中闪电网络（Lightning Network）是最主要的代表。闪电网络作为比特币之上的第二层协议，通过在链下建立支付通道实现快速且低成本的比特币交易。两方预先在主链上锁定一定金额的BTC后即可频繁地进行链下互相支付，最终再将净额结算回主链。这极大提高了交易吞吐量，使小额支付变得高效可行。自推出以来，闪电网络的规模不断扩大：统计显示，自2021年初至今，Lightning节点数量增长了105%，已超过17,000个，网络每日可处理价值约8,300万美元的BTC交易。随着更多钱包和交易平台集成闪电网络，比特币作为支付手段的实用性有所增强。然而，当前闪电网络的实际应用仍主要集中在少量小额转账和极客社区中，其对比特币整体需求的拉动有限。值得注意的是，2023年闪电网络生态出现新进展：Lightning Labs发布了Taproot Assets协议，开始支持在比特币/闪电网络上发行稳定币和其他资产。这一创新有望使比特币网络承载多资产转移功能，在不显著增加主链负担的情况下拓展应用场景。从估值角度看，Layer 2方案提升了比特币的可扩展性和实用性，有助于强化其“数字货币”属性。如果未来闪电网络能被更广泛采用（例如用于商户支付、跨境汇款等），那么比特币的潜在用户群和交易需求将扩大，从而对价值产生正向影响。但短期内，其影响仍取决于网络效应能否真正建立。（3）比特币和其他区块链的竞争关系比特币面临着来自新兴区块链平台的竞争，其中以太坊是最主要的竞争者。以太坊通过智能合约和丰富的去中心化应用，吸引了大量开发者和用户，在功能性上形成对比特币的差异化优势。然而，比特币凭借先发优势和简洁稳定的定位，在市值和用户认知上依然占据主导地位。投资者往往将比特币视作加密市场的价值基石和避险资产，而将以太坊及其他山寨币视作风险更高的创新投资标的。这一点从市场表现可见一斑：据IntoTheBlock数据，2023-2024年间ETH/BTC价比一度跌至40多个月低点，反映投资者在动荡市况下更偏好比特币的稳定性而非以太坊的高波动性。同时，比特币有限供应和高度去中心化的特点使其获得了“数字黄金”的共识，这种品牌信任度不是后来者短期内能够复制的。当然，其他公链的创新（如更快的性能、不同的共识机制等）也不断对比特币形成挑战和补充。一些替代币在特定功能上表现出色（例如用于智能合约、隐私保护等），可能分流部分投资资金和使用场景。不过，从长期看，比特币在网络效应（持有者和支持者众多）、流动性深度（市场最广泛交易）以及基础设施（交易所、托管、支付渠道的支持）等方面的深厚积累，构筑了强大的竞争护城河。只要比特币社区能够通过协议升级（如SegWit、Taproot等）逐步提升性能并保持安全性，它将在与其他区块链的竞争中继续保持相对优势。这种竞争环境也提醒我们，比特币的估值不仅取决于自身，还与整个加密生态的此消彼长息息相关——投资者会在不同资产间重新分配资本，但截至目前，比特币依然牢据加密市场的“定海神针”地位。4.挖矿之外比特币当前的高估值是多重因素综合作用的结果。从技术原理来看，区块链架构、PoW共识和通缩经济模型奠定了比特币作为稀缺、安全数字资产的基本价值；区块链生态的发展既为比特币带来新的机遇（Layer 2扩容、新应用场景）也提出挑战（来自其他公链的竞争），这些外部环境影响着投资者对比特币前景的预期；链上数据提供了洞察内在供需动态的窗口，HODL比例、活跃地址等指标反映出网络的长期健康增长，为估值提供数据支撑；市场接受度与安全性方面，机构的参与和监管的完善正在降低比特币的风险溢价，而持续走高的算力与稳健的安全性则增强了市场对比特币承载巨大价值的信任。总体而言，比特币已经从早期的小众试验演变为全球认可的价值储藏和投资资产。其估值逻辑类似于介于技术产品和宏观资产之间的混合体：既要考虑网络技术指标和用户增长这样的“基本面”，也要考虑宏观流动性、市场情绪和制度环境等因素。比特币能否维持并提升当前估值水平，将取决于其在技术上持续创新和保持安全，在应用上扩大实际使用场景，在生态竞争中巩固地位，并在传统金融体系中赢得更广泛的认可。随着越来越多的数据和研究涌现，我们对比特币价值驱动因素的理解也将更加深入，为投资决策和学术分析提供更完善的框架。5.ARK Invest核心观点总结：现货比特币EFT发行速度快积累资金多，未来可期在第四次减半后，比特币的通胀率降至低于黄金长期供应增长水平，未来可期比特币的年波动率降到历史最低点，风险调整后的回报率仍然优于大多数主要资产类别，值得投资尽管减半后矿工收入大幅下滑，但比特币的算力仍然创下历史新高（区块链的维护者的长期信仰坚定，不用担心崩盘）闪电网络未来可期，比特币交易量激增，流动性有保障比特币在2024年吸收了主要的抛售压力，未来大幅回撤概率小越来越多的上市公司现在持有比特币，你的同事上司都买了你不买就是吃大亏2024年比特币的总成本基础创下新高，因为大家都想赚钱所以比特币未来的估值会越来越高最后，比特币正按部就班地向我们2030年的价格目标迈进，熊市30万刀正常71万刀牛市150万刀，好大的一个饼image.png三、稳定币在我们人类世界的货币演进过程中，黄金的物理重量、纸币的防伪水印、银行账户的电子符号和投资者账户上的债券期权等本质上都是不同形态的信用凭证。移动互联网革命后，我们突然意识到区块链正在重构概念上的货币——新系统既继承了中央银行对货币创造的垄断权（通过算法发行），又保留了传统货币最重要的稳定基因。稳定币（Stablecoin）正是这种双重属性的完美融合，你可以像法币一般具有锚定的购买力，又具备加密货币的链上流动性。这类数字货币通常采用三种锚定机制：最保守的 USDT 将美元现钞锁进银行金库，以1:1储备铸造链上代币；更具加密原教旨色彩的 DAI则以超额加密资产为抵押，在去中心化协议中维持价值稳定；最大胆的算法稳定币如 UST（已崩溃）则试图用数学方程式替代真金白银，通过供需调节机制维系虚拟信用。后续有机会的话我还挺想写篇博客去分析UST1.稳定币的发展历程（1） 早期稳定币稳定币（Stablecoin）是在加密货币领域中用于保持价格稳定的数字资产。早期的稳定币概念可以追溯到2014年，当时出现了世界上第一批稳定币项目，例如BitUSD和NuBits。BitUSD于2014年7月21日在BitShares区块链上推出，由加密货币（BitShares平台的BTS代币）作为抵押品来支持其价值。NuBits则于2014年9月推出，采用有争议的“铸币税”（Seigniorage）算法机制来调节供应，以尝试维持与美元的锚定。这些早期稳定币是开创性的尝试：BitUSD开创了用加密资产抵押来维持稳定价值的模式，NuBits则探索了算法调节供应的模式。然而，这两者最终都未能长期保持与美元的平价——BitUSD在2018年末失去了与美元1:1的锚定（价格跌至约0.8美元），NuBits甚至因机制缺陷导致价值较发行目标贬损了94%。这些早期案例表明实现价格稳定对于纯粹依靠加密资产或算法的模型是极具挑战性的，为后来的稳定币发展提供了经验教训。（2）Tether（USDT）的推出及影响2014年末，一种由法定货币支持的稳定币开始出现，即Realcoin项目，不久后更名为Tether（USDT）。Tether于2014年由Tether有限公司推出，并在2015年由交易所Bitfinex率先引入市场交易。作为第一个由法币储备支持的大型稳定币，USDT开创了通过法币抵押保持价值稳定的模式——每发行1枚USDT代币，理论上都有1美元的储备作为支撑。Tether的出现对加密市场产生了深远影响：它为交易者提供了在加密货币和法币之间快速切换的工具，极大提升了市场流动性和资金进出效率。随着加密市场的扩张，USDT的发行量迅速增长，成为交易量最大的加密资产之一。例如，截至2023年1月，USDT流通市值约678亿美元，占所有稳定币市值的近一半；其在中心化交易所的交易量份额更是超过75%，远超其他稳定币。然而，Tether在发展过程中也伴随着争议和风险。一方面，其规模效应使其成为整个加密生态的重要基石；另一方面，市场对其法币储备的透明度和合规性提出质疑。Tether公司曾卷入储备金不足和资金挪用的指控：例如，2019年纽约州检察长调查发现其关联交易所曾挪用约7亿美元的储备填补资金缺口，引发了监管罚款和和解。另外，2017年Tether曾遭遇黑客事件，3,100万USDT被盗。尽管如此，Tether基本维持了代币1:1锚定美元的承诺，其价格绝大多数时间紧贴1美元。在2022年5月TerraUSD（UST）崩盘引发市场恐慌时，USDT价格一度短暂下跌至约0.96美元，但很快恢复到接近1美元，并且Tether公司继续兑现1:1赎回。总体而言，USDT作为第一大稳定币，在推动稳定币概念普及和提供市场流动性方面具有里程碑意义，但其集中式模式也使其受到监管关注和信任度考验。（3）去中心化稳定币（DAI）的发展随着稳定币概念的发展，社区开始探索更去中心化的稳定币模式。2017年底，MakerDAO项目推出了去中心化稳定币Dai（DAI）。与USDT依赖法币储备不同，DAI通过超额抵押加密资产来维持与美元的锚定率。MakerDAO的用户可以将以太币等加密资产锁定在智能合约中，生成对应价值的DAI；为了应对抵押品价格波动，系统要求抵押品价值超过生成DAI的价值（例如150%或更高），并通过链上清算机制保证DAI的足额抵押。这种模式实现了稳定币发行和管理的去中心化：无需中心机构背书，全靠智能合约和社区治理维护稳定。DAI的出现被视为稳定币领域的“圣杯”式创新——既保持了价值稳定，又不依赖传统金融资产。在实践中，DAI的发展经历了逐步壮大并融入去中心化金融（DeFi）生态的过程。2018-2019年，DAI主要以单一抵押品（ETH）运作，后来扩展为多抵押品DAI，引入更多种类的加密资产作为抵押，甚至包括一些现实世界资产和其他稳定币，以提高稳定性和流动性。DeFi热潮中（2020-2021年），DAI的发行量快速上升，一度超过90亿枚，成为仅次于USDT和USDC的主要稳定币之一。许多去中心化借贷平台和去中心化交易所都将DAI作为基础稳定资产。但DAI也面临挑战：例如在2020年3月加密市场暴跌时，抵押品价值骤降导致部分仓位清算困难，出现过短暂的锚定偏离和债务缺口，之后MakerDAO通过增发治理代币等手段弥补了不足。这表明，虽然DAI无需信任中心机构，但对系统参数和风险控制的治理要求很高。此外，随着稳定币市场的发展，DAI自身也开始依赖于其他稳定币（如USDC作为抵押品）来巩固锚定，这引发了去中心化程度的讨论。去中心化稳定币的出现丰富了稳定币的形态，使用户在交易和DeFi应用中有了不依赖中心机构的选择。DAI等去中心化稳定币在去中心化借贷、衍生品交易等场景中发挥了关键作用，证明了基于智能合约的稳定机制的可行性。它们的发展也反映出，通过社区治理和机制设计，可以在一定程度上缓解纯算法或纯法币模式的缺点，在稳定性与去中心化之间取得平衡。（4）监管和合规进展（USDC、BUSD 等）随着稳定币规模的扩大，各国监管机构开始密切关注其合规性和潜在风险。一些稳定币发行方选择主动遵循法规，以获取主流金融体系的信任。其中代表性的是USD Coin（USDC）和Binance USD（BUSD）。USDC：USDC由Circle公司和Coinbase等组成的Centre财团于2018年发行，定位为合规透明的美元稳定币。USDC坚持1:1全额储备，由受监管的金融机构托管美元资产，并定期由审计机构出具储备证明。例如，据Circle披露，其储备约80%投资于美国国债，20%持于现金存款，严格保证流动性和安全性。USDC发行方在美国FinCEN注册为货币服务业务，并遵守各州的货币传输法律。这种“先合规后发展”的策略使USDC赢得了更高的机构信任度，其市场份额在2020-2022年间大幅提升，一度占据稳定币市场约30%的份额。USDC也广泛应用于中心化交易所和链上交易，尤其是在以太坊等公链上的交易量占比常年保持在40%以上，反映出其在DeFi和跨境支付场景的受欢迎程度。2023年3月，美国硅谷银行倒闭事件曾导致Circle部分储备金无法及时取出，引发USDC短暂脱锚（价格跌至0.9美元以下）。不过，得益于透明的储备披露和后续美国政府对银行存款的保护，USDC很快恢复了锚定。这一事件凸显了合规和透明对于稳定币信心的重要性：尽管市场出现恐慌抛售，但USDC凭借可信的储备支持和快速的信息披露，稳定了市场预期。BUSD：BUSD是币安（Binance）与受纽约监管的信托机构Paxos合作于2019年推出的美元稳定币。BUSD同样采取1:1美元储备，由Paxos托管资金并获得纽约州金融服务署（NYDFS）的批准发行，初期被视为合规运营的范例。借助币安交易所的生态优势，BUSD流通量在2021-2022年迅速扩大，最高时于2022年11月达到约235亿美元市值，成为第三大稳定币。然而，2023年2月纽约监管机构要求Paxos停止发行新的BUSD代币，原因据报道与监管审查和合规问题有关。此举对BUSD影响巨大：禁令发布后BUSD供应量迅速萎缩，从2023年初的约160亿美元降至6月的38亿美元左右，半年内市值蒸发近70%。到2024年底，BUSD流通规模已降至不到1亿美元，基本退出主流稳定币行列。BUSD的兴衰表明，监管政策可以直接决定一个稳定币的生死：再强大的市场需求，一旦失去监管支持，用户信心和使用场景也会迅速消退。除USDC、BUSD外，全球范围内对稳定币的监管正在逐步成形。在美国，监管机构曾于2021年发布《总统金融市场工作组稳定币报告》，建议将稳定币发行限定在受监管的存款机构内，以防范风险。这引发了美国国会关于《稳定币监管法案》的讨论（如《支付稳定币透明度法案》等草案），虽尚未通过但显示出立法方向：要求发行人持有高质量储备、及时兑现赎回，以及接受严格监管。在欧盟，全面的加密资产市场监管框架MiCA于2023年正式通过，其中对稳定币（称为电子货币代币或资产参照代币）提出了明确要求，包括发行需许可、储备资产须安全保管、设立资本金和流动性缓冲等。MiCA将于2024-2025年生效，这意味着在欧盟运营稳定币需要满足统一的合规标准。在亚洲，一些国家也在积极应对：日本于2023年修订《支付服务法》，允许合规实体发行日元稳定币，并对储备和赎回作出规定；新加坡金融管理局（MAS）在2023年8月发布稳定币监管框架，要求单一币种稳定币发行人持有100%准备金、及时赎回并取得牌照等。总体来看，稳定币正从早期的野蛮生长走向强监管时代。合规透明的稳定币（如USDC）在政策收紧中反而赢得更多市场，而不合规的产品则可能被迫退出。这一趋势有望提升稳定币整体的安全性和信誉度，但短期内也可能限制一些创新模式（例如算法稳定币或小型企业发行的稳定币）的发展。（5）近期发展趋势（央行数字货币与算法稳定币）进入最近两年，稳定币领域出现了两大显著趋势：一是各国央行数字货币（CBDC）的推进，二是算法稳定币的兴衰和演变。央行数字货币（CBDC）的兴起：稳定币的成功引发了各国央行对法定数字货币的兴趣。许多央行意识到，由私营机构发行的美元稳定币（如USDT、USDC）在全球范围内被广泛使用，甚至可能影响本国货币政策和金融稳定。因此，各国开始研发由央行直接发行、与本国法币挂钩的数字货币。典型例子包括：中国的数字人民币（e-CNY）已经在全国多个城市试点；欧洲央行正就数字欧元进行论证和原型开发；美国联储也在研究数字美元的技术可能性，尽管在政治上尚未形成共识。CBDC与稳定币在功能上有相似之处——都力图提供法币的数字化形式——但在控制权和技术架构上有本质区别。央行倾向于认为，由官方发行CBDC可以避免私营稳定币可能带来的金融风险，同时保障货币主权和金融稳定。例如，欧洲方面更支持数字欧元，认为私营稳定币可能带来风险；而美国一些政策制定者相对支持由合规的美元稳定币来满足市场需求，态度上对央行直接发行CBDC持保留意见。可以预见，未来几年内，部分主要经济体的CBDC将落地，这将与现有稳定币产生竞争或共存关系：在国内支付领域，CBDC可能占优，而在跨境转账和加密交易领域，私营稳定币可能继续发挥作用。两者的发展都会对全球稳定币生态产生深远影响，例如可能促使稳定币发行人提升合规标准，与央行合作或者调整运营模式，以适应新的竞争环境。目前全球主要经济体对CBDC与稳定币的态度不尽相同，正如前文所述：美国倾向于让私营合规稳定币发挥作用，同时对推出数字美元持谨慎态度，而欧盟和中国等更积极推进CBDC，希望以官方数字货币为主导，同时对私人稳定币加强管控。可以预见，在技术层面，稳定币和CBDC可能长期并存：稳定币侧重于加密生态和跨境场景，CBDC服务于国内零售支付和中央银行职能。两者也可能出现融合，例如央行支持的稳定币**（由商业银行或受许可机构发行、100%持有央行准备金的稳定币）模式。在技术实现上，一些稳定币公司（如Circle）表示愿意将CBDC纳入其储备或在CBDC网络上发行代币，由此可见未来可能形成公私合作的数字货币体系。算法稳定币的新探索与反思：算法稳定币是指主要依靠算法和市场博弈机制来维持币值稳定的稳定币类型。2020-2021年间，一些算法稳定币项目兴起，试图在无需足额抵押资产的情况下实现价格稳定。其中最引人瞩目的是Terra生态的UST。TerraUSD(UST)于2020年推出，采用LUNA-UST双代币体系和算法铸销机制：用户可以在1UST≠1美元时通过与LUNA的兑换套利来调节UST供需，从而使UST价格回归锚定。然而，这种机制高度依赖市场信心和流动性支持。UST在2021-初2022年取得了惊人的增长，一度成为市值第三大的稳定币（市值从2021年初的1.8亿美元飙升至2022年3月接近150亿美元）。其吸引力不仅在于算法机制的新颖，还因为Anchor协议提供的高达19.5%的存款收益率，吸引了大批用户将资金投入UST。然而，UST的繁荣掩盖了潜在脆弱性：缺乏独立于市场情绪的资产支持。2022年5月，面对宏观环境转冷和部分大户资金退出，UST的锚定出现松动并引发连锁反应：短短几天内，UST从接近1美元暴跌至数美分，关联的LUNA代币几乎归零，整个Terra生态瞬间崩溃，投资者损失估计高达420亿美元。这次崩盘对行业的冲击极大，不仅让大量投资者蒙受损失，也引发了监管层对稳定币特别是算法稳定币的强烈关注，被誉为“加密市场的雷曼时刻”。UST事件之后，算法稳定币的设计理念遭到全面反思。一些项目选择主动收缩或调整策略，例如Tron的USDD在UST崩盘后增加了超额抵押资产作为保障。部分仍在运行的算法稳定币开始强调部分抵押（部分由资产支撑、部分算法调节）的模式，以避免“无担保”模式的信任危机。Frax (FRAX) 就是一个代表性案例：它号称“部分算法、部分抵押”的稳定币，通过持有一定比例的USDC等储备资产以及其治理代币FXS的算法调节，来保持1美元锚定。FRAX在市场平稳时可以降低抵押率提高资本效率，而在压力时期则提高抵押率确保稳定。据统计，在2022年市场震荡和UST崩盘期间，FRAX的供应量从18亿美元缩减至约10亿美元（跌幅43.5%），显示出市场需求的下降和项目为稳健运行而主动收缩规模的策略。FRAX基本维持了锚定，没有发生极端崩盘，但其市占率仍然很小，这说明市场对纯或部分算法模型依然保持谨慎。近期也有一些新的算法稳定币尝试和实验，比如Ampleforth（AMPL，采用弹性供应机制而非严格锚定1美元）、基于社区治理的算法外汇稳定币等。但总体而言，算法稳定币在UST事件后进入低谷。投资者和开发者更加认识到此类模型的高风险，高收益伴随着高不确定性。因此，未来算法稳定币的发展可能会更侧重于“小规模+高抵押”的实验，或是在明确的合规框架下引入混合设计，而不大会重现UST崩盘前那种爆炸式增长。监管层面也可能对算法稳定币提出特别的要求，甚至有国家考虑禁止无资产支持的稳定币发行，以保护投资者。这些都预示着算法稳定币领域将朝着更谨慎和创新并存的方向演化。2.稳定币的主要技术架构稳定币根据其价值支撑和稳定机制的不同，大体可分为以下几种主要技术架构：法币抵押型、加密资产抵押型、算法型（包含部分算法混合型）以及由中央银行发行的数字法币（CBDC）。它们在抵押物、稳定机制、信任假设等方面各有特点。下面分别介绍这些架构的原理，并分析各自的优缺点与适用场景。（1）法币抵押型稳定币法币抵押型稳定币是目前市面上规模最大、影响最广的一类稳定币，包括USDT、USDC、BUSD等。其基本原理是：每发行1枚稳定币代币，在银行等托管机构存入等值的法定货币或合规资产作为储备，从而确保代币可以1:1锚定法币价值。这种模式下，用户可以用法币（如美元）向发行方兑换等值的稳定币，反之亦然，发行方承诺随时按1:1比例赎回。以USDC为例，当用户通过Circle的平台存入100美元资金，Circle会增发100枚USDC给用户；若用户需要兑回法币，则销毁相应的USDC并返还等额美元。锚定机制方面，由于持有人始终有权将稳定币兑换回法币，其市场价格一般紧贴锚定价。如果二级市场价格出现偏离，套利者会买入低价稳定币并赎回获取1美元，或反之，这种套利交易将价格拉回1美元附近。法币抵押型稳定币依赖中心化的发行机构来管理储备和兑现承诺。为了保持信任，主流发行人通常会将储备资产存放在信誉良好的银行，并持有安全、流动性高的资产（例如现金或短期国债）。如USDC的储备有约80%为美国短期国债、20%为现金存款。另外，发行人会定期披露储备情况，聘请独立审计或出具证明（例如USDC由会计师事务所出具月度证明）。一些发行人还对智能合约进行审核，确保代币发行和销毁与储备变动一一对应。优点：法币抵押型稳定币的最大优点在于价值稳定可靠。只要发行方确实持有充足的法币储备，并且银行托管安全无虞，理论上就能保证其代币始终等值于锚定货币。这类稳定币价格波动极小，非常接近1美元（或其他锚定币种）。同时，由于采用成熟的金融市场资产作为支撑（如美元、国债），这类稳定币很容易被交易所、机构投资者接受，是交易流动性的重要来源。在中心化交易所（CEX）中，法币稳定币通常充当基础交易对，使投资者无需离开加密市场就能在风险资产和现金头寸之间切换，大大提高了交易便利性。此外，法币稳定币的使用门槛较低，普通用户理解起来也较为简单（1枚代币代表1单位法币），这帮助其迅速推广。缺点：这类稳定币的不足主要在于中心化信任风险和监管依赖。用户必须信任发行机构真正存有足额储备并能兑付，而储备资产通常托管在传统金融体系内，受到银行运营和监管环境影响。例如，若发行机构管理不善、挪用储备或发生破产，用户持有的稳定币价值将难以保障。另外，中心化发行人通常有能力冻结特定地址的代币或配合监管进行账户封锁（USDT和USDC都曾多次冻结涉嫌犯罪活动的地址），这意味着资产可控性和隐私性不如去中心化方案。监管层的政策变化也会直接影响这类稳定币的存续和扩张（正如前文BUSD案例所示）。在极端情况下，如果政府全面打击私人发行的稳定币，用户将面临资产被限制或赎回困难的风险。适用场景：法币抵押稳定币非常适合于交易结算、支付和价值储存等需要低波动性的场景。在加密交易所，它们是交易对的标准计价资产，提供市场流动性和价格锚定。在场外交易和支付领域，用户可以使用稳定币进行跨境汇款和支付，避免传统汇款的高费用与延迟。同时，对于希望暂时退出波动市场的加密投资者，持有稳定币是一种便利的避险方式（无需将资金转回银行，也不会像直接持有美元那样受到地域限制）。机构方面，一些加密友好企业把稳定币当作现金等价物，用于商业结算或国与国之间的快速转账。因此，法币抵押型稳定币在当前的CeFi（中心化金融）和部分传统金融融合应用中扮演了不可或缺的角色。（2）智能合约加持下的加密资产抵押型稳定币加密资产抵押型稳定币通过链上抵押其他加密资产来维持稳定价值，典型代表是MakerDAO的DAI。此外早期的BitUSD也是类似原理。这类稳定币依托智能合约，实现超额抵押和自动清算机制，其核心理念是用波动性更高的加密资产作为担保，换取价值相对稳定的代币发行。以DAI为例，用户（借款人）可以将ETH等加密资产存入MakerDAO的金库合约（Vault）中作为抵押品，然后按照一定抵押率（例如150%）生成所需数量的DAI。只要用户的抵押品价值高于最低抵押比要求，就可以借出DAI。当用户想赎回抵押的ETH时，需要归还等额的DAI（加上一定的稳定费利息），智能合约随即销毁这些DAI并释放抵押品。如果抵押资产价格下跌导致抵押比不足（低于150%），智能合约会自动将抵押品拍卖（清算）以偿还所欠的DAI，确保系统中流通的每1 DAI都有足额的抵押资产支撑，从而保持DAI的价值稳定。整个过程在链上透明执行，由去中心化网络维护价格预言机提供抵押品价格数据，并由MakerDAO持有的治理代币（MKR）持有人投票治理参数（如稳定费率、抵押品种类）。\nDAI的市场价主要通过套利和市场调节来维持在1美元附近。如果DAI价格高于1美元，用户有动力通过抵押ETH新铸造DAI并卖出，增加供给使价格回落；反之如果DAI跌破1美元，用户会买入便宜的DAI去偿还债务或储备，从市场收回DAI减少供应。此外，MakerDAO也引入了一些辅助稳定手段，如目标利率（通过调节借贷利率影响DAI供需）和锚定稳定模块（PSM，允许用户直接用其他稳定币如USDC以固定汇率兑换DAI，提供锚定支撑）。这些机制共同作用，帮助DAI尽可能保持与美元1:1的价值。优点：加密抵押型稳定币最大的优点是去中心化和透明。其发行和运行完全通过智能合约执行，不依赖于任何单一公司或银行，只要智能合约可靠，用户无需信任某个特定机构即可使用。所有抵押资产和代币流通的数据公开可查，系统的风险状况（如抵押倍数）实时透明。这带来了抗审查性：没有中心化机构能够单方面冻结或没收用户的DAI，只要用户管理好自己的抵押仓位。在一些重视隐私和自主权的场景下（比如点对点交易、某些对法币管制严格的地区），去中心化稳定币提供了不依赖传统金融机构的价值储存和交换手段。此外，利用现有的加密资产来发行稳定币，可以为持币者提供流动性释放的渠道——用户无需卖出手中的加密货币，就能借出稳定币用于其他投资或消费。这种模式也被视为将传统银行抵押贷款概念引入链上的一种尝试。缺点：首先是资本效率低：由于抵押品本身价格不稳定，系统要求超额抵押（常见150%以上，有的甚至需200%以上抵押率），这意味着要发行1美元的稳定币，可能需要锁定价值1.5美元甚至更多的加密资产。大量资产被锁定提高了资金成本。从用户角度看，借出稳定币相当于拿自己的资产借了一笔相对较小的美元，相比法币抵押型稳定币的1:1效率要低很多。其次，稳定性仍受加密市场极端波动影响：如果出现剧烈熊市，抵押品价值暴跌，可能触发连锁清算，造成稳定币供应剧减和市场恐慌，进而使锚定承压（例如2020年3月“黑色星期四”事件中，ETH暴跌导致部分DAI无法及时清算，DAI价格一度高于1美元，因为市场上流动DAI不足）。再次，机制较复杂，依赖良好治理：维持这套体系需要持续调整参数和引入新抵押品，治理过程复杂且对参与者能力有要求。如果治理不善，可能出现系统性风险或经济攻击。例如，预言机失灵或被攻击会影响抵押品定价，从而威胁稳定币价值。最后，目前许多去中心化稳定币（包括DAI）为了加强稳定性，开始持有部分中心化资产作抵押（如USDC），这在一定程度上削弱了去中心化纯度，引入了传统金融风险。适用场景：加密抵押型稳定币主要服务于去中心化金融（DeFi）生态和注重隐私、去信任环境的用户。在DeFi应用中，如借贷平台Aave、Compound，或去中心化交易所Uniswap等，DAI等去中心化稳定币常被用作基础货币和计价单位。因为在这些场景下，参与者希望尽量减少对中心化资产的依赖，以避免遭受第三方冻结或审查的风险。对于持有大量加密资产又不想全部变现的投资者，抵押借出DAI也是一种获得流动性的方式，可用于套利交易、流动性挖矿等，从而增强资产利用效率。此外，在一些对法币渠道不友好的地区或人群，去中心化稳定币提供了获取美元等硬通货的替代途径，只需互联网和加密钱包即可参与。总的来说，加密抵押型稳定币适用于那些高度依赖智能合约自治和跨国界的加密金融活动场景，它们与整个DeFi体系共同成长，成为去中心化经济的重要基石。（3）算法稳定币的设计与崩溃算法稳定币试图通过算法和市场机制（而非足额抵押）来维持币价稳定，通常不以等量资产直接抵押支持，因此也被称为无抵押或部分抵押稳定币。其设计多种多样，但核心是在供需层面进行调节，以使稳定币价格锚定目标（如1美元）。常见的算法稳定币模型包括铸币税股份模型（如Basis、NuBits）、双代币模型（如UST/LUNA）以及弹性供应模型（如Ampleforth）。算法稳定币通常内置一个中央弹性调节机制：当稳定币价格高于锚定价时，系统会增加供应（或激励用户赎回），使价格回落；当价格低于锚定价时，系统会减少供应（或激励用户买入），使价格回升。例如，在Basis（已停项）和部分早期项目中，引入了“债券”或“股份”代币：当稳定币低于锚定价，用户可用稳定币折价购买债券，销毁流通的稳定币；当稳定币高于锚定价，系统发行新稳定币偿还债券或分配给股份持有人，从而调节供需。这类机制的理论基础类似于央行调节货币供给的思路。而在Terra UST模式中，则采用双代币套利：用户总可以按1 UST = 1美元价值的LUNA进行交换。当UST市价<1美元时，可以用1 UST兑换价值1美元的LUNA（相当于花低于1美元买入1美元等值的LUNA），然后卖出获利；反之UST>1美元时，可用1美元的LUNA铸造1 UST卖出。这种市场套利机制在理想情况下应能稳定UST价格。Terra UST曾被视为算法稳定币的成功典范，但其在2022年5月的崩盘揭示了算法稳定币的系统性脆弱。UST的设计完全依赖市场信心和LUNA市值来支撑。UST崩盘的直接导火索是大额资金撤出和卖压增大，导致UST价格跌破1美元。尽管Terra基金会动用了巨额比特币储备试图维稳，仍无法阻止恐慌。随着UST价格跌破关键阈值，套利者开始大量兑换LUNA，导致LUNA供应量爆炸性增加（因每赎回1 UST就需新发行等值的LUNA），LUNA价格因抛售压力崩盘，进而进一步减弱对UST的支撑，形成死亡螺旋。短短几天内，UST从接近1刀跌至不足0.1刀，LUNA价格几乎归零。UST的失败暴露了算法稳定币的几个致命问题：其一，没有外部资产托底，完全依赖二级市场信心，一旦信心崩溃便无锚可循；其二，激励失衡，如Anchor协议过高的利率吸引了短期套利资本，但当宏观环境变化时这些资本迅速撤离，加剧了危机；其三，缺乏熔断机制，UST/LUNA模型在极端情况下供应和价格互动造成了不可控的循环下跌。除UST外，历史上还有多次算法稳定币失败案例。例如前述NuBits在2016年和2018年两次崩盘，最终价值几乎归零；Iron Finance的IRON稳定币（部分抵押，Mark Cuban参与的项目）在2021年因为算法调节失灵和流动性枯竭导致币值崩盘；Empty Set Dollar (ESD)、Basis Cash等项目也都未能长久保持锚定。这些失败案例往往有共同点：过于理想化地假设市场理性和参与者信心，缺少在极端压力下保护稳定币价值的硬抵押。当然，也有少数算法稳定币在调整策略后存续至今，例如前文提到的FRAX（部分抵押部分算法）和Ampleforth（通过每日弹性调整供应，使代币价格围绕目标震荡而非固定$1）。FRAX通过引入部分USDC抵押，某种程度上降低了纯算法的风险，并在UST事件后进一步提高了抵押比重，保持了对美元的基本锚定。不过，这也说明纯粹的算法模型很难独立运作，需要向混合模式妥协。目前来看，算法稳定币更多是实验性质，尚未证明适合大规模商用。在特定的试验性DeFi协议中，算法稳定币可能被用来测试新的货币理论或自动化做市机制。一些金融创新产品也许会用小规模算法稳定币来作为实验工具。此外，在学术研究和编程游戏的环境下，算法稳定币是展示机制设计和博弈论的一个舞台。然而，对于一般用户或大型应用，算法稳定币并不适合作为主要的价值承载工具。经过UST的教训后，除非有重大理论突破，否则很少有场景会信任一个全新的、纯算法支撑的稳定币来承担重要价值。未来若有算法稳定币取得长时间稳健运行，才有望逐步拓展应用场景。因此当前算法稳定币更多地被视为稳定币领域的高风险实验，其适用范围相对狭窄。3.金融分析：稳定币的市场影响稳定币的兴起对加密货币市场产生了深远的金融影响，其作用主要体现在提供流动性、充当价值中介和稳定锚定等方面：（1）交易流动性的引擎稳定币为加密交易市场注入了大量流动性。在传统观念中，法币进出加密市场需要通过银行通道，过程缓慢且受限。而稳定币作为法币的数字替身，可以在链上或交易所内快速流通。如今，大部分加密交易对都使用稳定币而非直接使用美元等法币。比如在币安、火币等大型交易所，USDT长期作为主要报价和结算货币。据统计，大约90%的加密交易量发生在中心化交易所（CEX），其中绝大多数又是与USDT配对交易**。这意味着USDT等稳定币已经成为交易所的“基础货币”。稳定币让投资者可以24/7全天候进行币币交易，无需银行开市。这极大提高了市场效率**，也降低了不同交易所之间的价差——套利者可以方便地用稳定币搬砖，使全球市场价格更趋统一。此外，稳定币提供了“中间账户”功能：投资者可以在避险时将仓位转换为稳定币，等待机会再行投资，而无需每次都提现回法币账户，从而减少了摩擦成本和时间延迟。（2）DeFi生态的基础资产在去中心化金融中，稳定币扮演着结算单位和储值工具的角色。借贷协议如Aave、Compound主要以稳定币作为借贷资产和计息单位，用户可以存入稳定币获取利息，或借入稳定币用于杠杆交易。去中心化交易所（DEX）中，大量流动性资金池采用稳定币对（如DAI/ETH、USDC/USDT），以减少价差和无常损失，因为两边之一是稳定资产。稳定币还被用于发行合成资产、衍生品保证金、收益聚合等各种创新应用。可以说，没有稳定币，就没有近年蓬勃发展的DeFi。稳定币为这些协议提供了价值尺度（unit of account）和低波动的交易媒介，使复杂的金融操作成为可能。（3）市场稳定锚和避险工具在剧烈波动的加密市场中，稳定币充当了“安全港”的功能。当比特币等加密货币暴跌时，资金往往涌入稳定币避险，从而稳定币市值占比会上升。例如，据CoinGecko报告，稳定币在2022年5月Terra事件后的总体市值占加密市场比重一度超过8%，在市场低迷时其占比反而增高。对于投资者而言，将资产转为稳定币可以暂时规避价格剧烈波动，同时又保持资金随时可以重新投入市场。这一点在24小时不间断交易的加密领域尤为重要。此外，一些交易平台在缺乏法币通道的情况下，会将稳定币视作美元等价物，为用户账户提供计价，降低了使用加密服务的门槛。稳定币还方便了跨市场套利和衍生品交易：比如期货交易所经常以USDT作为保证金计价，这样交易者可以统一用稳定币结算盈亏，而不必频繁换算法币。（4）支付和跨境转账虽然稳定币主要在交易和投资领域发挥作用，但其支付功能也不容忽视。与传统跨境转账相比，通过稳定币汇款可以在几分钟内到账，费用低廉，而且不受银行营业时间限制。这对一些外汇管制严格或汇款成本高昂的地区具有吸引力。例如，一些新兴市场的个人和企业开始使用USDT或USDC进行跨境贸易结算或侨汇。在2022年乌克兰危机期间，稳定币也被用于紧急筹款和转移资产。尽管目前稳定币支付还不是主流，但其潜力已经显现，特别是在无银行服务（unbanked）或高通胀国家，稳定币提供了获取美元价值的便捷渠道，为金融包容性做出了一定贡献。当然，稳定币并不总是优点。稳定币高度融入交易系统也意味着单一稳定币的风险传染效应显著：如果某主流稳定币出现信用问题或技术故障，可能导致交易停滞和市场恐慌。2018年曾发生USDT短暂脱锚引发币价震荡的事件；2023年3月USDC脱锚也导致部分DeFi协议损失和市场波动。好在这些事件都较快平息。但像UST崩盘这样的极端案例则证明，不稳定的稳定币会加剧市场崩盘的深度和范围。4.总结综上，稳定币作为连接加密世界与传统金融的桥梁，其重要性只增不减。在过去的十年里，稳定币从无到有、从边缘尝试到市值数千亿美元，证明了市场对稳定价值数字资产的巨大需求。展望未来，稳定币的生态将更加成熟规范。一方面，合规化、透明化将成为主旋律，用户对稳定币的信心有望加强，大规模商业应用变得可行；另一方面，多元化和创新仍会持续，新的稳定机制、新的发行主体可能涌现，为市场注入活力。在央行数字货币和宏观监管的浪潮下，稳定币也将不断自我调整，寻找最佳的定位。可以预期，稳定币的市场份额在加密领域会进一步提高，甚至突破以往的规模天花板，与此同时，它也会越来越深地嵌入我们的日常经济活动，真正发挥数字化货币的变革潜力。不同类型稳定币的优缺点及适用场景总结：（如下表所示）| 稳定币类型               | 代表例子            | 优点                                                         | 缺点                                                         | 适用场景                                   |\n| ------------------------ | ------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------ |\n| 法币抵押型<br>（中心化） | USDT、USDC、BUSD     | - 价值稳定，1:1有足额法币储备背书<br>- 使用门槛低，易于理解，获得广泛接受<br>- 交易流动性强，在交易所和支付领域应用广泛 | - 中心化依赖，需信任发行机构储备充足<br>- 可能受监管和政策影响，被冻结或停止发行的风险<br>- 不够匿名，发行方可配合监管追踪资金 | 加密交易（主要交易对，避险资产）<br>跨境支付和汇款<br>为传统企业提供链上结算手段 |\n| 加密抵押型<br>（去中心化） | DAI、BitUSD、LUSD    | - 去中心化运作，无单一主体控制，抗审查<br>- 抵押品和系统参数透明可查，增强信任<br>- 无需法币支持，可在纯区块链环境下运作 | - 需超额抵押，资金利用效率低<br>- 机制复杂，依赖智能合约和预言机，存在技术风险<br>- 抵押品价值波动大时稳定性面临考验，可能脱锚 | DeFi生态中的借贷、交易（强调去信任）<br>跨国界的数字经济活动<br>为加密资产持有者提供流动性 |\n| 算法稳定型<br>（部分/无抵押） | UST、AMPL、FRAX      | - 不需大量储备资产，理论上扩展性好，资本效率高<br>- 如果机制可靠，可实现真正的去中心化稳定币<br>- 某些模型下具有创新性，可自动调节供需 | - 对市场信心高度依赖，历史上多次崩盘失败<br>- 缺乏最后价值支撑，出现挤兑时易陷入死亡螺旋<br>- 投资者认知不足时风险巨大，监管层高度警惕 | 暂以试验为主，适合小规模创新项目<br>特殊DeFi策略（套利、博弈实验）<br>未来若成熟后，可能用于一般支付储值 |\n| 央行数字货币<br>(CBDC) | 数字人民币<br>数字欧元 | - 国家信用背书，法定货币地位，信用风险最低<br>- 由央行发行，能有效服务货币政策和金融稳定<br>- 可实现普惠金融，推动支付系统现代化 | - 中心化控制，交易隐私和自由度受限<br>- 可能冲击商业银行，引发金融脱媒<br>- 技术实现复杂，推广需改变用户习惯 | 零售和批发支付（国内）<br>政府转移支付、补贴发放<br>跨境结算（央行间合作） |5.ARK观点2024年，稳定币作为数字资产中增长最快的领域之一，其交易额已超过万事达卡和Visa；2024年12月，稳定币交易量创下历史新高（前景好）在2023年经历回撤后，2024年稳定币的供应量和活跃稳定币地址数量均创下历史新高随着一些国家逐渐远离美元，数字资产正朝它靠拢稳定币因Layer 2 的低成本和高效率而吸引零售兴趣点对点交易与个人钱包储存主导稳定币应用场景image.pngTether的财务表现无论在绝对值还是相对值上都令人震惊（意思是这玩意太赚钱了）在「去美元化」对冲下，稳定币正增加对美国政府债务作为抵押品的需求（意思是这玩意对美国也好）稳定币到2030年可能从全球法币M2供应量的0.17%增至0.9%。如果这样，稳定币将成为第13大流通货币，排在西班牙之后，领先于荷兰"
  },
  {
    "title": "当信息流开始遵循我的语法：TG RSS BOT 搭建教程与开源项目推荐",
    "summary": "「滴——」手机在晨光中震动，锁屏界面已被信息洪流冲垮：GitHub trending推送了新的AI工具、订阅的Newsletter准时抵达邮箱、关注的Podcaster突然日更三集……你滑动着永无止境的未读红点，突然意识到自己像被困在API接口里的数据包——被调度、被解析、却从未真正抵达「已处理」状态。在这个信息过载纪元，我们正经历着两种极端的撕裂：一边是算法用精准的「猜你喜欢」编织数据茧房，一边",
    "tags": [],
    "url": "/posts/TechnicalTutorials/tgrss-revival/",
    "date": "2025-02-03T00:00:00.000Z",
    "content": "「滴——」手机在晨光中震动，锁屏界面已被信息洪流冲垮：GitHub trending推送了新的AI工具、订阅的Newsletter准时抵达邮箱、关注的Podcaster突然日更三集……你滑动着永无止境的未读红点，突然意识到自己像被困在API接口里的数据包——被调度、被解析、却从未真正抵达「已处理」状态。在这个信息过载纪元，我们正经历着两种极端的撕裂：一边是算法用精准的「猜你喜欢」编织数据茧房，一边是散落在43个平台的知识碎片让人患上数字仓鼠症。当Ctrl+S已成为肌肉记忆，1999年诞生的RSS协议却像一位沉默的守夜人，握着锈迹斑斑的钥匙，静候我们重启去中心化的信息管道。本篇博客就希望借助 Telegram Bot，实现RSS信源自动推送，稍稍缓解我们的信息依赖症，将重要信息归集起来集中处理。一、项目搭建流程项目地址::github{repo=\"Rongronggg9/RSS-to-Telegram-Bot\"}1.在Telegram中新建Bot并获取相关信息在tg中搜索 @BotFather，聊天框发送 /newbot，按提示输入机器人名称/机器人用户名。image.png记录下生成的HTTP API，后面需要用。在tg中搜索@userinfobot,点击start,记录返回的用户idimage.png获取 Telegraph API 获取 access tokenhttps://api.telegra.ph/createAccount?short_name=RSSBot&author_name=Myself&author_url=https://github.com/Rongronggg9/RSS-to-Telegram-Bot2.搭建bot在 vps 根目录下新建文件夹 mkdir tgrss ，并进入文件夹cd tgrss ，新建docker compose文件 nano docker-compose.yml。在打开的编辑器中，添加 Docker Compose 配置：version: '3.9'\n\nservices:\n  rssbot:\n    image: rongronggg9/rss-to-telegram:dev\n    container_name: rss-bot\n    restart: unless-stopped\n    volumes:\n      - ./config:/app/config\n    environment:\n      - TZ=Asia/Shanghai\n      - TOKEN=  # 使用 @BotFather 返回的 API Token\n      - MANAGER=  # 使用从 @userinfobot 获得的用户id\n      - TELEGRAPH_TOKEN= # 使用请求 telegraph API 返回的 Token最后docker-compose up -d 启动即可。回到tg，向我们刚创建的bot发送/start就可以开始使用了。二、开源项目推荐1.Rsshub::github{repo=\"DIYgod/RSSHub\"}“万物皆可 RSS” 是 RSSHub 的口号，也是它的灵魂。这个由国内开发者维护的开源项目，像一把万能钥匙，能解锁互联网上几乎所有平台的订阅可能——从微博热搜到 B 站 UP 主更新，从 GitHub 仓库动态到豆瓣小组新帖，甚至是淘宝商品降价提醒、机场航班延误播报……只要你能想到的内容，几乎都能通过 RSSHub 转化为标准的 RSS 订阅源。为什么选择 RSSHub？破除平台封锁：许多平台（比如某红书、某音）不提供原生 RSS 支持，RSSHub 通过解析网页或调用 API 强行“投喂”内容；规则丰富灵活：社区贡献了 1000+ 条路由规则（官方文档堪称 RSS 版“百科全书”），且支持自定义规则；部署自由度高：你可以直接使用官方公共实例（需注意频率限制），也可自建服务实现“订阅自由”；无缝对接 Bot：生成的 RSS 链接可直接填入 Telegram Bot，实现“订阅-解析-推送”全链路自动化。2.Follow::github{repo=\"RSSNext/Follow\"}新一代高颜值RSS阅读器（我目前正在用的主力阅读器），但目前尚处测试阶段，性能方面似乎存在一定问题3.FreshRSS::github{repo=\"FreshRSS/FreshRSS\"}自建RSS生态的基石。这款基于PHP/MySQL的阅读器支持Docker一键部署，具有以下核心优势：多协议支持：除常规RSS外，还能解析JSON Feed、YouTube频道等特殊格式智能过滤：通过CSS选择器自定义内容清洗规则，过滤广告/干扰元素浏览器插件：配套的WebSub扩展实现\"一键订阅\"多用户体系：适合团队共享订阅源，支持OPML批量导入导出4.Miniflux::github{repo=\"miniflux/v2\"}极简主义者的福音。采用Go语言编写的轻量级阅读器（内存占用<20MB），特别适合：开发者：提供RESTful API，可与Huginn/Automate等自动化工具联动隐私控：默认关闭图片代理，支持基于规则的文章永久存档键盘党：全快捷键操作（按?唤出快捷键列表）PWA应用：支持离线阅读，安卓/iOS均可添加至主屏幕<BASH>\n\n# 典型Docker部署命令docker run -d --name miniflux -p 8080:8080 \\  -e DATABASE_URL=\"postgres://user:password@host/dbname?sslmode=disable\" \\  miniflux/miniflux:latest\n三、结论RSS技术栈的复兴绝非偶然——在算法推荐肆虐的今天，这套始于1999年的协议仍然是最优雅的信息自主权解决方案。借助RSS，我们既能享受算法带来的效率红利，又能避免陷入\"信息茧房\"的陷阱。建议从RSSHub+Follow的轻量级组合开始，逐步构建自己的数字巴别塔。当你的订阅源开始流淌经过精心筛选的知识时，或许会突然理解《黑客帝国》中墨菲斯那句台词的含义：\"You take the blue pill... the story ends. You take the red pill... you stay in Wonderland.\""
  },
  {
    "title": "用飞书多维文档打造博客书架页—支持 GitHub Actions 自动更新",
    "summary": "前言与总结项目代码还请直接参见我的博客GitHub库的scripts文件夹\n::github{repo=\"Lapis0x0/fuwari\"}情况是这样的：我现在将日常任务管理、OKR编排和个人书库影音库放到了飞书里。得益于飞书强大的自定义能力和开放的 API 接口，我能够根据自身需求构建个性化的信息管理系统。然而，仅仅在飞书内部管理这些数据还不够，我还需要一个对外展示的窗口，尤其是针对我的书库——",
    "tags": [],
    "url": "/posts/TechnicalTutorials/bookshelf-with-feishu/",
    "date": "2025-01-28T00:00:00.000Z",
    "content": "前言与总结项目代码还请直接参见我的博客GitHub库的scripts文件夹\n::github{repo=\"Lapis0x0/fuwari\"}情况是这样的：我现在将日常任务管理、OKR编排和个人书库影音库放到了飞书里。得益于飞书强大的自定义能力和开放的 API 接口，我能够根据自身需求构建个性化的信息管理系统。然而，仅仅在飞书内部管理这些数据还不够，我还需要一个对外展示的窗口，尤其是针对我的书库——一个精美的、可自动更新的博客书架页。在当前的技术栈中，Astro作为静态站点生成器（SSG）提供了很棒的博客框架与组件化能力。但传统静态博客的痛点在于：每当飞书书库新增条目时，需要手动导出数据、更新Front Matter、重新部署站点。这种机械的重复劳动显然违背了自动化管理的初衷。为了解决这个问题，我设计了一个自动化工作流：通过Github Action自动从飞书多维表格中同步数据，并触发博客的自动构建与部署，整个流程节点如下：数据源管理 在飞书多维表格（Bitable）中，我创建了一个结构化的书库表格，记录每本书的基本信息、阅读状态、笔记等。这种方式不仅便于日常管理，还能通过飞书移动端随时记录读书心得。数据同步与处理 我编写了一个 Python 脚本来处理数据同步，主要功能包括：通过飞书开放平台的 API 获取书库数据智能处理书籍封面图片：自动压缩和转换为 WebP 格式优化图片尺寸（最大 800×1200）控制文件大小（不超过 300KB）保持透明通道（如果原图有的话）将处理后的数据转换为博客可用的 JSON 格式自动化部署 利用 GitHub Actions 的定时任务功能，系统会：定期执行数据同步脚本使用处理后的数据更新博客内容自动触发站点重新构建和部署通过这种方式，我实现了一个真正的“阅读优先”的工作流，只需要在飞书中维护书库数据，博客页面就会自动保持同步。二、脚本代码解析1.环境配置与图片资源优化脚本通过环境变量管理敏感配置信息：APP_ID = os.getenv('FEISHU_APP_ID')\nAPP_SECRET = os.getenv('FEISHU_APP_SECRET')\nBITABLE_ID = os.getenv('FEISHU_BITABLE_ID')\nTABLE_ID = os.getenv('FEISHU_TABLE_ID')确保安全性，同时也方便在不同环境（本地开发/GitHub Action）间切换。环境变量介绍：FEISHU_APP_ID飞书应用的唯一标识符在创建飞书应用后可以在应用凭证页面获取用于识别是哪个应用在访问飞书 APIFEISHU_APP_SECRET飞书应用的密钥与 APP_ID 配对使用，用于生成访问令牌（access token）需要妥善保管，不能泄露FEISHU_BITABLE_ID多维表格的唯一标识符可以从多维表格的 URL 中获取用于指定要操作的具体多维表格FEISHU_TABLE_ID多维表格中具体数据表的唯一标识符一个多维表格可以包含多个数据表，这个 ID 用于指定具体要操作哪个数据表可以从数据表的 URL 或者 API 获取为了确保博客页面的加载性能，实现了智能的图片处理机制：# 图片压缩配置\nMAX_SIZE = (800, 1200)  # 最大尺寸\nWEBP_QUALITY = 85      # 初始质量\nMAX_FILE_SIZE = 300 * 1024  # 目标大小上限自动转换为现代的 WebP 格式智能压缩算法：从85%质量开始，逐步降低直至满足大小要求保留透明通道：自动检测和保持图片的透明度渐进式压缩：在保证视觉质量的同时实现最优压缩比2.数据同步同步过程分为以下几个：（1）认证def get_tenant_access_token():\n    \"\"\"获取飞书应用的 tenant_access_token\"\"\"\n    url = \"https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal\"\n    headers = {\n        \"Content-Type\": \"application/json\"\n    }\n    data = {\n        \"app_id\": APP_ID,\n        \"app_secret\": APP_SECRET\n    }通过飞书开放平台的 OAuth2 流程获取访问令牌，确保安全访问。（2）获取多维表格中的记录def get_bitable_records():\n    \"\"\"获取多维表格中的记录\"\"\"\n    token = get_tenant_access_token()\n    if not token:\n        print(\"Failed to get access token\")\n        return None\n    \n    url = f\"https://open.feishu.cn/open-apis/bitable/v1/apps/{BITABLE_ID}/tables/{TABLE_ID}/records\"\n    headers = {\n        \"Authorization\": f\"Bearer {token}\",\n        \"Content-Type\": \"application/json\"\n    }\n    \n    response = requests.get(url, headers=headers)\n    return response.json()获取飞书多维表格中的表格记录def download_image(url, token, save_dir):\n    \"\"\"下载图片并返回本地路径\"\"\"\n    try:\n        # 生成文件名（使用URL的哈希值）\n        url_hash = hashlib.md5(url.encode()).hexdigest()\n        filename = f\"{url_hash}.webp\"  # 使用webp格式\n        local_path = os.path.join(save_dir, filename)\n        \n        # 如果文件已存在，直接返回路径\n        if os.path.exists(local_path):\n            print(f\"Image already exists: {filename}\")\n            return os.path.join('/images/books', filename)\n        \n        # 下载图片\n        headers = {\"Authorization\": f\"Bearer {token}\"}\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        \n        # 压缩图片\n        compressed_data = compress_image(response.content)\n        \n        # 保存压缩后的图片\n        with open(local_path, 'wb') as f:\n            f.write(compressed_data)\n        \n        original_size = len(response.content) / 1024  # KB\n        compressed_size = len(compressed_data) / 1024  # KB\n        compression_ratio = (1 - compressed_size / original_size) * 100 if original_size > 0 else 0\n        print(f\"Downloaded: {filename} (Original: {original_size:.1f}KB, Compressed: {compressed_size:.1f}KB, Saved: {compression_ratio:.1f}%)\")\n        \n        return os.path.join('/images/books', filename)\n    except Exception as e:\n        print(f\"Error downloading image {url}: {str(e)}\")\n        return Nonedef process_records(records, token):\n    \"\"\"处理记录，下载图片并更新图片路径\"\"\"\n    if not records or 'data' not in records or 'items' not in records['data']:\n        return records\n    \n    # 确保图片目录存在\n    save_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'public', 'images', 'books')\n    os.makedirs(save_dir, exist_ok=True)\n    \n    # 处理每条记录\n    for item in records['data']['items']:\n        if '封面' in item['fields'] and item['fields']['封面']:\n            covers = item['fields']['封面']\n            new_covers = []\n            for cover in covers:\n                if 'url' in cover:\n                    # 下载图片并获取本地路径\n                    local_path = download_image(cover['url'], token, save_dir)\n                    if local_path:\n                        new_cover = cover.copy()\n                        new_cover['local_path'] = local_path\n                        new_covers.append(new_cover)\n            if new_covers:\n                item['fields']['封面'] = new_covers\n    \n    return records\n\ndef save_to_json(data):\n    \"\"\"将数据保存为 JSON 文件\"\"\"\n    output_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'public', 'data', 'books.json')\n    \n    # 添加更新时间\n    data['last_updated'] = datetime.now().isoformat()\n    \n    with open(output_path, 'w', encoding='utf-8') as f:\n        json.dump(data, f, ensure_ascii=False, indent=2)\n    \n    print(f\"Data saved to {output_path}\")提取书籍信息下载并优化封面图片生成适用于静态站点的本地路径将处理后的数据序列化为 JSON 格式添加时间戳，便于追踪更新状态保存到博客的 public/data 目录（3）文件组织处理后的资源按照类型分类存储：图片资源：public/images/books/数据文件：public/data/books.json这种组织方式与 Astro 的静态资源处理完美契合，确保了资源的正确引用和加载。2.静态博客书架页样式设计---\nimport MainGridLayout from '../layouts/MainGridLayout.astro';\nimport { i18n } from '../i18n/translation';\nimport I18nKey from '../i18n/i18nKey';\n\n// Read and parse the books data\nconst response = await fetch(new URL('/data/books.json', Astro.url));\nconst booksData = await response.json();\n// Filter books with reading progress \"1\"\nconst books = booksData.data.items.filter(book => book.fields['阅读进度'] === \"1\");\n\n// Group books by category (领域)\nconst booksByCategory = books.reduce((acc, book) => {\n  const category = book.fields['领域'] || '未分类';\n  if (!acc[category]) {\n    acc[category] = [];\n  }\n  acc[category].push(book);\n  return acc;\n}, {});\n\n// Function to get cover URL\nfunction getCoverUrl(book) {\n  if (book.fields['封面']?.[0]) {\n    // 使用本地路径\n    return book.fields['封面'][0].local_path;\n  }\n  return null;\n}\n---\n\n<MainGridLayout title={i18n(I18nKey.bookshelf)} description={i18n(I18nKey.bookshelf)}>\n  <style>\n    .custom-scrollbar::-webkit-scrollbar {\n      width: 4px;\n    }\n    .custom-scrollbar::-webkit-scrollbar-track {\n      background: transparent;\n    }\n    .custom-scrollbar::-webkit-scrollbar-thumb {\n      background-color: rgba(255, 255, 255, 0.3);\n      border-radius: 2px;\n    }\n    .custom-scrollbar::-webkit-scrollbar-thumb:hover {\n      background-color: rgba(255, 255, 255, 0.5);\n    }\n  </style>\n  <div class=\"flex w-full rounded-[var(--radius-large)] overflow-hidden relative\">\n    <div class=\"card-base z-10 px-6 py-6 relative w-full\">\n      {Object.entries(booksByCategory).map(([category, books]) => (\n        <div class=\"mb-12\">\n          <h2 class=\"text-2xl font-bold mb-6 pb-2 border-b border-zinc-200 dark:border-zinc-800 text-[var(--primary)]\">\n            {category}\n          </h2>\n          <div class=\"grid grid-cols-2 sm:grid-cols-3 lg:grid-cols-4 xl:grid-cols-5 gap-6\">\n            {books.map((book) => (\n              <div class=\"group relative flex flex-col\">\n                <div class=\"aspect-[3/4] overflow-hidden rounded-lg bg-zinc-100 dark:bg-zinc-900 shadow-md transition-all duration-300 group-hover:shadow-xl\">\n                  {getCoverUrl(book) ? (\n                    <img \n                      src={getCoverUrl(book)}\n                      alt={book.fields['书名']} \n                      class=\"h-full w-full object-cover transition-transform duration-300 group-hover:scale-105\"\n                    />\n                  ) : (\n                    <div class=\"flex h-full w-full items-center justify-center bg-zinc-100 dark:bg-zinc-900 p-4\">\n                      <span class=\"text-center text-sm text-[var(--text-2)]\">{book.fields['书名']}</span>\n                    </div>\n                  )}\n                  <div class=\"absolute inset-0 bg-gradient-to-t from-black/60 to-transparent opacity-0 transition-opacity duration-300 group-hover:opacity-100\">\n                    <div class=\"absolute bottom-0 left-0 right-0 p-4\">\n                      <h3 class=\"text-sm font-bold text-white mb-1 line-clamp-2\">\n                        {book.fields['书名']}\n                      </h3>\n                      {book.fields['作者']?.length > 0 && (\n                        <p class=\"text-xs text-zinc-200 mb-2\">\n                          {book.fields['作者'].join(', ')}\n                        </p>\n                      )}\n                    </div>\n                  </div>\n                </div>\n                <div class=\"overlay absolute inset-0 bg-black/80 opacity-0 transition-opacity duration-300 rounded-lg invisible group-hover:visible group-hover:opacity-100 flex items-center justify-center overflow-hidden\">\n                  <div class=\"p-4 text-white h-full overflow-y-auto custom-scrollbar\">\n                    <h3 class=\"text-sm font-bold mb-2 sticky top-0 bg-black/80 py-2\">{book.fields['书名']}</h3>\n                    {book.fields['书评'] ? (\n                      <>\n                        <p class=\"text-sm text-zinc-100 mb-3\">{book.fields['书评']}</p>\n                        {book.fields['书籍简介'] && (\n                          <div class=\"pt-3 border-t border-white/20\">\n                            <p class=\"text-xs text-zinc-400\">\n                              {book.fields['书籍简介']}\n                            </p>\n                          </div>\n                        )}\n                      </>\n                    ) : (\n                      <p class=\"text-xs text-zinc-300\">{book.fields['书籍简介']}</p>\n                    )}\n                  </div>\n                </div>\n              </div>\n            ))}\n          </div>\n        </div>\n      ))}\n    </div>\n  </div>\n\n  <!-- giscus评论 -->\n  <div style=\"margin-top: 20px;\"></div>\n  <script src=\"https://giscus.app/client.js\"\n          data-repo=\"Lapis0x0/blog-discussion\"\n          data-repo-id=\"R_kgDONda6_g\"\n          data-category=\"Announcements\"\n          data-category-id=\"DIC_kwDONda6_s4ClN0D\"\n          data-mapping=\"pathname\"\n          data-strict=\"0\"\n          data-reactions-enabled=\"1\"\n          data-emit-metadata=\"0\"\n          data-input-position=\"bottom\"\n          data-theme=\"preferred_color_scheme\"\n          data-lang=\"zh-CN\"\n          crossorigin=\"anonymous\"\n          async>\n  </script>\n</MainGridLayout>\n\n<style>\n  .line-clamp-2 {\n    display: -webkit-box;\n    -webkit-line-clamp: 2;\n    -webkit-box-orient: vertical;\n    overflow: hidden;\n  }\n\n  .line-clamp-3 {\n    display: -webkit-box;\n    -webkit-line-clamp: 3;\n    -webkit-box-orient: vertical;\n    overflow: hidden;\n  }\n\n  .line-clamp-6 {\n    display: -webkit-box;\n    -webkit-line-clamp: 6;\n    -webkit-box-orient: vertical;\n    overflow: hidden;\n  }\n</style>\n3.Github Action工作流设定为每周日从飞书那里拉取一次数据，更新书架页信息。name: Update Books Data\n\non:\n  schedule:\n    - cron: '0 0 * * 0'  # 每周日 UTC 00:00 运行\n  workflow_dispatch:  # 允许手动触发\n\njobs:\n  update-books:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write  # 明确设置写入权限\n    \n    steps:\n    - uses: actions/checkout@v3\n      with:\n        token: ${{ secrets.GITHUB_TOKEN }}\n    \n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.10'\n        cache: 'pip'  # 启用pip缓存\n    \n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install pillow requests  # 直接指定必要的依赖\n    \n    - name: Update books data\n      env:\n        FEISHU_APP_ID: ${{ secrets.FEISHU_APP_ID }}\n        FEISHU_APP_SECRET: ${{ secrets.FEISHU_APP_SECRET }}\n        FEISHU_BITABLE_ID: ${{ secrets.FEISHU_BITABLE_ID }}\n        FEISHU_TABLE_ID: ${{ secrets.FEISHU_TABLE_ID }}\n      run: |\n        python scripts/test_feishu_bitable.py\n        \n    - name: Commit and push if changed\n      run: |\n        git config --local user.email \"github-actions[bot]@users.noreply.github.com\"\n        git config --local user.name \"github-actions[bot]\"\n        git add public/data/books.json public/images/books/*\n        git diff --quiet && git diff --staged --quiet || (git commit -m \"Update books data [skip ci]\" && git push)\n三、实际效果请访问 此链接 来体验"
  },
  {
    "title": "2025年1月投资月报：耐心、预期管理与认知局限",
    "summary": "本月实现收益率为32%，本文主要提炼在投资过程中形成的认知，探讨如何在波动市场中建立可持续的投资框架。1.耐心：对抗市场噪声的终极武器加密货币市场7x24小时不间断交易，价格波动剧烈，信息爆炸，投资者极易受到市场情绪的影响，产生FOMO和FUD情绪，做出非理性的投资决策。耐心，是抵御市场噪声、避免情绪化交易的终极武器。首先就是等待合适的时机，不轻易出手。频繁交易只会将投资收益浪费在每次交易的费率上",
    "tags": [
      "投资月报"
    ],
    "url": "/posts/ScheduledReport/Trading-Monthly-Report-01/",
    "date": "2025-01-28T00:00:00.000Z",
    "content": "本月实现收益率为32%，本文主要提炼在投资过程中形成的认知，探讨如何在波动市场中建立可持续的投资框架。1.耐心：对抗市场噪声的终极武器加密货币市场7x24小时不间断交易，价格波动剧烈，信息爆炸，投资者极易受到市场情绪的影响，产生FOMO和FUD情绪，做出非理性的投资决策。耐心，是抵御市场噪声、避免情绪化交易的终极武器。首先就是等待合适的时机，不轻易出手。频繁交易只会将投资收益浪费在每次交易的费率上，应当耐心等待市场出现明显的机会，例如价格大幅回调至合理估值区间，或者项目出现重大积极进展时，才会考虑加仓或建仓。深入研究，独立思考。应当将更多的时间用于深入研究项目白皮书、团队背景、技术架构、代币经济模型、社区活跃度等关键信息，形成自己独立的判断，而不是盲目跟随市场热点或KOL的意见。这需要极大的耐心，因为深入研究是一个耗时费力的过程，但只有这样才能真正理解投资标的的价值，坚定持有的信心。适当坚持长期主义。虽然我这个月做的都是短线交易，每次交易基本上收益也都在15%左右，但一直押注短期市场情绪必然会在某一天迎来重大回撤全盘皆输。未来应当将一半以上的资产置于更长的时间维度考量上，只要投资标的的基本面良好，长期持有优质资产，时间会熨平短期波动带来的风险，带来更为可观的回报和更低的交易风险。2.预期管理：用安全垫构建投资护城河加密货币市场充满不确定性，即使是再深入的研究也无法完全预测未来的走势。因此，合理的预期管理至关重要，它能帮助我们构建投资的安全垫，抵御市场风险，提高投资的容错率。在每一阶段的投资开始前，应当设定合理的收益预期，千万千万不能追求一夜暴富。应当避免过度冒险以致成为实质上的赌博，努力降低投资组合的波动性。分散投资，降低单一资产风险。 应将资金分散投资于多个不同类型的加密货币资产，例如公链、DeFi、NFT等，并根据市场情况动态调整资产配置比例。这可以有效降低单一资产价格波动对整体投资组合的影响。预留安全边际，应对极端情况。 在评估投资标的的价值时，应预留一定的安全边际，例如在估值的基础上打个8折或7折。这样即使市场出现极端情况，也能保证投资组合的安全。虚拟货币投资的残酷性在于，单次高收益可能源自运气，而长期盈利必须依赖风险报酬比的精密控制。可在未来投资中构建\"动态安全垫\"机制，当浮动收益达到15%时立即将本金部分转出，仅用利润参与后续博弈；当收益突破25%后启动\"阶梯止盈\"，每上涨3%自动锁定三分之一仓位。这种设计让心理账户始终处于\"已盈利\"状态，有效规避了\"盈利回吐焦虑症\"导致的非理性持仓。3. 从\"求胜\"到\"不败\"：投资哲学的范式转换最初开始投资时每个人都会想着“求胜”，追求高收益，渴望战胜市场。但在加密货币市场，\"不败\"比\"求胜\"更重要。 这是一种投资哲学的范式转换，它意味着将风险管理置于收益之上，追求长期稳定的回报，而不是短期的高收益。承认自己的无知，敬畏市场。 加密货币市场是一个复杂且不断进化的系统，没有人能够完全预测未来的走势。应深刻认识到自己的认知局限性，对市场保持敬畏之心，不盲目自信，不固执己见。控制仓位，避免爆仓风险。 应严格控制仓位，避免使用高杠杆，将爆仓风险降到最低。这是\"不败\"投资哲学的核心原则之一，只有保住本金，才能在市场中长期生存下去。持续学习，不断进化。 加密货币行业发展日新月异，新的项目、技术和模式层出不穷。应将持续学习，不断更新自己的知识体系，提高认知水平，以适应市场的变化。保持良好的心态，享受投资的过程。 投资是一场马拉松，而不是短跑。应努力保持良好的心态，不以一时的得失而喜悲，享受投资的过程，享受与市场共同成长的过程。传统投资教育强调\"抓住机会\"，而加密市场的生存法则更注重\"避免致命错误\"。承认自身认知局限，在混沌市场中构筑以生存为底线的防御体系，反而能捕捉到真正的阿尔法机会。2月策略展望当前加密市场处于\"政策预期博弈期\"与\"叙事真空期\"的叠加态：美联储降息路径摇摆导致风险资产估值重构，比特币ETF资金流入放缓引发市场流动性担忧，以太坊坎昆升级落地形成技术面利好兑现。在此背景下，期望采用\"防守反击\"策略——将整体仓位控制在60%-70%，预留30%以上USDT/Tether应对极端波动，重点捕捉结构性机会。在二月可能出现的\"政策真空期震荡行情\"中，投资者需重点锤炼三项能力：噪音过滤能力：当市场同时出现\"ETF资金枯竭论\"和\"减半前最后一次抄底机会\"等矛盾叙事时，坚持查看链上巨鲸地址持仓变化（Glassnode预警系统）痛苦承受阈值：预设账户20%回撤的心理防线，通过历史回测数据验证策略有效性而非情绪驱动机会成本认知：接受\"错过暴涨\"本就是稳健投资的必要代价，用凯利公式计算每笔交易的期望值（EV>1.5才值得出手）总结资本质上是一场与自我认知缺陷对抗的修行。本月的实践再次证明：在非有效市场，手动投资可通过“规则约束+认知优势”创造超额收益，但其核心并非预测市场，而是管理好自身的贪婪、恐惧与脆弱性。正如格雷厄姆所言：“投资者最大的敌人不是市场，而是自己。”新征程刚刚开始，愿与诸位同行者共勉。2025年的市场将奖励那些用规则驯服欲望，用概率思维替代胜负执念的投资者。投资不需要璀璨的烟火，而是确保永远留在赛场。"
  },
  {
    "title": "零一万物之死",
    "summary": "我在2024年10月19日的博客中曾经很明确地预判过：:::note\n我作为金融壬持续看空零一万物这家公司，无论是它的商业逻辑还是运营能力，在我看来都难以支撑其「独角兽」的市场地位。\n:::\n这一观点在当时（李开复刚买了大量通稿吹零一万物和新模型并强调不会放弃预训练）可能显得有些激进，但2025年1月初的新闻最终还是印证了我预判的含金量：image.png嘴硬没有任何意义，零一万物从未找到清晰的产",
    "tags": [],
    "url": "/posts/AI and Deep Learning/the-downfall-of-01AI/",
    "date": "2025-01-25T00:00:00.000Z",
    "content": "我在2024年10月19日的博客中曾经很明确地预判过：:::note\n我作为金融壬持续看空零一万物这家公司，无论是它的商业逻辑还是运营能力，在我看来都难以支撑其「独角兽」的市场地位。\n:::\n这一观点在当时（李开复刚买了大量通稿吹零一万物和新模型并强调不会放弃预训练）可能显得有些激进，但2025年1月初的新闻最终还是印证了我预判的含金量：image.png嘴硬没有任何意义，零一万物从未找到清晰的产品定位，也始终无法证明自己在商业链条上的不可替代性。24年10月份写下那篇博客时，我的预判还只是「对零一万物未来的发展持谨慎态度，并倾向于看空其长期表现」，现在来看人家的资金链比我想象的还要紧张，谁又能想到这个曾经巨头加盟声势浩大的公司成为第一个在大模型时代出局的独角兽了呢？当2025年的年初清冷地敲响钟声，这场闹剧式的收场显得荒诞但并不意外——零一万物的商业野心最终以预训练研发团队打包出售给阿里的形式画上了终止符，而公司CEO李开复博士的“白菜价模式”“SOTA领先模型”等豪言壮语，也最终随着他在媒体面前的解释显得苍白无力。在资本与技术竞赛的狂飙中，我认为零一万物失败的原因并不复杂——它并不是被技术打败了，能训练出Yi-Lighting这种规模和性能的模型代表零一万物并不是一无是处，它是被自身缺乏清晰战略的营运模式给拖垮的。从一个打着「零一智能，万物赋能」标签的明星独角兽到黯然出局，零一的没落就像一面镜子，硬照出了大模型创业浪潮的光与影。今天，我们不妨从几个视角再来回顾下零一万物从崛起到溃败的过程，在大模型赛道从狂欢到冷静再到理性的起伏中进行再反思。一、零一发展历程梳理起高楼——豪华的创业团队2023年3月下旬，创新工场董事长兼CEO李开复正式宣布以Project AI 2.0之名入局大模型，从3月开始在三个月内拉起了数十名核心成员的团队，成员集中在大模型技术、人工智能算法、自然语言处理、系统架构、算力架构、数据安全、产品研发等领域。技术副总裁及AI Alignment负责人是 Google Bard/Assistant 早期核心成员，主导或参与了从 Bert、LaMDA 到大模型在多轮对话、个人助理、AI Agent 等多个方向的研究和工程落地；首席架构师曾在Google Brain与Jeff Dean、Samy Bengio等合作，为TensorFlow的核心创始成员之一。而算法和模型团队成员中，有论文曾被GPT-4引用的算法大拿，有获得过微软内部研究大奖的优秀研究员，曾获得过阿里CEO特别奖的超级工程师。总计在ICLR、NeurIPS、CVPR、ICCV等知名学术会议上发表过大模型相关学术论文100余篇。作为主力战将之一，零一万物技术副总裁及 Pretrain 负责人黄文灏、技术副总裁及AI Infra负责人戴宗宏今天也正式亮相，并对最新产品进行介绍。此前，黄文灏曾先后任职于微软亚洲研究院和智源研究院；戴宗宏则是前华为云 AI CTO 及技术创新部长、前阿里达摩院 AI Infra 总监。其中已加入的联创团队成员包含前阿里巴巴副总裁、前百度副总裁、前滴滴/百度首席算法负责人、前谷歌中国高管、前微软/SAP/Cisco/副总裁，算法和产品团队背景均来自国内外大厂。三个月内零一团队已经实现百亿参数规模的模型内测，正往300到700亿参数规模扩大。宴宾客——发展历程梳理2023年11月6日：零一万物正式发布首款开源中英双语大模型「Yi」。同期，零一万物完成新一轮融资，由阿里云领头，估值超10亿刀。2024年3月14日：零一万物发布Yi大模型API开放平台，为开发者提供多种模型服务。2024年5月7日：零一万物推出一站式AI工作平台“万知”，支持会议纪要、周报、写作助手等功能。2024年5月13日：零一万物发布千亿参数闭源大模型Yi-Large。2024年6月：零一万物的Yi-Large等系列大模型正式登陆阿里云百炼平台。2024年8月：零一万物完成下一轮融资，金额达数亿刀，此轮融资参与方包括某国际战投、东南亚财团等多家机构。2024年10月16日：零一万物发布新旗舰模型Yi-Lightning，并公布ToB战略下的AI 2.0数字人产品。楼塌了2024年10月：零一万物被传放弃预训练，李开复辟谣称将继续专注于预训练模型。2025年1月2日：零一万物与阿里云达成战略合作，成立“产业大模型联合实验室”，聚焦技术、业务、人才等板块的深度共建。2025年1月6日：市场传言零一万物将预训练团队出售给阿里云，李开复辟谣称该消息不实。结果还是卖了二、为什么楼会塌？（一）战略迷失：在开源与闭源之间反复横跳的“精神分裂”零一万物自诞生之初就展现出明显的战略摇摆。在2023年11月高调发布其开源模型Yi时，李开复曾宣称“开源是AI民主化的必由之路”，但短短几个月后推出的闭源Yi-Large却转而强调\"核心技术必须掌握在自己手中\"。2024年5月重申不打价格战，「价格战烧不出 AI 超级应用，好模型有贵的道理」，四个月后新发布的Yi-Lightning价格又迅速降到1元/M的量级。这种180度的转向背后，暴露出团队对商业模式认知的混乱。更致命的是，当阿里云在2024年6月将其模型接入通义百炼平台时，零一万物实际上已经沦为云厂商的算法供应商。此时李博士再转头布局\"万知\"企业服务平台，试图直接触达终端客户，本质上形成了与合作伙伴的竞争关系。这种既要当运动员（做产品）又想当裁判员（做基建）的定位，最终导致其既失去了阿里云的深度支持，又未能建立起独立的产品生态。数据最能说明问题：截至2024年Q3，Yi系列API调用量始终徘徊在GPT-4调用量的3%左右，而其引以为傲的\"万知\"平台企业用户数未突破5000家，客单价更是不足竞品DeepSeek的1/3。这种两头不靠岸的尴尬处境，像极了当年在社交与工具之间摇摆的子弹短信。（二）产品空心化：技术至上主义的致命陷阱翻阅零一万物官网的产品矩阵，我们会发现一个有趣的现象：从Yi-Large到Yi-Lightning，所有版本迭代都在强调\"参数规模提升50%\"\"MMLU评分超越GPT-4\"，却始终回避回答最核心的问题——这些技术突破如何转化为商业价值？这种\"为SOTA而SOTA\"的研发导向，在2024年10月发布的数字人产品上达到顶峰。当团队还在炫耀数字人的微表情延迟降低了0.3秒时，市场早已被硅基智能、风平智能等玩家的\"千元级数字人解决方案\"占领。据某券商调研，零一万物单个数智人客户的获客成本高达8.7万元，而行业均值仅1.2万元。更值得玩味的是其产品落地场景的选择：既有面向开发者的模型API，又有针对企业的\"万知\"办公套件，还布局了数智人赛道。这种撒胡椒面式的扩张，恰恰暴露了其缺乏核心场景深耕能力的短板。在大模型领域，尤其像零一万物这种独角兽，做十款60分产品不如做一款90分产品。产品矩阵过多过广会极大的分散团队的注意力和共识，内斗会极大的拖缓整体公司决策的步伐。（三）资本豪赌：算力军备竞赛下的现金流危机零一万物的融资轨迹揭示了一个危险的信号：从2023年到2024年，其估值从70亿飙升至200亿人民币，但经营性现金流始终为负。作为前大模型独角兽，零一万物为了保证自家大模型不掉队，绝大多数融资一定会投入到预训练算力的采购中。这种\"融资-买卡-刷榜-再融资\"的击鼓传花游戏，在2024年遭遇致命打击。随着美国新一轮芯片禁令出台，直接导致其千卡集群建设计划搁浅。而此时距离其宣称\"启动下一代万亿参数Yi-XLarge MoE模型训练\"的豪言，才过去不到三个月。零一万物引以为傲的\"白菜价\"战略中，为抢占市场份额，其API定价仅为GPT-4的1/5，但根据内部测算，每处理100万tokens的实际成本却远大于收费价格。这种饮鸩止渴的定价策略，本质上是用投资人的钱补贴客户，最终在资本寒冬来临时轰然崩塌。如今，李开复不得不承认，“当前只有大厂能够‘烧’超大模型。”虽然否认了打包出售，但他在接受媒体采访时表示，愿意继续训练超大参数模型的成员，加入了零一万物和阿里云成立的“产业大模型联合实验室”。（四）组织熵增：豪华团队的布朗运动当我们审视这个集结了谷歌大脑、阿里达摩院、华为2012实验室精英的\"全明星团队\"，会发现一个诡异的悖论：成员个体越优秀，组织内耗反而越严重。多位离职员工在匿名社区爆料，光是\"应该先做对话式AI还是先做行业大模型\"的路线之争，就导致三个月内更换了四次技术架构。接下来就是我们非常熟悉的山头内斗了，零一万物内部也存在\"海归派\"与\"本土派\"的隐形割裂。从流出的会议纪要可见，拥有海外背景的高管坚持\"技术驱动论\"，主张持续投入预训练；而来自国内大厂的成员则力推\"场景先行\"，要求砍掉部分研发预算转向垂直领域。这种理念分歧直接导致Yi-Lightning成为了\"四不像\"产品——既想保持通用性又要强调金融场景适配，最终在两项评测中都未能进入前三。三、Deepseek与零一万物——大模型创业启示录:::note\n当然，我还要给零一万物找补一下：深度求索背靠幻方，自家爸爸有钱不用担心投资人压力，零一万物自成立之初就一直有沉重的变现盈利商业化运作压力，资本的考量不可谓不重要。\n:::零一万物的溃败与DeepSeek-R1的崛起，共同勾勒出大模型赛道从资本狂欢到理性回归的清晰脉络。零一万物的故事或许是中国大模型创业最好的启蒙教材——它用近30亿美元的代价告诉我们：在AI 2.0的世界里，没有战略定力的技术狂欢，终将沦为资本游戏中的烟花表演。1. 技术护城河幻觉的破灭：开源生态重构竞争格局DeepSeek-R1的爆发印证了一个残酷现实：单纯依赖参数规模和榜单刷分的时代已终结。其通过全栈开源策略（MIT协议），不仅开放了660B参数的模型权重，还允许用户基于R1进行二次开发与模型蒸馏，甚至将6个蒸馏后的小模型（1.5B-70B）开源。这直接导致了一个现象：原本需要天价算力支撑的顶级推理能力，如今中小开发者仅用开源社区资源即可复现，甚至通过微调在特定场景超越闭源模型。更关键的是，DeepSeek-R1-Zero的实验证明，纯强化学习方法无需依赖监督微调（SFT），仅通过极简奖励规则（准确性+格式约束）即可激发模型涌现推理能力。这种技术民主化彻底击碎了\"闭源即壁垒\"的幻想——当算法框架、训练方法论甚至思维链生成机制都被透明化，技术护城河已从\"独家秘籍\"转变为\"开放协作的起点\"。2. 生态绑定与效率革命的双重碾压当零一万物因战略摇摆陷入\"既要当云厂商的算法供应商，又想直接争夺终端客户\"的困境时，DeepSeek-R1用生态协同+成本屠刀的组合拳重构了竞争规则。一方面，其输入tokens每百万1元的超低定价（仅为OpenAI o1的3%）倒逼企业用户迁移，配合\"思维链API接口\"实现技术价值与产业需求的无缝咬合；另一方面，通过群组相对策略优化（GRPO）将标注数据需求骤降至传统方法的0.5%，结合动态知识蒸馏技术使3B小模型性能超越竞品15%，最终在同等性能下实现训练成本仅为Llama3的1/11。这种战略与技术的双重碾压，本质上是用工程创新支撑商业野心——当零一万物还在烧钱买卡时，DeepSeek已通过算法架构革新，将每单位算力的商业回报提升了27倍。3.破除精英迷信：年轻血液重构创新范式零一万物的陨落与DeepSeek的崛起，揭示了大模型创业中一个被长期忽视的真理：过度迷信海外大牛和明星团队，往往导致战略失焦与组织内耗。当行业还在追捧“谷歌大脑+FAIR+OpenAI”的履历组合时，DeepSeek用一支平均年龄不足28岁的本土团队，完成了对传统精英叙事的颠覆。（1）认知红利DeepSeek的成员构成极具反叛性——85%的核心技术岗位由应届毕业生或毕业两年内的新人担任，甚至包括在读博士生。这种看似冒险的用人策略，实则暗含对大模型技术特性的深刻洞察：技术代际跃迁的红利期：当行业处于范式变革期（如从Transformer到MLA架构），经验反而可能成为思维定势的枷锁。年轻研究者未被既有框架束缚，更敢于挑战“Attention机制不可修改”等行业教条。极致效率导向：年轻团队对算力优化有近乎偏执的追求。清华毕业生赵成钢主导的Fire-Flyer超算架构，通过动态资源调度算法将GPU利用率提升至92%，远超行业平均60%的水平。这种工程能力，恰是零一万物等依赖云厂商的团队难以企及的。（2）本土创新的组织优势与零一万物高调引进海外人才不同，DeepSeek坚持“本土培养+内部造血”模式：文化认同消除沟通损耗：团队成员多来自清北、北邮等国内高校，共享相似的教育背景与研究范式。这种同源性大幅减少了“海归派”与“本土派”常见的理念冲突（如预训练优先还是场景优先的路线之争）。扁平化协作激发创造力：DeepSeek采用OpenAI式的“自然分工”机制——任何小组只要对某个方向感兴趣，即可自由调用算力资源启动项目。这种模式使GRPO强化学习算法从构想到论文发表仅耗时47天，而传统企业同等规模创新平均需6个月。中国大模型创业正在书写新的规则：不再需要复刻硅谷的人才崇拜，也不必困于“海归光环”的焦虑。正如梁文锋所言：“我们不需要世界前50的AI专家，因为我们可以自己培养出第51到100名——而他们终将重新定义排名。”这种自信，或许才是中国AI穿越周期真正的护城河。4. 开源协作与技术透明度成竞争加速器DeepSeek-R1的MIT协议开放策略，不仅赢得开发者社区支持，更倒逼技术透明度成为行业准入门槛。其论文中坦承R1-Zero存在\"语言混杂\"\"可读性差\"等缺陷，并通过冷启动数据迭代改进，这种开放纠错机制反而增强了技术公信力。相比之下，零一万物封闭的技术路线与夸大宣传，最终导致信任崩塌。未来，大模型竞争将演变为开放生态的协同效率之争——谁能更快吸收社区创新、更低成本整合产业链，谁就能在洗牌中存活。正如Nature评论所言：\"DeepSeek的成功证明，资源效率比算力规模更重要\"。结语：理性时代的生存法则当资本泡沫退去，大模型创业已从\"造神运动\"回归商业本质。零一万物和DeepSeek-R1的启示在于：技术必须服务于可量化的商业价值，而价值必须通过生态协作实现指数级放大。零一万物的墓碑上刻着\"战略迷失\"，而DeepSeek的里程碑则写着\"开源即护城河，效率即生命力\"。这场范式转移中，唯有拥抱开放、深耕场景、极致提效的玩家，方能穿越周期，见证AGI的真正曙光。参考[1] 李开复麾下大模型公司零一万物上线，数十位核心成员就位，量子位[2] 刚刚，李开复最快独角兽诞生：零一万物估值超70亿，投资界PEdaily[3] 「零一万物」完成数亿美元融资，某国际战投、东南亚财团加盟，36氪独家[4] 零一万物决定给大厂让路，界面新闻[5] 全网都在扒的DeepSeek团队，是清北应届生撑起一片天，量子位[6] 揭秘DeepSeek:一个更极致的中国技术理想主义故事，暗涌Waves[7] 回望大模型这一年：混搭、扩散、ROI，腾讯研究院[8] DeepSeek's Unconventional Talent Strategy: Why They Hire Fresh Graduates Over Industry Veterans"
  },
  {
    "title": "模型考古学（二）：视觉大模型发展梳理与Qwen2-VL论文解读",
    "summary": "如果说「模型考古学」第一篇主要聚焦于大语言模型（LLM）的内部机制与演进脉络，那么本篇博客将拓宽视野，探求视觉大模型（Vision Large Language Model，VLLM）的技术原理和发展历程。在单纯的文本世界之外，视觉大模型融合了图像理解能力，赋予了AI“看”世界的眼睛，让模型理解世界的方式从一维的文字扩展到了二维的图像。本文将从两个方面展开论述：首先，我将回溯视觉大模型的发展历程，",
    "tags": [
      "模型考古学"
    ],
    "url": "/posts/AI and Deep Learning/deeplearning-research-002/",
    "date": "2025-01-22T00:00:00.000Z",
    "content": "如果说「模型考古学」第一篇主要聚焦于大语言模型（LLM）的内部机制与演进脉络，那么本篇博客将拓宽视野，探求视觉大模型（Vision Large Language Model，VLLM）的技术原理和发展历程。在单纯的文本世界之外，视觉大模型融合了图像理解能力，赋予了AI“看”世界的眼睛，让模型理解世界的方式从一维的文字扩展到了二维的图像。本文将从两个方面展开论述：首先，我将回溯视觉大模型的发展历程，梳理其关键的技术节点和代表性模型，力求勾勒出一幅清晰的技术演进图景；其次，我将解读阿里的旗舰视觉模型Qwen2-VL的技术报告，剖析其架构和创新点。一、视觉大模型基本原理从技术原理上看，视觉大模型的基础架构大多融合了现代深度学习中的两大支柱：卷积神经网络（CNN）和自注意力机制（Transformer）。前者曾是早期视觉任务的主流方案，擅长在局部感受野中提取特征，而后者的引入则显著提升了模型对全局关系的建模能力，使视觉大模型能够以更加通用和灵活的方式处理图像。1.深度学习带来的变革：特征学习以卷积神经网络 (Convolutional Neural Networks, CNNs) 为代表的深度学习模型，能够自动从大量数据中学习到层次化的特征表示，而无需人工设计特征。CNN 的核心组件是卷积层。卷积层通过一组可学习的滤波器（也称为卷积核）对输入图像进行卷积操作，提取出图像的局部特征。通过多个卷积层的堆叠，CNN 可以逐渐提取出从低级到高级的特征表示：低级特征: 例如边缘、角点等。中级特征: 例如纹理、形状等。高级特征: 例如物体部件、物体类别等。除了卷积层，CNN 中还包含池化层和全连接层：池化层: 用于降低特征图的维度，减少计算量，并增强模型的平移不变性。常用的池化操作包括最大池化和平均池化。全连接层: 用于将卷积层和池化层提取的特征进行整合，并输出最终的预测结果。经典 CNN 模型，例如 AlexNet、VGG、GoogLeNet、ResNet 等，在图像分类、目标检测等任务上取得了巨大成功，推动了计算机视觉领域的飞速发展。2.从独立视觉任务到视觉-语言融合VLLM之前的计算机视觉模型大多都只针对特定任务进行训练，例如图像分类、目标检测、语义分割等。这些模型只能处理视觉输入，并输出视觉相关的结果。但我们人类对于世界的理解是多模态的，既包括视觉信息也包括语言信息。为了让 AI 具备更接近人类的智能，研究者们开始探索将视觉和语言融合起来，构建能够同时处理图像和文本的模型。这就是视觉大模型 (VLLM) 的雏形。VLLM 的核心思想是，通过一个统一的模型架构，将图像和文本映射到同一个语义空间，从而实现跨模态的理解和推理。现代视觉大模型普遍采用Vision Transformer（ViT）架构。ViT的核心思想是将图像分割成一系列图像块（patches），然后像处理文本序列一样用Transformer来处理这些图像块序列。具体来说，ViT首先将输入图像切分成固定大小的patch（例如16×16像素），每个patch经过线性投影后转换为一个特征向量。这些特征向量序列再加入位置编码，构成Transformer的输入序列。通过多层self-attention机制，模型能够捕获图像各个部分之间的关系，从而学习到更抽象的视觉特征表示。初代的 VLLM 通常会使用两个独立的编码器分别处理图像和文本，然后通过一个融合模块将两种模态的信息进行整合，最后输入到一个语言模型解码器中生成文本描述或者执行相应的视觉-语言任务。例如早期的 Visual Question Answering (VQA) 模型，以及将图像和文本映射到同一语义空间进行对比学习的 CLIP 等，都采用了这种思路。二、视觉大模型发展历程：从单模态到多模态涌现和其他事物一样，视觉大模型的发展并非一蹴而就，其演进路径可划分为三个阶段：单模态视觉模型主导期、多模态融合探索期，以及多模态通用智能涌现期。这三个阶段既体现了技术范式的跃迁，也揭示了从“被动感知”到“主动交互”的AI能力进化。1.单模态时代：视觉表征学习的奠基（2012-2020）以 AlexNet （2012）为代表的早期CNN模型开启了深度学习在计算机视觉的黄金时代。通过卷积层堆叠与ImageNet大规模监督训练，模型首次展现出通用视觉表征学习能力 。此后，VGGNet （2014）通过更深层网络验证了深度对性能的提升，ResNet （2015）凭借残差连接突破梯度消失瓶颈，EfficientNet （2019）则通过复合缩放法则实现精度与效率的平衡。这些模型虽局限于图像分类任务，但其预训练权重被广泛迁移至目标检测（Faster R-CNN）、分割（Mask R-CNN）等下游任务，形成了“预训练-微调 ”的经典范式。当然，这个时代的单模态模型也存在显著的局限性。首先就是不同的视觉任务需要独立设计网络头，缺乏统一架构，存在任务隔离性。正因为其是单模态模型，我们没办法将视觉特征与语言语义对齐，难以实现跨模态推理。最后，在ai领域有一个经典笑话：「有多少智能就有多少人工」，当时严重依赖人工标注的边界框/掩码数据，模型的泛化能力有限。2.多模态融合萌芽：视觉-语言对齐的探索（2020-2022）Transformer在NLP领域的成功催生了视觉架构的变革。Vision Transformer（ViT） （2020）首次将图像切分为序列化Patch，通过自注意力建模全局关系，打破了CNN的局部归纳偏置限制。与此同时，CLIP （2021）与ALIGN （2021）开创了双塔对比学习范式 ：图像编码器（ViT/CNN）与文本编码器（Transformer）通过海量互联网图文对进行对比学习，使模型无需人工标注即可建立跨模态语义关联。这类模型展现出强大的零样本迁移能力 ——仅通过文本提示（Prompt）即可完成图像分类、检索等任务。这一阶段的突破性在于：模态对齐 ：通过对比损失函数将视觉-语言映射至共享语义空间弱监督学习 ：利用互联网天然图文对减少人工标注依赖提示工程 ：以文本指令控制模型行为，初步展现多模态交互潜力但局限性仍存：双塔架构的模态交互仅发生在特征对齐阶段，缺乏深层次的跨模态信息融合 ，难以完成复杂推理任务（如视觉问答、图像描述生成）。3.多模态涌现：通用视觉-语言交互的崛起（2022至今）随着大语言模型（LLM）在文本理解与生成上的突破，研究者开始探索将视觉能力与LLM深度融合，推动多模态模型从浅层对齐 向深度协同推理 跨越。这一阶段的技术革新不仅体现在架构设计上，更标志着AI从“感知工具”向“通用交互智能体”的范式转变。（1）视觉和语言的初步耦合Flamingo （DeepMind, 2022）：首次提出交叉注意力适配器 （Cross-Attention Adapter）架构，将预训练视觉编码器（如NFNet）与冻结的LLM（Chinchilla）连接。通过插入可训练的交叉注意力层，模型能够将视觉特征动态注入语言模型，支持多图多轮对话 和少样本学习 。Flamingo的上下文学习能力 （如根据少量示例完成VQA任务）证明了多模态涌现的潜力。BLIP-2 （Salesforce, 2023）：设计Q-Former （Querying Transformer）模块，通过一组可学习的查询向量（learnable queries）从视觉编码器中提取与文本相关的特征，再输入LLM生成响应。这一设计显著降低了训练成本（仅需训练Q-Former和部分投影层），使研究者能够灵活组合不同视觉编码器（如ViT、CLIP-ViT）与LLM（如FlanT5、OPT），为开源社区提供了高效的多模态训练范式。（2）闭源巨头入场：GPT-4V与GeminiGPT-4V （OpenAI, 2023）：GPT-4的视觉版本（Vision）标志着闭源多模态模型的巅峰。其技术细节未完全公开，但通过API展示的能力可知：支持任意分辨率图像输入 ，通过空间感知的token化策略保留细节信息实现复杂视觉推理 ，如流程图解析、抽象漫画理解、跨图像时空推理通过RLHF与多模态指令微调 对齐人类意图，避免幻觉输出GPT-4V的推出重新定义了多模态模型的上限，但其黑盒性质也引发了对技术透明性的争议。Gemini （Google, 2023）：作为首个原生多模态模型 ，Gemini从预训练阶段即统一处理图文数据，而非拼接独立编码器。其关键技术包括：MoE（Mixture of Experts）架构 ：动态路由不同模态至专家子网络，提升计算效率多模态思维链 （Multimodal CoT）：通过中间推理步骤解释视觉-语言决策过程3D空间理解 ：支持点云、视频等三维输入，拓展多模态交互场景（3）开源社区：从LLaVA到Qwen-VLLLaVA （威斯康星大学, 2023）：首次在开源社区验证“视觉指令微调 ”的有效性。通过将CLIP视觉编码器与Vicuna语言模型连接，并利用GPT-4生成的视觉-指令数据微调，LLaVA以较小参数量（7B/13B）达到接近商用模型的性能，推动了开源多模态应用的普及。Qwen-VL系列 （阿里云, 2023-2024）：作为中文开源多模态模型的代表，Qwen-VL的技术亮点包括：多粒度视觉表征 ：通过动态分辨率处理与自适应token采样，平衡计算成本与细粒度理解（如OCR、物体属性识别）多图多轮对话 ：支持用户上传多张图像并基于历史上下文进行连贯推理（如对比分析、事件排序）定位-描述协同 ：联合训练目标检测与描述生成任务，实现“指哪说哪”的交互能力尽管Qwen-VL在通用性和综合性能上可能仍逊于当时的4v，但其在中文场景 （如古诗词配图理解、电商产品分析）和垂直任务 （如医学图像报告生成）上的优化，为行业应用提供了高性价比选择。（4）本阶段的技术特征与挑战1.架构统一化：主流方案采用“视觉编码器+语言模型 ”的耦合架构，通过轻量级适配器（Adapter）或中间表示（如Q-Former）实现跨模态特征交互。趋势：逐步从“冻结视觉/语言模块”向“端到端联合优化”演进（如Qwen-VL、Gemini）。2.训练范式革新：两阶段训练 ：先对齐视觉-语言表征（对比学习），再通过指令微调激发推理能力。数据引擎 ：利用LLM生成合成数据（如LLaVA）、构建多模态思维链数据（如CogVLM），突破高质量标注数据瓶颈。3.涌现能力：零样本迁移 ：无需微调即可处理未见任务（如GPT-4V解读手写笔记）。组合推理 ：融合常识与视觉线索解答复杂问题（如“推断图中人物的情绪并解释原因”）。当然，目前视觉模型仍然会存在幻觉问题，生成与图像无关的虚假描述，需通过强化学习与规则约束降低风险。在长尾场景下，如对罕见物体（如特殊医疗器械）或文化特定内容（如传统服饰）的理解仍不稳定。三、Qwen2-VL论文解读Qwen2-VL整体架构上仍然延续了Qwen-VL中ViT加Qwen2的串联架构，在三个不同尺度的模型上都采用600M大小的ViT。不说废话，直接总结Qwen2-VL的创新点：引⼊了 Naive Dynamic Resolution 机制，与上一代模型相比，Qwen2-VL 能够处理任意分辨率的图像输入，不同大小图片被转换为动态数量的 tokens，最小只占 4 个 tokens。这种设计不仅确保了模型输入与图像原始信息之间的高度一致性，更是模拟了人类视觉感知的自然方式，赋予模型处理任意尺寸图像的强大能力，使其在图像处理领域展现出更加灵活和高效的表现。集成多模态旋转位置嵌入（M-RoPE），传统的旋转位置嵌入只能捕捉一维序列的位置信息，而 M-ROPE 通过将原始旋转嵌入分解为代表时间、高度和宽度的三个部分，使得大规模语言模型能够同时捕捉和整合一维文本序列、二维视觉图像以及三维视频的位置信息。这一创新赋予了语言模型强大的多模态处理和推理能力，能够更好地理解和建模复杂的多模态数据。例如对text输入，distinct-IDs退化为1D-RoPE；对image输入，distinct-IDs是由height & width components决定的；对于video输入，distinct-IDs是由height & width + temporal决定的。image.png采用统一的范式处理图像和视频，增强了模型的视觉感知能力1.基础：以Qwen2-VL为例解析一个视觉大模型的结构image.png我们直接以Qwen2-VL技术报告里这张结构图为例，来解析一下一个视觉大模型应该包含哪些部分。（1）、输入处理模块首先就是文本输入处理，模型支持自然语言文本输入，并在多模态情境下与视觉内容进行整合。然后，作为多模态模型，重要功能就是视觉输入处理，Qwen2-VL可以处理各种类型的视觉输入，包括高分辨率图片和视频帧。样例输入包括：图片（Picture 1, 2, 3） ：例如网页截图、自然风景等。其中，输入分辨率可能各不相同，如高度8204像素的网页截图，或者更小分辨率的风景图片。视频（Video 1） ：输入是多帧视频流，包含时间序列信息，例如16秒长的视频序列。（2）、视觉编码器（Vision Encoder）Qwen2-VL的视觉编码器采用改进型Vision Transformer（ViT）架构，参数规模为6.75亿，通过Naive Dynamic Resolution 机制突破传统固定尺寸限制。其核心创新体验在：原生分辨率支持：动态分块策略：输入图像不再强制缩放，而是根据原始分辨率自适应划分图像块（patches）。例如8204像素高度的网页截图会被分割为587个14x14像素块（8204/14≈586），而224x224标准图片则生成256个块（(224/14)^2）。空间信息保留：通过2D旋转位置编码（RoPE-2D）替代传统绝对位置编码，将二维坐标(x,y)映射到复数空间进行旋转操作，使模型能精确感知每个图像块在原始图像中的几何位置。多模态时空建模：视频处理机制：对视频输入每秒采样2帧，通过深度可分离3D卷积提取时空特征。每帧视为独立图像进行分块编码后，额外叠加时间轴RoPE分量，形成三维位置编码（高度、宽度、时间）的联合表征。跨模态对齐：在ViT末层引入可学习的模态标记（<vision_start>, <vision_end>），与文本标记共享嵌入空间，为后续跨模态融合奠定基础。特征压缩与优化：相邻特征聚合：在ViT输出端加入MLP压缩层，将相邻2x2视觉标记（如16x16区域）合并为超标记，既降低序列长度（例如224x224输入从256标记压缩至64），又增强局部语义连贯性。显存优化技术：采用动态序列打包（Dynamic Sequence Packing），将不同分辨率图像的视觉标记拼接为连续张量，通过掩码机制隔离不同样本，实现GPU显存利用率提升37%。之后，视觉编码器的输出通过自适应门控机制注入语言模型。（3）、Token化与跨模态表示视觉 Token处理经过视觉编码器处理后，每张图片或视频被转化为一组 token。分辨率自适应的分块策略：每个图像块（patch）固定为14x14像素，但分块数量由输入分辨率动态决定。例如：网页截图（8204像素高度）⇒ 587个垂直分块（8204/14≈586.71，向上取整）标准224x224图片 ⇒ 16x16网格（共256个分块）时空统一编码：视频帧通过三维位置编码（M-RoPE）实现时空感知：空间维度：每个分块的(x,y)坐标映射为复数空间的旋转相位时间维度：帧序列位置t通过线性递增的旋转角度编码示例：16秒视频（32帧）⇒ 时间轴RoPE角度从0°到31°线性分布示例中，图片和视频的特征被编码为不同数量的 token，例如：Picture 1 转为 11427 个 token。Video 1 转为 2208 个 token。Picture 2 转为较小数量的 token（8个token），表明小图可能具有更少的信息量。统一 Token 表示跨模态位置对齐：通过模态间位置映射函数，将视觉/语言的位置编码统一到同一度量空间：文本位置i → θ_i = i / 10000^(2d/D)\n视觉位置(x,y) → θ_x = x/10000^(2d/D), θ_y = y/10000^(2d/D)动态掩码注意力：在自注意力层引入模态感知掩码，控制跨模态交互强度：# 视觉→文本注意力权重衰减\nif query_modality != key_modality:\n    attention_scores *= 0.7  # 跨模态衰减系数（4）、语言解码器（QwenLM Decoder）QwenLM Decoder 负责将视觉编码器提取的视觉 token 与语言 token 进行深度融合，并最终生成自然语言输出。这种跨模态的融合是通过注意力机制实现的，包括自注意力和交叉注意力，使得模型能够在文字和视觉内容之间建立起紧密的关联。例如，解码器可以理解图片中的场景并用文字进行描述，或者根据视频内容生成文字总结，从而实现对多模态信息的有效整合。作为模型的语言生成组件，QwenLM Decoder 采用典型的自回归式生成方式，即生成的每一个 token 都依赖于已有的 token 和视觉上下文。这种方式确保了生成文本的连贯性和与视觉内容的关联性。（5）、输出模块与标注任务对齐：模型的输出通常是文本，但可以是其他可能的结果，如进一步的特征表示或用于下游任务的结构化信息。典型功能 ：描述生成 ：如对 Picture 1 生成描述 —— “这是来自一个博客的图片”。视频总结 ：为 Video 1 生成文字性总结。问答系统 ：结合输入，回答像 \"What is in Picture 3?\" 这类的多模态问题。为了有效处理多个输入（例如多张图片和多段视频），模型对每个输入模态进行了标识，并在每个模态的 token 数量上进行了明确说明，实现了模态之间的序列标注。通过任务对齐和数据训练，模型学习如何整合视觉与文本信息，并能够动态调整以适应特定任务，如生成描述、进行问答、联想推理等。这种任务自适应的能力，使得模型在实际应用中具有极高的灵活性和实用性。2.M-RoPE粗解（1）、技术背景之前的传统旋转位置嵌入（Rotary Position Embedding, RoPE）通过旋转操作将位置信息动态融入注意力机制，解决了传统位置编码在灵活性、效率和泛化性上的瓶颈。相较于传统位置编码，采用RoPE的模型在同等参数量下实现更优的困惑度（Perplexity）和下游任务准确率，其天然支持动态长度输入，适合处理长文本任务，在PG-19（长篇小说生成）和arXiv论文理解任务中，RoPE模型相比基线（如ALiBi）的生成连贯性提升显著。RoPE技术的数学优雅性、计算高效性以及对长序列的支持，使其成为现代LLM的核心技术之一，并为多模态模型的进一步发展奠定了基础。RoPE主要用于对语言模型中一维序列的位置编码，通过复数域的旋转操作捕捉位置关系。然而，因为图像和视频的视觉信息具有天然的空间或时空结构，例如图像中的像素位置（高度、宽度）和视频的帧序列（时间），RoPE无法有效建模高度、宽度和时间维度上的位置关联，通常将多维位置压缩为一维或静态处理，导致信息丢失。因此，学术界提出M-RoPE，通过以下方式扩展传统RoPE，实现多模态位置信息的动态建模：（2）、实现方式多维位置分解将旋转嵌入分解为独立的时间、高度和宽度分量，分别对应视频的帧序列、图像的垂直和水平位置：文本输入：时间、高度、宽度分量使用相同的位置ID，退化为传统1D-RoPE。图像输入：时间分量固定（单帧），高度和宽度分量根据视觉标记在图像中的实际位置动态分配。视频输入：时间分量随帧数递增，高度和宽度分量与图像处理一致。跨模态位置编码模态间位置隔离：不同模态的位置ID独立分配。例如，若前一个模态的最大位置ID为 $N$，下一模态的起始位置ID为 $N+1$，避免跨模态位置冲突。动态序列打包：在推理阶段，不同分辨率的图像或视频帧被打包为单一序列，通过控制序列长度平衡计算效率与信息保留。数学实现对于输入向量 $ \\mathbf{x} $，M-RoPE通过旋转矩阵 $ \\mathbf{R} $ 注入位置信息：\n$$\n\\mathbf{R}(t, h, w) = \\mathbf{R}_t(t) \\otimes \\mathbf{R}_h(h) \\otimes \\mathbf{R}_w(w)\n$$\n其中：$ \\mathbf{R}_t $ 、$ \\mathbf{R}_h $ 、$ \\mathbf{R}_w $ 分别表示时间、高度和宽度分量的旋转矩阵。$ \\otimes $ 为张量积操作，将各分量的旋转效应组合为多维位置编码。（3）、优势动态分辨率支持M-RoPE允许模型处理任意分辨率的图像，无需固定输入尺寸。视觉标记数量随图像分辨率动态调整，避免下采样或填充导致的信息损失。长序列外推能力通过分离时间与空间分量，M-RoPE在视频任务中显著提升了长度外推能力。实验表明，模型在推理时能处理远超训练时最大长度（16K token）的序列（如80K token），性能保持稳健。跨模态信息融合统一的编码框架无缝整合文本、图像和视频的位置信息，增强模型对动态内容（如视频流）的理解能力。3.其他技术报告摘录与解读这部分主要选取我感兴趣的内容训练过程Qwen2-VL沿袭了Qwen-VL（Bai等人，2023b）的核心训练框架，采用分阶段渐进式训练方法，兼顾视觉-语言对齐与模型泛化能力：视觉语义奠基阶段首阶段聚焦视觉Transformer（ViT）组件的专项训练，通过海量图像-文本对数据，强化大型语言模型（LLM）对视觉特征的语义映射能力。此阶段ViT参数保持可调，而LLM部分冻结，确保视觉模块的基础能力沉淀。全参数协同优化阶段第二阶段全面解冻模型参数，引入更丰富的数据类型（如OCR文本、图文交错文档等），促使视觉与语言模块深度融合。这种「全开放」训练模式有助于模型捕捉跨模态关联规律，提升复杂场景下的多模态推理能力。指令微调精修阶段最终阶段锁定已成熟的ViT参数，专注使用指令数据集对LLM进行针对性微调。这种设计既保留了视觉编码器的稳定性，又通过指令驱动的方式强化了模型的任务响应与逻辑表达能力。4.数据格式与定位能力与 Qwen-VL ⼀致，Qwen2-VL 也采⽤特殊标记来区分视觉和⽂本输⼊。标记 2023)被 RoPE-2D <|vision_start|>和<|vision_end|>取代，分别插⼊图像特征序列的开始和结束位置，以界定图像内容。格式示例：<|im_start|>⽤户 <|vision_start|>Picture1.jpg<|vision_end|><|vision_start|>Picture2.jpg<|vision_end|>这两张图\n⽚有什么共同点？<|im_end|> <|im_start|>助⼿ 这两张图⽚都是海绵宝宝。<|im_end|> <|im_start|>⽤户 视频中\n发⽣了什么？<|vision_start|>video.mp4<|vision_end|><|im_end|> <|im_start|>助⼿ 视频中的主⻆正在煎蛋。\n<|im_end|>视觉定位。为了赋予模型视觉定位能⼒，边界框坐标在[0, 1000)范围内归⼀化，并表示为“(X 左上⻆, Y 左上⻆), (X 右下⻆, Y 右下⻆)”。Tokens <|box_start|> 和 <|box_end|> ⽤于界定边界框⽂本。为了准确地将边界框与其⽂本描述关联起来，Qwen引⼊了tokens <|object_ref_start|> 和 <|object_ref_end|> 来指示边界框引⽤的内容，从⽽使模型能够有效地解释并⽣成特定区域的精确描述。示例：<|vision_start|>Picture1.jpg<|vision_end|> <|object_ref_start|>⻓颈⿅的眼睛<|object_ref_end|><|box_start|>\n(176,106),(232,160) <|box_end|>模型总结我们推出了 Qwen2-VL 系列，这是⼀系列多功能的⼤型视觉语⾔模型，包括总参数量分别为 20 亿、80 亿和 720 亿的三个开源模型。Qwen2-VL 在⼀系列多模态场景中与 GPT-4o 和Claude3.5-Sonnet 等顶级模型性能相当，超越了所有其他开源 LVLM 模型。Qwen2-VL 系列引⼊了朴素动态分辨率和多模态旋转位置嵌⼊（M-RoPE），以有效融合跨模态信息，并能够理解超过 20 分钟的视频。凭借先进的推理和决策能⼒，Qwen2-VL 可以与⼿机、机器⼈等设备集成。此外，Qwen2-VL 现在⽀持理解图像中的多语⾔⽂本，包括⼤多数欧洲语⾔、⽇语、韩语、阿拉伯语、越南语等。参考文献[1] Liu H, Li C, Wu Q, et al. Visual instruction tuning[J]. Advances in neural information processing systems, 2024, 36.[2] Liu H, Li C, Li Y, et al. Improved baselines with visual instruction tuning[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024: 26296-26306.[3] Bordes F, Pang R Y, Ajay A, et al. An introduction to vision-language modeling[J]. arXiv preprint arXiv:2405.17247, 2024.[4] Wang P, Bai S, Tan S, et al. Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution[J]. arXiv preprint arXiv:2409.12191, 2024."
  },
  {
    "title": "模型考古学（一）：大模型原理探赜",
    "summary": ":::note\n本篇博客的大量图片来自3Blue1Brown，你可以点击这个链接找到他们的B站官方账号\n:::谈及AI，我们现在大概率会直接想到大模型。诚然，大模型背后的庞大参数量和实现原理固然令人赞叹，但追本溯源我们会发现这些庞然大物的根基仍然是我们熟知的那个概念——神经网络。本篇作为“模型考古学”系列的第一篇，我会从神经网络的结构开始，一步步探寻大模型背后的奥秘。机器学习的迷人之处在于，它赋予",
    "tags": [
      "模型考古学"
    ],
    "url": "/posts/AI and Deep Learning/deeplearning-research-001/",
    "date": "2025-01-13T00:00:00.000Z",
    "content": ":::note\n本篇博客的大量图片来自3Blue1Brown，你可以点击这个链接找到他们的B站官方账号\n:::谈及AI，我们现在大概率会直接想到大模型。诚然，大模型背后的庞大参数量和实现原理固然令人赞叹，但追本溯源我们会发现这些庞然大物的根基仍然是我们熟知的那个概念——神经网络。本篇作为“模型考古学”系列的第一篇，我会从神经网络的结构开始，一步步探寻大模型背后的奥秘。机器学习的迷人之处在于，它赋予了机器“学习”的能力，而不再需要我们在代码中事无巨细地规定任务的执行步骤。这与 AI 发展初期的思路截然不同，那时，我们需要为每个特定任务编写明确的指令。如今，我们更倾向于构建一种通用的、具有可调参数的灵活架构，然后利用大量的样本数据（即输入与期望输出的对应关系）去训练这个架构。通过不断调整参数，模型逐渐学会模仿数据中蕴含的规律。以最简单的线性回归为例，我们输入房屋面积，期望得到预测的价格，这中间只需找到一条最佳拟合线——它由斜率和截距这两个关键参数定义。通过优化这些参数，我们就能让这条直线最大程度地贴合已知的房屋面积与价格数据，从而预测未来的房价。而这，仅仅是机器学习的冰山一角。一个更容易理解的说法是：我们不直接告诉机器怎么做，而是搭建一个灵活的“大脑”——神经网络，然后给它看海量的“例子”，比如“这个面积的房子大概值多少钱”。机器“看”多了，自己就能琢磨出规律，慢慢地，它就能根据输入的面积，猜出个八九不离十的价格。这就像我们小时候学东西，不是靠死记硬背公式，而是通过不断的观察和练习，学会举一反三。从最简单的线性回归，到如今火爆的各种深度学习模型，背后的原理其实都一样：用数据训练模型，让模型自己找到最佳答案。一、从神经网络结构开始说起1.基本结构顾名思义，神经网络之名来源自人的大脑结构，神经网络里的神经元（Neuron）也可以对应我们大脑中的神经。在大脑中，一个神经元通常有多个树突用于接收信号，一个轴突用于发送信号。神经元会通过突触与其他神经元进行连接，并根据接收信号的总和决定其激活状态，就像一个生物版本的逻辑门。神经元之间连接的强弱会在学习过程中不断发生改变，进而影响信息处理的方式，这便是我们学习和记忆的基础。人工神经网络中的神经元模型 正是对生物神经元的简化模拟。一个典型的人工神经元模型，例如经典的 McCulloch-Pitts (M-P) 模型，也拥有类似的功能结构。它接收来自其他神经元或外部输入的信号，每个输入信号都乘以一个对应的 权重（weight） ，这些加权后的信号在神经元内部进行 求和（summation） ，然后将总和与一个 阈值（threshold） 进行比较。如果总和超过了阈值，神经元就会被激活，并通过 激活函数（activation function） 产生一个输出信号；否则，神经元则保持静默。这个简单的数学模型，虽然看起来和我们生物体内的神经元相去甚远，却奠定了整个神经网络大厦的基石。我们可以将激活函数理解为对神经元是否“兴奋”的判定，不同的激活函数，例如阶跃函数、Sigmoid 函数、ReLU 函数等，都扮演着将神经元输入转化为输出的角色，同时也为神经网络引入了非线性，使其能够处理更复杂的任务。从单个神经元到神经网络， 我们可以将多个神经元按照一定的层次结构连接起来，形成神经网络。最简单的结构便是 前馈神经网络（Feedforward Neural Network） ，其中神经元分层排列，信号只能从前一层单向传递到后一层，层内神经元之间没有连接。在这种网络结构中，第一层被称为 输入层（Input Layer） ，负责接收外部输入的数据；最后一层被称为 输出层（Output Layer） ，负责输出网络的计算结果；中间的层被称为 隐藏层（Hidden Layer） ，隐藏层的层数和每层的神经元数量可以根据任务的复杂程度进行调整。image.png我们可以把神经元看做是一个函数（Function），它输入的是上一层所有神经元的输出，而它的输出是一个0到1之间的值。其实整个神经网络就是一个函数，在上图中是一个输入784个值（因为图片的像素是28*28），输出10个值（因为输出的是十个数字的概率）的函数。不过这个函数极其的复杂，它用了13002个权重参数偏置函数来识别特殊图案，当然这个函数要是不复杂的话我们又怎么能放心的用它来识别数字了呢（）image.png那么，我们的神经网络是如何处理这项艰巨任务的，神经网络又是如何通过数据来获得合适的权重和偏置的？答案是 反向传播算法（Backpropagation）。:::note我们想要这么一种算法，你可以给这个网络看一大堆训练数据，其中包括一堆不同的手写数字图像，以及它们代表哪个数字的标记，算法会调整这13000个权重和偏置值，以提高网络对训练数据的表现。我们希望这种分层结构可以让它举一反三，识别训练数据之外的图像。训练好网络后，我们会给它更多以前从未见过的带标记的数据作为测试，你就可以看到这个模型对新图像进行分类的准确度。:::2.反向传播算法反向传播算法 可以说是神经网络的灵魂所在，它的核心思想可以概括为：计算损失，反向传播，更新权重 。（1）、计算损失（Loss Calculation）：首先，我们需要一个衡量神经网络当前输出与期望输出之间差距的指标，这就是 损失函数（Loss Function） 。例如，在手写数字识别任务中，如果我们输入一张数字“2”的图片，期望的输出是“[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]”，而神经网络实际输出的是“[0.1, 0.2, 0.5, 0.05, 0.02, 0.03, 0.01, 0.02, 0.05, 0.02]”，那么我们就需要一个损失函数来计算这两个向量之间的差异。常用的损失函数包括均方误差（Mean Squared Error, MSE）、交叉熵损失（Cross-Entropy Loss）等。损失函数的值越大，表示网络的输出与期望输出的差距越大，网络的性能越差。（2）、反向传播（Backpropagation）这一步是反向传播算法的精髓所在。它利用 链式法则（Chain Rule） ，从输出层开始，逐层计算每个权重对最终损失的 梯度（Gradient） 。可以把梯度理解为“权重对损失的影响程度”，它是一个向量，指明了损失函数在当前权重值下，沿着哪个方向变化最快，以及变化的速率。让我们用一个简化的例子来说明：假设输出层的某个神经元 j 的输出值为 $y_j$，它与期望输出 $t_j$ 之间的误差为 $E$ (假设使用 MSE 作为损失函数，则 $E = 0.5 * (y_j - t_j)^2$)。神经元 j 的输出 $y_j$ 是由上一层神经元 i 的输出 $y_i$ 经过加权求和并经过激活函数得到的，即 $y_j = f(∑ w_{ij} * y_i + b_j)$，其中 $w_{ij}$ 是神经元 i 到神经元 j 的权重，$b_j$ 是神经元 j 的偏置。现在，我们想要知道权重 $w_{ij}$ 对误差 $E$ 的影响，即 $\\partial E/\\partial w_{ij}$。根据链式法则，我们可以将这个偏导数分解为：\n$$\n∂E/∂w_ij = ∂E/∂y_j * ∂y_j/∂net_j * ∂net_j/∂w_ij\n$$\n其中 $$net_j = ∑ w_ij * y_i + b_j$$。$\\partial E/\\partial y_j$ 表示误差对神经元 j 输出的变化率，可以直接根据损失函数的定义计算得出。$\\partial y_j/\\partial net_j$ 表示神经元 j 的输出对其加权输入和的变化率，这取决于激活函数的导数。$\\partial net_j/\\partial w_{ij}$ 表示神经元 j 的加权输入和对权重 $w_{ij}$ 的变化率，这个值恰好等于 $y_i$。通过这种方式，我们可以计算出输出层每个权重对损失的梯度。然后，我们可以将误差信号继续向后传播，计算隐藏层每个权重对损失的梯度。这个过程一直持续到输入层，所有权重的梯度都被计算出来。（3）、更新权重（Weight Update）:得到每个权重的梯度后，我们就需要根据梯度来更新权重。更新的原则是：**沿着梯度的反方向调整权重，因为梯度的反方向是损失函数下降最快的方向，**常用的权重更新方法是 梯度下降法（Gradient Descent）。总结来说，反向传播算法通过计算损失函数对每个权重的梯度，并根据梯度来更新权重，从而使得网络的输出逐渐逼近期望输出。这个过程不断迭代进行，直到网络的损失降到足够小，或者达到预设的训练轮数。通过反向传播算法，神经网络可以从大量的训练数据中学习到合适的权重和偏置，从而具备强大的模式识别和预测能力。而大模型，则是在此基础上，通过增加网络的深度和宽度，使用更复杂的网络结构和训练技巧，进一步提升了模型的性能和泛化能力。2.梯度下降法梯度下降法（Gradient Descent） 是一种广泛应用于机器学习，尤其是神经网络训练中的一阶迭代优化算法。其核心思想是，通过迭代地沿着损失函数梯度的反方向来更新模型参数（例如神经网络中的权重和偏置），从而逐步逼近损失函数的最小值，最终找到模型的最优参数。（1）、梯度的含义回顾在深入了解梯度下降法之前，让我们再次回顾一下梯度的概念。梯度是一个向量，它指向函数在某一点处变化最快的方向，并且其大小表示函数在该方向上的变化率。对于一个多元函数，其梯度由各个自变量的偏导数组成。在神经网络中，我们关注的是损失函数关于各个权重和偏置的梯度。想象一下你站在一座山上，目标是走到山谷的最低点。你环顾四周，找到了最陡峭的下坡方向（梯度反方向），然后迈出了一小步。接着你再次观察周围环境，找到新的最陡峭下坡方向，然后又迈出了一小步。重复这个过程，你最终将到达山谷的最低点。这就是梯度下降法的直观体现。（2）、数学描述假设我们有一个损失函数 $J(\\theta)$，其中 $\\theta$ 是一个向量，表示模型的所有参数（权重和偏置）。梯度下降法的目标是找到一组 $\\theta$，使得 $J(\\theta)$ 最小化。梯度下降法的更新规则如下：$\\theta(t+1) = \\theta(t) - \\eta * \\nabla J(\\theta(t))$其中：$\\theta(t)$ 表示第 $t$ 次迭代时的参数值。$\\theta(t+1)$ 表示第 $t+1$ 次迭代时的参数值。$\\eta$ 是学习率（Learning Rate），一个正数，控制每次迭代的步长。$\\nabla J(\\theta(t))$ 表示损失函数 $J(\\theta)$ 在 $\\theta(t)$ 处的梯度。（3）、计算步骤1.初始化参数： 随机初始化模型参数 $\\theta(0)$。\n2.计算梯度： 使用反向传播算法（或其他方法）计算损失函数 $J(\\theta)$ 关于当前参数 $\\theta(t)$ 的梯度 $\\nabla J(\\theta(t))$。\n3.更新参数： 按照上述更新规则，使用梯度和学习率来更新参数 $\\theta(t+1)$。\n4. 重复步骤 2 和 3： 不断迭代，直到满足停止条件。常见的停止条件包括：\n- 达到预设的最大迭代次数。\n- 损失函数的值变化小于某个阈值。\n- 梯度的模长小于某个阈值。（4）、学习率学习率 η 是梯度下降法中一个至关重要的超参数。它决定了每次参数更新的步长。学习率过大： 可能导致参数更新过猛，越过最小值，甚至导致损失函数发散，无法收敛。就像你在下山时步子迈得太大，可能会直接跳过山谷，甚至跑到另一座山上。学习率过小： 会导致参数更新缓慢，训练过程耗时过长。就像你下山时步子迈得太小，可能需要很长时间才能到达山谷。合适的学习率： 使得参数能够平稳地接近最小值，并在最小值附近震荡，最终收敛到最小值。（5）、梯度下降法的变体为了提高梯度下降法的效率和稳定性，研究者们提出了许多变体，常见的包括：批量梯度下降法（Batch Gradient Descent, BGD）： 每次迭代使用 所有 训练样本来计算梯度。优点是每次更新都朝着全局最优方向前进，缺点是计算量大，训练速度慢，尤其是对于大规模数据集。随机梯度下降法（Stochastic Gradient Descent, SGD）： 每次迭代 随机选择一个 训练样本来计算梯度。优点是计算速度快，尤其适合大规模数据集；缺点是由于每次只使用一个样本，更新方向可能不稳定，存在较大噪声，但从期望来看，它是沿着正确的方向的。小批量梯度下降法（Mini-Batch Gradient Descent, MBGD）： 每次迭代使用 一部分（一个 mini-batch） 训练样本来计算梯度。这是 BGD 和 SGD 的折中方案，既能加快训练速度，又能提高稳定性，是目前最常用的梯度下降法变体。当然，梯度下降法也会有其局限性。例如其可能会陷入局部最小值，而无法达到全局最小值，尤其是对于非凸函数。就比如我们在下山时可能会到达一个小的山谷，但这个山谷并不是整座山的最低点。梯度下降法在鞍点处可能会停滞不前，因为鞍点处的梯度为零。鞍点是一个既不是局部最小值也不是局部最大值的点，就像马鞍的中心点一样。最后，学习率的选择对于训练结果的影响很大，需要按照实际经验来一点点调整。二、大模型的架构解析目前，绝大多数主流的大语言模型都基于 Transformer 架构。Transformer 架构最初是在 2017 年的论文 \"Attention is All You Need\" 中提出的，它彻底改变了自然语言处理领域。为什么Transformer如此重要？并行化处理：因为相较于之前的循环神经网络（RNN）和长短期记忆网络（LSTM），Transformer 能够并行处理输入序列中的所有词，大大提高了训练效率。注意力机制： Transformer 的核心是注意力机制（Attention Mechanism），它允许模型关注输入序列中不同词之间的关系，并根据这些关系动态调整每个词的权重，从而更好地理解上下文信息。长距离依赖：Transformer 能够有效地捕捉长距离依赖关系，这对于理解复杂的语言结构至关重要。1.组成架构image.png（1）、嵌入层在输入到 Transformer 之前，输入序列中的每个词都需要被转换成一个向量表示，这个过程称为 词嵌入 (Word Embedding)。嵌入层负责将每个词映射到一个固定维度的向量，这个向量能够表示该词的语义信息。常用的词嵌入方法: Word2Vec, GloVe, FastText 等。子词嵌入 (Subword Embedding): 为了解决未登录词 (Out-of-Vocabulary, OOV) 问题，现代 LLM 通常使用子词嵌入，例如 字节对编码 (Byte Pair Encoding, BPE) 或 WordPiece。这些方法将词分解成更小的子词单元，并为每个子词单元学习一个向量表示。:::note嵌入层之后就是我们的 Transformer 了，一个典型的 Transformer 模型由两个主要部分组成：编码器 (Encoder) 和 解码器 (Decoder)。:::（2）、Encoder 编码器编码器的作用是将输入序列（例如一句话）转换成一个包含丰富语义信息的向量表示，称为 上下文向量 (Context Vector) 或 隐藏状态 (Hidden State)。我们的Encoder编码器通常由多个相同的编码器层（Encoder Layer）堆叠而成，而每个编码器层又包含两个主要子层：自注意力层 (Self-Attention Layer): 这是 Transformer 的核心。自注意力机制允许模型关注输入序列中每个词与其他所有词之间的关系，并计算出一个权重矩阵，表示每个词对其他词的重要性。通过这种方式，模型可以理解每个词在句子中的上下文含义。计算过程: 自注意力层会为输入序列中的每个词计算三个向量：查询向量 (Query)、键向量 (Key) 和 值向量 (Value)。然后，通过计算查询向量和键向量的点积来衡量每个词之间的相关性，并使用 Softmax 函数将这些相关性分数归一化为权重。最后，将这些权重与相应的值向量相乘并求和，得到每个词的上下文表示。多头注意力 (Multi-Head Attention): 为了捕捉更丰富的语义信息，通常会使用多头注意力机制。它将输入序列映射到多个不同的表示空间，并在每个空间中独立地计算自注意力，最后将所有头的输出拼接起来。前馈神经网络层 (Feed-Forward Network Layer): 这是一个简单的全连接神经网络，对自注意力层的输出进行进一步的非线性变换，增强模型的表达能力。（3）、Decoder 解码器解码器的作用是根据编码器输出的上下文向量生成目标序列（例如翻译后的句子）。与编码器类似，解码器也由多个相同的 解码器层 (Decoder Layer) 堆叠而成。每个解码器层包含三个主要子层：自注意力层 (Self-Attention Layer): 与编码器中的自注意力层类似，但解码器中的自注意力层只能关注到当前词和之前的词，这是为了防止模型在生成当前词时“偷看”到未来的信息，这被称为 掩码自注意力 (Masked Self-Attention)。编码器-解码器注意力层 (Encoder-Decoder Attention Layer): 这个子层允许解码器关注编码器输出的上下文向量。解码器中的每个词都会计算一个查询向量，并与编码器输出的所有键向量和值向量进行交互，从而获取与当前生成任务相关的上下文信息。前馈神经网络层 (Feed-Forward Network Layer): 与编码器中的前馈神经网络层类似，对注意力层的输出进行非线性变换。（4）、Output Layer 输出层解码器的最后一层输出一个向量，这个向量的维度与词汇表大小相同。然后，通过一个 Softmax 函数将这个向量转换成一个概率分布，表示每个词作为下一个词的概率。2.为什么大模型如此之大？在之前的讨论中，我们了解了神经网络的基础：反向传播和梯度下降，也领略了 Transformer 架构的精妙。现在，一个自然而然的问题浮现在我们脑海：为什么现在的大语言模型（LLM）都如此庞大？动辄数十亿、上千亿甚至上万亿的参数，究竟这些庞大的模型是如何炼成的，海量的训练数据又被模型“消化”到哪里去了呢？（1）、大模型的“大”体现在哪里：大模型的“大”，直观上体现在两个方面：模型参数量巨大： 正如前面提到的，GPT-3 的参数量达到了 1750 亿，而后续的 PaLM、Gopher 等模型更是将参数量推向了新的高度。这些参数主要指的是模型中神经元之间的连接权重和偏置，每一个参数都是一个需要通过训练来确定的数值。训练数据量庞大： 大模型的训练离不开海量的数据。GPT-3 使用了约 45TB 的压缩文本数据，而其他大模型使用的训练数据量也都在数百 GB 到数 TB 的级别。这些数据通常来源于互联网、书籍、论文等各种来源，涵盖了各种各样的主题和语言风格。（2）、为什么要这么大？简而言之，更大的模型和更多的数据通常意味着更强的能力和更好的泛化性能。 这背后的原因可以从以下几个方面来理解：更强的模式识别能力： 大模型拥有更多的参数，这意味着它拥有更复杂的内部结构和更强大的非线性拟合能力。这使得它能够捕捉到训练数据中更细微、更复杂的模式和规律。如果把模型比作一个函数，那么更多的参数就意味着这个函数可以拥有更复杂的形态，从而更好地逼近真实世界中各种复杂的现象。更好的泛化能力： 泛化能力是指模型在面对从未见过的数据时的表现。大模型通常拥有更好的泛化能力，因为它们在训练过程中见过了更多的数据，学习到了更普遍性的规律，而不是仅仅记住了训练数据中的特定例子。这就像一个学生，如果他只做了几道练习题，那么他可能只会做这几道题，但如果他做了大量的练习题，那么他就更有可能掌握解题的普遍方法，从而能够解决各种各样的新题目。更丰富的知识表示： 大模型可以看作是一个巨大的知识库，它将海量的训练数据中蕴含的信息压缩并存储在其参数中。模型参数越多，这个知识库的容量就越大，能够存储的信息就越丰富。当模型遇到新的任务或问题时，它可以从这个知识库中检索相关的信息，并利用这些信息来生成答案或执行任务。image.png（3）、海量的训练数据都去哪了？那么，如此庞大的训练数据，在训练完成后都去哪里了呢？它们并没有以原始的形式存储在模型中，而是被模型“消化吸收”，转化成了模型的参数（权重和偏置）。我们可以将模型的训练过程类比为“读书学习”。当我们阅读一本书时，我们并不会把书中的每一个字都一字不差地记住，而是会理解书中的内容，并将这些内容提炼成我们自己的知识，存储在我们的记忆中。类似地，模型在训练过程中，会不断地调整自己的参数，使得模型的输出能够更好地匹配训练数据。这个过程实际上就是将训练数据中的信息压缩并编码到模型参数中的过程。具体来说，训练数据通过以下方式影响模型的参数：梯度下降： 在训练过程中，模型会计算损失函数关于每个参数的梯度，并根据梯度来更新参数。训练数据决定了损失函数的具体形式，从而影响了梯度的计算，最终影响了参数的更新方向和幅度。参数的最终值： 经过大量的迭代训练后，模型的参数会收敛到一个特定的值，这些值就是模型从训练数据中学到的知识的体现。不同的训练数据会导致不同的参数值，从而使得模型表现出不同的行为和能力。可以这样理解：训练数据塑造了模型的参数，而模型的参数则承载了模型从训练数据中学到的知识。（4）、这些知识都是如何储存的？需要注意的是，模型对知识的存储方式与人类的记忆机制有很大的不同。人类的记忆是显式的，我们可以清晰地回忆起具体的事件和知识。而模型的“知识”是隐式地分布在其所有的参数中，我们很难从某个具体的参数值中解读出模型学到了什么具体的知识。这就像一个黑盒，我们知道输入（训练数据）和输出（模型预测），但我们很难理解中间的“知识”是如何被表示和存储的。 这也是目前深度学习领域的一个重要的研究方向：可解释性。3.大语言模型（LLM）架构的发展历程基于 Transformer 架构，目前主要有三种主流的 LLM 架构：仅编码器模型 (Encoder-only Models): 例如 BERT、RoBERTa。这类模型只使用 Transformer 的编码器部分，擅长于理解语言，常用于文本分类、情感分析、命名实体识别等任务。它们通常通过 预训练 (Pre-training) 和 微调 (Fine-tuning) 的方式进行训练。预训练: 在大规模无标注文本数据上进行预训练，学习通用的语言表示。常用的预训练任务包括 掩码语言模型 (Masked Language Modeling, MLM) 和 下一句预测 (Next Sentence Prediction, NSP)。微调: 在特定任务的标注数据集上进行微调，将预训练学到的通用语言表示适配到具体任务。仅解码器模型 (Decoder-only Models): 例如 GPT 系列 (GPT-1, GPT-2, GPT-3, GPT-4)。这类模型只使用 Transformer 的解码器部分，擅长于生成文本，常用于文本生成、对话系统、机器翻译等任务。它们通常通过 自回归 (Autoregressive) 的方式进行训练，即根据前面已生成的词来预测下一个词。编码器-解码器模型 (Encoder-Decoder Models): 例如 BART、T5。这类模型同时使用 Transformer 的编码器和解码器部分，兼具理解和生成能力，常用于机器翻译、文本摘要等任务。image.png在大模型发展的早期阶段，encoder-only和encoder-decoder模型更受欢迎，但随着 2021 年 GPT-3 的横空出世，decoder-only 模型完成了一次漂亮的翻身仗。在 BERT 带来的最初爆炸性增长之后，encoder-only 模型逐渐开始失宠。|  | Encoder-Decoder or Encoder-only (BERT-style) | Decoder-only (GPT-style) |\n| --- | --- | --- |\n| 训练方式 | Masked Language Models（遮盖某些单词） | Autoregressive Language Models（自回归） |\n| 模型类型 | （Discriminative）判别式 | （Generative）生成式 |\n| 预训练任务 | 预测遮掩掉的单词（完形填空） | 预测下一个单词 |\n| 对应模型 | ELMo , BERT , RoBERTa , DistilBERT , BioBERT , XLM , Xlnet , ALBERT , ELECTRA , T5 , GLM , XLM-E , ST-MoE , AlexaTM  | GPT 3/4 , OPT . PaLM , BLOOM , MT-NLG , GLaM ,Gopher , chinchilla , LaMDA , GPT-J , LLaMA , BloombergGPT  |（1）、BERT风格语言模型：encoder-decoder 或 encoder-only因为自然语言数据在前大模型时代还是很容易获取的，为了更好的利用这些超级数据集，人们提出了很多无监督训练的方式。这其中一种很常见的方法就是在给定上下文的情况下，预测句子中掩盖（masked）掉的单词，这种训练范式被称为 Masked Language Model (MLM)。典型模型包括BERTRoBERTaT5这种模型在许多 NLP 任务（如情感分析和 named entity 识别）中取得了 state-of-the-art 的结果， 已经成为自然语言处理领域的重要工具。（2）、GPT风格语言模型：decoder-only尽管语言模型通常在架构上是任务无关的，但都需要在特定下游任务的数据集上进行微调。研究人员发现，扩展语言模型的参数规模（scaling up） 能显著提高少样本（few-shot）甚至零样本（zero-shot）性能。 少样本和零样本最成功的模型是自回归语言模型（Autoregressive Language Models，ALM）。这些模型的训练方式：给出前面的单词，生成这句话的下一个单词。这些模型已被广泛用于文本生成和问题回答等 NLP 任务。典型的自回归语言模型包括，GPT-3OPTPaLMBLOOM这其中，GPT-3 是一个划时代的模型，它首次通过提示（prompting）和上下文学习（in-context learning） 展示了少样本/零样本也能取得不错的性能，展现了自回归语言模型的优越性。还有一些模型针对特定任务进行了优化，如CodeX ：代码生成BloombergGPT ：金融领域最近的突破是 ChatGPT，它专门针对对话任务优化了 GPT-3，从而在各种实际应用中 互动性、连贯性，以及更好的上下文理解能力。参考文献[1] Vaswani A. Attention is all you need[J]. Advances in Neural Information Processing Systems, 2017.[2] Yang J, Jin H, Tang R, et al. Harnessing the power of llms in practice: A survey on chatgpt and beyond[J]. ACM Transactions on Knowledge Discovery from Data, 2024, 18(6): 1-32."
  },
  {
    "title": "使用 Qwen VL 系列模型实现图片分类和OCR任务",
    "summary": "阿里云的通义千问（Qwen）大模型在闭源和开源领域齐头并进，性能表现一直都非常不错。在2024年年末，Qwen-VL（Vision-Language）系列模型迎来了一次大幅降价，这对于像我这样希望利用大模型处理个人项目的开发者来说无疑是一大利好。今年年初我在进行图片分类时，主要还依赖于ResNet这类经典的卷积神经网络，然而随着多模态视觉-语言模型（VLM）的迅猛发展，加上Qwen-VL的成本优势",
    "tags": [],
    "url": "/posts/TechnicalTutorials/ai-powered-image-organization/",
    "date": "2025-01-10T00:00:00.000Z",
    "content": "阿里云的通义千问（Qwen）大模型在闭源和开源领域齐头并进，性能表现一直都非常不错。在2024年年末，Qwen-VL（Vision-Language）系列模型迎来了一次大幅降价，这对于像我这样希望利用大模型处理个人项目的开发者来说无疑是一大利好。今年年初我在进行图片分类时，主要还依赖于ResNet这类经典的卷积神经网络，然而随着多模态视觉-语言模型（VLM）的迅猛发展，加上Qwen-VL的成本优势凸显，给自己相册的几百上千张图片分类的价格成本已经可以降低至可以接受的、极具吸引力的水平。于是，我开始着手探索如何利用这些强大的视觉语言模型（VLM）来改进自己的工作流。原本还得自己打标分类痛苦的训练微调ResNet模型，一点一点的炼丹看损失曲线是否收敛，现在可以直接借助VLM的零样本学习能力 (Zero-Shot Learning)，写点prompt就能让模型会意自动分类图片，甚至还能根据我的需求产出细腻的分类结果。比如，我在整理旅行照片时，可以直接告诉Qwen-VL模型：哪些照片是“日落”、“美食”、“人像”、“风景”，还可以进一步制定更加细化的类别，比如“黄昏下的海滩”或者“城市天际线中的日出”，模型都能给出相当靠谱的分类结果，完全不需要额外训练，这在几年前是不可想象的。作为一名开发者，这种易用性与强大性能兼具 的体验堪称福音。以往在开发诸如 ResNet 或 EfficientNet 等模型时，我不得不投入大量精力进行繁琐的参数调优工作，甚至经常需要通宵进行数据标注，开发效率极其低下。然而，依托于VLM这种性能卓越的预训练模型和便捷的推理机制 ，我仅需构建精巧的提示词（Prompt） ，便可通过调用阿里云开放的 API 接口，迅速实现所需的分类或分析功能。这极大地解放了生产力，使我得以将更多精力专注于核心业务逻辑的构建，而非耗费在基础模型的训练与调优上。第一节 使用 Qwen VL 执行图片分类任务其实这部分原理非常简单，因为VLM模型可以同时理解图像和文本，能很方便的进行跨模态的理解和推理，所以我们只需要每次向模型发送图片和特定的提示词（prompt），模型就会自动分类判断输出该图片的类别，为了简化结果处理，我们只需编写一个简单的结果匹配解析模块即可。在系统架构层面，本项目采用与 OpenAI 兼容的 API 接口与 Qwen-VL 模型进行交互，并通过环境变量来管理 API 密钥及其他相关配置，确保了系统的灵活性、安全性与可维护性。为提高分类速度，本项目支持多图片并发处理，并集成了图片预处理与压缩功能，有效平衡了处理效率与图像质量，确保系统高效稳定的运行，以下为项目在 GitHub 上的仓库地址：::github{repo=\"Lapis0x0/VLMClassifier\"}具体处理管线本项目的具体处理流程如下：首先对输入的图片进行精细化预处理。该步骤包括将图像尺寸统一调整至最大 1024x1024 像素，转换为 RGB 色彩空间，并使用质量系数为 85 的 JPEG 压缩算法以优化数据传输效率。预处理完成后，系统将图片转换为 Base64 编码格式，并构建一个包含图片信息和预定义分类提示词的请求。随后，通过 API 调用 Qwen-VL-Plus 模型执行推理操作。针对模型返回的结果，项目采用深度解析策略来精确判定图像的最终类别。目前，系统预设了包括二次元、生活照片、宠物、工作和表情包在内的多个分类类别，并支持通过环境变量进行自定义类别扩展，从而满足不同用户的个性化需求。在性能优化方面，本项目采用了线程池技术实现了多图片并发处理，并集成了完善的异常处理机制以应对各种潜在问题。此外，所有主要参数均可通过环境变量进行灵活配置，而图片优化策略则在保证处理效率的同时兼顾了图像质量。本项目的主要优势在于：其一，依托先进的 VLM 模型，确保了对图片内容的准确理解；其二，实现了高效的并发处理机制，大幅提升了处理速度；其三，具备良好的可配置性和扩展性，方便用户根据自身需求进行定制；其四，集成了完善的图片预处理功能，在保证图像质量的同时提升了处理效率。得益于这些特性，本项目可广泛应用于批量图片分类整理、图片库管理以及自动化图片分类系统等多种场景。总结我就喜欢VLM这种简单粗暴泛用性强的解决方案，不需要过多设计效果就会非常棒。第二节 使用Qwen-vl-ocr模型实现笔记归档整理思路介绍除了内容分类，Qwen vl还有一个特化分支——Qwen-vl-ocr，该模型专门针对图像中的文字提取任务进行了优化，它能够高效地识别并提取各种类型图像中的文字信息，包括：文档: 扫描的文档、PDF文档等表格: 各种形式的表格数据试题: 试卷、练习题等手写体文字: 手写笔记、信件等目前，Qwen-vl-ocr模型支持多种语言，包括：中文、英文、法文、日文、韩文、德文、俄文、意大利文、越南文和阿拉伯文 。:::note\n此模型的输入输出单价为5元/百万 tokens，性价比拉满\n:::因此，我们可以利用Qwen-vl-ocr模型强大的文字识别能力来实现笔记的自动化归档整理。具体实现步骤如下：图像预处理：我自己的笔记通常是多个页面拼接在一起的，因此需要对输入的图像进行必要的预处理，例如：分页、调整图像大小、灰度化、去噪等，以提高OCR模型的识别准确率。虽然Qwen VL OCR模型对图像质量有一定的鲁棒性，但良好的预处理可以进一步提升识别效果。文字提取：将预处理后的图像输入到Qwen VL OCR模型，模型会自动识别并提取出图像中的文字信息，并以文本的形式输出。文本后处理：模型OCR后输出的文本是非结构的，顺序不符合要求的原始文本，需要我们再调用一次其他模型进行修改润色，使其更符合我们的阅读习惯和归档需求。归档整理： 根据提取的文本内容，结合我们的实际需求，将笔记内容归类到不同的文件夹或数据库中。例如，我们可以根据关键词、主题、日期等信息进行分类整理。项目地址：::github{repo=\"Lapis0x0/NoteOCR\"}1.笔记检测与分页——基于边缘和轮廓的页面识别考虑到模型单次能“记住”的信息有限，如果直接把十几页笔记直接丢给它，识别效果恐怕会大打折扣。所以，我们需要先给笔记做个“瘦身”——检测并分好页。 这样，模型每次只需处理一页的内容，识别起来自然更轻松，结果也更准确。我的主要检测方法目前基于经典计算机视觉技术，通过预处理 、边缘检测与直线提取 以及页面区域识别三个阶段来定位每一页笔记的边界。（1）预处理灰度转换: 首先，我们将彩色图像转换为灰度图像。这简化了后续的处理步骤，因为我们只需要处理一个通道的信息。gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)CLAHE 对比度增强: 为了应对光照不均或对比度较低的情况，我使用了对比度受限自适应直方图均衡化 (CLAHE) 技术。CLAHE 通过在图像的局部区域上进行直方图均衡化，有效地增强了图像的对比度，同时避免了过度放大噪声。CLAHE 的数学原理可以简述为：将图像分成多个小块（tiles），对每个小块计算直方图并进行均衡化，然后使用双线性插值将结果平滑地组合起来。其核心公式为（以一个 tile 为例）：\n$$\ng = \\frac{(L-1) \\sum_{i=0}^{f} hist(i)}{N}\n$$\n其中：$g$ 表示均衡化后的像素值。$f$ 表示原始像素值。$L$ 表示灰度级数（例如 256）。$hist(i)$ 表示灰度级为 $i$ 的像素数量。$N$ 表示 tile 内的总像素数。clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\nenhanced = clahe.apply(gray)高斯模糊降噪: 为了消除图像中的高频噪声，我们使用高斯模糊进行平滑处理。高斯模糊的内核大小可以根据图像的噪声水平进行调整。二维高斯函数的公式为：\n$$\nG(x, y) = \\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2+y^2}{2\\sigma^2}}\n$$\n其中：$(x, y)$ 表示像素坐标。$\\sigma$ 表示标准差，控制模糊的程度。blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)（2）边缘检测与直线提取：勾勒出页面的轮廓经过预处理后，我们就可以开始寻找页面的边缘了。Canny 边缘检测: 我使用了经典的 Canny 边缘检测算法。Canny 算法通过计算图像梯度、非极大值抑制和双阈值处理等步骤，能够有效地检测出图像中的边缘。edges = cv2.Canny(blurred, 50, 150)霍夫变换直线检测: 为了进一步提取出页面边缘的直线特征，我使用了霍夫变换。霍夫变换可以将图像空间中的直线映射到参数空间中的点，从而检测出图像中的直线。直线在极坐标系下可以表示为：\n$$\n\\rho = x\\cos\\theta + y\\sin\\theta\n$$\n其中：$\\rho$ 表示直线到原点的距离。$\\theta$ 表示直线法线与 $x$ 轴的夹角。$(x, y)$ 表示直线上的点。霍夫变换通过在 $(\\rho, \\theta)$ 参数空间中进行投票，找出峰值点对应的直线。lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)创建线条掩码并进行形态学处理: 检测到的直线需要进一步处理，以形成完整的页面边界。我通过创建线条掩码，并进行膨胀和腐蚀操作，将断裂的边缘连接起来，并去除一些小的噪声。（3）页面区域识别：框选出每一页笔记有了清晰的边缘信息，我们就可以识别出每一页笔记的区域了。查找轮廓: 使用 cv2.findContours 函数查找图像中的轮廓。contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)筛选矩形区域: 根据面积和长宽比等特征，筛选出可能是页面区域的矩形轮廓。透视变换矫正: 对于倾斜或有透视变形的页面，我们需要进行透视变换进行矫正。通过找到矩形区域的四个顶点，并将其映射到标准矩形的四个顶点，可以实现页面的矫正。透视变换的矩阵 $M$ 可以通过解以下方程组得到：\n$$\n\\begin{bmatrix} x_i' \\ y_i' \\ 1 \\end{bmatrix} = M \\begin{bmatrix} x_i \\ y_i \\ 1 \\end{bmatrix}\n$$\n其中：$(x_i, y_i)$ 表示原始图像中的点。$(x_i', y_i')$ 表示变换后图像中的对应点。$i = 1, 2, 3, 4$ 表示四个顶点。根据位置排序: 最后，根据检测到的页面区域的位置，从左到右进行排序，确保页面的顺序正确。（4）备选方案：基于文本密度分析的页面分割尽管主要检测方法在大多数情况下都能取得很好的效果，但为了进一步提高系统的鲁棒性，我还设计了一个备选方案 (_fallback_page_detection)。当主要方法未能检测到预期数量的页面时（如未能检测到页面或页面数量不是3个），就会启用备选方案。这个备选方案基于文本密度分析，它假设笔记页面之间存在一定的空白区域，这些区域的文本密度较低。图像二值化: 首先，将图像进行二值化处理，将文本和背景分离。常用的二值化方法有全局阈值法和自适应阈值法，自适应阈值法公式为：\n$$\nT(x, y) = \\mu(x, y) - C\n$$\n其中：$T(x, y)$ 表示像素 $(x, y)$ 的阈值。$\\mu(x, y)$ 表示像素 $(x, y)$ 邻域的平均灰度值。$C$ 是一个常数。计算水平方向的文本密度分布: 对二值化后的图像，逐行计算像素值为前景（例如黑色）的像素数量，从而得到水平方向的文本密度分布。移动平均平滑: 为了消除噪声的影响，使用移动平均对密度曲线进行平滑处理。寻找局部最小值: 在平滑后的密度曲线上，寻找局部最小值。这些局部最小值通常对应于页面之间的空白区域。等距分割 (备选): 如果找不到合适的分割点，则采用等距分割作为最后的保障。反思：这个检测分页方法是最优的吗？当然不是。我最近发现像Qwen vl和Gemini这样的模型似乎直接支持进行目标检测，输出图片后可以直接输出检测框。未来的版本可以测试直接采用vlm来进行检测分页，进一步提高本项目的健壮性。2.执行OCR任务和后处理修改润色经过处理后的笔记分页直接提交给模型进行OCR即可，以下是Qwen-vl-ocr的代码示例：import os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n)\ncompletion = client.chat.completions.create(\n    model=\"qwen-vl-ocr\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": \"https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20241108/ctdzex/biaozhun.jpg\",\n                    \"min_pixels\": 28 * 28 * 4,\n                    \"max_pixels\": 28 * 28 * 1280\n                },\n                # 为保证识别效果，目前模型内部会统一使用\"Read all the text in the image.\"进行识别，用户输入的文本不会生效。\n                {\"type\": \"text\", \"text\": \"Read all the text in the image.\"},\n            ]\n        }\n    ])\n\nprint(completion.choices[0].message.content)在每一个笔记分页被送去执行OCR后，OCR的结果会送到新的LLM那里执行后处理润色。这是我自己的润色Prompt:messages = [\n\t{\"role\": \"system\", \"content\": \"你是一个专业的笔记整理助手。你需要帮助整理和优化OCR识别出的课堂笔记内容，使其更加清晰、结构化，并保持原有的重点标记。请注意，你应该只输出整理后的笔记内容，不要包含任何其他信息。\"},\n\t{\"role\": \"user\", \"content\": f\"\"\"请帮我整理以下课堂笔记内容，要求：\n1. 保持原有的结构和格式\n2. 保留所有重点标记\n3. 修正明显的OCR错误（比如不合理的人名、称呼和名词等）\n4. 优化段落和缩进\n5. 确保数学公式和符号的正确性模型我一般会用Deepseek v3或者gpt-4o-1120。最后，程序会自动将各个分页ocr润色后的结果合并到一份markdown文件里输出。:::note\n下一篇博客可能会解读一下Qwen vl的技术报告，并且探索使用Qwen vl/Gemini进行笔记检测分页\n:::"
  },
  {
    "title": "Trading101：策略交易解析",
    "summary": "与传统的主观交易方式不同，策略交易摒弃了传统的主观判断和情绪化交易，转而依靠严谨的数学模型、海量的历史数据分析以及高效的计算机程序 ，构建系统化的交易策略，力求在市场波动中捕捉获利机会。策略交易的迷人之处在于其理性与客观 。它将投资决策建立在量化分析的基础之上，通过对历史数据的回测，发现市场运行的规律，并制定出相应的交易规则。这些规则如同精密的仪器，指导着交易的每一个环节，从入场时机的选择，到仓位",
    "tags": [
      "投资101"
    ],
    "url": "/posts/Finance and Economics/Trading101-quant-trading/",
    "date": "2025-01-03T00:00:00.000Z",
    "content": "与传统的主观交易方式不同，策略交易摒弃了传统的主观判断和情绪化交易，转而依靠严谨的数学模型、海量的历史数据分析以及高效的计算机程序 ，构建系统化的交易策略，力求在市场波动中捕捉获利机会。策略交易的迷人之处在于其理性与客观 。它将投资决策建立在量化分析的基础之上，通过对历史数据的回测，发现市场运行的规律，并制定出相应的交易规则。这些规则如同精密的仪器，指导着交易的每一个环节，从入场时机的选择，到仓位大小的控制，再到止损止盈的设定，都经过了严格的计算和验证。 例如，一个简单的基于移动平均线的趋势跟踪策略可以用以下公式表示：$$\n\\text{如果 } P_t > MA(P, n) \\text{, 则买入；如果 } P_t < MA(P, n) \\text{, 则卖出}\n$$其中， $P_t$ 表示当前时刻的价格, $MA(P,n)$ 表示价格 $P$ 的 $n$ 周期移动平均线。当然，实际的策略交易系统会复杂许多，你需要考虑更多的因素运用更复杂的模型。策略交易的优势在于其纪律性、高效性和风险可控性 。它能够帮助投资者克服人性的弱点，避免情绪化操作带来的损失，并通过程序化交易提高交易效率，同时利用量化模型对风险进行有效管理。当然，策略交易并非万能的“圣杯”。它也面临着模型失效、过度优化以及黑天鹅事件等挑战。因此，深入理解策略交易的原理、构建方法以及潜在风险，对于投资者而言至关重要。本文就将简单介绍一下几种简单的策略交易工具，权当是我自己的知识库和备忘录了。一、现货/合约网格在策略交易中，网格交易尤其经典且应用广泛，适合用在震荡行情（波动率较高且价格趋势相对横盘的市场）。网格交易通过在不同价格区间内买入卖出的方式不断赚取每一个价格波动中的差价，从而在市场的不确定性中寻找稳定的获利机会。因为现货网格和合约网格差不太多，只是合约网格可以加杠杆，因此我就不在这里专门介绍合约网格了。1.什么是现货网格现货网格是指专门针对现货市场（如数字货币现货、股票等）设计的网格交易策略，现货网格策略的核心思想是将资产价格波动划分成若干价格区间，如网格的格子一般，并按照预设规则，在价格触及网格线时持续买入或卖出资产。其本质是一种高抛低吸 的自动化交易策略，且无需对市场的未来趋势有准确预测，只需依赖价格在一定范围内的波动即可获利。我们假设当前资产的价格为 $P$ ,操作时设置以下几个关键参数：网格区间： 设定价格的下限 $Plow$ 和上限 $P_{\\text{high}}$；网格数量： 将区间划分为 $n$ 个等间隔网格，每个网格的间距为：$$\n\\Delta P = \\frac{P_{\\text{high}} - P_{\\text{low}}}{n}\n$$初始资金分配： 确定投资资产和现金的起始比例，例如 50% 资产和 50% 现金。运作时，当价格下跌至某一网格线时，策略自动买入资产；当价格上涨至某一网格线时，策略自动卖出资产，从而不断低买高卖，赚取区间内的波动收益。2. 如何实现现货网格策略？现货网格的具体实施流程可以归纳为以下三个步骤：(1) 划分网格将价格区间从 $P_{\\text{low}}$ 到 $P_{\\text{high}}$ 均匀划分。例如，假设价格区间为 $10 到 20$，设置 $5$ 个网格，则每个网格的间距 $\\Delta P$ 为：\n$$\n\\Delta P = \\frac{20 - 10}{5} = 2\n$$\n网格价格点为 $10, 12, 14, 16, 18, 20$。(2) 配置初始资金根据网格设计，分配一定比例的现货资产和现金，用以在网格内实现买卖。例如，如果账户总资金为 $10,000$，可以选择将 $5,000$ 拨为现货资产，$5,000$ 留作现金。(3) 执行策略当价格变动时，根据网格触发的规则进行交易：如果价格从 $14$ 下跌到 $12$：买入固定数量的现货。如果价格从 $14$ 上涨到 $16$：卖出固定数量的现货。以此类推，随着价格的波动不断进行买卖交易，每笔交易赚取固定的价差。(4) 示例假设某加密货币当前价格为 $100$，投资者设置网格区间为 $90$-$110$，划分为 $5$ 个网格（即每个网格 $4%$）。初始投资为 $10,000$，其中 $5,000$ 用于购买现货（初始持仓 50 个币），剩余 $5,000$ 保留为现金。如果价格从 $100$ 上升到 $104$（触及下一个网格线），策略卖出 $10%$ 的现货，获得 $5,200$ 的现金；如果价格又从 $104$ 回落到 $100$，策略买回同等数量的现货，补回 $50$ 个币，同时获利 $200$。这种通过不断“低买高卖”的方式，即使资产价格整体未发生显著变化，投资者也可以利用波动实现收益。3.总结现货网格技术是策略交易领域中备受欢迎的方法之一，其优势在于操作的简洁与稳定的盈利能力。首先，这种策略尤其适合于震荡行情，因为无需对市场价格的未来趋势进行判断，交易者仅需依赖价格的波动便可获利。而结合自动化程序执行交易后，现货网格策略将进一步减少人为干预所带来的情绪化错误，让交易过程更加高效和纪律化。此外，通过网格划分的设计，该策略能够在价格的波动中不断低买高卖，实现稳定的小额差价收益，堪称“稳健型策略”的代表。然而，这种看似完善的体系也有其局限性。例如，当面对价格单边上涨或单边下跌的行情时，网格策略可能难以有效应对，容易因追不上涨幅或无法及时止损而导致亏损。此外，由于现货网格需要同时配置现货资产与现金，在较小波动幅度里上下频繁交易可能会占用大量资金，降低资金的整体利用效率。更进一步来说，如果市场长期处于低波动且紧窄的区间内运行，这种策略的获利能力甚至可能不足以覆盖交易手续费。二、合约/现货马丁格尔马丁格尔策略的主要特色在于其加仓策略。马丁格尔起源于 18 世纪法国的赌场，最初是一种赌博策略，后来被逐渐应用于金融交易领域。而合约马丁格尔 ，顾名思义，是将马丁格尔策略应用于合约交易 （例如期货合约、永续合约等）中，通过杠杆效应放大收益，同时也放大了风险。还是一样，合约现货区别不大，在这一节就只介绍合约马丁格尔了。1.基本原理马丁格尔策略的核心思想是：在亏损时加倍下注，直到盈利为止 。在合约交易中，这意味着当交易出现浮动亏损时，策略会在原有仓位的基础上，以更高的杠杆倍数开立更大的仓位，以期望在价格反转时快速回本并盈利。策略的关键参数：初始仓位： 确定首次开仓的仓位大小和杠杆倍数。加仓条件： 设定触发加仓的条件，例如当浮动亏损达到一定比例时（例如，每亏损 10% 加仓一次）。加仓倍数： 确定每次加仓的倍数，经典的马丁格尔策略采用 2 倍加仓，即每次加仓的仓位大小是前一次的两倍。止盈条件： 设定盈利目标，当总仓位达到预设的盈利目标时，平仓所有仓位，结束本轮交易。2.运作逻辑合约马丁格尔策略的运作逻辑可以用以下公式来表示：假设初始仓位大小为 $S_0$，杠杆倍数为 $L_0$，初始开仓价格为 $P_0$。当价格下跌导致浮动亏损达到预设比例 $R$ 时，进行第一次加仓，加仓倍数为 $M$（通常为 2），则第一次加仓后的仓位大小 $S_1$ 和杠杆倍数 $L_1$ 为：$$\nS_1 = S_0 \\times M\n$$$$\nL_1 = \\frac{S_0 \\times L_0 + S_1 \\times L_0}{S_0 + S_1} = \\frac{S_0 \\times L_0 (1 + M)}{S_0 (1 + M)} = L_0\n$$可以看到，每次加仓时杠杆倍数维持不变，但是总仓位变大了。假设当前价格为 $P_1$，则第一次加仓后的平均开仓价格 $P_{\\text{avg1}}$ 为：$$\nP_{\\text{avg1}} = \\frac{S_0 \\times P_0 + S_1 \\times P_1}{S_0 + S_1}\n$$以此类推，第 $n$ 次加仓后的仓位大小 $S_n$、杠杆倍数 $L_n$ 和平均开仓价格 $P_{\\text{avg,n}}$ 为：$$\nS_n = S_0 \\times M^n\n$$$$\nL_n = L_0\n$$$$\nP_{\\text{avg,n}} = \\frac{S_0 \\times P_0 + S_1 \\times P_1 + \\dots + S_n \\times P_n}{S_0 + S_1 + \\dots + S_n}\n$$当价格反弹使得总仓位盈利达到预设目标时，策略会平掉所有仓位，完成一次马丁格尔循环。3.优劣分析合约马丁格尔策略最大的优点就是理论上可以在价格反转时快速回本并盈利，但其风险也极高（毕竟是赌徒发明的）。首先，此策略爆仓风险高，由于采用杠杆交易，且在亏损时不断加仓，一旦价格持续向不利方向移动，账户将面临巨大的爆仓风险。尤其是当加仓次数过多，仓位过重时，即使很小的价格波动也可能导致爆仓。资金需求限制：马丁格尔策略需要充足的资金来支持不断加仓的操作。如果资金不足，将无法完成一个完整的马丁格尔循环，导致前功尽弃。心理压力大：持续的亏损和不断加大的仓位会给交易者带来巨大的心理压力，容易导致非理性的交易决策。三、智能套利套利策略的主要优势是低风险和相对稳健。随着人工智能和大数据技术的发展，智能套利 正逐渐成为套利领域的新宠，它利用先进的算法和强大的算力，捕捉更广泛、更隐蔽、更短暂的套利机会，并实现自动化交易，大大提高了套利效率和收益率。1.简介套利 ，简而言之，就是利用同一资产在不同市场或不同形式之间的价差 进行交易，从而获取无风险或低风险的利润。传统的套利策略，如跨市场套利 、跨期套利 、三角套利 等，主要依赖人工盯盘和手动操作，效率较低，且难以捕捉瞬息万变的套利机会。智能套利 则是在传统套利的基础上，引入了人工智能、机器学习等技术，构建复杂的数学模型，对海量的市场数据进行实时分析，自动识别和执行套利机会。它可以实现：全市场、多品种、7x24 小时监控： 突破人工盯盘的局限，对全球多个市场、多个交易品种进行全天候监控，不错过任何潜在的套利机会。复杂套利策略的构建： 除了简单的价差套利，智能套利还可以构建更复杂的套利模型，例如涉及多个品种、多个市场、甚至包含期权等衍生品的套利策略。毫秒级交易执行： 一旦发现套利机会，智能套利系统可以自动下单，并在毫秒级别完成交易，确保以最优价格成交，避免因延迟交易而错失良机。动态风险控制： 智能套利系统可以根据市场波动和风险指标，动态调整仓位和交易参数，控制套利交易的风险。2.智能套利的常见类型(1) 统计套利统计套利是智能套利中应用最广泛的一种类型。它利用历史数据和统计模型，发现资产之间的协整关系 或均值回归 特性，构建套利模型。例如，如果两种资产在历史上存在稳定的价差关系，当价差偏离历史均值时，就可以进行套利交易，预期价差将回归到均值水平。一般的统计套利首先会经历数据收集预处理等的前期准备，然后再利用统计学方法，例如协整检验、回归分析等，建立资产之间的关系模型，常用模型公式如下：$$\nY_t = \\beta_0 + \\beta_1 X_t + \\epsilon_t\n$$其中，$Y_t$ 和 $X_t$ 分别代表两种资产在 $t$ 时刻的价格，$\\beta_0$ 和 $\\beta_1$ 是回归系数，$\\epsilon_t$ 是误差项。模型构建后，会通过模型计算出的价差或残差，设定交易阈值。当价差或残差超过阈值时，触发交易信号。(2) 期现套利期现套利是指利用期货合约和现货资产之间的价差进行套利。由于期货合约存在到期日，其价格与现货价格之间存在一定的基差。当基差偏离合理范围时，就可以进行期现套利。例如，在数字货币市场中，永续合约是一种特殊的期货合约，它没有到期日，但通过资金费率机制来锚定现货价格。当资金费率为正时，永续合约价格通常高于现货价格，此时可以卖出永续合约，同时买入现货资产，进行套利。反之，当资金费率为负时，可以进行反向套利。(3) 三角套利三角套利是指利用三种或多种资产之间的汇率差异进行套利。例如，在数字货币市场中，如果 BTC/USDT、ETH/USDT 和 ETH/BTC 三个交易对之间的汇率关系出现偏差，就可以进行三角套利。原理：在一个理想的、无摩擦的市场中，三种货币之间的汇率应该满足以下关系：$$\n\\text{Rate}{A/B} \\times \\text{Rate}{B/C} = \\text{Rate}_{A/C}\n$$例如，如果：1 BTC = 10,000 USDT (BTC/USDT 汇率)1 ETH = 250 USDT (ETH/USDT 汇率)那么理论上，1 ETH 应该等于 0.025 BTC (250 / 10,000)，即 ETH/BTC 的理论汇率应为 0.025。当实际的 ETH/BTC 汇率偏离理论汇率时，就产生了套利机会。示例：假设当前市场汇率为：1 BTC = 10,000 USDT (BTC/USDT = 10,000)1 ETH = 250 USDT (ETH/USDT = 250)1 ETH = 0.026 BTC (ETH/BTC = 0.026)此时，ETH/BTC 的实际汇率 (0.026) 高于理论汇率 (0.025)，存在套利空间。套利步骤如下 (假设初始资金为 1 BTC)：卖出 BTC，买入 USDT： 用 1 BTC 换取 10,000 USDT (1 * 10,000)卖出 USDT，买入 ETH： 用 10,000 USDT 换取 40 ETH (10,000 / 250)卖出 ETH，买入 BTC： 用 40 ETH 换取 1.04 BTC (40 * 0.026)通过以上步骤，初始的 1 BTC 变成了 1.04 BTC，盈利了 0.04 BTC，收益率为 4%。更详细的计算过程：我们可以用以下公式来计算套利利润：$$\n\\text{Profit} = \\text{Initial Amount} \\times (\\frac{\\text{Rate}{1}}{\\text{Rate}{2}} \\times \\text{Rate}_{3} - 1)\n$$其中：$\\text{Initial Amount}$ 是初始资金量$\\text{Rate}_{1}$ 是第一个交易对的汇率（用中间货币兑换目标货币）$\\text{Rate}_{2}$ 是第二个交易对的汇率（用基础货币兑换中间货币）$\\text{Rate}_{3}$ 是第三个交易对的汇率（用目标货币兑换基础货币）在上面的例子中：$\\text{Initial Amount} = 1 \\text{ BTC}$$\\text{Rate}_{1} = \\text{BTC/USDT} = 10,000$$\\text{Rate}_{2} = \\text{ETH/USDT} = 250$$\\text{Rate}_{3} = \\text{ETH/BTC} = 0.026$套利利润为：$$\n\\text{Profit} = 1 \\times (\\frac{10,000}{250} \\times 0.026 - 1) = 1 \\times (40 \\times 0.026 - 1) = 1 \\times (1.04 - 1) = 0.04 \\text{ BTC}\n$$当然的当然，上述计算过程里没有考虑到交易手续费，在实际操作中你需要计算实际的手续费，也一般没啥套利空间了。三角套利对交易速度要求极高，通常需要使用程序化交易才能捕捉到套利机会（毫秒），在成熟的市场中套利空间通常很小，且很快会被套利者抹平。四、定投策略1.核心原理定投策略，又称为定期定额投资策略（Dollar-Cost Averaging, DCA） ，是一种旨在平滑市场风险的被动投资策略。其核心是持续以固定金额在固定周期内购买某种资产，无论市场价格高低，始终坚持执行投资计划。通过这一方法，投资者能够在市场下跌时购买更多的资产单位，而在市场上涨时则购买较少的资产单位，最终降低投资的成本均值。2.数学推导与优势假设投资者在每期以固定金额 $P$ 购买某种资产，而资产在不同周期内的价格为 $S_t$，则累计购买的资产总量 $Q$ 可表示为：$$\nQ = \\sum_{t=1}^n \\frac{P}{S_t}\n$$定投策略的优势主要在于其可以平滑市场波动风险，作为投资者可以无需判断市场时机，通过分批买入摊薄价格波动带来的影响，当资产价格下跌时，定投有助于降低持仓平均成本，从而改善盈利条件。相较于一次性投资，定投在下跌行情中也更容易感知到“抄底”的心理优势。适用场景：波动性较大的资产： 如股票、指数基金、加密货币等，这些资产可能具备长期上涨潜力，但短期价格往往剧烈波动。长期视角的投资者： 定投的优势通常需要较长周期才能显现出来。中译中就是你长期看好这个资产，那么就可以定投买入了。3.实际推演以传统基金定投为例，假设某投资者每月定投 100刀 到一支基金中，分别在以下周期内进行买入操作：首次买入价格 10刀，之后价格波动为 9、11、8、12，则每月对应的购买份额为：第 1 月买入：$\\frac{100}{10} = 10$ 份;第 2 月买入：$\\frac{100}{9} \\approx 11.11$ 份;第 3 月买入：$\\frac{100}{11} \\approx 9.09$ 份;第 4 月买入：$\\frac{100}{8} = 12.5$ 份;第 5 月买入：$\\frac{100}{12} \\approx 8.33$ 份。五个月总投入为500刀，总购买份额约为 51.03刀，计算得出的平均成本约为9.80刀，低于直观价格平均值10刀。五、信号策略1.核心原理信号策略是一种主动型投资方式，通过解读市场的技术指标、量化信号或基本面数据，在触发特定条件时执行买入或卖出操作。这类策略的目标通常是提高资金使用效率，以捕捉市场的短期趋势或重要反转点。可能的指标：技术指标： 运用移动平均线、RSI（相对强弱指数）、布林带等技术工具判断买卖机会。量化分析： 利用历史数据和统计模型，设计公式或算法确定交易信号。基本面分析： 结合资产估值或宏观经济数据，在收益风险比相对较优的情况下做出决策。2.数学模型实现以双均线交叉策略为例，这是技术分析中一种应用广泛的信号方法，基于短期均线（$MA_{short}$）和长期均线（$MA_{long}$）的交叉点来判定市场趋势变动方向。短期均线的计算公式为：$$\nMA_{short} = \\frac{1}{n_{short}} \\sum_{i=0}^{n_{short}-1} P_{t-i}\n$$长期均线的计算公式为：$$\nMA_{long} = \\frac{1}{n_{long}} \\sum_{i=0}^{n_{long}-1} P_{t-i}\n$$其中，$P_t$ 是时间 $t$ 时的资产价格，$n_{short}$ 和 $n_{long}$ 分别为短期和长期均线窗口。策略规则：当 $MA_{short} > MA_{long}$ 时，生成买入信号；当 $MA_{short} < MA_{long}$ 时，生成卖出信号。类似的，其他技术信号如 RSI（超买或超卖）、布林带（突破上下轨）等均基于特定条件触发交易指令。3.优劣势分析信号策略的优势在于能够主动应对市场变化，特别是在波动性加剧的行情中，具备潜在的收益放大效果。然而，与定投策略相比，信号策略也面临三方面的风险与挑战：过度交易： 频繁的交易行为可能导致高额交易成本，侵蚀利润。信号失真： 在震荡市或低流动性市场中，信号的精确性容易受到干扰。技术复杂性： 复杂的交易算法或模型需要充足的数据支持，如过拟合问题可能导致策略失效。"
  },
  {
    "title": "国行Xbox series X/S账户转港区教程",
    "summary": "作为一位老Gamer，我最近终于下定决心买了御三家中的Xbox（狗东国行Xbox Series X）。众所周知，国行在游戏库和XGP上相较于另外五个区域存在较大的限制。为了体验更多的优质游戏和享受XGP服务，我决定尝试将Xbox账号从国行转到港区。如果你也和我一样，希望摆脱国行 Xbox 的限制，拥抱更完整的游戏体验，那么这篇博客将为你提供一份详细、亲测有效的保姆级教程。 我将一步步记录我转区的整",
    "tags": [],
    "url": "/posts/TechnicalTutorials/xbox-hk-tutorial/",
    "date": "2024-12-29T00:00:00.000Z",
    "content": "作为一位老Gamer，我最近终于下定决心买了御三家中的Xbox（狗东国行Xbox Series X）。众所周知，国行在游戏库和XGP上相较于另外五个区域存在较大的限制。为了体验更多的优质游戏和享受XGP服务，我决定尝试将Xbox账号从国行转到港区。如果你也和我一样，希望摆脱国行 Xbox 的限制，拥抱更完整的游戏体验，那么这篇博客将为你提供一份详细、亲测有效的保姆级教程。 我将一步步记录我转区的整个过程，包括：转区前的准备工作详细的操作步骤及注意事项转区后该怎么做希望我的经验可以帮你少走弯路，爽完玩GP！一、前期准备工作一台Xbox游戏机（当然！这里指的是你的国行Xbox Series X/S 主机）一个u盘（容量无需太大，建议至少 1GB 以上 ，需要格式化为 NTFS 格式 ）一台运行着Windows系统的电脑（MacBook跑win虚拟机也可）二、开始操作1.格式化硬盘并转换格式和分区首先，你需要用Windows系统把U盘格式化成NTFS格式，并转化成MBR分区！这一步非常重要，我就是因为网上绝大多数教程只提格式化成NTFS格式没有提MBR分区导致浪费了一个小时的时间。如何操作：打开cmd窗口单击“Win + R”，在“运行”窗口中键入“cmd”，打开终端；在终端中输入以下命令：diskpart接着输入：list disk找到你的U盘对应的磁盘号（注意核对容量大小），假设是磁盘1，继续输入：select disk 1接下来清除所有的数据和分区：clean然后输入转换命令：convert mbr完成后你的U盘就被格式化为NTFS格式并转换为MBR分区了。最后，你需要打开Windows的磁盘管理工具，给你格式化后的u盘新建一个简单卷，具体步骤如下：右键点击\"此电脑\"，选择\"管理\"在\"计算机管理\"窗口中，找到并点击\"磁盘管理\"找到你的U盘（通常显示为\"未分配\"状态）右键点击未分配空间，选择\"新建简单卷\"按照向导完成操作，选择NTFS格式，分配驱动器号（卷名不要用中文字符）u盘硬件方面就此准备完成！2.准备我们的妙妙小代码打开 Windows 资源管理器，开启文件扩展名显示： 在资源管理器窗口上方菜单栏中，点击“查看”选项卡，勾选“文件扩展名”选项。这一步是为了确保我们能够正确修改文件的后缀名。打开 U 盘根目录（即直接打开 U 盘后看到的目录，不要进入任何文件夹）。在空白处右键单击，选择“新建” -> “文本文档”。将新建的文本文档命名为：$ConsoleGen9 （注意：如果你的 Xbox 是 Xbox One 系列，则应命名为 $ConsoleGen8） 。这里需要特别注意，务必删除 .txt 后缀，确保文件名只有 $ConsoleGen9 或 $ConsoleGen8。准备就绪，插入 U 盘： Xbox 无需关机，保持开机状态。首先进入 Xbox 的系统设置：依次选择“系统” -> “时间和语言” -> “区域”，停留在 “区域” 这个页面。然后将包含“神秘代码”文件的 U 盘插入 Xbox 主机的 USB 接口。重启设备： 稍等片刻，Xbox 屏幕下方会出现“已连接到移动存储设备”的提示。此时，直接选择屏幕上最右侧的“重启”选项（即硬重启）。3.转区如果你所有的操作都严格按照了上文要求，那么你大概率一次重启之后就可以在“区域”页面里修改自己的地区和语言了。直接选择港服即可，因为港区是除国行外所有区域里唯一可以直接用支付宝的地区。三、转区后直接去某宝上买XGP会员即可，然后爽玩！"
  },
  {
    "title": "Trading101：简析投资中常见的技术指标和其背后的逻辑",
    "summary": "我们都知道股票投资市场中的交易本质上是因为价格不认可而产生。每一次交易达成实际上就代表这笔交易的空方和多方互喷互骂对方没有眼光，双方都在心里默念“谢谢你，我的对手盘”。事实上，这就是市场价格形成的微观机制：预期差。正是因为多空双方对标的资产未来价值的预期存在分歧，才会在某一价格点位上达成交易。卖方（空方）认为价格已高估或未来将下跌，而买方则认为价格尚低估或未来将上涨。因此，任何一个时刻下的价格，都",
    "tags": [
      "投资101"
    ],
    "url": "/posts/Finance and Economics/Trading101-investing-indicator-logic/",
    "date": "2024-12-23T00:00:00.000Z",
    "content": "我们都知道股票投资市场中的交易本质上是因为价格不认可而产生。每一次交易达成实际上就代表这笔交易的空方和多方互喷互骂对方没有眼光，双方都在心里默念“谢谢你，我的对手盘”。事实上，这就是市场价格形成的微观机制：预期差。正是因为多空双方对标的资产未来价值的预期存在分歧，才会在某一价格点位上达成交易。卖方（空方）认为价格已高估或未来将下跌，而买方则认为价格尚低估或未来将上涨。因此，任何一个时刻下的价格，都是无数因素博弈后，买卖双方力量达到均衡的状态，是双方的共识。直到有因素影响买卖双方的力量对比，平衡被打破，价格出现变动，朝一个方向持续运动，这就会出现趋势行情，直到趋势终结，买卖双方达到新的平衡，新的共识。新平衡状态下，价格在一个区域内波动，这就是震荡行情。行情在趋势和震荡之间，反复切换。基于上述的预期差的博弈关系，我们人类中最聪明的那部分大脑提出了技术分析中的大量指标工具。技术指标通过提取交易数据（如价格、成交量等）中的规律性特征，帮助投资者识别市场趋势、反转信号以及超买超卖的状态。在本文中，我们将介绍几种投资中常见的技术指标，并讨论它们的应用场景和局限性。一、VOLUME（成交量）成交量指的是在特定时间段内（例如一天、一周或一个月）交易的股票或其他金融资产的总数量。它是衡量市场活跃度和流动性的重要指标。我们进行分析的核心思路之一就是结合成交量指标进行量价分析。在量价分析中，价指的是价格，通常指收盘价；量指的是成交量，代表了一定时间内市场交易的活跃程度。成交量就好比是市场的“动能”，价格的变动需要有成交量的配合才能持续和有效。通过分析价格变动和成交量变化之间的关系，我们可以更好地判断市场趋势的强弱，识别潜在的买卖机会。\n示例图简单来说，我们可以把量价关系概括为四种基本情况：价涨、价跌、量增、量缩。这四种情况的排列组合构成了以下八种主要的量价关系：1.价涨：（1）价涨量增：解析： 这是最健康的上涨模式，表示市场人气旺盛，买方力量强劲，推动价格上涨的同时伴随着成交量的放大。这种情况下，上涨趋势大概率将持续。这种情形也常被描述为量价齐扬。图示： 价格上涨，成交量柱体同步增长。公式举例 (非严格公式，仅示意)：\n如果第 $t$ 日收盘价为 $P_t$，成交量为 $V_t$，那么价涨量增可以表示为：\n$P_t > P_{t-1}$ 且 $V_t > V_{t-1}$。（2）价涨量缩：解析： 这表示价格上涨，但成交量却在萎缩。这可能是上涨趋势中的短期调整，也可能是上涨趋势即将结束的信号。这通常意味着上涨动能减弱，市场追涨意愿不强，需要警惕价格反转下跌的风险。此时，价格还继续上涨可能是少数筹码就能拉动价格上涨造成的。这在熊市反弹中较为常见，多头动能不足，只是空头暂时力量衰竭导致的。也可能出现在牛市主升浪中，由于筹码高度集中，导致上涨时量能已经无法进一步放大。具体是哪种情况，需要结合实际情况进行判断。图示： 价格上涨，但成交量柱体较之前缩小。公式举例 (非严格公式，仅示意)：\n$P_t > P_{t-1}$ 且 $V_t < V_{t-1}$。（3）价涨量平：解析： 价格上涨，但成交量保持相对平稳，没有明显变化。这通常表示市场在延续之前的上涨趋势，但缺乏新的增量资金进场。上涨动能可能有所减弱，需要观察后续成交量的变化来判断趋势是否能够持续。图示： 价格上涨，但成交量柱体高度与之前大致持平。公式举例 (非严格公式，仅示意)：\n$P_t > P_{t-1}$ 且 $V_t ≈ V_{t-1}$。2.价跌：（1）价跌量增：解析： 这表示价格下跌，同时成交量放大。这通常是一个危险的信号，表示市场恐慌情绪蔓延，卖方力量强大，抛售行为增加，加速了价格下跌。如果出现在高位，可能是头部形成的信号；如果出现在下跌途中，可能是下跌中继；如果出现在长期下跌后的低位，则有可能是最后一跌，需要结合其他指标和市场环境综合判断。图示： 价格下跌，成交量柱体放大。公式举例 (非严格公式，仅示意)：\n$P_t < P_{t-1}$ 且 $V_t > V_{t-1}$。（2）价跌量缩：解析： 这表示价格下跌，但成交量萎缩。这种情况比较复杂，需要具体分析。如果出现在下跌初期，可能是下跌趋势的开始，表示买盘不济，少量卖单就能打压价格；如果出现在长期下跌后的低位，则可能是市场惜售的表现，表示卖方力量已经衰竭，下跌动能减弱，有可能是底部临近的信号。图示： 价格下跌，成交量柱体缩小。公式举例 (非严格公式，仅示意)：\n$P_t < P_{t-1}$ 且 $V_t < V_{t-1}$。（3）价跌量平：解析： 价格下跌，但成交量保持平稳。这种情况表明市场仍然处于下跌趋势中，但空方力量并没有进一步增强。这可能表示多空双方都较为谨慎，市场观望情绪浓厚。需要观察后续成交量的变化来判断下跌趋势是否会持续或反转。图示： 价格下跌，成交量柱体高度与之前大致持平。公式举例 (非严格公式，仅示意)：\n$P_t < P_{t-1}$ 且 $V_t ≈ V_{t-1}$。3.特殊：（1）价平量增：解析： 价格几乎没有变动，但成交量显著增加。这通常出现在重要支撑位或阻力位附近，表示多空双方在此位置展开激烈争夺。如果最终价格选择向上突破，则可能是买方力量占据上风；如果向下突破，则可能是卖方力量胜出。此情况也需要结合整体走势综合判断。图示： 价格几乎不变，但成交量柱体明显放大。公式举例 (非严格公式，仅示意)：\n$P_t ≈ P_{t-1}$ 且 $V_t > V_{t-1}$。（2）价平量缩：解析： 价格几乎没有变动，成交量也显著萎缩。这通常表示市场观望情绪极度浓厚，多空双方都缺乏交易意愿。这种情况常出现在长期盘整阶段的末期，预示着即将到来的重大趋势性变动。图示： 价格几乎不变，成交量柱体非常矮小。公式举例 (非严格公式，仅示意)：\n$P_t ≈ P_{t-1}$ 且 $V_t < V_{t-1}$。总结:以上八种量价关系是市场中最常见的形态，每种形态都代表了不同的市场含义。在实际分析中，我们需要结合具体的市场环境、趋势位置、K线形态以及其他技术指标来进行综合判断，才能更准确地把握市场的脉搏。需要牢记的是，量价关系不是绝对的，没有哪一种量价关系能够保证价格一定会上涨或下跌，它们只是提供了一种观察市场和辅助决策的视角。二、MA（Moving Average，移动平均线）1.介绍MA是一种趋势跟踪指标，它通过对指定时间段内的价格（常为收盘价）求平均，从而得到一条平滑的曲线。MA去除了价格中的噪声波动，可以帮助我们专注于价格的总体方向。核心作用：识别趋势方向： 判断市场是处于上升趋势、下降趋势还是横盘整理。支撑与阻力： 在上升趋势中，MA 经常成为支撑位；而在下降趋势中，它经常充当阻力位。交易信号： 如金叉和死叉，这二者是MA中最常用的买卖信号。\n示例图2.MA指标的分类根据计算方式和参数的不同，MA 可分为以下几类：（1）简单移动平均线 (Simple Moving Average, SMA)：定义：对指定时间段内的价格进行简单平均，例如 5 日均线是最近 5 天的收盘价之和除以 5。优点：容易计算、直观。缺点：对最新价格变化反应较慢，容易滞后。（2）指数移动平均线 (Exponential Moving Average, EMA)：定义：对较近的价格赋予更高权重，因此 EMA 比 SMA 更能快速反映价格变化。优点：敏感性高，更适合短期交易者。缺点：由于对近期价格赋予更高权重，容易受到短期波动干扰。（3）加权移动平均线 (Weighted Moving Average, WMA)：定义：为每个时间段的价格赋予不同的权重，一般是将最近数据的权重设为最高。优点：在敏感性和稳定性之间取得平衡。缺点：较 SMA 更复杂，使用相对少见。这些指标都是如何计算的呢？MA 的计算非常简单，只需要将选定时间段内的价格求平均。以 5 日简单移动平均线为例：$SMA = \\frac{P_1 + P_2 + P_3 + P_4 + P_5}{5} $其中，$ P_1, P_2, ..., P_5 $ 表示最近 5 天的收盘价。而对于 EMA，其计算公式稍微复杂一些，需要计算平滑系数  $ \\alpha $，公式如下：$$\nEMA_t = (P_t \\cdot \\alpha) + [EMA_{t-1} \\cdot (1 - \\alpha)]\n$$其中：$P_t$：当天的价格 (通常是收盘价)$EMA_t$：当天的 EMA$EMA_{t-1}$：前一日的 EMA$\\alpha = \\frac{2}{n+1}$，$n$ 表示移动平均线的周期。3.MA参数的选择和优劣分析根据我们不同的投资需求，MA的投资参数主要有以下几个：短期均线 (如 5 日、10 日): 适用于捕捉短期波动，用于快进快出的短线交易。中期均线 (如 20 日、50 日): 适用于捕捉中期趋势。长期均线 (如 100 日、200 日): 适用于识别长期趋势，常用于牛熊市的判断。一般的，我们认为MA指标的优点在于简单明了，计算方式容易理解，门槛较低。其作为趋势指标可以有效过滤短期波动，识别长期趋势，还可用来识别支撑阻力、进行趋势判断和信号提示。但MA指标同时也不可避免的具有滞后性，信号滞后于价格变化。此外，在横盘震荡时，MA经常发出假信号，参数设置的不同会显著影响结果，导致解读偏差。三、BOLL（Bollinger Bands, 布林带）布林带 (Bollinger Bands)，又称布林通道，是由约翰·布林格 (John Bollinger) 在 1980 年代发明的技术分析工具，广泛应用于股票、期货、外汇等各种投资市场。它通过统计学原理中的标准差概念，勾勒出价格的波动范围，从而帮助投资者判断市场状态、寻找交易机会。\n示例图1.布林带的构成：三条轨道线布林带由三条线组成，分别是：中轨 (Middle Band): 通常是一条 N 日的简单移动平均线 (SMA)。最常见的参数 N 为 20，即 20 日均线 (公式如下)。中轨 = N日收盘价之和 / N上轨 (Upper Band): 在中轨的基础上加上 K 倍的 N 日标准差。标准差反映了价格偏离平均值的程度，也就是价格的波动性。上轨 = 中轨 + K * (N日的标准差)下轨 (Lower Band): 在中轨的基础上减去 K 倍的 N 日标准差。下轨 = 中轨 - K * (N日的标准差)其中，K 值通常设置为 2。这意味着上下轨包含了大约 95% 的价格波动范围（基于正态分布的假设）。2.标准差的计算理解标准差的计算对于理解布林带至关重要。标准差的计算公式如下：计算每个交易日的 (收盘价 - N日收盘价均值) 的平方。将过去 N 个交易日的上述平方值加总。将总和除以 N。将结果开平方根。标准差 = √[∑(收盘价 - N日收盘价均值)² / N]简而言之，标准差越大，说明价格波动越剧烈；标准差越小，说明价格波动越平缓。3.布林带指标解读：布林带的宽度和位置提供了丰富的市场信息：带宽 (Bandwidth)： 上轨与下轨之间的距离称为带宽。带宽扩大： 表明市场波动性增加，可能预示着趋势的开始或加速。带宽收窄： 表明市场波动性降低，可能处于盘整状态，也可能预示着即将到来的突破。当带宽极度收窄时，称为“布林带收缩”(Bollinger Squeeze)，往往预示着重大行情即将发生。价格与轨道的关系：价格在中轨上方运行： 倾向于认为市场处于上升趋势。价格在中轨下方运行： 倾向于认为市场处于下降趋势。价格突破上轨： 可能表示市场超买 ，但也可能是强势上涨的信号，需结合其他指标判断。价格跌破下轨： 可能表示市场超卖 ，但也可能是强势下跌的信号，需结合其他指标判断。价格在中轨附近波动： 表明市场可能处于震荡或盘整状态。当价格持续沿着上轨运行，且布林带开口向上，可视为上升趋势的确认，考虑买入；反之，当价格持续沿着下轨运行，且布林带开口向下，可视为下降趋势的确认，考虑卖出。当价格触及或突破上轨时，可以考虑卖出，特别是当价格从上轨回落时；当价格触及或跌破下轨时，可以考虑买入，特别是当价格从下轨反弹时。此外，当布林带极度收窄后，一旦价格向上突破上轨，且伴随成交量放大，通常是买入信号；反之，当价格向下突破下轨，且伴随成交量放大，通常是卖出信号。四、SAR (Parabolic Stop and Reverse, 抛物线转向指标)SAR指标，中文称之为抛物线转向指标，是由著名技术分析大师 J. Welles Wilder 提出的技术分析工具，旨在识别市场趋势的方向，并提供潜在的趋势反转点和交易信号。它是一种动态的交易指标，常用于趋势交易系统，与止损策略结合得尤为紧密。\n示例图1.基本原理SAR的核心思想是在一个趋势中，价格通常倾向于沿着某个方向运行，直到趋势结束，而 SAR 通过在趋势中动态调整 \"跟踪点\" 来提示可能的反转。\"SAR\" 的意思是 \"停止并反转\" ，即当价格触发当前的停止点（Stop Point）时，意味着趋势可能反转。SAR 指标通常以点或小圆圈的形式绘制在价格图表的上方或下方，当点位于价格 下方 ，表明为上涨趋势，SAR 提示为支撑；当点位于价格 上方 ，表明为下跌趋势，SAR 提示为阻力。该指标还有一个特点：随着时间的推移，它会逐步 \"追踪\" 价格，不断收紧对价格的容忍范围。最终，当价格偏离当前趋势时，它会提示趋势可能反转。2.指标计算方式这个指标计算起来比较复杂，步骤和核心概念如下：(1) 初始值（EP 和 AF 的定义）：EP (Extreme Point, 极值点)：在上涨趋势中，EP 表示当前趋势中出现的最高点。在下跌趋势中，EP 表示当前趋势中出现的最低点。AF (Acceleration Factor, 加速因子)：加速因子是一个控制 SAR 灵敏度的参数，初始值通常设为 0.02 ，每当价格创造新高或新低时，加速因子会逐步增加（默认为每次递增 0.02），但其最大值通常限制为 0.2 。AF 的作用：AF 越大，SAR 越敏感，但更容易出现假突破。AF 越小，SAR 趋于平滑但可能反应迟钝。(2) SAR 的递推公式：SAR 的计算公式如下：当前 SAR = 前一 SAR + 加速因子 (AF) × (极值点 EP - 前一 SAR)该公式的核心逻辑是：SAR 会随着趋势延续而不断向新的极值点靠近。如果趋势向下，SAR 将逐步降低；如果趋势向上，SAR 将逐步升高。(3) 反转条件：SAR 一旦穿越价格，其值将重新从下一根 K 线的极值点开始计算，并且趋势方向由多转空或由空转多，实现 \"停止并反转\"。3.优劣势分析优点：简单直观： 图表上的点清晰显示了趋势方向和潜在的反转。动态止损： SAR 能帮助投资者动态调整止损位，锁定利润或控制风险。趋势系统利器： 它在单边趋势行情中表现优异，可以减少不必要的交易噪音。缺点：震荡行情失灵： 在盘整或震荡行情中，SAR 往往发出频繁的虚假信号，因此投资者需格外警惕。滞后性： SAR 是滞后指标，它的信号需要等待价格变动，不适用于捕捉快速反转。敏感度难以调节： 如果加速因子设定不当，可能导致指标过于敏感或反应过慢，投资者需要根据市场实际情况调整参数。实际应用思路：牛市期间：随着价格不断创新高，SAR 点位逐渐跟随价格上移。在趋势延续的过程中，SAR 点位与价格保持较大距离，为投资者提供持仓空间。一旦价格回落并突破 SAR 点位，则视为反转信号，提示卖出。震荡行情：在价格上下波动但未形成明显趋势时，SAR 点会频繁穿越价格，导致假信号。这种情况下，应避免依赖 SAR，结合其他指标（如布林带或 RSI）更为稳妥。五、总结：种类繁多的技术指标到底是什么？1.本质一：技术指标是市场数据的「提炼与模块化」我们智人的注意力和计算能力都是有限的，市场价格、成交量等数据浩繁且波动频繁，难以观测。技术指标的作用就在于通过数学公式从混乱的数据中提炼出有意义的规律或趋势，将复杂的问题简单化，混沌的现象规律化。例如：均线 (MA) 将过去一段时间的价格数据平滑化，提炼出趋势的「方向」；RSI (相对强弱指数) 提炼出市场的「超买」或「超卖」状态；布林带 (BOLL) 提炼出价格波动的「区间」范围和市场的「波动性大小」。换句话说，技术指标是一组工具，它们抽象化了市场的关键动态，并将其呈现为我们更容易解读的形式。2.本质二：技术指标是「人类心理与市场行为的展现」金融市场的核心驱动力来源于参与者的交易行为，而交易行为本质上又受到人类心理、情绪和偏好的影响。技术指标虽然基于数学公式，但其背后的意义往往隐含了交易者的行为模式和群体心理。例如：当价格突破某条移动平均线（如 50 日均线），意味着很多投资者可能会认为市场进入了新的趋势，因此可能引发更多交易，这是一种群体行为的反馈机制 。RSI 超过 70 意味着市场可能过热，超买压力增加，投资者可能倾向于获利了结，这反映了市场心态的变换。因此，技术指标可以看作是市场行为和投资者心理的「影子」，它记录并揭示了这些行为和心理的规律。3.本质三：技术指标是也只是一种「统计概率模型」绝大多数技术指标都基于历史数据进行计算，因此它们本质上是滞后的。换句话说，技术指标反映的是已经发生的事情，而非正在发生或者即将发生的事情。这种滞后性是由其计算机制决定的，因此投资者不能完全依赖技术指标预测未来。在实际博弈中，市场也并非严格遵循历史模式来运行，因此技术指标使用的「推测性」也容易导致误判。双均线交叉系统 （如短期均线上穿长期均线）并不能每一次都预测趋势，但在历史中，这个现象可能在多数情况下与趋势上涨的概率相关。技术指标本质上依赖于「统计学上的过去是否对未来有参考意义」，但市场的随机性本质仍然存在。技术指标的作用更倾向于提供过去数据的描述视角 ，并允许投资者在此基础上推测市场可能的未来走向，绝非什么庙算神器，不可神话技术分析。4.本质四：技术指标也是参与者共识的「映射」技术指标之所以有效，往往源于其广泛使用。当大量交易者都关注某一指标并根据其行为制定交易计划时，这个指标会自我强化，成为市场走势中不可忽视的一部分。当股价跌破某条知名均线（如 200 日均线），可能会触发大量投资者的止损行为，进而导致价格加速下跌。当 RSI 提示市场「超卖」，很多交易者会根据这一信号寻找买点，从而导致价格开始反弹。因此，技术指标并非完全由市场决定，而是大量市场参与者行为的反馈与共识的结果 ，技术指标的有效性源自其他参与者的认可和运用。技术指标的正确使用方式应该是与其他分析方法结合，基于投资者对市场的理解，制定自己的规则和策略，并辅以严谨的风险控制。用技术指标追求 \"完全掌控市场\" 是不现实的，但用它来提高交易效率、减轻决策负担，却是非常有用的。"
  },
  {
    "title": "新一代静态博客框架Astro的部署优化指南与使用体验",
    "summary": ":::caution\n本篇博客写于2024年12月，于5月18日少量更新，Astro和Fuwari项目可能会有更新，导致部分信息不再准确，请以官方文档为准。\n:::信源1.仓库::github{repo=\"withastro/astro\"}\n::github{repo=\"saicaca/fuwari\"}2.参考文章Astro官方文档给你的Fuwari添加一个友链页面利用giscus给你的网站添加评",
    "tags": [],
    "url": "/posts/TechnicalTutorials/astro-deploy-and-optimization/",
    "date": "2024-12-14T00:00:00.000Z",
    "content": ":::caution\n本篇博客写于2024年12月，于5月18日少量更新，Astro和Fuwari项目可能会有更新，导致部分信息不再准确，请以官方文档为准。\n:::信源1.仓库::github{repo=\"withastro/astro\"}\n::github{repo=\"saicaca/fuwari\"}2.参考文章Astro官方文档给你的Fuwari添加一个友链页面利用giscus给你的网站添加评论功能一、前言我一直以来都在寻找一个既能满足写作需求，又简单易懂容易上手的博客框架。\n最初，我选择了 Halo 作为我的博客框架。作为国产飞致云团队出品的有口皆碑的博客框架，halo以其简单易用的后端功能和优雅的文章管理迅速成为中文互联网播客圈内的主流框架之一。\n当然，享受动态博客框架的好，就得承担动态博客框架的代价：想运行WordPress和Halo这种动态框架，你需要至少准备一台性能好于1c1g的VPS你需要定期维护升级框架和对应的数据库文章数量多的话，对于博客框架的性能和稳定性会有影响因为我是一个懒人，懒得去维护服务器和数据库，受益于现代前端技术的发展，我开始在静态博客框架中寻求替代方案。\n最终，我在群友的推荐下选择了Astro框架和fuwari主题。二、Astro和fuwari介绍1.什么是 Astro？Astro 是一个现代化的静态站点生成框架，其核心目标是帮助开发者创建 快速、轻量、且以内容为核心 的网站。它于 2021 年首次发布，由于其独特的设计理念和对性能的极致追求，迅速在开发者社区中崭露头角。Astro主页Astro 的特性不仅专注于生成高性能的静态网站，还致力于降低开发门槛，同时提供与现代前端需求兼容的技术栈支持。这使得它成为博客站点、文档网站、甚至复杂 Web 项目的理想选择。2.Astro 的独特设计理念Astro 的开发核心理念可以用一句话概括：“Ship less JavaScript”（更少的 JavaScript 输出）。这意味着 Astro 会尽可能地减少前端 JavaScript 的加载，提供近乎纯静态的 HTML 页面，从而极大提升网站加载速度和用户体验，尤其适合内容导向型的站点，如博客、文档和营销页面。Astro 引入了一个非常独特的架构设计 —— 群岛架构（Islands Architecture）：在传统的静态站点中，页面通常是完全静态的；而在现代动态站点中，许多部分过度依赖 JavaScript。Astro 提供了一种两者兼得的方式：你可以定义页面中哪些部分是静态的（如文章内容），哪些部分是动态可交互的（如评论系统或搜索栏）。这种架构在提高性能的同时，确保了站点的交互能力。3.Astro 的核心特点零 JavaScript 默认输出：与传统框架（如 React、Vue）相比，Astro 默认不会输出多余的 JavaScript，仅生成纯静态的 HTML 和 CSS。这种轻量化的特性能显著减少浏览器的负担，使页面加载速度更快。支持多种框架：Astro 拥有惊人的灵活性，它允许开发者在同一个项目中同时整合多种前端框架（如 React、Vue、Svelte 和 SolidJS）。你可以选择最适合问题域的工具，而无需被某一个特定框架所限制。内容优先：Astro 是为内容驱动型网站设计的，特别适合博客、文档或新闻类项目。它能快速处理 Markdown 和 MDX，开发者可以轻松地将内容与组件结合。开箱即用的开发体验：Astro 提供了许多默认特性，如文件路由（File-based Routing）、内置的 Markdown 支持、静态资产优化、自动图片处理等；即使是不熟悉前端开发的用户，也能快速上手。扩展能力：Astro 拥有丰富的插件生态系统，可以轻松扩展功能，比如支持 TypeScript、Tailwind CSS、PWA 等技术栈。您还可以无缝接入第三方服务，比如 CMS 系统、数据库或者 API。4.Fuwari主题介绍Fuwari是基于 Astro 开发的静态博客模板。::github{repo=\"saicaca/fuwari\"}:::tip\n“ふわり (fuwari) ” 是一个日文词汇，常用来描述某种动作、感觉或状态，意境整体偏向轻柔、舒适、飘逸、无负担感，常用于描绘自然风景或者精致、柔和的物品与情感，是一个充满日语美感的拟声词/副词。\n:::alt text✨ 功能特性[x] 基于 Astro 和 Tailwind CSS 开发[x] 流畅的动画和页面过渡[x] 亮色 / 暗色模式[x] 自定义主题色和横幅图片[x] 响应式设计[ ] 评论[x] 搜索[ ] 文内目录三、部署教程1.准备工作首先的首先，你需要一个Github账号，你可以注册一个注册之后，你需要使用此模板生成新仓库或 Fork 此仓库然后，你需要进行本地开发，Clone 新的仓库，执行 pnpm install 和 pnpm add sharp 以安装依赖若未安装 pnpm，请执行 npm install -g pnpm在执行完上述命令后，你可以通过 pnpm dev 命令启动本地开发服务器，访问 http://localhost:4321 进行预览。2.博客自定义2.1 博客配置你可以通过配置文件 src/config.ts 自定义博客，这里以我自己的配置文件为例：博客基本内容：export const siteConfig: SiteConfig = {\n  title: '时歌的博客',\n  subtitle: '理解以真实为本，但真实本身并不会自动呈现',\n  lang: 'zh_CN',         // 在这里设置你的博客语言，'en', 'zh_CN', 'zh_TW', 'ja', 'ko'\n  themeColor: {\n    hue: 250,         // 在这里设置你的主题色， Default hue for the theme color, from 0 to 360. e.g. red: 0, teal: 200, cyan: 250, pink: 345\n    fixed: false,     // 选择是否固定主题色，默认false\n  },\n  banner: {\n    enable: true,\n    src: 'assets/images/blog-banner.webp',   // 在这里设置你的首页横幅图片，Relative to the /src directory. Relative to the /public directory if it starts with '/'\n    position: 'center',      // 在这里设置你的横幅图片位置，Equivalent to object-position, only supports 'top', 'center', 'bottom'. 'center' by default\n    credit: {\n      enable: false,         // 这里可以设置你的横幅图片的作者信息，Display the credit text of the banner image\n      text: '',              // Credit text to be displayed\n      url: ''                // (Optional) URL link to the original artwork or artist's page\n    }\n  },\n  toc: {\n    enable: true,           // 这里可以设置是否显示文章目录，Display the table of contents on the right side of the post\n    depth: 2                // 文章目录默认显示到2级，Maximum heading depth to show in the table, from 1 to 3\n  },\n  favicon: [    // Leave this array empty to use the default favicon\n    // {\n    //   src: '/favicon/icon.png',    // Path of the favicon, relative to the /public directory\n    //   theme: 'light',              // (Optional) Either 'light' or 'dark', set only if you have different favicons for light and dark mode\n    //   sizes: '32x32',              // (Optional) Size of the favicon, set only if you have favicons of different sizes\n    // }\n  ]\n}个人信息与联系方式：export const profileConfig: ProfileConfig = {\n  avatar: 'assets/images/avatar.jpg',  // 个人头像，Relative to the /src directory. Relative to the /public directory if it starts with '/'\n  name: '时歌',\n  bio: '理解以真实为本，但真实本身并不会自动呈现.',\n  links: [\n    {\n      name: 'QQ',\n      icon: 'fa6-brands:qq',       // 图标可以在 https://icones.js.org/ 中找到，Visit https://icones.js.org/ for icon codes\n                                        // 感谢溪午的指正，这里直接使用了本地图标集，不需要额外安装依赖\n      url: 'https://qm.qq.com/q/Qm6VfZnWM0',\n    },\n    {\n      name: 'NetEaseMusic',\n      icon: 'tabler:brand-netease-music',\n      url: 'https://music.163.com/#/user/home?id=1997803975',\n    },\n    {\n      name: 'GitHub',\n      icon: 'fa6-brands:github',\n      url: 'https://github.com/Lapis0x0',\n    },\n  ],\n}2.2 创建文章Astro框架是基于Markdown的，所以你可以在src/content/posts/目录中创建新的Markdown文件，编辑文章内容。\n你也可以在终端中执行 pnpm new-post <filename> 创建新文章，并在 src/content/posts/ 目录中编辑。文章格式：---\ntitle: My First Blog Post //文章标题\npublished: 2023-09-09 //文章发布日期\ndescription: This is the first post of my new Astro blog.  //文章描述\nimage: ./cover.jpg  //这是文章封面，路径可以是相对路径，也可以是绝对路径\ntags: [Foo, Bar] //文章标签\ncategory: Front-end //文章分类\ndraft: false //是否为草稿\nlang: jp      //仅当文章语言与 `config.ts` 中的网站语言不同时需要设置\n---2.3 部署如果你的博客基本信息已经设置完成，文章也已经迁移/创建好了，你可以选择参考官方指南将博客部署至 Vercel, Netlify, GitHub Pages 等；部署前需编辑 astro.config.mjs 中的站点设置。具体来说，你可能需要修改 astro.config.mjs 文件的 site 配置（大约在24行左右），将其设置为你的域名。// https://astro.build/config\nexport default defineConfig({\n  site: \"https://www.lapis.cafe/\", // 修改为你的域名\n  base: \"/\",\n  trailingSlash: \"always\",\n  integrations: [\n    tailwind(\n        {\n          nesting: true,\n        }\n    ),2.3.1 部署到 Vercel部署到Vercel非常简单，默认情况下你的 Astro 项目是一个静态站点。你无需任何额外配置即可将静态 Astro 站点部署到 Vercel。首先，将你的博客全部代码push到你的GitHub仓库，然后在Vercel里选择import from GitHubVercel将自动检测 Astro 项目并自动为其配置正确的设置，一路点点点就行了部署后，你可以通过 https://<your-username>.vercel.app 访问你的博客，也可以在settings里设置自定义域名2.3.2 部署到 cloudflare pagesCloudflare Pages是一个免费的静态网站托管平台，你可以在这里部署你的Astro站点。在开始之前，你需要：一个 Cloudflare 账号。如果你暂时还没有，你可以现在免费去 Cloudflare 官网注册一个。你的源代码存储在一个 GitHub 或者 GitLab 仓库里。部署流程：在 Cloudflare Pages 设置一个新项目。将你的代码提交到一个 Git 仓库中 (GitHub, GitLab)。登录 Cloudflare Dashboard 并在 Account Home > Workers & Pages > Overview 选择你的账号。选择 Create application，然后选择 Pages 标签页，接着选择 Connect to Git 选项。选择你想部署的 Git 项目并点击 Begin setup（初始设置）。使用以下的构建设置：Framework preset（框架预设）: AstroBuild command（构建命令）: npm run buildBuild output directory（构建输出目录）: dist点击 Save and Deploy（保存并部署）按钮。\n最后，你可以通过 https://<your-username>.pages.dev 访问你的博客，也可以在settings里设置自定义域名。2.3.3 部署到 GitHub Pages你可以使用 GitHub Actions 将 Astro 站点自动构建和部署到 GitHub Pages。为此，你的源代码必须托管在 GitHub 上。Astro 维护了一个官方的 GitHub Action withastro/action 来帮助你部署项目.由于本节流程比较复杂，请直接参见官方文档2.3.4 部署到 Netlify如果你的项目存储在 GitHub、GitLab、BitBucket 或 Azure DevOps 中，你可以使用 Netlify 的网站用户操作界面来部署你的 Astro 网站。在 Netlify dashboard 页面上，点击 Add a new site选择 Import an existing project当你从你的 Git 提供商中导入 Astro 仓库时，Netlify 应该会自动检测并预填充正确的配置设置。确保已输入以下设置，然后按下 Deploy 按钮：Build Command: astro build or npm run buildPublish directory: dist部署后，你将被重定向到站点概览页面。在那里，你可以编辑你站点的详细信息。根据你的部署配置，未来对源代码库的任何修改都将触发预览和生产部署。四、主题个性化调整1.添加页脚ICP备案信息和运行时间信息你可以在 src/components/Footer.astro 文件中添加你的ICP备案信息，例如:---\nimport { profileConfig } from '../config'\nimport { url } from '../utils/url-utils'\nconst currentYear = new Date().getFullYear()\n---\n\n<!--<div class=\"border-t border-[var(&#45;&#45;primary)] mx-16 border-dashed py-8 max-w-[var(&#45;&#45;page-width)] flex flex-col items-center justify-center px-6\">-->\n<div class=\"transition border-t border-black/10 dark:border-white/15 my-10 border-dashed mx-32\"></div>\n<!--<div class=\"transition bg-[oklch(92%_0.01_var(&#45;&#45;hue))] dark:bg-black rounded-2xl py-8 mt-4 mb-8 flex flex-col items-center justify-center px-6\">-->\n<div class=\"transition border-dashed border-[oklch(85%_0.01_var(--hue))] dark:border-white/15 rounded-2xl mb-12 flex flex-col items-center justify-center px-6\">\n    <div class=\"transition text-50 text-sm text-center\">\n        &copy; <span id=\"copyright-year\">{currentYear}</span> {profileConfig.name}. All Rights Reserved. /\n        <a class=\"transition link text-[var(--primary)] font-medium\" target=\"_blank\" href={url('rss.xml')}>RSS</a> /\n        <a class=\"transition link text-[var(--primary)] font-medium\" target=\"_blank\" href={url('sitemap-index.xml')}>Sitemap</a> /\n        <a class=\"transition link text-[var(--primary)] font-medium\" target=\"_blank\" href=\"https://www.travellings.cn/go.html\">开往</a><br>\n        Powered by\n        <a class=\"transition link text-[var(--primary)] font-medium\" target=\"_blank\" href=\"https://astro.build\">Astro</a> &\n        <a class=\"transition link text-[var(--primary)] font-medium\" target=\"_blank\" href=\"https://github.com/saicaca/fuwari\">Fuwari</a>\n        <br>\n+       <a class=\"transition link text-[var(--primary)] font-medium\" + target=\"_blank\" href=\"https://beian.miit.gov.cn/\"> \n+         辽ICP备2023010881号-1</a> //  添加备案信息\n    </div>\n    <script type=\"text/javascript\">function runtime(){const t=new Date(\"07/01/2023 08:00:00\"),n=new Date,s=n-t,e=Math.floor(s/1e3),o=Math.floor(e/86400),i=Math.floor(e%86400/3600),a=Math.floor(e%3600/60),r=e%60;document.getElementById(\"runningtime\").innerHTML=`⭐本站已运行: ${o}天${i}小时${a}分${r}秒 ☁️`}setInterval(runtime,1e3)</script>\n    <div class=\"transition text-50 text-sm text-center hidden md:block\"><p id=\"runningtime\"> </p></div>  //  添加博客运行时间\n</div>2.添加友链页面2.1 添加友链页面文件在src\\content\\spec目录下新建文件friends.md:::note\n这个文件是新友链页面的内容文件，类似于其他页面内容（例如关于页面）来源的 about.md 文件。\n添加这个文件的目的是为 \"友链\" 页面提供对应的内容数据，也便于通过统一方式调用内容。\n:::在src\\types\\config.ts文件约41行位置添加以下内容export enum LinkPreset {\n  Home = 0,\n  Archive = 1,\n  About = 2,\n+ Friends = 3,  \n}:::note\n定义一个新的导航链接 \"Friends\"。在项目结构中，LinkPreset 枚举可能用于统一管理网页导航条或特定页面布局，对应页面的标识。\n:::2.2 国际化i18n翻译在src\\i18n\\i18nKey.ts文件约35行位置添加以下内容  author = 'author',\n  publishedAt = 'publishedAt',\n  license = 'license',\n+ friends = 'friends',  :::note\ni18nKey.ts 文件负责国际化功能，这里添加了 friends 键值，表示新页面 \"友链\" 的国际化字符串键。\n后续会根据项目支持的语言为 friends 提供不同语言的翻译。\n:::按照自己的语言，在 src\\i18n\\languages 目录中编辑相应语言文件,以 zh_CN.ts 为例，在约 38 行位置添加内容  [Key.author]: '作者',\n  [Key.publishedAt]: '发布于',\n  [Key.license]: '许可协议',\n+ [Key.friends]: '友链', :::note\n编辑语言文件，为新增的 friends 翻译字符串提供对应语言的翻译（这里是中文：友链）。\n如果项目支持其他语言，这个步骤需要在每个语言文件中添加 friends 的翻译，保证页面多语言显示功能。\n:::在 src\\constants\\link-presets.ts 文件约 18 行位置添加内容   [LinkPreset.Archive]: {\n     name: i18n(I18nKey.archive),\n     url: '/archive/',\n   },\n+  [LinkPreset.Friends]: { \n+    name: i18n(I18nKey.friends),  \n+    url: '/friends/',  \n+  },   \n }:::note\n在 LinkPreset 到页面路径的映射中，加入新的友链页面配置。\nname 设置链接名称，这里使用国际化 i18n(I18nKey.friends) 来确保多语言支持。\nurl 指定这个页面的路径 /friends/。\n:::2.3 创建和配置页面的Astro文件在src\\pages目录下复制原本的about.astro文件，重命名为friends.astro，在此文件中更改第 11 行、第 17 行和第19行的内容-  const aboutPost = await getEntry('spec', 'about')\n+  const friendsPost = await getEntry('spec', 'friends')\n\n-  const { Content } = await render(aboutPost);\n+  const { Content } = await render(friendsPost);\n\n-  <MainGridLayout title={i18n(I18nKey.about)} description={i18n(I18nKey.about)}>\n+  <MainGridLayout title={i18n(I18nKey.friends)} description={i18n(I18nKey.friends)}>:::note\n创建 friends.astro 作为友链页面的模板文件，复制使用了类似 about.astro 的结构代码。\n修改了内容获取函数，使其加载的是 friends.md 数据，而非 about.md 数据。\n修改了标题 title 和描述 description，指向 friends 的国际化字符串。\n:::2.4 在导航栏中添加友链页面在 src\\config.ts 文件约 48 行位置添加内容，注意要在 LinkPreset.About 末尾添加,export const navBarConfig: NavBarConfig = {\n  links: [\n    LinkPreset.Home,\n    LinkPreset.Archive,\n    LinkPreset.About,\n+   LinkPreset.Friends,  \n    {:::note\nnavBarConfig 用于配置页面的导航栏。\n在导航栏中添加新的 \"友链\" 入口，使用户能够通过导航直接访问这个页面。\n:::2.5 创建卡片效果友链在之前创建的 friends.astro 文件中编辑\n---\n\nimport MainGridLayout from \"../layouts/MainGridLayout.astro\";\n\nimport { getEntry } from \"astro:content\";\nimport { render } from \"astro:content\";\nimport Markdown from \"@components/misc/Markdown.astro\";\nimport I18nKey from \"../i18n/i18nKey\";\nimport { i18n } from \"../i18n/translation\";\n\nconst friendsPost = await getEntry('spec', 'friends')\n\nif (!friendsPost) {\n\tthrow new Error(\"Friend page content not found\");\n}\n\nconst { Content } = await render(friendsPost);\n\nconst items = [\n  {  \n    title: 'Astro',  \n    imgurl: 'https://avatars.githubusercontent.com/u/44914786?s=48&v=4',  \n    desc: 'The web framework for content-driven websites. ⭐️ Star to support our work!',  \n    siteurl: 'https://github.com/withastro/astro',  \n    tags: ['框架'],  \n  },\n]\n---\n<MainGridLayout title={i18n(I18nKey.friends)} description={i18n(I18nKey.friends)}>\n    <div class=\"flex w-full rounded-[var(--radius-large)] overflow-hidden relative min-h-32\">\n        <div class=\"card-base z-10 px-9 py-6 relative w-full \">\n            <div class=\"grid grid-cols-1 sm:grid-cols-2 gap-x-6 gap-y-8 my-4\">\n                {items.map((item) => (   \n                    <div class=\"flex flex-nowrap items-stretch h-28 gap-4 rounded-[var(--radius-large)]\">\n                        <div class=\"w-28 h-28 flex-shrink-0 rounded-lg overflow-hidden bg-zinc-200 dark:bg-zinc-900\">\n                            <img src={item.imgurl} alt=\"站点头像\" class=\"w-full h-full object-cover\">\n                        </div>\n                        <div class=\"grow w-full\">\n                            <div class=\"font-bold transition text-lg text-neutral-900 dark:text-neutral-100 mb-1\">{item.title}</div>\n                            <div class=\"text-50 text-sm font-medium\">{item.desc}</div>\n                            <div class:list={[\"items-center\", {\"flex\": true, \"hidden md:flex\" : false}]}>\n                                <div class=\"flex flex-row flex-nowrap items-center\">\n                                    {(item.tags && item.tags.length > 0) && item.tags.map((tag,i) => (  \n                                    <div class:list={[{\"hidden\": i==0}, \"mx-1.5 text-[var(--meta-divider)] text-sm\" ]}>\n                                        /\n                                    </div>  \n                                    <span class=\"transition text-50 text-sm font-medium\">\n                                        {tag}\n                                    </span>))}\n                                    {!(item.tags && item.tags.length > 0) && <div class=\"transition text-50 text-sm font-medium\">{i18n(I18nKey.noTags)}</div>}\n                                </div>\n                            </div>\n                        </div>\n                        <a href={item.siteurl} target=\"_blank\" rel=\"noopener noreferrer\"class=\"flex btn-regular w-[3.25rem] rounded-lg bg-[var(--enter-btn-bg)] hover:bg-[var(--enter-btn-bg-hover)] active:bg-[var(--enter-btn-bg-active)] active:scale-95\">\n                            <svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" aria-hidden=\"true\" role=\"img\" class=\"transition text-[var(--primary)] text-4xl mx-auto iconify iconify--material-symbols\" width=\"1em\" height=\"1em\" viewBox=\"0 0 24 24\">\n                                <path fill=\"currentColor\" d=\"M12.6 12L8.7 8.1q-.275-.275-.275-.7t.275-.7t.7-.275t.7.275l4.6 4.6q.15.15.213.325t.062.375t-.062.375t-.213.325l-4.6 4.6q-.275.275-.7.275t-.7-.275t-.275-.7t.275-.7z\"></path>\n                            </svg>\n                        </a>\n                    </div>\n                ))}\n            </div>  \n            <Markdown class=\"mt-2\">\n                <Content />\n            </Markdown>\n        </div>\n    </div>\n</MainGridLayout>:::note\n在 friends.astro 文件中，添加卡片效果的友链信息，包括站点名称、头像、描述、链接、标签等信息。const items 部分就是添加的友链部分，继续添加即可。\n:::最终效果：friends3.添加评论系统本主题作者未来会计划添加评论系统，但目前主题原生不支持，可采用giscus等第三方评论系统，本节就采用giscus来进行演示。3.1 giscus配置首先，你需要创建一个新的GitHub库用来“装下”博客的那些评论，你需要确保该仓库是公开的,否则访客将无法查看 discussion。然后，你需要给你的这个仓库repo安装giscus app,否则访客将无法评论和回应。最后，你需要确保 Discussions 功能已在你的仓库中启用。打开giscus官方网站https://giscus.app/，进行配置：语言：选择你目前正在使用的语言（一般应该都是简中吧？）仓库：填写你刚刚创建的仓库（格式为你的用户名/仓库名）页面 ↔️ discussion 映射关系(默认即可)Discussion 分类（默认即可）特性（默认即可）主题（默认即可）按照顺序配置好之后，下方会自动生成具体字段会根据你的情况自动生成<script src=\"https://giscus.app/client.js\"\n        data-repo=\"[在此输入仓库]\"\n        data-repo-id=\"[在此输入仓库 ID]\"\n        data-category=\"[在此输入分类名]\"\n        data-category-id=\"[在此输入分类 ID]\"\n        data-mapping=\"pathname\"\n        data-strict=\"0\"\n        data-reactions-enabled=\"1\"\n        data-emit-metadata=\"0\"\n        data-input-position=\"bottom\"\n        data-theme=\"preferred_color_scheme\"\n        data-lang=\"zh-CN\"\n        crossorigin=\"anonymous\"\n        async>\n</script>3.2 添加评论系统3.2.1 友链页面如果你的友链界面已经配置好，直接在src\\pages\\friends.astro文件中添加即可，插入最后一行上方即可            <Markdown class=\"mt-2\">\n                <Content />\n            </Markdown>\n        </div>\n    </div>\n\n<!-- giscus评论 -->\n<script src=\"https://giscus.app/client.js\"\n        data-repo=\"AULyPc/aulypc.github.io\"\n        data-repo-id=\"xxxxxxxxx\"\n        data-category=\"Announcements\"\n        data-category-id=\"xxxxxxxxxxxx\"\n        data-mapping=\"pathname\"\n        data-strict=\"0\"\n        data-reactions-enabled=\"1\"\n        data-emit-metadata=\"0\"\n        data-input-position=\"top\"\n        data-theme=\"preferred_color_scheme\"\n        data-lang=\"zh-CN\"\n        crossorigin=\"anonymous\"\n        async>\n</script>  \n\n</MainGridLayout>3.2.2 文章页面找到 src\\pages\\posts\\[...slug].astro 文件\n在 </MainGridLayout> 行上方添加即可                <Icon name=\"material-symbols:chevron-right-rounded\" class=\"text-[2rem] text-[var(--primary)]\" />\n            </div>}\n        </a>\n    </div>\n\n<!-- giscus评论 -->\n<script src=\"https://giscus.app/client.js\"\n    data-repo=\"AULyPc/aulypc.github.io\"\n    data-repo-id=\"xxxxxxxxxxx\"\n    data-category=\"Announcements\"\n    data-category-id=\"xxxxxxxxxxxxx\"\n    data-mapping=\"pathname\"\n    data-strict=\"0\"\n    data-reactions-enabled=\"1\"\n    data-emit-metadata=\"0\"\n    data-input-position=\"top\"\n    data-theme=\"preferred_color_scheme\"\n    data-lang=\"zh-CN\"\n    crossorigin=\"anonymous\"\n    async>\n</script>  \n\n</MainGridLayout>\n\n<style is:global>\n#post-container :nth-child(1) { animation-delay: calc(var(--content-delay) + 0ms) }\n#post-container :nth-child(2) { animation-delay: calc(var(--content-delay) + 50ms) }\n#post-container :nth-child(3) { animation-delay: calc(var(--content-delay) + 100ms) }\n#post-container :nth-child(4) { animation-delay: calc(var(--content-delay) + 175ms) }\n#post-container :nth-child(5) { animation-delay: calc(var(--content-delay) + 250ms) }\n#post-container :nth-child(6) { animation-delay: calc(var(--content-delay) + 325ms) } \n</style>:::note\n关于页面，归档页面同理，修改对应的如about.astro，posts.astro，archive.astro，index.astro，即可\n::::::caution\n因为在我实际使用过程中，发现评论系统在页面的位置比较靠上，和文章正文贴得太近不美观，因此修改了下实际代码：<!-- giscus评论 -->\n<div style=\"margin-top: 20px;\"></div>\n<script src=\"https://giscus.app/client.js\"\n        data-repo=\"Lapis0x0/blog-discussion\"\n        data-repo-id=\"R_kgDONda6_g\"\n        data-category=\"Announcements\"\n        data-category-id=\"DIC_kwDONda6_s4ClN0D\"\n        data-mapping=\"pathname\"\n        data-strict=\"0\"\n        data-reactions-enabled=\"1\"\n        data-emit-metadata=\"0\"\n        data-input-position=\"bottom\"\n        data-theme=\"preferred_color_scheme\"\n        data-lang=\"zh-CN\"\n        crossorigin=\"anonymous\"\n        async>\n</script>:::"
  },
  {
    "title": "简析经济学与金融学实证中的几个常用简单模型",
    "summary": "引言经济学和金融学作为社会科学的重要分支，其研究目的在于理解和预测经济主体的行为以及金融市场的运作规律，二者研究范围很大一部分都重叠于分析复杂经济体系中各种行为主体的决策及其相互作用机制。实证研究作为连接理论与现实的桥梁，通过对数据的收集、整理和分析来检验经济理论的有效性，并为政策制定和投资决策提供依据。随着近年数据可得性的大幅提升以及量化方法的发展，经济学和金融学实证研究的深度广度均得到了显著增",
    "tags": [],
    "url": "/posts/Finance and Economics/简析经济学与金融学实证中的几个常用简单模型/",
    "date": "2024-12-03T00:00:00.000Z",
    "content": "引言经济学和金融学作为社会科学的重要分支，其研究目的在于理解和预测经济主体的行为以及金融市场的运作规律，二者研究范围很大一部分都重叠于分析复杂经济体系中各种行为主体的决策及其相互作用机制。实证研究作为连接理论与现实的桥梁，通过对数据的收集、整理和分析来检验经济理论的有效性，并为政策制定和投资决策提供依据。随着近年数据可得性的大幅提升以及量化方法的发展，经济学和金融学实证研究的深度广度均得到了显著增强。在具体的分析中，模型和变量选择是整个研究全过程的核心。不同模型适用于不同的数据特征与分析需求，可以帮助研究者合理抽象和描述经济现象。尤其是一些相对简单、经典的模型，能够以较低的复杂度实现对真实问题的高效分析。本篇博客将简要介绍经济学与金融学实证研究中最常用的几个简单模型，包括线性回归模型、时间序列分析、面板数据分析、Logit和Probit模型、以及事件研究法。通过对这些模型基本概念、应用案例、优点与局限的梳理，试图帮助读者更好地理解这些模型的功能及其应用场景，为进一步的研究打下基础。线性回归模型以其简洁性和解释性，成为研究变量之间线性关系的首选工具，例如分析经济增长与投资的关系，或股票价格与宏观经济指标的关系。时间序列分析则专注于研究随时间变化的数据，能够捕捉数据的动态变化，适用于GDP预测和股票市场波动性分析等问题。面板数据分析结合了横截面数据和时间序列数据的优势，能够控制个体异质性，提高估计精度，常用于公司财务绩效分析和国家经济发展比较研究。Logit和Probit模型适用于研究二元选择问题，例如信贷违约预测和投资决策分析，它们能够解释事件发生的概率。事件研究法则专注于评估特定事件对市场的影响，例如公司并购公告的影响或政策变动对市场的影响。一、线性回归模型（Linear Regression Model）线性回归模型是经济学和金融学实证研究中最基础且最广泛应用的模型之一，用于描述因变量与一个或多个自变量之间的线性关系。它具有直观的表现形式和较强的解释能力，因此长期以来受到各类研究者的青睐。本节将重点介绍线性回归模型的基本概念、经典应用案例，并讨论其优点与局限。1. 基本概念（1）定义和公式线性回归模型的基本形式为：$$\nY = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\cdots + \\beta_kX_k + \\varepsilon\n$$其中：$Y$为因变量（被解释变量），代表所研究的现象或结果；$X_1, X_2, \\cdots, X_k $ 为自变量（解释变量），代表影响因变量的不同要素；$\\beta_0$为截距，表示当所有自变量取值为0时因变量的期望值；$\\beta_1, \\beta_2, \\cdots, \\beta_k$为回归系数，衡量每个自变量对因变量的边际影响；$ \\varepsilon $为误差项，表示模型未能解释的部分。在线性回归模型中，自变量和因变量之间的关系假定为线性，通过最小二乘法（Ordinary Least Squares, OLS）估计模型参数，使得误差项平方和最小化。OLS的目标函数为：$$\n\\min_{\\beta_0, \\beta_1, \\cdots, \\beta_k} \\sum_{i=1}^n (\\hat{Y}_i - Y_i)^2\n$$（2）假设条件为了保证OLS估计具有良好的统计性质（如无偏性和有效性），线性回归模型需满足以下经典假设条件：线性假设：因变量与所有自变量之间的关系是线性的；随机抽样：样本数据是按照随机抽样的方法获取的；同方差性：误差项的方差是恒定的，不随着自变量的变化而变化；误差项独立性：误差项彼此之间相互独立，且与自变量无关；误差项正态性（在小样本情况下重要）：误差项服从正态分布；无完全多重共线性：各自变量之间不存在完全线性关系。上述假设提供了理论支持，但在实际应用中可能不完全成立，研究者需根据数据特性进行检验和调整。2. 应用案例（1）经济增长与投资的关系经济学中，线性回归模型常用于分析经济增长与影响因素之间的关系。例如，一些研究通过回归模型检验投资对经济增长的影响，具体设定为：$$\nGDP_{growth_rate} = \\beta_0 + \\beta_1Investment + \\beta_2Labor + \\beta_3Capital + \\varepsilon\n$$在上述公式中，经济增长率作为因变量，投资、劳动力和资本等作为解释变量，通过估计各变量的系数可以判断其对经济增长的边际贡献。（2）股票价格与宏观经济指标的关系金融学中，线性回归模型常用于测试宏观经济变量对股票市场的影响。以某股票价格指数为因变量，该模型可能包括的解释变量有利率、通货膨胀率、货币供应量等：$$\nStock_Price = \\beta_0 + \\beta_1Interest_Rate + \\beta_2Inflation + \\beta_3Money_Supply + \\varepsilon\n$$这样的分析可以帮助投资者或政策制定者了解宏观经济环境的变化对资本市场的影响，有助于优化投资策略或政策设计。3. 优点与局限（1）优点简单易用：线性回归模型形式简单，参数估计方法可靠，易于实施；解释性强：回归系数能直接反映自变量对因变量的边际影响；适用范围广：适用于大多数实证研究场景，无论是单变量问题还是多变量问题，都可以利用线性回归模型进行分析。（2）局限假设线性关系：线性回归模型假设因变量和自变量之间为线性关系，但实际经济和金融现象中可能存在复杂的非线性关系；多重共线性问题：当自变量之间存在高度相关性时，模型可能会导致系数不稳定，影响结果的可靠性；对异常值敏感：模型对异常值非常敏感，可能导致系数估计值和模型预测不准确；忽略动态性：线性回归模型仅关注静态关系，无法捕捉时间序列数据中的动态变化趋势。线性回归模型作为经济学与金融学实证研究的基础工具，在许多场景下能够快速提供清晰的结果。但其应用也需要注意基本假设对结果的潜在影响，并结合数据特性选择最适合的模型。二、时间序列分析（Time Series Analysis）时间序列分析是一类专门用于研究随时间变化数据的方法，在经济学与金融学中用于模型化和预测动态变量（如GDP、股票价格等）的趋势与周期。这类方法特别适用于时间相关的数据，通过合理的建模能够捕捉其动态特性。本节将围绕时间序列分析的基本概念、经典应用案例及其优点与局限展开讨论。1. 基本概念（1）定义和分类时间序列分析是用于研究序列数据（例如按天、月份或年度记录的观测值）的一类统计方法，其核心目标在于发现时间序列的规律并进行预测。根据时间序列的生成机制，可大致将时间序列模型划分为以下几类：自回归模型（Autoregressive Model, AR）\nAR模型假设当前序列值 ( y_t ) 可以用过去的若干序列值的线性组合表示：$$\ny_t = \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\cdots + \\phi_p y_{t-p} + \\varepsilon_t\n$$其中，$\\phi_1, \\phi_2, \\ldots, \\phi_p$为自回归系数，$p$为滞后阶数，$\\varepsilon_t $为白噪声。滑动平均模型（Moving Average Model, MA）\nMA模型假设当前序列值与过去的误差项（白噪声）的线性组合相关：$$\ny_t = \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\cdots + \\theta_q \\varepsilon_{t-q}\n$$其中，$\\theta_1, \\theta_2, \\ldots, \\theta_q $为滑动平均系数，$q$为滞后阶数。混合模型（Autoregressive Integrated Moving Average Model, ARIMA）\nARIMA模型综合了AR模型和MA模型，同时允许序列数据通过差分运算转化为平稳序列：$$\ny_t = \\phi_1 y_{t-1} + \\cdots + \\phi_p y_{t-p} + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\cdots + \\theta_q \\varepsilon_{t-q}\n$$若数据非平稳，则需通过 $d $ 阶差分运算$\\Delta^d y_t = y_t - y_{t-1}$使其平稳，以达到建模要求。（2）平稳性和非平稳性在时间序列分析中，平稳性是一个关键假设。平稳时间序列的统计特性（如均值、方差、自相关函数等）不随时间变化。常用的平稳性检验方法包括：单位根检验（Unit Root Test）：如ADF检验（Augmented Dickey-Fuller Test）和KPSS检验，用于检查序列是否存在单位根（非平稳）。图示法：观察序列的趋势和方差变化，初步判断是否平稳。若序列非平稳，则可通过如下方法进行处理：差分运算：对序列进行一次或多次差分 $\\Delta y_t = y_t - y_{t-1}$ 直到序列平稳；对数变换或 Box-Cox 变换：处理非平稳序列由于趋势或波动过大引起的问题。2. 应用案例（1）GDP预测时间序列分析大量用于宏观经济预测。例如，研究者可以基于季度或年度的 GDP 数据构建 ARIMA 模型，以捕捉GDP的增长趋势和周期波动，公式如下：$$\n\\Delta GDP_t = \\phi_1 \\Delta GDP_{t-1} + \\cdots + \\phi_p \\Delta GDP_{t-p} + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\cdots + \\theta_q \\varepsilon_{t-q}\n$$模型能够有效结合历史趋势与短期异常，生成可靠的中短期 GDP 增长率预测。（2）股票市场波动性分析在金融市场中，股票价格或收益率通常显示出较强的波动聚集效应和自相关性。通过时间序列模型（如 ARIMA 或 GARCH 模型），可以分析股票市场的动态特征。例如，使用 AR 模型分析每日的股票回报率（returns）：$$\nr_t = c + \\phi_1 r_{t-1} + \\phi_2 r_{t-2} + \\cdots + \\phi_p r_{t-p} + \\varepsilon_t\n$$此外，通过扩展为 GARCH 模型，还可以刻画波动率的动态变化。此类模型对投资策略和风险管理具有重要意义。3. 优点与局限（1）优点适应时间数据：时间序列分析方法专门设计用于处理时间序列数据，能够捕捉其动态特性；预测能力强：通过识别过去的模式，可以预测序列的未来变化趋势；适应多样性问题：AR、MA、ARIMA 等不同模型能够分别处理平稳、非平稳数据以及复杂周期问题。（2）局限对数据要求高：时间序列数据要求具有较好的质量（完整无缺失），且观测时间较长，否则难以获得准确结果；平稳性处理复杂：非平稳数据较难建模，前期需要对趋势性、季节性进行充分识别与处理；对模型选择敏感：不同模型的效果依赖于数据特性，变量的滞后阶数选择（如ARIMA中的 $p, d, q$严重影响结果，需要借助信息准则（如AIC、BIC）优化模型。时间序列分析在处理动态数据、研究变量之间的时间依赖性方面具有重要优势。但其建模和预测过程依赖于严格的方法论和数据质量，研究者需要根据数据特性及研究目标谨慎选择合适的模型与处理方式。三、面板数据分析（Panel Data Analysis）面板数据分析是一种结合横截面数据（Cross-sectional Data）和时间序列数据（Time Series Data）的分析方法。它广泛应用于经济学和金融学的实证研究中，用于分析不同个体（如公司、地区或国家）随着时间变化的行为差异和动态变化趋势。本节将讨论面板数据分析的基本概念、经典应用案例及其优点和局限性。1. 基本概念（1）定义和类型面板数据指同时包含横截面观测（多个个体）和时间序列观测的数据。例如，第 (i) 个公司的第 (t) 年的财务绩效数据可以表示为 (y_{it})。面板数据模型的基本形式为：$$\ny_{it} = \\alpha + \\beta X_{it} + u_{it}, \\quad i = 1, 2, ... , N; \\quad t = 1, 2, ... , T\n$$$$\n\\begin{aligned}\n\\text{其中：} \\\n& y_{it}：\\text{第 } i \\text{ 个个体在第 } t \\text{ 时期的因变量；} \\\n& X_{it}：\\text{解释变量矩阵；} \\\n& \\alpha：\\text{截距项；} \\\n& \\beta：\\text{回归系数向量，表示解释变量对因变量的作用；} \\\n& u_{it}：\\text{误差项，可能包含个体效应（个体特有的影响）、时间效应或其他随机部分。}\n\\end{aligned}\n$$根据个体和时间效应的处理方式，主要分为以下两类模型：固定效应模型（Fixed Effects Model, FEM）\n固定效应模型通过控制不可观测的个体特性（例如，国家的制度差异或企业的特点）来减少模型偏误。它假设这些个体特性不会随时间变化，是固定的。其模型形式为：$$\ny_{it} = \\alpha_i + \\beta X_{it} + u_{it}\n$$其中，$alpha_i$是各个个体的固定特定因素。固定效应模型通过引入“个体哑变量（dummy variable）”或“去均值法（within transformation）”实现估计。随机效应模型（Random Effects Model, REM）\n随机效应模型假设个体差异是随机的，且与解释变量无关。模型形式为：$$\ny_{it} = \\alpha + \\beta X_{it} + v_i + u_{it}\n$$$v_i$ 表示个体特有的随机效应，满足 $E(v_i) = 0$，且与解释变量 $X_{it}$不相关。REM 的估计通常基于广义最小二乘法 (GLS)。（2）优势：结合横截面和时间序列数据面板数据分析的一个核心优势在于它结合了横截面数据和时间序列数据的特点，能够捕捉个体间差异及其动态变化趋势。具体优势包括：提供更大的数据量，有助于提高估计精度；更好地控制不可观测异质性，减少遗漏变量偏误；能够分析个体随时间变化的动态关系，例如政策效应、长期趋势等。2. 应用案例（1）公司财务绩效分析在企业层面的研究中，面板数据分析能够有效结合公司间差异与时间上的变化特征。例如，研究上市公司资本结构对绩效的影响时，可以构建如下模型：$$\nPerformance_{it} = \\alpha + \\beta_1 Leverage_{it} + \\beta_2 Size_{it} + \\beta_3 R&D_{it} + u_{it}\n$$其中，$Performance_{it}$表示第 $i$ 个公司的财务绩效（如ROE或利润率），$Leverage_{it}$ 为杠杆率，$Size_{it}$ 为公司规模，$R&D_{it}$ 为研发投入。通过固定效应模型，可控制公司特定的不可观测特性（如管理能力、文化差异等）。（2）国家经济发展比较在宏观层面，面板数据分析被广泛用于比较国家间的经济发展。例如，可以分析人口增长率与GDP增长率的关系，模型形式为：$$\nGDP_Growth_{it} = \\alpha + \\beta_1 Pop_Growth_{it} + \\beta_2 Trade_{it} + \\beta_3 Invest_{it} + u_{it}\n$$其中，第 $i$ 个国家的 GDP 增长率（$GDP_Growth_{it}$）受人口增长率（$Pop_Growth_{it}$）、贸易额占比（$Trade_{it}$）和固定资本投资占比（$Invest_{it}$）的影响。通过随机效应模型，可以捕捉不同国家间的异质性及全球经济变化趋势。3. 优点与局限（1）优点控制个体异质性：有效控制个体间的不可观测异质性，减少模型偏误。提高估计精度：面板数据结合了时间序列和横截面维度，使得估计结果更加精确可靠。捕捉动态变化：能够分析个体间差异以及动态调整过程，例如政策对经济的长短期影响。适用范围广：适用于多种研究领域，如企业行为分析、政策评价等。（2）局限数据收集难度较大：面板数据需要同时涵盖横截面和时间维度，尤其长期面板数据（long panel）很难获取。模型选择复杂：固定效应和随机效应模型的选择需要基于理论和统计检验（如 Hausman 检验），且处理过程较繁琐。潜在内生性问题：解释变量可能与误差项相关，导致估计结果偏误，需要引入工具变量（IV）或广义矩估计（GMM）进行纠正。假设依赖性较强：随机效应模型假设个体随机效应与解释变量无关，这一假设在实际中往往较难满足。面板数据分析为经济学与金融学的实证研究提供了有效工具，帮助研究者整合多维度数据分析个体差异和动态关系。然而，其模型的复杂性及对数据的高要求也对研究者的专业能力提出了挑战。四、Logit和Probit模型（Logit and Probit Models）Logit和Probit模型是经济学、金融学及其他社会科学领域常用的非线性二元选择模型，它们主要用于研究因变量是二元选择数据（如“成功/失败”、“同意/拒绝”）的关系。在很多场景中，研究者关注的是某一事件发生的概率，而Logit和Probit模型可以将这种概率通过解释变量建模。本节将介绍Logit和Probit模型的基本概念、应用案例以及它们各自的优点与局限性。1. 基本概念（1）定义和公式Logit和Probit模型都是基于二元因变量的概率模型，用于研究某事件发生的概率在什么条件下会改变，因变量 ((Y)) 通常取值为1或0（即代表事件分别“发生”和“不发生”）。两种模型的核心在于设定不同的分布函数，将解释变量通过某种形式转换为事件发生的概率。设 $P(Y=1|X)$ 为事件 $Y=1$ （某事件发生）的概率，模型的通用形式表示为：$$\nP(Y = 1|X) = F(X \\beta)\n$$其中：$F$：累积分布函数，决定模型类型；$X$：自变量（解释变量）；$\\beta$：回归系数向量。具体而言：1. Logit模型Logit模型基于累积逻辑分布函数，其公式为：$$\nP(Y = 1|X) = \\frac{1}{1 + e^{-X\\beta}}\n$$或等价地，可以写为对数几率形式：$$\n\\ln\\left(\\frac{P(Y = 1|X)}{P(Y = 0|X)}\\right) = X\\beta\n$$其中，$\\ln\\left(\\frac{P}{1-P}\\right)$ 称为对数几率（log odds）。Logit模型非常适合描述概率与线性组合之间的非线性关系，且保证所得概率介于0和1之间。2. Probit模型Probit模型基于标准正态分布函数，其公式为：$$\nP(Y = 1|X) = \\Phi(X\\beta)\n$$其中，$\\Phi$ 为标准正态分布的累积分布函数：$$\n\\Phi(z) = \\int_{-\\infty}^z \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{t^2}{2}} dt\n$$Probit模型假设事件发生的概率服从标准正态分布，适用于解释变量对结果具有正态分布特性的场景。（2）概率解释在实际研究中，Logit与Probit模型都用于估计变化后的概率。由于两者的函数形式决定了因变量对解释变量的非线性关系，因此结果通常用边际效应（Marginal Effects）来解释，即：$$\n\\frac{\\partial P(Y=1|X)}{\\partial X} = f(X\\beta) \\cdot \\beta\n$$其中，$f(X\\beta)$ 是对应的分布密度函数。对于 Logit 模型，密度函数为：$$\nf(z) = \\frac{e^{-z}}{(1+e^{-z})^2}\n$$对于 Probit 模型，密度函数为标准正态分布函数的导数：$$\nf(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{z^2}{2}}\n$$边际效应展示了解释变量变化时，因变量的发生概率如何随之波动，这为政策决策或现象预测提供了直观的量化依据。2. 应用案例（1）信贷违约预测在金融领域，Logit和Probit模型被广泛应用于信用风险管理。例如，研究贷款人是否违约 (Y = 1) （违约）或 (Y = 0) （不违约）时，可以将贷款申请者的特征（收入、资产负债比、信用评分等）作为解释变量：$$\nP(\\text{Default} = 1|X) = F(\\beta_0 + \\beta_1 \\cdot \\text{Income} + \\beta_2 \\cdot \\text{DebtRatio} + \\beta_3 \\cdot \\text{CreditScore})\n$$通过估计模型参数，可以得到贷款人违约的概率，从而辅助银行决策是否批准贷款。Logit模型因其解释简便和计算收益被更频繁使用，更能处理高度不平衡的数据集（如违约率较低）。（2）投资决策分析在企业投资中，Logit和Probit模型可用来分析企业是否选择进行某类新投资（如技术升级或多元化扩展）：$$\nP(\\text{Invest} = 1|X) = F(\\beta_0 + \\beta_1 \\cdot \\text{MarketCompetition} + \\beta_2 \\cdot \\text{Capital} + \\beta_3 \\cdot \\text{PolicyIncentives})\n$$其中：$\\text{MarketCompetition}$ 表示市场竞争程度；$\\text{Capital}$ 表示企业的资本状况；$\\text{PolicyIncentives}$ 表示政策激励的强度。模型可以帮助揭示影响企业投资决策的重要因素及其边际效应，为政策支持方向或管理调整提供参考。3. 优点与局限（1）优点适用于二元选择问题：Logit和Probit模型专门针对二值因变量问题，能够很好地捕捉解释变量对结果的影响；解释概率：模型输出可以直接被解释为某事件发生的概率，使得结果易于解读；灵活性：Logit模型和Probit模型都可以通过扩展（如Multinomial Logit或Ordered Probit）处理多类别选择问题。（2）局限假设分布形式：两种模型依赖于累积分布函数的假设（Logit假设逻辑分布，Probit假设正态分布），在某些实际中可能不适用；结果非线性：模型结果为非线性形式，直接解释可能困难（需要计算边际效应）；模型参数估计复杂：Logit和Probit模型的极大似然估计较为复杂，与OLS相比需要更高的计算要求；适用范围有限：模型仅适用于因变量为二元点的情形，对于连续型或分布更复杂的数据，其适用性受限。Logit和Probit模型是解释二元选择问题的核心工具，它们通过输出概率为决策提供依据。研究者需要结合数据特点选择合适的模型，并关注边际效应和模型假设可能对结果产生的影响。在实际应用中，对于分类变量分析，两种模型共同构成了强有力的统计支持体系。五、事件研究法（Event Study Method）事件研究法是一种用于度量某一特定事件对金融市场中特定资产价格或收益率影响的实证研究方法。它在金融学、经济学以及会计学中被广泛使用，特别是用于检验事件（如并购公告、政策变化、盈利警告等）是否显著影响了股票市场或其他金融市场的表现。本节将介绍事件研究法的基本概念、应用案例以及其优点与局限。1. 基本概念（1）定义和步骤事件研究法的核心目标是评估某个特定事件在一个短期窗口期内，对资产价格或市场表现的影响。这种方法利用经济学理论和金融市场的有效性假设，分析事件前后资产的异常收益（Abnormal Returns, AR），并测试其是否显著偏离正常水平。事件研究法的标准步骤如下：确定事件窗口期（Event Window）\n定义研究的关键事件及其发生日期（称为“事件日”，一般用 (t = 0) 表示），以及窗口期的范围。窗口期通常包括事件发生之前的一段时间（用于捕捉市场提前反应）和之后的一段时间（用于观察延迟反应）。例如，窗口期可以设定为 ([-10, +10])，即事件日前后各10天。估计窗口期（Estimation Window）\n窗口期之外的一段时期被称为估计窗口期，用于构建资产正常收益的估计模型（如市场收益模型或CAPM）。例如，估计窗口期可以设定为事件日前 ([-120, -11])。计算正常收益率（Normal Returns, NR）\n在估计窗口期内，使用历史数据构建模型预测正常收益。正常收益率的估计方法包括：市场模型（Market Model）：$$\nR_{it} = \\alpha_i + \\beta_i R_{mt} + \\varepsilon_t\n$$其中，$R_{it}$ 为第 $i$ 个资产在 $t$ 时期的收益率，$R_{mt}$ 为市场收益率，$\\alpha_i$ 和 $\\beta_i$ 为回归系数。无条件平均法：\n直接用估计窗口期的平均收益率作为正常收益。计算异常收益率（Abnormal Returns, AR）\n异常收益率表示资产真实收益相较于正常水平的偏离值，定义为：$$\nAR_{it} = R_{it} - \\hat{R}_{it}\n$$其中，$\\hat{R}_{it}$ 为估计的正常收益。计算累计异常收益率（Cumulative Abnormal Returns, CAR）\n将事件窗口中每一天的异常收益率叠加，得到累计异常收益率：$$\nCAR_{(t_1, t_2)} = \\sum_{t=t_1}^{t_2} AR_{it}\n$$统计检验\n使用统计方法（如 t 检验）检测异常收益率或累计异常收益率是否显著，判断事件对目标资产的影响是否显著非零。（2）异常收益率计算异常收益率的计算是事件研究的核心环节。基于市场模型，异常收益率可以具体表示为：$$\nAR_{it} = R_{it} - (\\alpha_i + \\beta_i R_{mt})\n$$其中：$R_{it}$：事件窗口期第 $i$ 个资产在 $t$ 时期的实际收益率；$\\alpha_i + \\beta_i R_{mt}$：第 $i$ 个资产在 $t$ 时期基于估计模型的正常收益；$R_{mt}$：市场收益率。通过在事件窗口期内累计多个 $AR_{it}$，可以得到累计异常收益率（CAR），用于衡量事件的整体影响。若 $CAR$ 显著为正或为负，说明事件对资产的影响显著。2. 应用案例（1）公司并购公告的影响并购事件（Mergers and Acquisitions，M&A）往往对并购双方的公司股价产生显著影响。研究者可以使用事件研究法评估并购公告对两家公司股价的短期市场反应：研究问题：并购公告是否提升了目标公司股东的价值？是否减少了收购公司的股东财富？步骤：以并购公告日期为 (t=0)，包含事件前后5天窗口期（([-5, 5])），并选择事件日前60天为估计窗口期。通过市场模型估计正常收益率，计算并购双方公司的异常收益率（AR）及累计异常收益率（CAR）。实证结果：事件研究通常显示目标公司股东的CAR通常为正，这表明市场对目标公司价值提升有较高预期；而收购公司的CAR则不显著，有时甚至可能为负。（2）政策变动对市场的影响政策变动（如利率调整、税收变化或监管放松）是事件研究常见的主题。例如，可以研究政府宣布降低某类行业税收对股票市场的影响：研究问题：税收变动是否提升了受影响行业的市场价值？步骤：选取政策公告日期作为事件日 (t=0)，观测政策执行前后两周（([-10, 10])）的股价运动。利用市场模型估计涉及行业公司股票的正常收益率，计算它们的异常收益率（AR）和累计异常收益率（CAR）。实证结果：某些研究发现，财政刺激政策如税收减免通常会显著提升相关行业上市公司的股价，而更严格的政策管控可能导致负向的CAR值。3. 优点与局限（1）优点评估特定事件的市场反应：事件研究法可以准确捕捉单一事件在短期内对资产价格的影响，具有高度针对性。灵活性强：可应用于多种场景（如并购、政策发布、业绩公告等），并能分析短期及长期影响。理论支持扎实：基于有效市场假设（EMH），事件研究法利用市场价格快速反映信息的特点，具有较强的理论基础。（2）局限需要大量数据：为了构建可靠的正常收益率模型，事件研究通常需要较长时间段的高频市场数据，这对数据收集带来挑战。受市场噪音影响：市场中存在大量噪音（非事件因素引起的价格波动），可能掩盖事件的真实影响。模型依赖性：异常收益率的计算依赖于所选模型（如市场模型、CAPM），模型不当可能导致结果偏误。仅限于可量化的事件：事件研究法适用于研究市场参与者以价格形式有所反应的事件，而一些难以量化的事件（如情感、文化问题）可能难以分析。事件研究法是分析关键事件影响的重要工具。它通过评估事件窗口内的异常收益，揭示事件对市场的短期直接效应。然而，其应用效果高度依赖于事件的选择、数据的质量以及模型的合理性。在实际应用中，研究者需要谨慎设计事件研究并采用严格的统计方法验证其结论的稳健性。"
  },
  {
    "title": "从最近的恶性事件看类《看门狗》中CtOS犯罪评估系统的可能性",
    "summary": "声明：相关性不等于因果性首先，必须要在本文开头声明的是，近期大众观念里的“恶性事件频发”可能并不能代表社会整体治安的恶化，更不能将犯罪现象治安问题和所谓的经济下行导致戾气严重相关联。我知道这种因果关系简单直接符合人类思维逻辑，在传播上也容易刺激到人们的爽点，但我在实际查证经济周期和犯罪案件数量之后认为简单将这二者联系起来实际上是一种非常愚蠢的，基于现代传媒操弄下的“提线木偶”思维。我可以很明确的讲",
    "tags": [],
    "url": "/posts/Essays/ctos-predictive-policing-review/",
    "date": "2024-11-19T00:00:00.000Z",
    "content": "声明：相关性不等于因果性首先，必须要在本文开头声明的是，近期大众观念里的“恶性事件频发”可能并不能代表社会整体治安的恶化，更不能将犯罪现象治安问题和所谓的经济下行导致戾气严重相关联。我知道这种因果关系简单直接符合人类思维逻辑，在传播上也容易刺激到人们的爽点，但我在实际查证经济周期和犯罪案件数量之后认为简单将这二者联系起来实际上是一种非常愚蠢的，基于现代传媒操弄下的“提线木偶”思维。我可以很明确的讲，世界上并没有有一个处于真空球形鸡的国家能满足所谓经济周期和戾气之间的因果关系，如果真的有kol输出这个结论，我只能说要么是他蠢到不值得继续订阅，要么就是坏到不惜败坏自己的学术/能力声誉也要讨好自己的粉丝。2023年审结故意杀人等严重暴力犯罪案件5.2万件，6.2万人，中国有两千多个行政县，基本上每个县每年起码跳一个学生，一年就得跳两千多个学生，可能就在你看我这篇文章的时候就有一个小孩在自由落体——这就是庞大绝对数量下的统计学真相。现代传媒常常出于吸引眼球、博取流量的目的，将个别突发事件进行过度放大，甚至营造出一种“社会正在崩溃”的错觉。我们又在现代社会中处于一个普遍的信息过载状态，非常容易对远方的事情产生“共情”，将这些个案与自己的日常生活联系起来，进而产生对社会整体治安的悲观认识，此即为“可得性偏差”和“证实偏差”。所以，为了写这篇文章，我只能把人类社会这个多层次的社会现象相叠加的混沌模型抽象为一种简单的猜想，假设社会经济周期和恶性事件发生的频率概率之间存在一个粗糙的，未经统计学实证检验的线性关系。这种联系只是表面上的相关而非实际的因果，相关性不等于因果性。有的人看到这里可能会感觉我的“求生欲”很强，但我写这么一大段的目的并非“求生欲”或者什么“免责”，我分享的都是带有我自己立场与惯性的叙事和分析框架，不是什么科学真理、惊天秘辛，也不是借助所谓的冲塔或者别的什么立场来提高自己的论证可靠性。还希望所有的读者仅仅只把我的文章当作参考，去形成自己的分析评价框架，反过来自己思考我的文章具体逻辑是否通顺、符合经济运行事物，让自己的脑子和嘴真正地思自己所思、言自己所言，以理性的形式主张自己的经济权益。基于治理恶化下的新思路因此，我们可以假设认为随着经济周期的演变+社会各思潮的演进，2024年乃至未来中短期内社会恶性事件发生的频率较前十年会持续增长。城市扩张和社会复杂性的提高似乎使得传统的安全措施和现有的大维稳体制逐渐难以有效维持原先的“平安”社会治理愿景。那有聪明的小朋友可能会说，只要xxx的根本问题/原因不解决，xxx就会越来越多巴拉巴拉巴拉……要我说这种就属于正确的废话，现代教育体系单单强调解决“核心问题”和“主要矛盾”，但大家很大程度上并没有亲身参与社会治理的经验，并不能真正了解“解决核心/根本问题”这个词本身就近乎不可能，如果社会中各种集团博弈斗争的根本那么好解决，我们现在应该还在周朝开开心心的种井田。基于这样的认知，我是一个极端现实的建制派，我不相信理想不相信伟大革命不相信爱与和平，我只相信制度博弈下的相互妥协，我只相信庸俗的技术主义，解决问题更多还是要靠工具箱里的方法论与实操性策略。如果我们关注近期恶性事件的导火索，不难发现多半是犯罪人自认为受到了周边人（上司、伴侣、学校管理人员）等的欺压，在气不过之后选择直接报复社会。嫌疑人在犯罪之前的显著特点就是导火索明确，且情绪积累和爆发的路径清晰可循。这类人群在犯罪前通常经历了一段时间的心理失衡和情绪积累，表现为对身边冲突越来越敏感，行为逐渐极端化。当我们把这些具体的案例进行归纳和分析，可以发现，在多数恶性事件前，这些个体已经在不同程度上表现出情绪波动、社交关系紧张甚至孤立无援的迹象。他们的行为模式往往可以通过数据痕迹、心理指标以及一些社交互动反馈来捕捉到。正是在这种前提下，传统的纠纷调解或维稳措施显得反应迟缓，未能及时介入或事先识别出风险。是的，在社会本身转型期矛盾没办法快速解决的前提下，我们能否提前识别这种“高危”个体，在他们做出不可挽回的极端行为之前进行有效干预？就像游戏《看门狗》中的 CtOS（Central Operating System）那样，借助类似于CtOS的犯罪预测系统，通过对公民包括社交媒体发言、职场行为、生活轨迹等在内的多维度数据进行全方位分析，形成一个“情境感知”的智能体系，以在潜在犯罪人情绪失控之前，分析其行为模式和关键风险点，构建一个从“情绪波动”到“行为极端化”的追踪路径，从而为执法部门、社区组织或心理健康服务提供提前介入的机会。这种技术能够有效缩短社会系统在面对潜在威胁时的反应时间，最大限度地预防恶性事件的发生。在探讨具体的技术实现和应用场景之前，我们有必要先回顾一下犯罪预测领域的研究现状。纵观相关领域的发展历史，犯罪预测的研究方向主要可以分为两类：一类是传统犯罪预测，聚焦于基于历史数据和已知犯罪行为模式的分析；另一类则是近年来兴起的数据驱动的以人为对象的犯罪预测，依赖于loT、大数据、人工智能和机器学习等新兴技术的支持。在接下来的部分中，我们将首先介绍传统犯罪预测的研究方向，探讨这种方法的优势与局限性。一、传统研究方向：以犯罪区域为对象早在20世纪中叶，西方国家的警察部门就已经应用以传统统计学为基础的犯罪预测方法。这一过程被认为是“精算司法”（actuarial justice）在刑事司法领域兴起的体现。和移动互联网兴起后的大数据云计算浪潮同步，区别于传统结构化、抽样、假设检验的犯罪预测模式，大数据背景下的犯罪预测正在全世界的主流主权国家社会中兴起。大数据背景下的“犯罪预测”被西方学者喻为“旧把戏，新技术”（old trick，new tech）。“旧”指的是犯罪预测惯用的理论模型与实践样态与传统背景下基本一致；“新”指的是犯罪预测的样本选择与分析方式在大数据背景下具有“数据化”的海量特色。1.核心模型在现代犯罪预测领域中最主要核心的两个模型分别是“近重复理论（Near Repeat Theory）”和“风险地形建模（Risk Terrain Modeling）”。近重复理论基于“犯罪行为在时间和空间上存在聚集效应”这一基本架设，即当某个地点发生犯罪时，未来相对较短的时间内，该地点及其周边区域再次发生类似犯罪的概率将显著增加。这种现象在盗窃、抢劫等财产犯罪中尤为明显，其背后的逻辑是犯罪分子在成功作案后可能会再次光顾熟悉的地点，或者附近的其他犯罪分子被“启发”，认为该区域易于作案。通过对历史犯罪数据进行分析，近重复理论能够助力预测犯罪行为的 “时间与空间簇集” 情况，进而为执法资源的部署提供参考依据。例如警方可以依据过往盗窃案件的分布情况，识别出未来有可能发生类似犯罪的热点区域，并提前强化巡逻力度或者采取相应的预防措施。风险地形建模则关注犯罪与环境之间的关系，其主要观点为某些物理环境因素（如商业区、酒吧、交通枢纽、空地等）会增加犯罪发生的可能性。因此，该模型识图通过将地理空间特征与犯罪历史数据结合，识别出上述“犯罪诱因”的分布特征，进而生成一个风险地图，显示哪些区域由于环境特点而更容易成为犯罪现场。通过识别这些高风险地带，执法部门可以更加有针对性地进行干预，例如安装更多监控设备、调整街区的照明条件或增加警力巡逻等。随着数据量的增大以及交互式信息技术的进步，风险地形的预测及预警机制正愈加精确化。2.局限性在之前信息化平台未普及时（乃至于现在），各种犯罪信息和城市数据一般都通过纸质归档，信息出自多门难以量化整合到一处进行分析，受限于部门间的信息壁垒和人力资源的限制，预测结果误差较大且高度依赖警察部门分析人员的主观结论。单纯依赖历史犯罪数据也无法完全捕捉到犯罪背后的复杂动因。例如区域的社会经济变动、人口结构的变化、政策的调整等都可能影响犯罪行为的发生，但这些因素往往无法通过简单的空间分析模型进行量化。最后过度依赖犯罪热点和区域特征还可能导致“执法偏见”的产生。特别是在一些长期被认为是高犯罪率的区域，执法资源的过度集中可能加剧对特定社区或少数族裔群体的歧视性执法，进而引发更深层次的社会矛盾。当然，之所以大家都以犯罪区域为预测对象而不是以人为预测对象当然还有法律制度和loT未普及的原因。这就是非不为也，实不能也。我国开展过一些预测性警务探索，但尚没有真正实现业务化运行，这可能与国内外警务模式之间存在的较大差异有关。借鉴IBM公司在美国孟菲斯市开发Blue CRUSH（Criminal Reduction Utilizing Statistical History，利用统计历史数据减少犯罪）项目的成功经验，北京市怀柔公安分局于2013年开发了相关应用，实现了警力投量投向的时空引导。江苏省苏州市公安局于2014年开发了一个类似于PredPol的犯罪预测系统，并在2个派出所内开展了试点，据相关报道称取得了不错的应用效果。然而，据了解，由于国内外警务模式的差异，系统运行与我国警务工作机制不相适应，相关系统后续均已停用。在国外，警察预防和打击犯罪的重要手段之一是州、县和城市警察巡逻，而在中国，社区巡逻工作通常是由派出所民警承担，每位民警所负责的警务责任区空间范围相对较小，责任民警对区内整体治安状况和犯罪热点较为熟悉。与责任民警的经验相比，当前大多数犯罪时空预测模型的预测效果并不理想，因此在实践中也就难以得到持续应用。总之，以美国预测性警务模式为参考，国外很多国家开展了将犯罪时空预测与警务模式相结合的应用实践。我国虽然也较早地同步开展了相关尝试，但由于国内外警务模式之间存在较大差异，并缺乏必要的系统化研究跟进指导，犯罪时空预测结果与国内警务模式的契合程度并不紧密，导致相关实践应用的效果并不理想。相比于过去单纯以犯罪区域为预测对象，现今越来越多的研究开始关注“以人为预测对象”，即通过数据分析和行为模式的研究，预测潜在犯罪分子的行动，从而在犯罪发生之前进行干预。这一转变不仅能够提高预测的准确性，还可以减少区域化执法偏见，进一步优化犯罪预防的策略。二、loT时代下以人为预测对象机制1.理论分析首先，我们来介绍一下什么是loT。IoT（Internet of Things）即物联网，是指通过互联网、传统电信网等信息承载体，将各种信息传感设备与互联网结合起来而形成的一个巨大网络。这个网络实现了物与物、物与人的泛在连接，实现智能化识别、定位、跟踪、监控和管理。在IoT系统中，各种设备（如智能手机、可穿戴设备、家用电器、车载设备等）都可以成为数据采集和传输的节点。这些设备通过各种传感器收集环境数据、用户行为数据等，并通过网络将这些数据传输到云端进行分析和处理。loT领域的快速发展使得强力机关利用互联网对个体实现全方位的监控有了基本的实现空间，IoT技术的应用意味着可以获取更丰富、更实时的数据源。人们的手机、智能手表、家用摄像头、智能交通系统，甚至是城市基础设施中的传感器，都可以捕捉和记录个体的行动轨迹、社交活动和环境变化。这些数据可以帮助执法部门更细致地了解个体的行为模式，并识别出可能的犯罪风险。传统的犯罪侦查是反应型的被动侦查模式，侦查总是要落后于犯罪行为的发生，公安机关只能做到打击犯罪而无法做到预防犯罪。但现在loT+大数据的发展使得公安机关不仅仅可以通过数据搜索、数据挖掘、数据碰撞和数据建模的方式进行事后的侦查活动，还可以在事前进行主动型的预测和介入。过去的侦测活动只能通过“犯罪心理画像”——根据现场遗留的痕迹、物证等信息，结合主观经验判断对犯罪嫌疑人的外形、身份和心理活动等要素进行描绘，而现在则可以通过对侦察机关数据库、社会公共数据库、大数据公司的用户数据中的数据与情报进行研判，对犯罪嫌疑人或相关人员的基本信息进行“数据画像”，从个人基本信息、形体特征、行为轨迹、消费习惯、经济状况、兴趣爱好等信息中提炼出性格特征、行为特征、职业特征，从而实现针对高危人员预警的功能。参见刑事专业研判平台，对前科犯罪人员数据库、旅馆住宿数据库、网吧上网数据库等信息进行算法处理和特征点筛选，初步实践了大数据画像的犯罪预警功能。2.应用情况此处有一大坨欧美实际应用场景，但我懒得超过来贴上去了。总之就是部分人类学家和社会学家组成了“社会物理学”学派，主要观点是人类社会的发展变化和人类本身的思想、行为，与自然界的其他组成部分一样遵循着一系列物理规律，只要掌握足够的信息，就能发现这些规律并对其进行预测乃至控制。最知名的案例就是芝加哥警察局和伊利诺伊理工学院合作语言发的“战略对象清单”行动，根据历史犯罪记录对市民犯罪或沦为犯罪受害者的风险进行量化评估并在0～500的区间内评分，据此确定警务工作重点。截至2017年，“战略对象清单”的数据库已包含约40万人的评分，其中约29万人因分数超过250而被标注为“高风险”。调查显示，在2016年，该项目评分为500（最高风险等级）的人员中约1/3卷入了枪击或谋杀案件；得分在429及以上的1400人卷入了芝加哥市当年约20%的涉枪暴力案件，显示该行动在预测暴力犯罪方面较高的准确率。2010年以后，随着大数据时代的到来，美国警察机关有条件利用更为海量和多元化的数据以提升“预测性警务”的准确性和效率。在奥巴马政府“21世纪警务工作队”倡议的框架下，数据科学和信息技术对改善警察效能和提升社区安全方面的潜力得到进一步重视，美国一些暴力犯罪高发的大城市，如芝加哥，建立了使用各种软件系统和专用工具处理来自城市各个角落的传感器所收集的数据的技术中心，并通过“融合”中心机制与其他政府部门实现了数据共享。新的传感器技术，如基于军队使用的狙击手定位装置的枪击声学感知系统（ShotSpotter）等得到迅速推广。纽约市警察局部署了集成联网摄像头、环境传感器、车牌读取器、报警电话记录系统、枪击声学感知系统等数据采集设备的“场域感知系统”（Domain Awareness system），用以支持基于名为“图形化”（Patternizr）的机器学习算法的“预测性警务”应用，根据2017年的评估，经过为期24周的实验，纽约总体犯罪指数下降了6%。什么，你说后来呢？后来各种后现代议题兴起了，这种检测手段被视为歧视性xxxx，已经被废除了。What can i say？当然，我相信FBI和CIA肯定不会放弃这么好用的东西，毕竟不道德归不道德，好用是真好用，强力部门当然不可能被简单的民意所裹挟。3.几个基本的预测分析思路社交网络分析马克思曾说\"人是社会的动物\"，以人为核心的犯罪预测自然要研究嫌疑人的关系网，这就是社交网络分析（SNA）。通过分析个体在社交网络中的互动，尤其是与犯罪分子或高风险群体的社交联系，执法机构可以识别潜在的犯罪嫌疑人或高危个体。例如某人的社交圈中频繁出现已知犯罪分子或有犯罪前科的人员，该人的犯罪风险可能随之增加。通过深入分析这些社交网络中的关系强度、互动频率和信息传播路径，预测系统能更早发现犯罪网络中的关键节点，从而提前干预，防止犯罪升级。进一步讲，SNA的经用场景当然不会仅仅局限于个人关系网分析，还可以帮助揭示整个犯罪网络。类似于金融犯罪洗钱诈骗等有组织犯罪活动背后会有一个复杂的群体犯罪网络结构作为支撑，一套高效的SNA框架可以帮助执法部门识别隐藏在各种三无小号之下的犯罪结构，辨别犯罪的领导者、核心成员和外围支持者，抽丝剥茧的针对性打击犯罪网络的关键节点，继而有效的瓦解整个犯罪组织。此外，SNA还可以帮助识别信息在犯罪网络中的传播路径。例如某些犯罪团伙可能通过社交媒体、即时通讯工具或线下社交圈传播犯罪计划和指令。通过监控这些信息流动，执法部门可以更加精准地预测犯罪活动的发生时间和地点，甚至预防潜在的犯罪企图。这种基于信息传播的分析能够极大提高犯罪预测的前瞻性，使得执法部门能够在犯罪尚未发生之前采取行动。行为模式分析相较于之前的SNA社交网络分析，行为模式分析更加侧重于个体的行动轨迹、日常活动和行为习惯。每个人的行为都有一定的规律性，无论是工作通勤、娱乐活动，还是购物消费，都会形成相对稳定的行为模式。而当某个个体的行为突然偏离了这些模式，尤其是出现与已知犯罪行为相似的轨迹或特征时，就可能意味着该个体正在策划或参与犯罪活动。例如，某人如果突然频繁出现在一个与其平时活动轨迹不符的高风险区域，或是经常出入某些犯罪高发场所，这些异常行为就可能引发系统的警示。社交平台言论分析在行为科学和认知科学领域的研究表明，人类的某些情绪状态或行为倾向于犯罪行为之间存在着密切的联系，焦虑、愤怒、冲动等负面状态情绪往往是某些犯罪行为的导火索，此类情绪的积累和爆发可能导致个体在短时间内失去理智，做出攻击性、破坏性或反社会的行为。因此，通过对个体情绪状态的监测和分析，执法部门以及相关的预测系统可以识别出潜在的高危人群，及早进行干预，防范犯罪行为的发生。刚好，当今几乎人人都沉浸在网络世界中。互联网上的自我与现实中的自我共同构成了现代社会中真实的\"自我\"。个体的心理状态常常通过社交媒体上的言论、文字表达和行为表现出来。例如当某人在社交平台上频繁发表消极、攻击性或极端言论时，他要么是疯了要么是近期情绪波动严重要么两者皆有（）。当这些言论包含愤怒、怨恨、报复、威胁等信息时，很可能预示着该人正处于情绪失控的边缘，这种情绪失控往往是暴力犯罪的前兆。一个人如果频繁发布自我否定、无助感或社会疏离相关的内容，则代表其心理健康处于危险状态，可能萌生制造极端行为的念头。在网络社群治理中，我们也可以发现某些极端思想和犯罪倾向往往通过网络社群或小圈子传播，尤其是在一些极端主义思想聚集的网络论坛、社交群组中，个体之间的情绪共振和相互煽动可能会加剧犯罪的发生。通过监控这些社交群体中的互动，特别是某些特定话题的讨论热度和情绪走向，系统可以识别出那些正在酝酿犯罪行为的群体，并提前采取行动，干预其犯罪计划的实施。除开个人/社群言论，个体的网络搜索记录也可暴露其内心变化。行为科学研究表明，人们的网络搜索行为往往与他们当前的心理状态和计划行为有关。当一个人开始频繁搜索与暴力、武器、违法行为或极端思想相关的内容时，可能表明其正在思考或筹划某种犯罪行为。有些恐怖主义行为的实施者在作案前曾进行详细的网络搜索，查找如何制造爆炸物或组织恐怖袭击的细节步骤。通过对这些搜索行为的分析，预测系统可以更早地察觉到个体的犯罪倾向，及时发出预警。三、CtOS技术原理解析《看门狗》系列中的CtOS（Central Operating System，中央操作系统）是一个高度集成和智能化的城市管理系统，能够实时监控并分析来自城市各个方面的数据，最终用于管理城市功能和预测犯罪行为。虽然这是一个虚构的系统，但背后的技术概念在现实中已经有了一定的雏形。首先，整个CtOS系统的实现基础在于其广泛的物联网（IoT）网络，这一网络将城市的各类设备和基础设施连接在一起。在游戏中，芝加哥市的摄像头、交通信号、公共设施、银行系统、智能手机和家用设备等，全部通过CtOS实现集中管理和数据共享。通过这些IoT设备，系统可以实时监控和管理城市中的一切活动。在现实中，城市物联网同样也正在全面铺开（虽然目前各公司部门各自为战数据不互通）：城市中的监控摄像头、智能交通灯、空气质量检测设备、智能电表、智能家居设备等，正在形成一个巨大的物联网网络。随着5G网络的普及，IoT设备的连接速度和可靠性得到了显著提升，使得大量数据可以在毫秒级的时间内传输到中央系统进行处理。基础有了，接下来就是GPU+深度学习加持下的犯罪预测引擎。深度学习是一类基于人工神经网络的机器学习方法，能够从海量数据中自动提取复杂的特征和模式。犯罪预测引擎通过对历史犯罪数据、社交媒体活动、行为模式、地理位置以及其他相关数据的分析，能够识别出潜在的犯罪风险。深度学习模型不仅可以识别已知的犯罪模式，还能够通过学习不断变化的环境和行为数据，逐步优化和改进预测精度。与传统的中央处理器（CPU）相比，GPU在处理大规模并行计算任务时具备显著优势，特别是在训练和运行深度学习模型时。犯罪预测系统需要处理海量数据，包括城市监控录像、实时传感器数据、社交网络信息等，这些数据的处理和分析对计算能力提出了极高的要求。GPU的高速运算能力能够大幅提升深度学习模型的训练效率，使得系统能够在短时间内处理数十亿条数据，并实时作出预测和决策。当我们操控艾登皮尔斯扮演私法制裁者的时候，预测犯罪还依靠CtOS系统能够实时获取市民的社交网络、财务记录、医疗数据等隐私信息的能力，通过抓取高风险市民的隐私对话记录关键词，系统会自动帮助我们判断ta卷入犯罪的风险，及时通知私法制裁者展开行动。四、类CtOS系统落地困境与未来展望尽管人类社会目前有差分隐私同态加密等手段来保护个人隐私，但现实中的城市管理系统仍然在获取和处理公民个人数据时面临着巨大的道德和法律压力。在《看门狗》中，艾登·皮尔斯可以利用CtOS获取到市民的详细背景信息，包括他们的职业、收入水平、甚至是私人健康问题，这种全方位的透明度在现实中几乎不可能被完全允许。哪怕我们抛开打造CtOS所需要的海量资源不谈，一个城市级别的操作系统如果拥有如此广泛的权限，将很容易引发公众对于大哥在看着你式的监控社会的恐惧。我要再重申一遍，这玩意放到任何一个地方都做不到，因为整合如此海量的数据需要耗费的政治经济资源是极其庞大的，放国内也差不多是要按着腾讯、阿里、字节、百度和华米OV联通电信等巨头的头，让几百万工程师在一起肝好几年统一各种数据规范和接口，然后在全国范围内建好几十座巨型超算中心和储存中心去算十四亿人产生的海量数据，光训和测试模型保底都得个大半年，效果也不一定好。非不为也，实不能也那么，距离我们真正实现如《看门狗》中的CtOS系统还有多远？虽然技术上我们已经具备了相当的基础，但一个完整的CtOS系统要真正落地仍然需要解决若干现实问题。除了隐私保护，还包括数据孤岛问题、系统安全问题，以及政策法规议程的推进。首先就是数据不互通，目前许多智能设备和城市基础设施都是由不同的公司和部门独立运营，数据无法在不同设备和系统之间自由流动。要实现像CtOS那样的全城市级别的数据集成和管理，市政当局和技术提供商必须打破数据孤岛，建立统一的数据标准和接口。这条就基本可以决定CtOS在5年内实现不了了其次，系统安全也同样重要。一个管理整个城市的中央系统，必然会成为黑客攻击的主要目标。在《看门狗》中，玩家可以通过入侵CtOS系统来操控交通信号灯、关闭电网、甚至引发大规模的社会混乱。虽然这在游戏中是为了提供娱乐性和戏剧性冲突，但在现实中这样的破坏性攻击可能会造成极为严重的后果。这一系统如果只能被极少部分人掌握就没办法完全发挥其预警作用，但一旦可以使用的人多了就极容易给全社会来个大的。警务通权限管理不严格已经在公民信息方面带来很多问题了总的来说，虽然像CtOS这样的系统在短期内不太可能以完全相同的形式出现，但它所代表的技术理念——即通过物联网、大数据和人工智能等技术手段，实现城市的高效管理和智能治理——已经在现实中逐步成型。随着技术的不断进步和隐私保护技术的完善，我们或许会看到一个更加智能、安全、且具备高度自动化管理能力的未来城市系统逐渐浮现。到那时，虽然我们可能不会亲自扮演艾登·皮尔斯，但我们生活的城市可能已经在悄然之间变得更加智能、高效——甚至，也许已经具备了某种程度的“犯罪预测”能力。五、可能的问题Q&AQ1：根本问题没解决，你这叽里咕噜的没有任何用处！A：我是一个极端现实的建制派，我不相信理想不相信伟大革命不相信爱与和平，我只相信制度博弈下的相互妥协，我只相信庸俗的技术主义。本文立论的基础就是经济周期和犯罪频率存在宏观意义上的线性关系，经济周期本身不可逆，那么从社会治理的角度就只能“压缩”犯罪而非搞点其他的什么行为艺术。Q2：不要xx要xx，我们要保护公民隐私……A：这其实是一个价值观的选择问题，但实际上哪怕在大洋对岸，FBI和CIA乃至于摩萨德也从来没有放弃我上面说的这种监视计划，他们走的要比我们远得多。强力部门不太可能向民意妥协，因为民意似水民动如烟，每一种思潮的奥弗顿窗口期就那么点，但各种恶性犯罪会永远存在并且需要强力部门实际投入资源去解决。一旦涉及到“我家里真的有一头牛”，所有人就会瞬间老实。当然如果你真的认为公民隐私对你来说非常非常非常重要，可以选择去相关部门网站的民意咨询中写下你的顾虑与建议，也可以考虑发表专门的学术论文来论证这一套系统无异于压缩犯罪/对社会弊大于利。Q3：这一系统是否会被滥用？A：当然会，我在分析问题时通常不会相信任何崇高。不过所幸建设这一系统所需要的巨量资源和上层建筑准备目前来看全世界都没办法在中短期内筹集到，如果真建成了在我的推演内也是利大于弊。参考文献[1] 胡铭 严敏姬.大数据视野下犯罪预测的机遇、风险与规制——以英美德“预测警务”为例[2] 朱浩文.大数据犯罪预测的法律分析[3] 李皛.美国“预测性警务”的发展与困境 Predictive Policing in the United States：Developments and Dilemmas[4] Mandalapu, V., Elluri, L., Vyas, P., & Roy, N. (2023). Crime Prediction Using Machine Learning and Deep Learning: A Systematic Review and Future Directions. IEEE Access, 11, 60153-60170. https://doi.org/10.1109/ACCESS.2023.3286344[5] Safat, W., Asghar, S., & Gillani, S. A. (2021). Empirical Analysis for Crime Prediction and Forecasting Using Machine Learning and Deep Learning Techniques. IEEE Access, 9, 70080-70091. https://doi.org/10.1109/ACCESS.2021.3078117[6] Kaur, M., & Saini, M. (2022). Indian government initiatives on cyberbullying: A case study on cyberbullying in Indian higher education institutions. Educational Information Technology, 1-7. https://doi.org/10.1007/s10639-022-11168-4[7] Kaur, M., & Saini, M. (2023). Role of artificial intelligence in cyberbullying and cyberhate detection. In 2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT), Delhi, 1-7. https://doi.org/10.1109/ICCCNT56998.2023.10308090[8] HE Rixing, LU Yumei, JIANG Chao, DENG Yue, LI Xinran, SHI Dong. (2023). Progress in Research and Practice of Spatial-temporal Crime Prediction over the Past Decade. ISPRS International Journal of Geo-Information, 12(4), 236."
  },
  {
    "title": "从碎片到系统：我的信息整理与优化之路",
    "summary": "我的管理方案和存在的问题在信息爆炸的时代，我们每个人的知识源都被碎片化地分布在不同的平台和工具中。从公众号文章到书籍摘录，从研究报告到PDF文件，广领域、多平台、全天候的各种信源交错与堆积，每天都有大量的信息需要管理和处理。作为一个知识工作者，我处理信息的软件一共有四个：Cubox用来集中处理解析网上看到的有价值的文章、视频、链接，等有时间了再看。Notion作为知识整理中心，我会将Cubox筛选",
    "tags": [],
    "url": "/posts/Essays/从碎片到系统：我的信息整理与优化之路/",
    "date": "2024-11-11T00:00:00.000Z",
    "content": "我的管理方案和存在的问题在信息爆炸的时代，我们每个人的知识源都被碎片化地分布在不同的平台和工具中。从公众号文章到书籍摘录，从研究报告到PDF文件，广领域、多平台、全天候的各种信源交错与堆积，每天都有大量的信息需要管理和处理。作为一个知识工作者，我处理信息的软件一共有四个：Cubox用来集中处理解析网上看到的有价值的文章、视频、链接，等有时间了再看。Notion作为知识整理中心，我会将Cubox筛选处理后的文章存入Notion的Database里（感谢Notion的万物皆block理念），由AI添加标签和摘要方便后期索引查询。思源笔记我则主要用来进行PDF书籍的批注和阅读，书籍研究报告中的重要摘录和思考都会放在这里。最近，因为飞书多维表格+AI自动化功能非常好用，我又将日常任务管理、OKR编排和个人书库影音库放到了飞书里。当然，我自己并不是有了这些知识管理工具就直接高枕无忧畅享“第二大脑”了，工具磨合与处理过程中的问题仍然不少。检索困难：在每个平台中，我都建立了多个分类与标签，以便快速查找。但当信息量积累到一定程度时，这种做法逐渐变得繁琐且低效。举个例子，当我需要回顾一篇文章中的某个概念，而这个概念在不同的笔记软件中可能以不同的形式存在，我往往需要花费大量时间去从多个地方检索（还不一定能找到想要的）另外，随着我知识库的不断扩展，如何筛选出最为核心、最具价值的信息也成了一个难题。很多时候，我在某个项目或研究中会收集大量的资料，但随着时间的推移，这些资料可能变得过时或不再相关，而我却依然在这些信息的海洋中徘徊，浪费了大量时间。如何筛选和整理出真正能帮助我思考和创作的内容，成了我的另一大困扰。维护困难：除了信息量的积压，另一个问题是知识管理的“可持续性”。目前的做法依赖于我每次将新的信息手动分类和存储，而这种方式需要持续的时间和精力投入。在繁忙的工作和生活中，很容易就会懈怠，导致知识库的更新和维护停滞不前。这不仅影响了知识库的完整性，也使得之前的知识积累变得碎片化、难以回溯。面对这些问题，我开始思考，是否有可能找到一种更高效、更系统化的管理方式，能够打破这些平台之间的“信息孤岛”，实现知识的无缝对接与整合。是否能设计一个更加简洁的流程，使得从收集、整理到应用的过程变得更为顺畅和自动化？在这个过程中，我意识到，我不仅需要更高效的工具，还需要在方法论上做出调整——如何从整体上重新审视我的知识管理系统，让它不仅能适应当前的需求，也能具备未来扩展的能力。解决方案1.建立信息筛选与知识梳理机制并不是所有我随手丢到Cubox里的信息都值得我专门存到数据库里方便未来回忆学习，很多时候收藏的文章并没有足够的时效性/重复阅读价值，信息收集的第一步是快速存储，但在日后回顾时，我们需要有一个快速筛选、提炼和更新的流程。定期整理：每隔一段时间（例如每月），我会对Cubox知识库进行一次全面的整理。重新审视每个信息类别的价值，删除那些已经过时或无关紧要的内容。定期回顾可以避免无用信息的积累，让知识库保持“精简且有效”。创建信息摘要：对每一篇文章、报告或者书籍的关键内容进行摘要，并将其汇总到 Notion 中。这不仅方便我日后的快速查阅，还能加深我对这些知识的理解和记忆。2.知识最终存放平台的统一一个最直接的方法就是将所有的终端沉淀下来的知识放到一个统一的平台，未来检索查询只在这一个平台就可以了，不需要多网页/应用/设备来回倒腾折磨自己。我现在会将Cubox完成筛查的文章统一导入到Notion的专属数据库，并且由Notion ai给文章打标和生成摘要，完美符合懒人天性，爽到。Notion 与其他平台同步：利用 Notion 的集成功能，将 Cubox、思源笔记中的信息通过 API 或手动导入的方式，集中管理。Notion 的强大数据库功能可以让不同类型的信息在一个地方整合，并通过标签、属性进行筛选和分类。Zapier 或 Integromat：利用自动化工具将不同平台之间的数据进行同步，例如将 Cubox 中保存的文章自动导入 Notion，并为其添加合适的标签。通过自动化处理，大大节省了手动输入的时间。3.P.A.R.A.知识整理方法P.A.R.A. 是什么及在 Notion 中的应用P.A.R.A.是一种知识管理方法，由生产力专家Tiago Forte提出。P.A.R.A.是Project（项目）、Area（领域）、Resource（资源）和Archive（归档）的缩写。这四个类别构成了PARA方法的核心框架。以下是PARA方法的主要组成部分：项目（Project）：具有明确目标和时间范围的任务。这是最小的执行单位。领域（Area）：你需要持续关注和精进的领域，通常与你的责任相关。资源（Resource）：你感兴趣的主题，可以支持当前和未来的领域发展。归档（Archive）：不再活跃但可能在未来有用的内容。其中 Goal 是贯穿始终的，Area 的持续精进是最终目的，Project 的选择和执行是阶可量化的段性目标，Resource 是支撑二级的「Area」的资源、资料（外部的）。围绕 Area 的精进，我们需要不断吸收外部的有效信息和进行阶段性的「创作」，而阶段性的创作需要的主题，可以是 Area 的拆分，也可以是基于 Project 的抽象和总结，但来源主要是通过实践（Project）和理论来进行的（即 Resource——外部参考、经验、方法论）。4. 逐步放弃“过度管理”过度的管理和分类往往会耗费大量的时间和精力，反而影响效率。为此，我决定放弃一些过于繁琐的管理方式，尽量简化流程：减少分类层级：避免对每个小类目都建立单独的文件夹或分类标签。简化分类，保持分类的层级尽量扁平化。优先关注使用频率高的内容：对一些长期不用的内容，我减少更新和整理频率，集中精力管理那些高频使用、对当前工作或学习有实际帮助的信息。5. 引入AI助手Notion数据库里可以用ai自动打标和生成摘要，检索也可以以自己的整个Notion库为索引范围询问Notion ai，效果非常不错（核心在于不用自己去操心数据库该如何索引用什么模型，Notion可以帮你全部包揽了）。飞书多维表格在ai方面则更加强一点，可以根据条目让ai在网上搜集可用信息，可以ai识图等等等等……飞书相较于Notion的缺点就是性能表现相对较差，在页面编排上灵活性也稍差（Notion的万物皆block太方便了）总结解决这些问题的核心在于建立一种更高效、更系统的管理机制，而不是单纯依赖某一款工具或平台。通过工具的整合、信息的筛选与梳理、跨平台的引用、以及引入 AI 等辅助手段，我希望能够让我的知识管理系统变得更加流畅、易于维护，并且能够适应未来信息量的增长和变化。说到底，知识管理最终的目的还是知识的运用，管理是为了更好的应用而非给自己营造一种虚假的秩序感来自我满足。我没有耐心和精力去投入大量的时间来维护一个数据库，大部分工作交给AI代劳岂不美哉？"
  },
  {
    "title": "不再依赖平台：如何打造自己专属的博客网站？",
    "summary": "序这两天我在读居伊·德波的《景观社会》，在网络社会崛起与“媒体过剩”的时代，借助于日益发达的大众传媒工具，景观的作用与功能也日益强化。从轻松的娱乐废料到严肃文学，从日常生活到人的感情和欲望，我们的生活几乎每一个角落都被景观所笼罩和取代，景观的无孔不入让每个个体仿佛置身于一场永不停歇的表演之中。在现代资本主义框架下的这场永无止境的拜物嘉年华中，“自我表达”便显得尤为宝贵。通过搭建一个属于自己的博客，",
    "tags": [],
    "url": "/posts/TechnicalTutorials/不再依赖平台：如何打造自己专属的博客网站？/",
    "date": "2024-11-06T00:00:00.000Z",
    "content": "序这两天我在读居伊·德波的《景观社会》，在网络社会崛起与“媒体过剩”的时代，借助于日益发达的大众传媒工具，景观的作用与功能也日益强化。从轻松的娱乐废料到严肃文学，从日常生活到人的感情和欲望，我们的生活几乎每一个角落都被景观所笼罩和取代，景观的无孔不入让每个个体仿佛置身于一场永不停歇的表演之中。在现代资本主义框架下的这场永无止境的拜物嘉年华中，“自我表达”便显得尤为宝贵。通过搭建一个属于自己的博客，我们可以选择脱离主流的内容展示平台，跳出景观对内容的定义，去建立一片属于自己的空间，不为流量和点赞左右，纯粹记录自己独立的思考与见解。一个独立的博客可以帮助我们避免信息的过度压缩与表面化处理，构建一个较为纯净的精神空间，让自己的思考和表达不至于被瞬时的注意力洪流所淹没，多输出一点严肃内容总归是对个人，乃至对这个社会是大有裨益的。在搭建个人博客的过程中，有多种方式可以选择。不同方法的难易程度和所需技术背景各不相同，还请各位读者根据自己的需求和技术水平来决定。以下我将按照从易到难的顺序，介绍几种搭建个人博客的方式。一、使用现成的博客管理框架在本节，你需要一台可以访问外部网络的VPS（如果你没有/没有足够的资金去购买一台2C2G以上的VPS，可以直接看第二节Vercel）本节适合有一定技术基础的用户，可以选择搭建在自己的VPS上，使用WordPress或Halo等开源博客程序。这类程序提供丰富的主题和插件，便于高度定制，也让博客具备较强的拓展性。你可以通过选择不同的主题来调整外观，安装插件来添加更多功能，比如SEO优化、数据分析、订阅等。虽然安装和配置过程稍显复杂，但有丰富的文档和社区支持，适合希望有更高自主权的用户。（一）、WordPress1.1Panel部署你可以先安装1Panel（宝塔也可），然后直接通过GUI部署WordPress# 1Panel安装（CentOS）\n\ncurl -sSL <https://resource.fit2cloud.com/1panel/package/quick_start.sh> -o quick_start.sh && sh quick_start.sh\n\n# Ubuntu\n\ncurl -sSL <https://resource.fit2cloud.com/1panel/package/quick_start.sh> -o quick_start.sh && sudo bash quick_start.sh\n\n# Debian\n\ncurl -sSL <https://resource.fit2cloud.com/1panel/package/quick_start.sh> -o quick_start.sh && bash quick_start.sh安装成功后，控制台会打印面板访问信息，可通过浏览器访问 1Panel：http://目标服务器 IP 地址:目标端口/安全入口如果使用的是云服务器，请至安全组开放目标端口。ssh 登录 1Panel 服务器后，执行 1pctl user-info 命令可获取安全入口（entrance）从浏览器里访问1Panel之后就可以在应用商店里一键部署WordPress了，容器跑起来之后记得在网站里添加自己的域名，绑定证书并开启反向代理以便通过域名直接访问你的博客。2.Docker部署（以CentOS为例）（不推荐，因为麻烦）实际上用1Panel部署WordPress也是在用Docker部署，只是1Panel可以很方便的帮你管理各种镜像和网站。更新系统软件包：sudo yum update -y安装依赖：sudo yum install -y yum-utils添加官方仓库：sudo yum-config-manager --add-repo <https://download.docker.com/linux/centos/docker-ce.repo>安装Docker：sudo yum install -y docker-ce docker-ce-cli [containerd.io](<http://containerd.io/>)启动并启用 Docker 服务：sudo systemctl start docker\nsudo systemctl enable docker验证Docker安装：docker --versionDocker拉取WordPress镜像：docker pull wordpress启动WordPress容器：docker run --name some-wordpress --network some-network -d wordpress以下环境变量也可用于配置您的 WordPress 实例（通过自定义 wp-config.php实现⁠）：e WORDPRESS_DB_HOST=...e WORDPRESS_DB_USER=...e WORDPRESS_DB_PASSWORD=...e WORDPRESS_DB_NAME=...e WORDPRESS_TABLE_PREFIX=...e WORDPRESS_AUTH_KEY=..., e WORDPRESS_SECURE_AUTH_KEY=... , e WORDPRESS_LOGGED_IN_KEY=... , e WORDPRESS_NONCE_KEY=..., e WORDPRESS_AUTH_SALT=..., e WORDPRESS_SECURE_AUTH_SALT=... , e WORDPRESS_LOGGED_IN_SALT=... , e WORDPRESS_NONCE_SALT=...（默认为唯一的随机 SHA1 值，但仅在提供其他环境变量配置时）e WORDPRESS_DEBUG=1（默认禁用，非空值将启用 WP_DEBUG在 wp-config.php中）e WORDPRESS_CONFIG_EXTRA=...（默认为空，该值将由 eval()函数在 wp-config.php中进行评估。此变量特别适用于应用此镜像默认未提供的额外配置值，例如 WP_ALLOW_MULTISITE；更多详情请参见docker-library/wordpress#142⁠）WORDPRESS_DB_NAME 需要在给定的 MySQL 服务器上已经存在；它不会由 wordpress 容器创建。如果您希望能够在主机上访问实例而无需使用容器的 IP 地址，可以使用标准端口映射：$ docker run --name some-wordpress -p 8080:80 -d wordpress然后，通过浏览器访问 http://localhost:8080 或 http://host-ip:8080。（二）、Halo（博主目前正在用的）这部分我懒得写了，俺寻思直接把官方文档链接贴到下面然后读者自己去看肯定比我自己花20分钟照虎画猫憋出一段远不如官方详细完整的博客片段对于读者来说要有价值得多。1Panel部署（推荐，因为Halo和1Panel均属飞致云团队出品）部署方法同WordPress，在应用商店中部署后在网站中绑定域名并设置反代即可详细部署文档（官方）Docker部署详细部署文档（官方）（三）、Typecho（轻量级，适合低性能VPS）这篇博客已经介绍的非常完整了，参照这位博主的部署过程即可，不过他用的是宝塔，大致流程可以直接迁移平替到1Panel。才不是我懒得写二、Vercel（适合白嫖党）那有人就要问了：我现在没有VPS也不打算买/我懒得维护服务器/我希望直接将Notion数据库里的文章作为博文发表……那恭喜你，你适合用Vercel！Vercel 是一个提供静态网站和无服务器功能的平台，主打免费便捷、快速部署的优势。它特别适合不想花费太多精力管理服务器的用户，互联网上也有一大批开源项目支持非常方便的直接用Vercel部署你的个人博客，只需要点点点和填点关键信息。 对于预算有限的个人用户来说，Vercel 几乎可以说是“白嫖”搭建个人博客的理想选择。（一）、NotionNext1.项目介绍NotionNext是一个使用NextJS + Notion API 实现的，部署在 Vercel 上的静态博客系统。为Notion和所有创作者设计。项目开源地址项目文档地址NotionNext的愿景是帮助非技术人员的小白，最低成本、最快速地搭建自己的网站，帮助您将自己的产品与故事高效地传达给世界。 NotionNext可以将Notion笔记实时渲染成静态博客站点，无需购买服务器，只要一个笔记即可搭建完全属于您自己的独立网站，让您与全世界建立连接！这个框架都有哪些特点？依托于Notion笔记：借助NotionNext建站，所有文章的编写发布都只在Notion笔记中完成，Notion本身作为次世代笔记软件的强大毋庸置疑。安装简单方便：安装一路点点点即可，需要修改的地方少，不需要独立VPS多主题快捷切换：多达数十款主题风格任您挑选，其中有适合做技术文档的Gitbook主题，也有适合做导航站点的Nav主题，还有适合做产品落地页官网的Landing主题与Starter主题，以及适合做相册的Plog主题。2.部署过程部署站点实际上只需要三步，分别是：复制作者的Notion模板复制作者的 Github 库代码在Vercel中一键部署（1）创建Notion页面首先，你需要注册并登录Notion账号（邮箱注册和直接用谷歌账号注册均可），然后打开这个链接，进入到作者的Notion模板页面，在右上角点击Duplicate复制模板，如图所示。点击后会将这个博客数据模板复制到你的笔记空间中。image.png（2）获取页面ID（此部分直接援引项目文档）在Notion笔记中：在页面右上角的菜单栏中，依次点击Share→Published→Share To Web，开启页面分享，获取共享链接如下图所示，点击右上角 **Share ，**在弹出窗口中点击 Publish → Share to web (点击展开截图)image.png复制页面ID：页面ID在您的共享链接中、域名中间的一串32位字母与数字image.png👇以下我的共享链接，其中标红加粗下划线部分才是页面ID！要忽略?v=后面的英文数字。 https://www.notion.so/tanghh/02ab3b8678004aa69e9e415905ef32a5?v=b7eb215720224ca5827bfaa5ef82cf2d 👇我的页面ID 是 02ab3b8678004aa69e9e415905ef32a5⚠️新版的notion中，页面ID的格式可能会有一点不同，例如会把页面的标题也带上： https://www.notion.so/tanghh/Today-261c36d269a74acd97682af86d7bc9a0?pvs=4 但不变的是，页面url中的那串连续32为的字符串就是id。（3）Fork 对应项目的GitHub库请先注册并登陆Github账号，然后点击此链接，可一键**Fork(复刻)**项目。image.png（4）使用Vercel进行部署首先，你需要注册一个Vercel账号，然后点击此链接来创建导入一个新项目。image.png在代码仓库列表中选择导入NotionNext，不要急着直接点Deploy，要先把环境变量填好。点击Environment Variables（环境变量），并添加一个属性名称为**NOTION_PAGE_ID，值为步骤一获取的页面ID**。例如，我的页面ID是：02ab3b8678004aa69e9e415905ef32a5，则配置如下：image.png填写后要点击右边的 Add按钮确认添加然后点击 Deploy按钮，静候两分钟等待部署。image.png（5）完成！在部署完成页面，点击 Go to Dashboard访问控制台image.png在控制台右上角的 Visit按钮访问您的站点。或在DOMAINS中获取您的网站地址image.png博客后期的美化还请参见本部分开头的项目文档（二）、Mix SpaceMixSpace采用前后端分离模式，后端部署在VPS上，前端采用Vercel进行渲染，因为安装比较麻烦所以我懒得写了。文档链接虽然但是，Mix Space的博客主题真的很好看三、静态博客静态博客里，最常见的选择采用Hexo框架，然后部署到Github Pages了。当然，你也可以采用Hexo框架然后部署到Vercel但静态博客一般都需要你将git库克隆到本地，在本地完成博文编写之后push到远程库中，我觉得这种方式不太优雅，因此懒得详细去介绍部署过程了。Hexo文档"
  },
  {
    "title": "为什么我过去、现在乃至未来都看空零一万物",
    "summary": "如果说OpenAI的O1开业内大模型推动System 2思考之浪潮，深度求索的deepseek以其极强的工程化能力一手力推了业内大模型迅速白菜价化，阿里通义千问自身开源闭源两路一同高歌猛进，更是在qwen2.0和qwen2.5发布后均力压meta的llama系列成为世界上最好的开源模型，那零一万物则一直扮演着一个疯狂追逐热点的“小丑”形象：李开复领导下的零一万物初代Yi模型被质疑换皮llama（后",
    "tags": [],
    "url": "/posts/AI and Deep Learning/为什么我过去、现在乃至未来都看空零一万物/",
    "date": "2024-10-19T00:00:00.000Z",
    "content": "如果说OpenAI的O1开业内大模型推动System 2思考之浪潮，深度求索的deepseek以其极强的工程化能力一手力推了业内大模型迅速白菜价化，阿里通义千问自身开源闭源两路一同高歌猛进，更是在qwen2.0和qwen2.5发布后均力压meta的llama系列成为世界上最好的开源模型，那零一万物则一直扮演着一个疯狂追逐热点的“小丑”形象：李开复领导下的零一万物初代Yi模型被质疑换皮llama（后来的辩解非常抽象）；模型在各种榜单上刷爆所谓SOTA但实际效果一般；2023年年中成立后到现在产品路线模糊，定位不清晰，原本all in C端在被市场暴打后仓促转向B端；再到黄文灏等核心人才出走加入豆包……我直说吧，从一位金融壬的角度，零一万物并不能被视为一件值得投资的标的物。在分析零一万物之前，我们需要先探讨一个议题——当前国内，乃至全世界除了OpenAI之外的大模型独角兽共同面临的问题都有哪些？一、独角兽们的集体困境我觉得最明显的问题就是：烧钱，并且是遥遥无期的烧钱。从OpenAI正式推出ChatGPT之后，全世界的投资市场都彻底的被AI浪潮引爆，并且维持了一段时间的极度繁荣（（从2022年12月到2023年6月），在这一时期整个VC/PE圈近乎彻底疯狂，每一位投资人和创业者都在念叨“大模型”、“新时代”、“第X次科技革命”等热词，认真的（相当大一部分人是假装自己能读懂）看各类前沿大模型研究论文，转发各种研报和AI早报……在这一阶段，投资市场的ai板块极度繁荣，市场上崛起了一大批大模型独角兽（基本都以中美为主，日韩欧俄似乎只出了Mistral一根法国独苗，还被微软给吞了），各种融资一轮一轮的给，每一位独角兽的创始人都意气风发，势要将全人类直接送到后ai时代。当然，后面的事我们都知道了。一大群独角兽和AI labs正在以非常离谱的估值在市场上狂揽资金，但彼此间做的事情却几乎完全一样：拿OpenAI的模型训练自家的模型-给科技媒体发通稿一顿吹-安抚投资人投钱然后继续砸钱（每次训练百万千万不等）标定OpenAI训练自己的新模型……随着模型能力提升速度的边际递减，过去大家坚信的“Scaling Law”技术曲线已经明显放缓。OpenAI的GPT-5发布一再推迟，行业龙头在内斗中也颓势逐显，长期拿不出真正颠覆性的新活。我们当然不能否认闭源模型和开源模型和研发对于科研教育市场和科技爱好者的重要性，但大模型的研发训练成本极为高昂，多次训练的压力对于弹药库非常珍贵的独角兽公司来说是难以承受的，而且即使大家愿意投入巨资，一旦市面上的头部企业发布了新的开源模型，原本的投入可能会变得毫无意义（例如meta的llama，阿里的qwen，发布之后很多公司自己炼的模型可以直接作废了，因为拿人家的开源模型效果还会更好）。在研发端大模型研发（成本）是一个资金黑洞，那消费端（营收）呢？很遗憾，这块更拉跨，至少对于独角兽来讲是拉跨的。大模型在产业端究竟该如何应用？我觉得可以分为两个层面。第一，大模型本身就构成了产业的核心商业模式和关键要素，以C端为主，抛开最原始的Chatbot不谈，软件层面包括最近风头比较旺的虚拟陪玩，社交领域的角色扮演，游戏行业的NPC，这一类场景是AIGC的上下游，有自己独特的工作流且一部分已经经历了PMF验证，但涉及到用户群体、内容创作的持续性以及虚拟人物的生命周期限制，当前的市场总量仍然非常非常非常的有限，可能做到底一年也只有数亿的流水。除了这种细分场景外还有硬件上的革新，例如AI PC和还有Apple和荣耀力推的AI手机，乃至于字节的豆包耳机ai pin等，都有一定的应用场景（但仍然非常有限）。这一大类软硬件模式可以称为大模型对于商业模式的大升级，或多或少可以把模型集中到新的商业模式中作为关键变量。第二类，是庞大的B端企业级市场，这类未必是对商业模式做了根本性重塑，而是在降本增效场景作用比较突出，比如最典型的客服场景、知识库的问答等等，这些场景在企业内部对提效来说有非常多的帮助。比较好的案例是阿里巴巴旗下的很多产品都使用了通义千问的模型能力，百度的comate阿里的通义灵码在b端也采购的比较多。一个比较有趣的视角就是，第一类应用是“先有模型，再找场景”；第二类应用则是“现有场景，再找模型”目前，市面上主流的大模型独角兽都还简单的停留在第一类应用上面，模式以简单的Chatbot为主，兼买点大模型api来自己骗自己真的会有开发者和公司来采购。什么？你说为什么他们不去做B端？非不为也，实不能也。更细的我懒得解释了，B端是什么阿猫阿狗刚创业几个月的公司就能碰的吗，BATH下一轮给你的融资不想要了是伐？这就是AIGC落地的普遍问题——创始人该如何找到PMF？如何找到一个合适场景，可以解决实际的问题，可以落地，而不是仍然沉浸在自己的叙事中造概念追热点。一个成功的大模型公司需要回答以下几个关键问题：市场需求是什么？ 是否有真正的痛点，大模型能够比现有解决方案更好地满足这些需求？产品价值如何体现？ 用户为什么会愿意为你的产品买单？这种价值是否是持久的，还是仅仅停留在新鲜感的层面？商业模式是否可持续？ 企业能够通过什么方式建立起长期的盈利能力？这种模式能否复制和扩展？很可惜，独角兽们并没有一个真正合理的叙事框架来回答这些问题。最后我中译中总结一下，对于当前大部分大模型独角兽企业，他们共同面临的困境是：需要的钱永无止境，但现在能挣到的钱屈指可数，未来预期更是迷雾重重。今天很困难， 明天更困难，后天不知道在缺钱并且挣不到钱这个核心问题之外，还有一个比较重要的方面是除了OpenAI之外的其他ai企业目前都只能追赶OpenAI的步伐，难以先于OpenAI做出新的比较彻底的创新，但这块我并不专业，讲了一定会露拙，所以不讲。二、乏善可陈的模型更新哦，当然，我们的李开复院长认为刚发布的Yi-Lightning是正式辟谣零一万物放弃预训练的有力证明。但他发的那一段话真的可以说服他自己吗？据介绍，在国际权威盲测榜单 LMSYS 上，Yi-Lightning 超越GPT-4o-2024-05-13、Claude 3.5 Sonnet，排名世界第六，中国第一。经典刷分王，实测能力味如鸡肋，更何况LMSYS本身公信力就已经弗如去年远甚。目前，Yi-Lightning已在Yi大模型开放平台上线，价格是0.99元/100万Tokens。在和媒体交流时，李开复多次提到这是“白菜价”，但表示“零一万物还是有利润空间的，不参与价格战”。无非是deepseek、阿里、字节等友商早在今年年终就把大模型成本大幅压缩的技术路径给提前铺好了，直接拿过来很方便就能用；今年五月信誓旦旦不参与价格战的通稿还在网上挂着呢，自己模型做的没特色没客户买账回旋镖终于打到自己身上了。他不是知错了，他只是知道他要死了.jpg392c914c25d4150daf6ff2f8d1d5e842.png李开复驳斥了关于中国无法进行大模型预训练的说法，表示零一万物不仅不会放弃预训练，而且在速度和质量上都达到了领先水平。这次超越GPT-4o，也表明中国与美国最先进的OpenAI模型之间的差距已缩小到仅5个月。懒得喷，有本事你跟深度求索月之暗面阿里一样为天下先，做出一点真正的前瞻性的工程探索。Yi-Lightning模型在现在的市场地位如同鸡肋，价格相近的有深度求索阿里豆包智谱，这四家久经市场验证客户才懒得迁移到你李博士这里（况且最考验团队模型雕花能力的工程细节零一万物也做的并不好），海外有OpenAI的4o mini和虎视眈眈的Claude 3.5 haiku（尚未发布），零一拿头去和其他友商竞争。新模型的唯一用处就是拿出来自己骗自己发一波通稿辟一波谣了，不会真的有成熟开发者和团队会放弃之前已经习惯的成熟模型转而选择零一的。三、总结零一万物从创立之初就定位不清职责不明，既没有那种深度求索和月之暗面潜心打磨产品和基座模型的技术理想，也没有阿里字节这种恐怖的渠道优势和产业整合能力，刷榜和白菜价打价格战在骗自己和投资人之外没有任何实际用处。市场上早已不缺一家新的AI lab，具有稀缺性的是能深刻理解行业痛点并提供切实可行解决方案的企业，而零一万物显然还没有找清楚自己的定位。在他找清楚之前（我质疑它是否有这个能力），我只能对零一万物未来的发展持谨慎态度，并倾向于看空其长期表现。"
  },
  {
    "title": "从2024到2025：我的社科学习书单",
    "summary": "阅读进度以本页面为准阅读进度以本页面为准阅读进度以本页面为准阅读进度以本页面为准阅读进度以本页面为准pixeleyes我很喜欢王小波的一句话：“任何貌似理所当然的神话，往往都是不可信的，越是无懈可击，往往越值得怀疑。当一个商业故事以无比圆滑和生动的姿态出现在你面前的时候，你首先必须怀疑，而所有的怀疑，最终都会被证明是正确的，或者至少是值得的。”社交媒体、广告和新闻常常将某种叙事包装得过于完美，以至",
    "tags": [
      "阅读笔记"
    ],
    "url": "/posts/Essays/从2024到2025：我的社科学习书单/",
    "date": "2024-10-12T00:00:00.000Z",
    "content": "阅读进度以本页面为准阅读进度以本页面为准阅读进度以本页面为准阅读进度以本页面为准阅读进度以本页面为准pixeleyes我很喜欢王小波的一句话：“任何貌似理所当然的神话，往往都是不可信的，越是无懈可击，往往越值得怀疑。当一个商业故事以无比圆滑和生动的姿态出现在你面前的时候，你首先必须怀疑，而所有的怀疑，最终都会被证明是正确的，或者至少是值得的。”社交媒体、广告和新闻常常将某种叙事包装得过于完美，以至于让我们失去了基本的怀疑心。无论是某种商业产品，还是一个政治论述，甚至是一种流行的社会观念，许多被广泛接受得理论或观点经过长时间的传播和重复引用，很可能会被赋予一种“神话化”的特质，当它们显得无懈可击时，往往就隐藏着某种不易察觉的盲点或利益关系，新自由主义如此，后凯恩斯亦如此。在我的社科书单中，我希望探索的正是这些潜藏在表象背后的复杂性。哲学、经济学和社会学的交叉阅读，能够帮助我更好地理解当今社会的“神话”是如何形成的，又如何通过批判性思考去解构它们。我始终相信这个世界可以同时存在多种并行不悖的体系，我们作为社科的学者要尽量的去解释，而非看到就直接去否定——君子美美与共，政治的最终目的应当是扩大共同体而非相互攻讦。通过专题式的阅读，我期望能够培养一种既能审视当前叙事，又能构建出自己对世界独立见解的能力专题——权力、潜意识与自我：福柯、弗洛伊德与荣格本专题侧重于人类近现代哲学与心理学的研究，主要包含三位心理学和哲学大家：福柯、弗洛伊德与荣格。米歇尔·福柯（Michel Foucault）的哲学思考深受历史和社会结构的影响，他最为人称道的就是对权力机制的揭露和批判。福柯认为权力无处不在，它不仅存在于政府和法律中，还渗透在我们的生活、知识生产、以及自我认知中。权力通过话语构建了我们对正常与异常的看法，进而塑造了个体的行为与思想。[X] 疯癫与文明：理性时代的疯癫史[ ] 词与物：人文科学的考古学[ ] 规训与惩罚[ ] 知识考古学[ ] 性经验史 第一卷: 认知的意志 (Histoire de la sexualité, I : La volonté de savoir)[ ] 性经验史 第二卷: 快感的享用 (Histoire de la sexualité, II : L'usage des plaisirs)[ ] 性经验史 第三卷: 关注自我 (Histoire de la sexualité, III : Le souci de soi)[ ] 性经验史 第四卷：肉欲的忏悔[ ] 临床医学的诞生西格蒙德·弗洛伊德（Sigmund Freud）提出的潜意识理论则打开了理解人类心理活动的全新窗口。他的观点揭示了意识之外的巨大心理力量如何控制我们的欲望、恐惧和行为。弗洛伊德相信许多看似无意识的行为背后，都隐藏着深层的心理动机，这些动机源自个体无法控制的潜意识冲动。[X] 性学三论[ ] 癔症研究/歇斯底里研究[ ] 梦的解析[ ] 精神分析引论[ ] 释梦[ ] 自我和本我、集体心理学和自我的分析、超越唯乐原则卡尔·荣格（Carl Jung）则在弗洛伊德的基础上，发展出了自己的分析心理学体系。他提出了“集体无意识”的概念，认为人类心理中存在一种超越个体经验的共性，这种共性通过“原型”展现出来。荣格关注个体自我与集体无意识的关系，探讨个体如何通过自我认知和心理发展，实现人格的完整。因为荣格全部的学术作品都包含在了《荣格全集》，比较卷帙浩繁，所以我会选择其中我比较感兴趣的去阅读[ ] 精神病学研究[ ] 实验研究[ ] 心理类型[ ] 精神疾病的心因学[ ] 弗洛伊德与精神分析[ ] 原型与集体无意识[ ] 心理治疗的实践专题——现代资本主义：消费社会与意识形态的批判现代资本主义的扩展和深化，不仅仅体现在经济结构的变化上，还深刻影响了我们的文化、政治和思想。两本经典著作——赫伯特·马尔库塞（Herbert Marcuse）的《单向度的人》（One-Dimensional Man）和居伊·德波（Guy Debord）的《景观社会》（The Society of the Spectacle）——为我们提供了批判现代资本主义的两种重要视角。它们揭示了当代社会中资本主义如何通过意识形态和视觉文化来控制和塑造个体的思想与行为。《单向度的人》是一部对技术理性统治下的资本主义社会的深刻批判。马尔库塞认为当代社会中，科技进步不仅没有解放人类，反而成为了压制反叛与批判性思维的工具。资本主义通过消费主义和同质化的文化，将人们变成了“单向度”的人，丧失了多元化的批判能力与精神自由。现代人越来越倾向于接受现状，并习惯于通过物质消费寻找自我满足，而非质疑和挑战资本主义体系。与此呼应，居伊·德波在《景观社会》中揭示了资本主义如何通过“景观”这一概念操控社会。德波则认为当代社会已经进入了“景观化”阶段，即图像和符号主导了现实，社会生活逐渐被商品化的景观所替代。资本主义不仅控制了经济生产，还塑造了我们对现实的感知，媒体和广告让我们生活在一个虚假的影像世界中，人的主体性被景观所侵占，成为被动的消费者。本专题将通过对这两本书的探讨，深入理解现代资本主义对社会、文化以及个体意识的影响。笔者希望通过这些经典作品的阅读与反思，帮助读者揭示当今资本主义制度背后隐藏的意识形态机制，并激发对现状的批判性思考与重新审视。[X] 单向度的人：发达工业社会意识形态研究[X] 景观社会[X] 景观意识形态与隐形奴役：居伊·德波《景观社会》解读与批判专题——法的逻辑与历史：从刑法到宪法的全景透视法律不仅是社会秩序的基础，更是人类文明发展的重要支柱。它通过规范人与人之间的关系、维护社会正义和保障公民权利，深刻影响着社会的方方面面。本专题将从五个核心领域——刑法、民法、法理学、宪法和法制史——展开，理解法律在社会生活中的角色以及其背后的思想脉络。刑法是规范行为与社会秩序的法律领域，它定义了什么行为是犯罪，并为违反这些行为的人制定了相应的处罚措施。在刑法的学习中，我们将探讨刑事责任的原则、犯罪的构成要件以及刑罚的合理性与公正性等议题。民法则是保障个人权利和调整社会经济关系的法律体系。通过阅读和分析民法经典案例和理论，我们将探讨契约、财产权、侵权责任等制度的内在逻辑，以及它们如何在现代社会中平衡个人利益与社会公共利益。法理学作为法学的理论基础，关注法律的本质、目的以及法律体系背后的哲学思考。通过研究不同的法理学流派与思想，我们将深入探讨法律与道德的关系、正义的标准、法律的解释方法等基本问题。宪法是国家的根本大法，规定了国家的基本结构、政府的权力来源以及公民的基本权利与自由。在宪法部分，我们将重点分析宪法如何保障公民权利、约束政府权力，并讨论现代宪政制度的发展和挑战。法制史则为我们提供了一个全景视角，展示了法律如何随着社会、经济和文化的变化而发展。从古代法制到现代法律制度的演变，法制史帮助我们理解当前法律制度的形成过程及其背后的历史逻辑。[ ] 刑法[ ] 民法[ ] 宪法[ ] 法理学[ ] 法制史[ ] 刑法学讲义专题——金融欺诈与公司财务透明度：上市公司财务舞弊与黑洞研究这个专题我觉得没啥好说的，会计/金融学学生老本行了。[ ] 上市公司财务舞弊审计研究与案例解析[ ] 上市公司财务黑洞研究理论及案例其他除此之外，我还可能会涉及到部分传媒学、宗教学和语言学的探究，传媒学可以帮助我理解当今社会信息传播的方式及其对公众意识的影响，特别是在资本主义、权力和社会控制等主题上的延展。语言学则可以进一步剖析语言在文化传播、社会规范和个体认知中的关键作用。由于相关内容尚未完全确定，未来我会在相关专题中深入探讨这些问题，因此本文暂不展开论述。"
  },
  {
    "title": "从《学园孤岛》看解离型身份障碍",
    "summary": "前言这两天把学园孤岛动漫刷完了，主角由纪的状况就非常有趣：老师佐仓慈 “慈姐”在丧尸压力下选择牺牲自己拯救学生们，但由纪并不能接受这一残酷事实，在精神退行后产生了一个救济人格（幻想中的慈姐）。同时，在她眼中整个学院仍然是鸟语花香一切如常，她每天都会去那已经残破不堪的教室里上课，还幻想了一大堆同学，她的时间从此停留在了灾变前一天。（所以第一集结尾由纪幻想中的学院切换到恐怖破败的现实世界之后着实给我来",
    "tags": [],
    "url": "/posts/Essays/从《学园孤岛》看解离型身份障碍/",
    "date": "2024-10-01T00:00:00.000Z",
    "content": "前言这两天把学园孤岛动漫刷完了，主角由纪的状况就非常有趣：老师佐仓慈 “慈姐”在丧尸压力下选择牺牲自己拯救学生们，但由纪并不能接受这一残酷事实，在精神退行后产生了一个救济人格（幻想中的慈姐）。同时，在她眼中整个学院仍然是鸟语花香一切如常，她每天都会去那已经残破不堪的教室里上课，还幻想了一大堆同学，她的时间从此停留在了灾变前一天。（所以第一集结尾由纪幻想中的学院切换到恐怖破败的现实世界之后着实给我来了个大的，直呼这番有趣）image.png我们抛开这番欢乐幻想与绝望现实绝妙的反差恐怖感不谈，如何从心理学的视角解释由纪的行为？心理学解释首先，最明显的就是精神退行下的解离性身份障碍（Dissociative Identity Disorder, DID）。解离性身份障碍是一种严重的心理疾病，主要特征为存在两个或更多独立的人格状态，每个都有各自的记忆、行为和情感。这些不同的人格状态会轮流控制个体的行为，致使个体在不同时间和情境下表现出截然不同的行为模式。通常，该疾病与童年时期的严重创伤有关，如虐待、忽视或其他极端压力形式。在学术界, 对于 DID的研究始于个案研究, Mitchill 在 1816 记录了美国宾夕法尼亚州一个名为玛丽·雷诺的病例, 被视为最早记载的 DID 案例。法国医生 Pierre Janet 通过对癔症的临床观察, 提出了 “分离”(dissociation) 的概念, 并于 1889 年出版专著《自动心理学》。在对 DID 形成机制的解释中,心理动力学派的观点影响深远。研究者普遍认为, DID 是一种防御的症状群, 创伤、冲突和缺陷均在 DID 的形成中起作用, 其中创伤起了决定性作用。患者使用分裂(splitting) 和分离的防御方式来保留“好的自身”和“好的客体”, 分离了不相容的心理内容。分离的同时, 也意味着除去感觉或认识的某些方面, 或者说它意味着意识状态的改变, 患者以此除去意识中某种事件或情境。由纪接受不了惨烈的现实与老师的离去，由此她身体自动触发逃避机制，现实和幻想发生了错位——此之谓解离。在剧情中，由纪的解离就表现为她自己想像出了一个“慈姐”去教她学习，会阻止忘记社团活动的由纪“回家”，会在学校图书馆捂住由纪的嘴不让她发出声音，在由纪脱离退行状态前的最后一刻还领着由纪去了广播室化解了危机。由此，幻想中的慈姐可以被视为由纪的一个内部支持系统，类似于心理学中的“救济人格”（auxiliary ego state）。这个幻想中的慈姐不仅是她内心深处对慈姐的怀念和依赖，更是她在极端环境中寻求安全感和稳定感的一种方式。每当由纪感到孤独、害怕或不知所措时，这个救济人格就会出现，给予她必要的支持和指导。除了慈姐这个救济人格之外，由纪每天都会去那已经残破不堪的教室里上课，幻想自己还有一群同学陪伴，这就是一种更深层次的“解离”。她无法接受现实的变化，通过现实与幻想的错位与时间感的扭曲，她选择停留在一个更安全、更熟悉的时间点，通过沉浸在理想化的记忆中来减轻当前的恐惧和无助感。非常非常非常有趣的是，剧情在进行到中期，直树美纪 “美君”加入社团并回忆当时驾车回校的情况时，由纪注意到车子的人数不对，这一事实打破了由纪小天使自己自洽的世界观，她意识到了“认知失调”，于是由纪选择离开当时的团体讨论并到其他屋子内，向“慈姐”寻求自己世界观的再自洽。费斯廷格（Leon Festinger）的“认知失调“理论认为当个体持有两个或多个相互矛盾的认知（信念、态度、行为等）时，会产生心理上的不适感，即认知失调。为了减少这种不适感，个体会采取各种措施来恢复认知的一致性。斯沃茨（William Swann）提出了“自我验证理论”同样可以解释这个行为。该理论认为个体倾向于寻求和维护与自己自我概念一致的信息和反馈。即使这些信息是消极的，只要它们与个体的自我概念相符，也会被接受和寻求。结论《学园孤岛》最令我着迷之处在于温暖的解离想象和绝望的现实，可爱的jk少女和残暴的丧尸带来的极致反差感。在学园孤岛的真相尚未揭露之前，观众的异常感与不适感会随着由纪在校园中走班串楼的活动而不断累积，直至结尾之时全数爆发，酣畅淋漓十分痛快。豪堪！参见[1]王铭,江光荣.分离性身份识别障碍的心理病理机制和临床评估[J].中国临床心理学杂志,2007,(04):426-429.[2] 萌娘百科.学院孤岛"
  },
  {
    "title": "Weekly通讯-第九期：置信度、乐观主义与为什么集体很容易做出烂决策",
    "summary": "信息置信度分级在一个争夺注意力的开放市场上，相较于积极、建设性的思想，较为阴暗的情绪更能吸引眼球。面对外部信源，我们可以将每一条信息按照置信度从A到F进行分级：A：完全确定。B，小规模事件中，关键截图等被刻意淡化，但有网友目击大量间接证明；大规模事件中，有明确方向定性，但规模太大无法在统计学上精确定量。但说东南不会到西北，方向基本上正确。C，向业内和临近行业的有关人士调查，有一定佐证，但是也有利益",
    "tags": [
      "Weekly通讯"
    ],
    "url": "/posts/ScheduledReport/Weekly通讯-第九期：置信度、乐观主义与为什么集体很容易做出烂决策/",
    "date": "2024-09-22T00:00:00.000Z",
    "content": "信息置信度分级在一个争夺注意力的开放市场上，相较于积极、建设性的思想，较为阴暗的情绪更能吸引眼球。面对外部信源，我们可以将每一条信息按照置信度从A到F进行分级：A：完全确定。B，小规模事件中，关键截图等被刻意淡化，但有网友目击大量间接证明；大规模事件中，有明确方向定性，但规模太大无法在统计学上精确定量。但说东南不会到西北，方向基本上正确。C，向业内和临近行业的有关人士调查，有一定佐证，但是也有利益相关和当局者迷导致结果不是很准确。D，零星的消息，提供者无利益相关和造假动机，结论符合逻辑，但缺乏证据E，没必要发了，有点依据但不多，其他可能性太多很难命中，故而不需采信。F，经过断章取义的谣言。革命乐观主义与先做个垃圾出来边防线上，肚子笑抽抽是常事。这个叫做革命乐观主义精神。请想象一幅宣传画：我是主角，浑身结结实实的肌肉，站在一滩烂泥里面，45 度仰望天空做憧憬状。 「他妈的」也是革命乐观主义精神。 《全金属外壳》里有个士官长，能够 10 分钟不换气地骂脏话，我觉得斯坦利·库布里克刻画得非常传神。美国也有乐观主义，或者可以叫民主灯塔乐观主义；非洲原始部落里也有乐观主义，可以叫酋长乐观主义。没有乐观主义可不行，人类就走不出东非大裂谷。你比方说，「兔子脚呱啦」今天被狮子拖走吃了，你要哭天抹泪的，保不定你也被狮子拖去吃了。环境艰苦，哭天抹泪是不顶用的，不如骂一声「他妈的」，该咋咋地。道理就是这样，很多时候完全没必要硬给自己加戏扮苦情人设，虽说人生如戏但绝大多数人演的都不会有观众。环境艰苦，未来可期，面对困难时哭天抹泪是没用的，真不如骂一句「他妈的」和「我操」然后继续干活，努力让损失小一点，可争取的收益多一点。别想着一次成功，别想着一稿通过，先做个垃圾出来。通过了也不会怎么样，成功了也有下一个人物，先做个垃圾出来。有垃圾就有变废为宝的机会。不制作垃圾，你就只有焦虑拖延的机会。垃圾这个概念，也值得辩证，为什么你做的就是垃圾呢？这个世界上很多拉胯的人都在信心满满地站在台上，领导团队、领导公司，对着世界指手画脚，对着别人好为人师，很多拉胯的人都不知道自己其实在拉胯，标准不一样罢了。什么是真正的垃圾，飘进海洋、填进陆地、污染空气的垃圾，物理垃圾难以处理，你写的垃圾已经很环保了。你做的真的中是你眼里的垃圾，你不做这个垃圾出来，下一个人做的还不如你做的垃圾好看好用好有价值，那现在做垃圾的人，凭什么不是你呢？（超级绕口令）反正大部分人都很垃圾。处理舆论时切忌懒惰思维互联网上经常会有这样的声音：反对建制派的会将建制派的思潮称之为“五毛”和“网评员”，建制派经常会将反建制派的思潮称之为“1450”和“网军”。我在这里当然不会否认各种主权政府和实体一定会出于自己的利益培养出自己的舆论力量，但给所有和自己价值观不同的人群思潮贴上一个“被刻意操纵”的标签实际上是一种懒惰和恐惧——因为不愿也不敢相信世界上真的存在和自己相悖的声音。中国乃至这个世界实在是太大太复杂了，各个地区、群体的经济基础不同，自然而然的就会催生出各种相异乃至于冲突的上层建筑思潮，思潮冲突天然就存在且合理。一味的去否认这些思潮存在的合理性相当于自己把自己的双眼给蒙住，自己给自己创造一大批没有办法去解决的敌人。我始终相信这个世界可以同时存在多种并行不悖的体系，我们作为社科的学者要尽量的去解释，而非看到就直接去否定。这个观点可以适用于一切左、右、粉、蓝等阵营。小人和而不同，君子美美与共，我们的最终目的应当是扩大共同体而非相互攻讦。为什么集体很容易做出烂决策？在写到这点的时候，我能想到的有两种可能：1.善战者无赫赫之功，集体决策中的好结果被我们当成“应有之事”被忽视了，反而是集体做出的烂决策被当做经典案例给放大，暗合90年代之后的个人主义自由主义之风（例如乌合之众的大火）2.任何一个集体，只要覆盖面越广，那么其成员的平均素质就会越贴近于全人类社会的平均素质，如果说这个集体的精英寡头能做出来的决策水平是80分，那么扩大到全集体的决策水平就可能会下降到60分；当集体作为决策单位的时候就更可能被煽动，和为了眼前的小利忽视了更为长远的利益……我觉得其实这两种可能都有道理。人类社会现在的两个主要经济体基本都实质性的实行精英寡头决策制度，所谓的各自的，带有全民参与的决策体系更像是用来安抚民意的制度花瓶。人类社会每天需要处理的议题茫茫多，让集体每天浪费行政资源去充分理解并处理这些议题本身就不可能，民主集中制理论上便是为了解决这个问题而构建的。言论许多艺术家对心理学都有些诟病，可能是将精神量化的学科让他们自由的灵魂深感抵触，科学界就相反，他们永远嫌心理学量化得不够彻底，可检验性不够高，哲学家的诟病可能就简单得多，单纯嫌它浅薄而已。为什么我们制定谋略的时候，总会想着一切都会按照我们想象的去发展，好像连天地都要为我们心中的计谋让路、乃至天地都要配合我们心中的计谋？使原本可能看不见的东西通过你被他人看见。 —— 法国著名导演 罗伯特・布列松 这也就是所有创作的意义，或者说是创作背后的逻辑。你提供自己独特的视角呈现给这个世界。任何貌似理所当然的神话，往往都是不可信的，越是无懈可击，往往越值得怀疑。当一个商业故事以无比圆滑和生动的姿态出现在你面前的时候，你首先必须怀疑，而所有的怀疑，最终都会被证明是正确的，或者至少是值得的。"
  },
  {
    "title": "上市公司财报分析思路",
    "summary": "现代社会已经进入到资本市场高度发达的阶段，财务报表所提供的财务信息无疑是投资者在资本市场进行决策最重要的信息来源。人们倚重财务报表，尤其是社会公众投资者，由于受到种种条件限制，既没有时间、精力到上市公司调研，也缺乏其他信息来源，就更加依赖财务报表。看各种上市公司的招股书和财报应该是各路经济学专业学生的基本功了，说到底，金融学仍然是一门需要和人打交道的学问，枯燥复杂的指标也仅仅是辅助决策的数学工具之",
    "tags": [],
    "url": "/posts/Finance and Economics/上市公司财报分析思路/",
    "date": "2024-09-15T00:00:00.000Z",
    "content": "现代社会已经进入到资本市场高度发达的阶段，财务报表所提供的财务信息无疑是投资者在资本市场进行决策最重要的信息来源。人们倚重财务报表，尤其是社会公众投资者，由于受到种种条件限制，既没有时间、精力到上市公司调研，也缺乏其他信息来源，就更加依赖财务报表。看各种上市公司的招股书和财报应该是各路经济学专业学生的基本功了，说到底，金融学仍然是一门需要和人打交道的学问，枯燥复杂的指标也仅仅是辅助决策的数学工具之一，真正发掘企业的价值/风险还是要靠分析师自己的慧眼与经验（乃至于各路酒桌上的小道消息）。一、初步审查快速浏览财务报表（最基础的三表一注：资产负债表、利润表、现金流量表和附注）注意任何异常的数字和趋势，例如收入或支出的突然变化二、比率指标分析计算关键财务比率，如流动比率、速动比率（酸性测试比率）、负债权益比率、毛利率、净利润率、资产回报率（ROA）、股东权益回报率（ROE）等。比较这些比率与行业平均水平或主要竞争对手的数据，以评估企业的相对健康状况。（一） 盈利能力指标毛利率 (Gross Margin)：显示销售收入减去销售成本后的剩余比例。公式：(销售收入 - 销售成本) / 销售收入 * 100%营业利润率 (Operating Margin)：衡量企业在扣除经营费用后的盈利能力。公式：营业利润 / 销售收入 * 100%净利润率 (Net Profit Margin)：显示最终净利润占销售收入的比例。公式：净利润 / 销售收入 * 100%（二）偿债能力指标流动比率 (Current Ratio)：表明企业短期债务偿还能力。公式：流动资产 / 流动负债速动比率 (Quick Ratio)：又称酸性测试比率，衡量企业在不依赖存货的情况下偿还短期债务的能力。公式：(流动资产 - 存货) / 流动负债负债权益比率 (Debt-to-Equity Ratio)：显示企业负债水平相对于股东权益的比例。公式：总负债 / 总股东权益（三）营运效率指标存货周转率 (Inventory Turnover)：显示企业每年销售并替换其库存的次数。公式：年度销货成本 / 平均存货应收账款周转天数 (Days Sales Outstanding, DSO)：衡量企业从销售到收到款项所需的平均天数。公式：(期初应收账款 + 期末应收账款) / 2 * 365 / 销售收入（四）投资回报指标资产回报率 (Return on Assets, ROA)：显示企业利用其总资产产生利润的效率。公式：净利润 / 平均总资产 * 100%股东权益回报率 (Return on Equity, ROE)：衡量公司使用股东资金创造利润的效率。公式：净利润 / 平均股东权益 * 100%（五）现金流指标自由现金流 (Free Cash Flow, FCF)：企业经营活动产生的现金减去维持或扩张资产基础所需的资金。公式：经营现金流 - 资本支出三、趋势分析查看过去几年的财务数据，识别收入、成本、盈利能力和现金流的趋势。分析这些趋势背后的原因，并考虑它们是否可持续。四、比较分析与风险评估将企业的财务表现与同行业的其他公司进行对比，识别其在市场中的位置。考虑宏观经济环境和行业特定因素对业绩的影响。识别可能影响公司未来业绩的风险因素，包括法律诉讼、供应链中断、市场需求变化等。评估管理层为应对这些风险所采取的措施的有效性。五、形成结论前面五板斧下去，企业基本面咋样，财务表现怎么样各位分析师其实心里也多少有定论了。到这块就就是根据之前的分析得出关于公司财务健康状况、盈利能力、成长潜力以及风险管理的综合结论。最后就是分析师提出建议，例如股票买卖建议或者改进财务管理的建议。具体财务造假分析参见：\n上市公司财务黑洞研究理论及案例\n上市公司财务舞弊审计研究与案例解析"
  },
  {
    "title": "中国与世界的现代化专题（二）：货币的本质与中国的税收体系",
    "summary": "注：本文为系列专题——“中国与世界的现代化”的一部分作为中国与世界的现代化专题的第二章，我希望就此开始为我和我的博客逐步构建起一套完整的，体系化的去分析中国乃至于世界现代化的理论框架——了解中国的现代化当然离不开了解政府，剖析政府的额行为动机也必然离不开最核心的财税制度。因此，我必须要在开头承认，我分享的都是带有我自己立场与惯性的叙事和分析框架，不是什么科学真理、惊天秘辛，也不是借助所谓的冲塔或者",
    "tags": [
      "风自东方来"
    ],
    "url": "/posts/Finance and Economics/中国与世界的现代化专题（二）：货币的本质与中国的税收体系/",
    "date": "2024-09-05T00:00:00.000Z",
    "content": "注：本文为系列专题——“中国与世界的现代化”的一部分作为中国与世界的现代化专题的第二章，我希望就此开始为我和我的博客逐步构建起一套完整的，体系化的去分析中国乃至于世界现代化的理论框架——了解中国的现代化当然离不开了解政府，剖析政府的额行为动机也必然离不开最核心的财税制度。因此，我必须要在开头承认，我分享的都是带有我自己立场与惯性的叙事和分析框架，不是什么科学真理、惊天秘辛，也不是借助所谓的冲塔或者别的什么立场来提高自己的论证可靠性。在现在的舆论上，批评公有制主体、唱空经济的可信度天然高人一等，为公有制辩护、解释政策的论证义务从头重上三分，这可不算什么“独立思考”。所以还希望所有的读者仅仅只把我的文章当作参考，去形成自己的分析评价框架，反过来自己思考我的文章具体逻辑是否通顺、符合经济运行事物，让自己的脑子和嘴真正地思自己所思、言自己所言，以理性的形式主张自己的经济权益。一、什么是货币1.人类社会视角下的货币我们先抛开宏大叙事中的金融战与国际贸易体系重构等议题，思考这样一个问题：在人类社会中，钱，或者说货币，到底是什么？要了解货币的用处，我们就需要先想象一下没有货币的世界会是什么样子——在远古时期，人们是如何交易商品和服务的？没有货币的经济体通常采用物物交易，即用一种商品或服务换另一种商品或服务。在这个世界中，任意两个人之间的交换交易将涉及到需求的双重巧合，两个人各自想要对方可以提供的商品或服务。 例如，如果铁匠想要一双鞋，则该铁匠必须找到一双正确尺码的鞋子，并且愿意用这双鞋换对应的钉子/工具的人。在几乎不存在分工的原始社会中，这样的交易制度尚且可以延续下去。但一旦人类进入到了农业社会，社会分工开始凸显，这样原始的物物交易制度便无以为继——因为这样交易的时间成本太高了。由此，人们开始使用“金银”作为货币，作为一般等价物来开展交易。货币作为一种交易媒介，其价值是买卖双方均承认的，采用货币的经济体广泛的接受这种货币可以作为商品、劳动力和金融资本市场上的一种支付方式。借用货币工具，市场中希望交易的双方不必再耗费大量的时间和精力去筛选交易信息，只要有货币就可以任意的买卖。马老爷子：金银天然不是货币，但货币天然是金银。 至于金银怎么变成货币的，这里我就懒得提了，这个又能新开一篇专题文章除了交易媒介，货币还具有价值储存的职能。想象一下，原始人在社会中该如何储存“价值”？他可能会囤米、囤肉乃至于囤家畜和囤奴隶，但是米会坏，肉会烂，家畜可能会生病，奴隶可能会暴动会死，并且这些价值只能保存到“现在”，而无法影响“过去”和“未来”。但货币就不一样了。货币作为一般等价物可以保存和积累价值，让人们可以跨时间和空间转移购买力。这意味着今天赚取的钱可以在未来用于消费或投资，货币的持有者知道他不需要立即花钱，因为它在第二天或第二年仍会保持其价值。 这种金钱功能并不要求金钱是完美的价值存储。 在通货膨胀的经济体中，金钱每年都会失去一些购买力，但它仍然是金钱。正是因为货币被广泛的运用到了市场的交易中，因此还发挥着记账单位的作用。货币为不同商品之间的“价值”提供了一个共同的衡量标准，使得他们之间可以相互被比较，物体的价值可以被抽象为一个简单的数字，例如我们都知道之前冰红茶三块一瓶，便宜的小汽车一般几万一辆，那么汽车和冰红茶之间的价值就可以通过一个统一的，借由市场凝聚来的价值共识来进行权衡比较。最后，货币的另一个功能是金钱必须作为延期付款的标准。 这意味着，如果今天有钱可以用来购物，那么今天进行将来付款的购买也必须是可以接受的。 贷款和未来协议以货币形式表示，延期付款的标准使我们能够在今天购买商品和服务，并在将来付款。信用贴现机制让我们得以通过投资亦或者是消费部门的杠杆来将未来的收益（增长）转移到当期（当下），利用带有预期正面收益的资产作为抵押物，分享预期的未来收益，虚空制造当期的额货币供应量，最终在本期经济循环中消费了未来的收益。2.政府视角下的货币在上一节中，我们说明了货币在人类社会中是交换、价值存储、记账单位和延期付款标准的媒介，那么现在由政府主权信用担保发行的货币又扮演着什么样的角色呢？兰小欢教授非常喜欢两部国产电视剧，分别是《大明王朝1566》和《走向共和》。这两部剧有个共同点：开场第一集中那些历史上赫赫有名的大人物们，出场都没有半点慷慨激昂或阴险狡诈的样子，反倒都在做世上最乏味的事——算账。大明朝的阁老们在算国库的亏空和来年的预算，李鸿章、慈禧和光绪则在为建海军和修颐和园的费用伤脑筋。然而算着算着，观众就看到了刀光剑影，原来所有的政见冲突和人事谋略，都隐在这一两一两银子的账目之中。国家调节生产秩序和分配秩序需要货币，而税收则是回收货币的极其重要的环节之一。对于任意一个主权政府，货币的发行和管理都反应了政府的信用与能力，货币工具的使用代表政府对经济的控制力和政策导向，是政府维护经济秩序、实现社会经济发展目标的核心工具。货币之于政府仅仅是一个调节社会生产秩序和分配秩序的工具，政府使用货币工具来对全社会的资源进行宏观的分配与再分配，现代社会中法定货币只是政府主权信用担保下的一张纸，货币有用的唯一原因就是全人类对对应货币的价值有普遍信念和信任，或者说对对应法定货币的发行政府的主权信用有普遍信念和信任。钱很重要，但钱实际上一点都不重要 钱可以近乎买到任何东西，但钱实际上也就是一张废纸所以，要真正了解政府行为，就必须要了解财税；而只有了解了货币的本质，才能真正理解财税。二、中国的税收体系世界上只有两件事是不可避免的，那就是税收和死亡 ——本杰明·富兰克林1.起步-改革开放：1978-1993我懒得从几千年前开始回顾中国的税制了，既然本系列的标题就是中国与世界的现代化，那还是直接从和现在的经济运行强相关的78年改革开放开始讲起吧 :D如果用一个词来概括20世纪80年代的中国经济的特点，那么非“承包”莫属。农村可以有家庭联产承包责任制搞土地承包，城市也有企业承包，那么按照这样的思路，政府也有财政承包——什么都可以被承包。我国的基本国策就决定了不能对所有权进行根本性的变革，只能对使用权和经营权进行承包制以提高积极性。财政承包就开始于1980年，在中央与地方之间的财政分配关系上，实行“分灶吃饭”，中央与省级财政之间对收入和支出进行包干，地方可以留下一部分增收。从 1980 年起，先后推出了“划分收支、分级包干”、“划分税种、核定收支、分级包干”以及“收入递增包干、总额分成、总额分成加增长分成、上解递增包干、定额包干、定额补助”等多种不同的体制模式。既然是承包，当然要根据地方实际来确定承包形式和分账比例，所以财政包干形式五花八门，各地不同。比较流行的一种是“收入递增包干”。以1988年的北京为例，是以1987年的财政收入为基数，设定一个固定的年收入增长率4%，超过4%的增收部分都归北京，没超过的部分则和中央五五分成。假如北京1987年收入100亿元，1988年收入110亿元，增长10%，那超过了4%增长的6亿元都归北京，其余104亿元和中央五五分成。学过初中历史的朋友们都知道，在家庭联产承包责任制下农民的生产积极性被极大的激发，相关的产出也有显著提高，财政领域的承包也是如此。财政承包制下，交足中央，剩下的都是地方自己的，因此地方有动力扩大税收来源，大力发展经济。这个阶段各种乡镇企业也如雨后春笋般涌出，和各地方政府大力支持脱不开关系。在这个时期，地方政府想出了这样的野路子：虽然财政包干制度下留足中央，剩下都是自己的……但如果我把一部分税实际转化成各种费用，不就不用给中央分钱了吗？藏富于民，挺好嘛！虽然地方预算内的税收收入要和中央分成，但预算外收入则可以独享，这也是为什么九十年代乃至千禧年初期各单位都非常流行预算外的“小金库”，这些小金库是可以不与上级乃至平级单位共享的，可以切切实实为“自己人”谋取利益。如果给地方企业减免税费，在再通过其他诸如行政收费、集资、摊派、赞助等手段收一些回来，就可以避免和中央分成，变成可以完全自由支配的预算外收入。在这一阶段，我们会惊讶的发现明面上地方政府会非常积极的给地方企业违规减税，企业偷税漏税也非常普遍，税收收入上不去但预算外收入却迅猛增长。1982—1992年，地方预算外收入年均增长30%，远超过预算内收入年均19%的增速。1992年，地方预算外收入达到了预算内收入的86%，相当于“第二财政”。这一时期是改革开放的起步时期，改革转型的特殊性和制度本身的不完善决定了很多承包制包括财政包干制注定不能持久。无论是放权还是让利，事实上都是以财政上的减收、增支为代价的。主要由财税担纲的以“放权让利”为主调的改革，却使财政收支运行自身陷入了不平衡的困难境地。财政包干造成了“两个比重”不断降低：中央财政预算收入占全国财政预算总收入的比重越来越低，而全国财政预算总收入占GDP的比重也越来越低。前者由 1978 年的 31. 1% ，相继减少到 1980 年的 25. 5% ，1985 年的22. 2% ，1990 年的 15. 7% 和 1993 年的 12. 3% ;后者则先升后降，1978 年为 15. 5% ，1980 年为24. 5% ，1985 年为 38. 4% ，1990 年下降为 33. 8% ，1993 年进一步下降至 22. 0% 。不仅中央变得越来越穷，财政整体也越来越穷。中央穷也代表弱干强枝，对于地方的掌控力和议价能力也会削弱另一方面，财政支出并未随之下降，反而因“放权”、“让利”举措的实施而出现了急剧增加.从 1978 年至 1993 年，财政支出由 1122. 09 亿元一路增加至 4642. 20 亿元，15 年间增加了 3. 1 倍，年均增加 9. 93%。任何一个体系都不能只进不出对伐，所以这个只能是权宜之计。“两个比重”的下降严重削弱了国家财政能力，不仅财政赤字逐年加大，债务规模日益膨胀，而且中央财政已经达到了难以担负宏观调控之责的空前水平，不利于推进改革。我们在前面就说过货币工具的使用代表政府对经济的控制力和政策导向，政府使用货币工具来对全社会的资源进行宏观的分配与再分配。改革开放后有大量的群体利益受损，这些都需要中央政府有足够的财力去补偿，否则改革就没办法推动，比如国企改革后的职工安置、裁军后的退伍军人转业等。像我国这样的超大规模的现代化国家，改革开放后地区差异进一步显著，如果没有中央财政大量去搞财政转移支付和各种补贴，那么东西的公共服务差异就会越来越大，乃至于中西部地方政府发不出工资，没办法维持政府职能。如果中央没钱，甚至要向地方借钱，那也就谈不上宏观调控的能力。正如时任财政部部长的刘仲藜所言：当时的理论界对我讲，财政是国家行政能力、国家办事的能力，你没有财力普及义务教育、救灾等，那就是空话。以中央财政债务依存度［债务收入/(中央财政本级支出 + 中央财政债务支出)］而论，到 1993年我国已经达到 59. 63% 的国际罕见水平。这意味着当年中央财政本级支出中的一半以上，要依赖于举债或借款收入来解决。搞到这个程度，地方政府再不妥协的话大家不如直接散伙，也别搞什么搭伙吃饭了2.分税制改革：1994-1998一方面，改革开放后的财政包干制度确实激发了地方搞活精力的积极性，但另一方面来“两个比重”的降低也带来了严重的财政危机，“放权让利”的改革不可持续，我国正酝酿着全新的财税体制。随着 1992 年 10 月中共十四大正式确立社会主义市场经济体制的改革目标，1993年 11 月召开的中共十四届三中全会通过了《关于建立社会主义市场经济体制若干问题的决定》。于是，以建立适应社会主义市场经济的财税体制为着眼点，从 1994 年起，财税体制改革踏上了制度创新之路(项怀诚，1994)。简单来说，94年的分税制改革将税收分成三类：中央税（如关税）、地方税（如营业税）、共享税（如增值税）。其中最重要的税种就是增值税，占全国税收收入的1/4，改革前增值税（产品税）是最大的地方税，改革之后变成了共享税，中央拿走75%，留给地方25%。改革由此建立中央税收和地方税收体系，分设中央税务机构和地方税务机构，实行中央对地方税收返还和转移支付制度，初步建立了分税制财政管理体制基本框架。此外，分税制改革还彻底取消向中央银行的透支或借款，财政上的赤字全部以举借国债方式弥补，从制度上斩断财政赤字与通货膨胀之间的必然联系。分税制改革我现在理解的实质就是中央将财权进一步上收，也是90年代推行的根本性和最成功的改革之一。改革后中央占全国预算收入的比重从改革前的22%一跃变成55%，并长期稳定在这一水平；国家预算收入占GDP的比重也从改革前的11%逐渐增加到了20%以上。改革大大增强了中央政府的宏观调控能力，为之后应付一系列重大冲击（1997年亚洲金融危机、2008年全球金融危机和汶川地震等）奠定了基础，也保障了一系列重大改革（如国企改革和国防现代化建设）和国家重点建设项目的顺利实施。可以说，1994 年的财税体制改革，为我国初步搭建起了适应社会主义市场经济体制的财税体制及其运行机制的基本框架，也从根本上改变了地方政府发展经济的模式（为未来的房地产经济也埋下了因果）。1994 年分税制改革显著增强了中央政府的财力，但地方政府的事权与财权并未做出调整导致事权财权失衡，财政收支问题凸显。分税制改革后，解决这一问题的手段一共有两种，一是财政转移支付，二就是未来轰轰烈烈的房地产经济，这个未来有机会讲。这么大财权的上收，期间中央政府和地方的博弈也是腥风血雨的。 “只要中央做了决策，地方不就只有照办的份儿吗？”有这种观念很正常，一方面，经过分税制改革后多年的发展，今天的中央政府确实要比20世纪80年代末和90年代初更加强势；另一方面，公众所接触的信息和看到的现象，大都已经是博弈后的结果，而缺少社会阅历的学生容易把博弈结果错当成博弈过程。其实即使在今天，中央重大政策出台的背后，也要经过很多轮的征求意见、协商、修改，否则很难落地。成功的政策背后是成功的协商和妥协，而不是机械的命令与执行，所以理解利益冲突，理解协调和解决机制，是理解政策的基础。所以，之前群里的神友发过一张很傻逼的图：image.png为什么这张图很弱智呢？因为分税制改革之后地方财权上交，地方要是财政真能做到自给才见鬼了image.pngimage.png只能说上面的那张图是非常典型的断章取义和糊弄外行人，我极其厌恶这种行为。3.税费改革与构建公共财政体制框架：1998-2003分税制改革固然基本解决了“两个比重”降低的难题，极大的提高了我国进行宏观调控和应对危机的能力，但94年分税制改革的仍然只是当时纳入预算视野的政府收支，游离于体制之外的政府收支小金库则并没有纳入改革的范畴。而且1994 年财税体制改革所着眼的，也主要是以税收制度为代表的财政收入一翼的制度变革。至于另一翼———财政支出的调整，虽有涉及，但并未作为重点同步进行。与此同时，既得利益的掣肘加之财政增收的动因，也在一定程度上束缚了改革的手脚，使得一些做法带有明显的过渡性或变通性色彩。由此，上世纪90年代后期，以规范政府收支行为及其机制为主旨的“税费改革”以及财政支出管理制度的改革，先后进入财税体制改革的重心地带并由此将改革带上了财税体制整体框架的重新构造之路———构建公共财政体制框架。1998年3月，当时的共和国朱总理在主持国务院工作之后举行的首次记者招待会上直言不讳：““目前存在的一个问题是费大于税。很多政府机关在国家规定以外征收各种费用，使老百姓不堪负担，民怨沸腾，对此必须整顿和改革。”以此为契机，中国开始了“税费改革”的大幕。在全国性的税费改革正式启动之前，实际上各个地方政府也做过很多的有益探索，例如“费改税”，通过将五花八门的各种收费改为统一征税的办法来减轻企业和居民的负担（征收程序化标准化）。后来在实践中探索得出，地方政府收费的种种弊端并非出在收费本身，而是大量的项目既未经过人民代表大会的审议，又基本不纳入预算，而是由各部门、各地区自立规章，作为自收自支的财源，或归入预算外收入，或进入制度外收入，直接装入各部门、各地区的“小金库”。因而，它实质是一种非规范性的政府收入来源。“费改税”的目的，显然不是要将本来意义的政府收费统统改为征税，而是以此为途径，将非规范性的政府收入纳入规范化轨道。于是，“费改税”开始跳出“对应调整”的套路而同包括税收在内的整个政府收入盘子的安排挂起钩来。也正是在这样的背景之下，“费改税”一词为“税费改革”所取代，进而被赋予了规范政府收入行为及其机制的特殊意义。在“税费改革”日渐深入并逐步取得成效的同时，财政支出一翼的改革也在紧锣密鼓地进行中。先后进入改革视野的有:财政支出结构由专注于生产建设领域逐步扩展至整个公共服务领域的优化调整;推行以规范预算编制和分类方法、全面反映政府收支状况为主要着眼点的“部门预算制度”;实行由财政(国库)部门集中收纳包括预算内外收入在内的所有政府性收入，且由国库单一账户集中支付政府部门所有财政性支出的“国库集中收付制度”;推进将政府部门的各项直接支出逐步纳入向社会公开竞价购买轨道的“政府采购制度”。所以，这一阶段的财税改革就是支出段和收入端同时标准规范，是更为深入的动刀子改革。学术界乃至于决策层也发现，如此覆盖规模广大的改革，要涵盖所有财税体制改革事项的概念，似乎除了学术界所采用的“公共财政”之外别无他词可用。由此，在赋予公共财政中国特色意义的基础上，以 1998 年 12 月 15 日举行的全国财政工作会议为契机，决策层做出了一个具有划时代意义的重要决定:构建公共财政基本框架。三、总结必然要明确的是，社会科学常常渴望发现一套“放之四海而皆准”的方法和规律，但这种心态往往是幼稚的。不能低估经济的复杂性，也不要高估理论框架和科学工具的质量。经济学不存在什么八纮一宇四海皆准的学说，有的只有对症下药。我始终坚信在这个世界可以同时存在多种并行不悖的理论体系与价值体系，这些上层建筑分别可以去解释各自对应的经济基础，我们每个人所看到的世界实际上都是真实的世界。朱门酒肉臭是真实的，路有冻死骨也是真实的；脱贫攻坚乡村复兴是真实的，贫富差距地方债务也是真实的；宏大叙事伟大复兴是真实的，小民尊严和时代之山也是真实的。中国，乃至这个世界实际上远比我们想象的要庞大得多，你方唱罢我登场姹紫嫣红的现实世界暗面是深不可测的庞然阴影，至少我自认为还没有开始躺平，放弃对于世界更优解的追求，那么自然要去不断的去探求测度这个世界运行的方法工具。下一篇系列专题文章预计为：城投与地方债：从分税制改革到房地产经济的逻辑解读参见[1]OpenStax.  (2022)宏观经济学/14.货币与银行业.  LibreTexts GLOBAL.[2]兰小欢.  (2021)置身事内：中国政府与经济发展.  上海人民出版社.[3]高培勇.中国财税改革40年:基本轨迹、基本经验和基本规律[J].经济研究,2018,53(03):4-20.[4]曾康华,徐薇.新一轮财税体制改革的历史起点、问题及设想——1994年以来我国财税体制改革回顾与展望[J].财政监督,2024,(16):5-12."
  },
  {
    "title": "新一代大模型对话框架——OpenWebUI部署教程",
    "summary": "前言在之前的博客里，我曾对当时最为流行的两个 AI 对话网页项目 ——ChatGPT-Next-web 与 Lobechat 进行了总结。诚然，这两个项目在部署方面极为便捷（能够一键通过 Vercel 启动或借助 Docker 进行部署），无需担忧托管问题，且社区教程文档丰富详实。市面上还有诸如 Chatbox 这般成熟的闭源 AI 对话工具……但终究各有各的缺点：Next-web 和 Lobec",
    "tags": [],
    "url": "/posts/TechnicalTutorials/新一代大模型对话框架——OpenWebUI部署教程/",
    "date": "2024-08-28T00:00:00.000Z",
    "content": "前言在之前的博客里，我曾对当时最为流行的两个 AI 对话网页项目 ——ChatGPT-Next-web 与 Lobechat 进行了总结。诚然，这两个项目在部署方面极为便捷（能够一键通过 Vercel 启动或借助 Docker 进行部署），无需担忧托管问题，且社区教程文档丰富详实。市面上还有诸如 Chatbox 这般成熟的闭源 AI 对话工具……但终究各有各的缺点：Next-web 和 Lobechat 终究只是纯前端工具，Nextweb 简洁美观，却在自定义程度上有所欠缺，功能也相对简单；Lobechat 则显得过于臃肿，卡顿现象频发，并且官方近来在商业化进程方面较为激进，还删去了 WebRTC 的同步功能。Chatbox 虽强大，但也存在各种小问题，其同步方式也较为原始。那么，有没有一款全平台支持，页面好看美观，自定义程度高，社区支持完善的AI对话开源项目呢？答案是肯定的，它就是我们的——OpenWebUI！https://github.com/open-webui/open-webui/blob/main/demo.gif?raw=true伟大，无需多言。优点：全平台支持（web也是全平台，同步也方便）页面仿ChatGPT原版设计，好看简洁美观自定义程度高（自定义模型、Tool、Function）社区完善，支持各类插件提示词一键导入缺点：最大的缺点就是部署在本地对于vps的性能和空间的要求相对较高，剩余内存>2G，硬盘空间>10G似乎不能编辑对话记录部署教程1.准备工作一台安装了Docker Compose的VPS推荐安装1Panel或者宝塔面板，方便编辑Docker Compose文件和设置反代2.开始使用SSH连接到服务器创建一个文件夹，用于存放docker compose文件mkdir openwebui\ncd openwebui\n# 创建docker-compose.yml文件\ntouch docker-compose.yml实际上这些动作直接用1panel等面板也都是一样的，总之创建一个文件夹然后创建docker-compose.yml并编辑即可。docker-compose.yml的文件内容如下：services:\n  open-webui:\n    image: ghcr.io/open-webui/open-webui:${WEBUI_DOCKER_TAG-main}\n    container_name: open-webui\n    volumes:\n      - ./data:/app/backend/data\n    ports:\n      - 8080:8080\n    environment:\n      - 'WEBUI_SECRET_KEY=123456789'\n      # openai 配置\n      - 'OPENAI_API_BASE_URL=https://api.openai.com/v1'\n      - 'OPENAI_API_KEY=sk-xxxx'\n      # 启用openai画图\n      - 'ENABLE_IMAGE_GENERATION=true'\n      - 'IMAGE_GENERATION_ENGINE=openai'\n      # 开启注册登录功能\n      - 'WEBUI_AUTH=true'\n      - 'ENABLE_SIGNUP=true'\n      - 'DEFAULT_USER_ROLE=pending' # 由于我自己没有分享需求，所以注册用户直接选择pending，需要管理员手动激活\n      # 模型白名单\n      - 'ENABLE_MODEL_FILTER=true'\n      - 'MODEL_FILTER_LIST=gpt-3.5-turbo;gpt-4o'\n      - 'WEBUI_NAME=OiChat'\n      # 默认模型\n      - 'DEFAULT_MODELS=gpt-4o' \n    restart: unless-stopped文件修改完保存即可，然后启动服务 (确保在 docker-compose.yml 所在目录下执行)：docker-compose up -d之后服务器会自动拉取镜像并启动docker服务，镜像比较大（2个g左右，小水管会比较痛苦），等服务启动后就可以访问了访问 Open-WebUI 服务，地址为：http://你的服务器IP:80803.反向代理1p直接新建网站-反向代理-代理 http://127.0.0.1:8080,然后绑定一下域名证书开启SSL即可（不开也行），宝塔也差不多一个路子。4.后续更新# 进入之前创建的文件夹\ncd openwebui\n\n# 拉取最新镜像\ndocker-compose pull\n\n# 重启\ndocker compose up -d"
  },
  {
    "title": "RSSHub在Vercel上部署与信源选取",
    "summary": "原来都是在vps上用docker部署的RSSHUB，这两天突然发现居然Vercel也能部署RSSHUB，太神奇了。虽然不像其他能vercel一键部署的项目那样，但实际操作流程也很简单：一、正式部署流程1.Fork这个仓库： https://github.com/DIYgod/RSSHub如果像其他项目，Fork之后直接去Vercel导入即可，但是RSSHub的master分支是没办法直接部署的，b",
    "tags": [],
    "url": "/posts/TechnicalTutorials/RSSHub在Vercel上部署与信源选取/",
    "date": "2024-08-18T00:00:00.000Z",
    "content": "原来都是在vps上用docker部署的RSSHUB，这两天突然发现居然Vercel也能部署RSSHUB，太神奇了。虽然不像其他能vercel一键部署的项目那样，但实际操作流程也很简单：一、正式部署流程1.Fork这个仓库： https://github.com/DIYgod/RSSHub如果像其他项目，Fork之后直接去Vercel导入即可，但是RSSHub的master分支是没办法直接部署的，bug一直都没修，所以我们必须要切换到legacy分支。2.将仓库切换到legacy分支Fork仓库后，在自己账号里被fork的仓库中打开“Setting”设置，于“General”的“Default branch”中将默认的分支从master选为legacy即可。“Switch default branch to another branch”3.Vercel部署部署流程就跟其他的项目没啥差别，去Vercel导入后一路点点点就行。完成后记得绑定一个自己的域名，Vercel自带的域名国内是没办法直连的。二、信源选取毕竟我使用RSS的目的就是主动的获取信息而非平台的算法推送，主打的就是一手高质量信源和多合一信息聚合带来的便利。以下列表是我截止到2024年8月18日订阅的几乎全部RSS信源，其中微信公众号大部分仍未完成迁移，B站订阅反爬限制严格没办法。这一套下来每天接收到的RSS推送大概一共200-400条，需要看一遍的大概60-80条，信息密度还行。大模型贯一智能科技鹤啸九天机器之心、量子位、新智元三大ai“顶刊”、极客公园技术极客湾阮一峰的网络日志少数派金融信息财联社东方财富网—策略报告国家金融与发展实验室港股研究社海豚投研镜像娱乐美股研究社远川研究所36氪-产品观察微信订阅号(RSS)甲子光年清华大学国际与地区研究院晚点LatePost新潮沉思录新闻联合早报-东南亚、国际、中港台半岛电视台格隆汇"
  },
  {
    "title": "Weekly通讯-第八期：悬而未决之事、时间窗口与结婚户口的思考",
    "summary": "一、消解悬而未决之事带来的焦虑感我们经常会对一件悬而未决的事情感到焦虑，这实际上是再正常不过的生理本能，悬而未决意味着风险，意味着可能有不确定性带来的损失，我们的本能自然会驱使着大脑尝试寻找解决办法——如果自己的能力阅历找不到，则会直接导致潜在的焦虑烦躁。但生活中往往不如意者十之八九，这个世界不可能专门按照某一个人划定的秩序去运转，计划刚有雏形的时候不可能指望决策者和参与者马上敲定，事情不可能有了",
    "tags": [
      "Weekly通讯"
    ],
    "url": "/posts/ScheduledReport/Weekly通讯-第八期：悬而未决之事、时间窗口与结婚户口的思考/",
    "date": "2024-08-18T00:00:00.000Z",
    "content": "一、消解悬而未决之事带来的焦虑感我们经常会对一件悬而未决的事情感到焦虑，这实际上是再正常不过的生理本能，悬而未决意味着风险，意味着可能有不确定性带来的损失，我们的本能自然会驱使着大脑尝试寻找解决办法——如果自己的能力阅历找不到，则会直接导致潜在的焦虑烦躁。但生活中往往不如意者十之八九，这个世界不可能专门按照某一个人划定的秩序去运转，计划刚有雏形的时候不可能指望决策者和参与者马上敲定，事情不可能有了开头就立马有结局。我能想到的解决方案：做事之前就想想自己的损失底线在哪，风险和相对的利润空间是否匹配？多做一些预案，尽人事之后方能听天命。不理会自己介入不了的事情，最多只是等待一个结果（从源头减少需要考量的事情）提高自己的洞察力与预判能力（能够根据手上现有的信息和过去的经验，对未来做一个相对可控可信的预判，压缩未来决策和执行过程中的不确定性和与之相伴的风险成本）如何提高自己的洞察力和预判能力又是一门深奥的学科了。终归需要博学而笃志，切问而近思，权力来源于信息，不断提高自己手上信息的深度和广度，然后多做一些预判的训练，及时修正自己的认知框架，洞察力自然会逐渐提高。洞察力实际上代表着我们拟合世界的能力，洞察力越强，对于未来的拟合能力越强，一些判断也会越接近事情未来真实的走向。二、时间窗口与周期性Weekly通讯第六期里讲了一个奥弗顿窗口的概念，大意是一个政治议题是否能被大众接受存在一个时间的窗口期，可能你这个时候不推动的话未来很长一段时间就都不会有这样的机会了。不仅仅是政治议题，基本上所有的社会活动均有其窗口期。继续把视角拉长，历史和现在实际上表现为大周期叠加小周期，大窗口叠加小窗口。产业趋势叠加资本周期，使得任何产业都有其周期性规律，传统资源产业是如此，科技产业亦非例外。大周期实际上是一个存在连续性的整体。所以，在判断一个产业当前的发展周期，首先必然是要拉长时间维度，对其过去的产业周期做一个定调，再来根据现有表现做出最新的周期判断。全中国乃至全世界有潜力的小孩太多了，都知道自己有天赋有潜力，但现在是下行周期，世界实际上没有那么多把潜力兑换成实力，把实力兑换成成就，把成就兑换成钱的空间。现在很多场景就是处在零和博弈的困境下面，这个是目前基本没有办法去解决的，我们作为芸芸众生的一份子除了直接开躺外没有办法跳出这个循环。此外，就像我之前一直讲的，世界是一个巨大的混沌模型，开展宏观一点的演算还可以抓住几个关键变量去搞判断，而短期内变量就太多太复杂，一般人很难去拟合出一个真的符合未来走向的结果。三、从结婚不需要户口本看未来社会的原子化趋势8月13日有一条新闻，《婚姻登记条例（修订草案征求意见稿）》在民政部网站全文公布并公开向社会征求意见，结婚登记和离婚登记都不再需要户口簿。这种变化与我国传统家庭结构的演变历程密切相关。我国传统社会的家庭结构最初是 “宗族式” 社会，皇权不下乡，基层社会治理依靠乡绅和宗族自治。后来工业化、城镇化浪潮冲破了传统的乡野文化，传统社会结构和社群纽带不断被削弱，随着工作方式的灵活化和流动性增加，人们不再局限于一个固定的社群或地点生活和工作，大量新市民组成了更小的家庭，也就是我们现在一般认知中的 “Family”（father and mother, I love you，天然的最小单位就是三个人，加上父母就是七人）。在高速现代化和独生子女政策的加持下，随着人们生活水平的提高和医疗条件的改善，老人的寿命延长，此阶段的家庭结构主要表现为“1+2+4”的特征，即一个孩子，两位大人，四个老人，相信这也是绝大多数独生子女家庭最熟悉的结构。那么，现在乃至于未来呢？结婚不需要户口本又代表一种什么样的趋势呢？户口本起源于改革开放前的城乡户籍制度，在家庭设计中本质上是承认“上一辈一家之主的权力”。在传统的家庭结构中，户口本的所有者（父母）天然且正当的被赋予了决定子女未来户口迁移，乃至于同意是否结婚、和谁结婚的权力。尽管在现实操作中这一权力会被社会道德、亲朋关系乃至于子女本身所抑制，但终究是一种制度性的权力分配。这一分配模式伴随着千禧年后中国的进一步工业化城市化已经愈发显得不合时宜，将个体的命运过度与原生家庭的决策紧密捆绑，这本质上不符合现代化的发展方向。从社会学理论框架审视，户口本及其背后代表的户籍制度，不仅仅是家庭结构和社会权力分配的体现，更是宏观社会结构与变迁的缩影。功能主义理论认为户籍制度如社会机器中的关键框架，维持社会秩序稳定，通过城乡价值输送来配置资源，在计划经济背景下有效控制人口规模，保障工农现代化的劳动力需求配置。但在改革开放资源由市场配置，那么城乡二元分化的户籍制度就形成了系统性的社会不平等。城市居民与农村居民在教育、医疗、就业机会等方面的显著差异，实质上是对社会资源的不公平分配。从经济基础角度，城市化进程中的人口流动也导致跨地域的家庭分离，高房价高生活成本使得年轻一代难以负担大家庭的生活开支等因素使得子女同父母分开的经济社会因素已经成熟。而现在结婚不需要户口本，代表着中国从顶层制度设计上剥夺了户口本户主对于子女婚姻的决定权，这从制度方面推动了更小家庭结构的产生（从 “1+2+4” 过渡到 “1+2” 乃至于 “0+2”）。经济基础与上层建筑共同作用，未来社会小家庭、无家庭化和个体原子化已成为大势所趋。对户口本和背后户籍制度权力结构的松绑反映的是中国现代化进程中经济与社会结构的转型，也是对个体主义的一种制度性回应。未来劳动力乃至性资源的配置如何设计，如何改革都需要进一步在实践中得到检验。摘录男儿立志出乡关，学不成名死不还。埋骨何须桑梓地，人生无处不青山。 向教员致敬为什么长期项目胜过短期项目：\n（1）这个世界上，大多数人都在玩短期游戏。如果你玩长期游戏，你会因此获得优势。\n（2）这是因为，如果你做其他人正在做的事情，回报应该跟其他人差不多，只能保证你获得平均结果，除非你很幸运。\n（3）要想获得高于其他人的回报，你要么做不同的事情，要么以不同的方式做事。\n（4）选择很少人玩的长期游戏，你更容易获得高于其他人的回报。这不是因为它更简单，事实上它更困难，但是你每天都投入去做困难的事情，会使得明天变得更容易。\n（5）长期游戏最困难的地方是第一步。你必须愿意承受当前的痛苦，才能让明天变得更容易一点。\n（6）在长期游戏中，你每天只能创造出一点微小的优势，它不明显但不意味着不存在。\n（7）你不能在所有事情上都进行长期游戏。你需要选择对你来说重要的事情，做一个长期规划，然后长期投入。王传福多年前关于造车的一句话给了我很大的勇气。 他说很多企业因为不了解，会把技术想象到令人畏惧的高度，这种畏惧正是对手给后来者营造了一种产业恐吓。他们不断地告诉你做不成，投入很大，研发很难，直到你放弃。其实你解决不了的不是因为你没有能力，而是你缺乏勇气。 来源于雷军的年度演讲以太坊创始人之一的 Vitalik Buterin 在2017年曾经提出，区块链存在三难困境：无法同时实现去中心化、可扩展性和安全性。"
  },
  {
    "title": "致瞬息万变之物，及亘古不变之物",
    "summary": "这篇小作文也勉强可以算是我迟来的20岁生日感想吧，距离我写下《十八岁-未济与求索》的生日感想不过区区两年，心态、见识却变化了太多。1517年的深秋，马丁·路德终于做好了最后的思想准备，将《九十五条论纲》贴在了德国维滕堡城堡教堂的大门上，轰轰烈烈的宗教改革运动就此开始，曾经不可一世的教会教皇逐渐会意识到世俗的权力必定会高于上帝，或者说上帝忠实的代理——教权。伴随着宗教改革启蒙运动的大潮，中世纪末教权",
    "tags": [],
    "url": "/posts/Essays/致瞬息万变之物，及亘古不变之物/",
    "date": "2024-08-07T00:00:00.000Z",
    "content": "这篇小作文也勉强可以算是我迟来的20岁生日感想吧，距离我写下《十八岁-未济与求索》的生日感想不过区区两年，心态、见识却变化了太多。1517年的深秋，马丁·路德终于做好了最后的思想准备，将《九十五条论纲》贴在了德国维滕堡城堡教堂的大门上，轰轰烈烈的宗教改革运动就此开始，曾经不可一世的教会教皇逐渐会意识到世俗的权力必定会高于上帝，或者说上帝忠实的代理——教权。伴随着宗教改革启蒙运动的大潮，中世纪末教权走向全面瓦解，其背后的基督教意识形态也不可避免的走向解体，科学理性和道德理性先后从基督教意识形态母体中剥离开来，在后期的实践中走向了分离。从伽利略到牛爵爷再到半统数学教科书的符号江山欧拉，以科学为核心的思维被从基督教体系中分离出来，形成了以数学和物理学为核心的科学理性体系。由此，恺撒的物当归给恺撒，上帝的物当归给上帝，凡人的权柄也当握在凡人手中，科学和理性成为现代价值观的基础，在信用的基础上逐渐演化出现代社会的庞大结构。信用贴现机制让我们得以通过投资亦或者是消费部门的杠杆来将未来的收益（增长）转移到当期（当下），利用带有预期正面收益的资产作为抵押物，分享预期的未来收益，虚空制造当期的额货币供应量，最终在本期经济循环中消费了未来的收益。这就是构建在数理逻辑上的现代信用社会的绝妙之处，繁杂的金融工具创造了近乎无限的财富。我们围绕着市场形成了一整套的民族国家的政治观念与资本主义法权观念，围绕其建立高效率的社会组织体系，并创建一整套以自由民主平等政治为核心的价值理念，而这个过程并不需要道德理性，只需要基于各方利益精算的政治经济哲学。这套体系看似完美无缺，也难怪福山老师会在苏联解体之后写出《历史的终结》。在福山老师看来，将各个层级和各个板块的权力制衡做到极致，所有的政治角色没有任何一个尼采哲学意义上的超人存在，这便是人类终极的乌托邦与理想国，代表着人类在政治哲学上的演化已经走到了尽头。当然，后面发生的事我们也都知道了。从中华帝国的皇帝再到高居于白宫的总统，从来都不存在所谓的昭昭天命，秩序本身的建立者正在推动毁灭这一秩序和虚假的天命，曾经的反叛者居然在在所谓的普世价值观下形成的秩序中扮演者受益者和捍卫者的角色。市场经济和资本主义模式的优势之一就在于其自发的会产生一套激励模式，但这并非是鸟语花香的和平竞争，而是一旦失败就万劫不复的生死竞速。尤其是在当前世界增量严重不足，而存量的争夺也愈发急切的情况下，和平共存的空间越来越少，你死我活的竞争越来越多。危机会被当下的零和博弈激化，但从更长远的历史走向来看，危机也是一种必然。多年以后，我们该如何定义2020年这个特殊的时间节点，如何定义从2020年开始的，全球矛盾显著激化的这一段特殊时期呢？一个可能合适的形容词便是“大争之世”。瘟疫大流行固然吓人，但其好处是让很大一部分人明白了一个道理——每个人都不天然是这个世界的一部分，世界不认识大多数人。祖逖在南下的惶恐中终于认识到了这个残酷的事实，才最终明白剑与火的回应是这个世界唯一看得懂的表情，暴力是这个世界永恒的底色。鲜花向来都停止不了战争，只能作为停战之后的装饰品慰藉人心。从古老的边疆区到北方的大城，幸存者们仓皇而行，残酷的屠灭已经从童年开始。从文明最北边的白令海峡到最南边的好望角，所谓的承平日久和世界村更像是建立在信用贴现工具和第三世界丧失话语权下的一种虚假繁荣，是一代年轻人已经被大麻和廉价色情所谋杀后的幻想。历史的终结，让世界无路可去。最好的制度，让人抱残守缺。政治正确，让天下离心离德。披着自由主义皮的世界市场实际上是在分享着跨国公司主导的全球化之下的赃物转移。我在纪念十八岁生日的博文中如此写到：易经以乾坤两卦开始，最后一卦却是 “未济”。何为 “未济”？孔夫子作的《序卦传》说，“物不可穷也，故受之以未济终焉。” 易经六十四卦到了既济这一卦，乾坤或几乎息矣。矛盾似乎消失，斗争已然停止 —— 但是唯物辩证法告诉我们，矛盾永远不会消失，“物不可穷”，因此既济之后还会有未济，事物矛盾的变化没有穷尽。世界瞬息万变，矛盾亘古不变。在唯物史观视角下，矛盾贯穿于历史的场合之中，旧有的矛盾消失了，新的矛盾业已产生，历史的发展正是在接连不断的矛盾的被解决之中波浪化地前进。于是乎，我们，我们之前的我们和我们之后的我们，都被视作了一条绵延不绝的历史展开的一个过程，一个片段。在这里，不会有\"历史的终结\"，甚至都不能被视作辉格史观下的高歌猛进，乐观主义的坦途。因为它有低潮，有倒退，有曲折，甚至有可能崩溃。中国的发展道路，总是在巨大的张力下行进，作为替代资本主义的现代性的第二条道路，不可能是坦途和一帆风顺。我们常常感叹历史总是在重复，祖逖以剑与火在北方建功立业，终究保的是皇帝的太平；李闯将闯王在陕西中原出生入死，不会妨碍江南的士绅糜烂涂地。历史终归不是非黑即白的，这一抹精致的灰夹杂着太多的妥协与人性的复杂。千百年后，我们还会赞叹闻鸡起舞，击楫中流的英雄豪气。我们也会感叹六朝何事，只成门户私计。可我们不也一样觉得名士风流，古今绝唱吗？我们不好指责什么，只能希望，享受英雄遗泽的人们不要太早辜负了这一切努力。二十年前的我们是孤独的，那时能支撑下来的只有伟人丰厚的文化经济遗产与锐意改革之后凝聚的共识，只有已经逝去的和将要逝去的，只有在荒原上的夜行本身。新的纪元大概是已经要到来了，但向前看只有一片混沌。当时的我们并不知道这份混沌究竟会通向何处，更不知道这样的混沌会持续多长时间，抵抗这种混沌只是一种本能，我们甚至不知道这种本能是从哪里继承而来的。在这片混沌前似乎之前所有的上层建筑都是废纸，唯有混沌本身才是真正的应许之地。在《前进，达瓦里希》让北方帝国的遗老唏嘘不已的时候，我们只是凭借本能知道，这个东西讲的并不是什么苏联。二十年后的我们依然孤独，但这种孤独和二十年前是不一样的，这是一种自我选择自我扬弃后的孤独，是黑夜中不断加快的脚步，是兴亡载覆峥嵘之后的启航，是亘古一片月之下的万化兴衰——是终会看到麋鹿角解，鲜花满枝。"
  },
  {
    "title": "Weekly通讯-第七期：跳大神、回报预期、奥弗顿窗口和为死亡定价",
    "summary": "一、不要随意的做出预言和定论很多营销号和所谓的经济学家经常喜欢渲染一个或者多个时间节点，来营造一种史诗感来彰显自己的专业，提纯粉丝和造神，通常这种我看到一个屏蔽一个，实在是污染互联网。归根结底，经济学和其他所有的社会科学一样都是一种归纳性的学问，舆论场上很多人却总喜欢把经济学/金融学当成是什么有前瞻性的预言类学问，实在是荒谬至极。它都预言了，还能叫科学吗？实际上经济学家看不懂才是常态，大家都是在对",
    "tags": [
      "Weekly通讯"
    ],
    "url": "/posts/ScheduledReport/Weekly通讯-第七期：跳大神、回报预期、奥弗顿窗口和为死亡定价/",
    "date": "2024-07-29T00:00:00.000Z",
    "content": "一、不要随意的做出预言和定论很多营销号和所谓的经济学家经常喜欢渲染一个或者多个时间节点，来营造一种史诗感来彰显自己的专业，提纯粉丝和造神，通常这种我看到一个屏蔽一个，实在是污染互联网。归根结底，经济学和其他所有的社会科学一样都是一种归纳性的学问，舆论场上很多人却总喜欢把经济学/金融学当成是什么有前瞻性的预言类学问，实在是荒谬至极。它都预言了，还能叫科学吗？实际上经济学家看不懂才是常态，大家都是在对过往知识数据的归纳基础上尽力拟合出现实世界未来的走向，这只是未来无限可能性中的其中一条。偏偏又有许多所谓的经济学学者会迎合媒体的要求，发表一些毫无根据的预言和判断，才强化了这种偏见。于是好好的一门归纳总结的正经社会学科，被整成了神神叨叨的命理学了。对于我自己来讲，我极其的厌恶所谓的神棍式“预言”，我们没办法准确的预知世界的走向，只能不断地逼近去拟合，就好像是我们永远没办法知道圆周率准确是多少，但我们可以不断的求圆周率的后小数位一直逼近到极限。但是他妈的现实世界太复杂变量太多了，混沌模型导致我们只能懵懵懂懂的揣测大致的走向，更具体的拟合谁都不好说二、从赌王之子看努力的回报预期星竞威武集团于 2024 年 7 月 26 日在美国纳斯达克交易所正式敲钟上市，成为“中国电竞第一股”。其董事长兼联席 CEO 为何猷君，何猷君出生于 1995 年，被纳斯达克副主席称为“亚洲最年轻的纳斯达克上市公司创始人”。当然，我在这里不是想继续复读鸡汤或者嘲讽人家是赌王之子的，而是想探讨一下不同人群的激励机制和“回报预期”。我们经常能听到各种富二代的励志故事，例如xx凌晨还泡在哈佛图书馆……是否有可能，对于他们来讲成功的路径是相对清晰的，回报也是相对可以被测定且有人替他们兜底？我们都知道权威来源于认可，权力来源于信息。这种贵族阶层可以掌握更高质量的信息，因此在投资决策中自然相较于普通人居于优势地位，所以他们努力奋斗的回报预期也相对明朗——毕竟从小就受到的商业教育会告诉他这样做大概率会赚钱，哪怕亏了家里人也可以兜底。而更为底层的普通人则没有这个教育环境和信息，他们的回报预期就更可能是“考上这所大学未来就xx”，自然没办法做出更长远的规划。我想了想还是不能这么讲，毕竟世界上多的是混吃混喝等死的富二代和鱼跃龙门的普通人，只能作为一种参考观点。三、奥弗顿窗口奥弗顿窗口（Overton Window）是一个政治学概念，由美国政策分析师约瑟夫·P·奥弗顿（Joseph P. Overton）提出。大意是在特定的时间段内存在一个公众能够接受的政治思想、政策提议或社会变革的范围窗口。在这个窗口内的观点被视为主流或至少是可以讨论的，而窗口外的观点则被认为是极端的、非主流的，很难在公共讨论或政治议程中获得认真考虑。奥弗顿窗口不是固定不变的，它可以随着时间、政治环境的变化、舆论领袖的言论、媒体的报道以及突发事件等因素逐渐移动。当公众对某个议题的态度发生变化时，原本被视为极端的观点可能逐渐被接纳，进入可接受的讨论范围，反之亦然。简单来说，奥弗顿窗口定义了公众认知中“可接受”的政治观念谱，从极为自由到极为保守最近的例子就是前几年经济形势还好，那么左派lgbt的相关议题政策就比较多；但疫情后世界经济进入困境，大家集体右转，保守势力重新掌权，那么这个阶段就可以被视为左翼议题窗口期已经过去。四、为死亡定价经济是一个抽象的概念，或许是一个真实的抽象，但终究是一个抽象，是一系列思想、概念和统计数据的集合，它们通常聚合了真实的人和事物，以及实际的生产和再生产网络。我经常感叹道资本主义好就好在它可以为万物“定价”，一切都是可以被量化定价去衡量的——当然也包括生命。社会统计数据告诉我们全世界包括富裕国家在内，因忽视和缺乏治疗而死亡的人数以百万计，而许多现代官僚机构在分配资源时，也会习惯性地权衡生命与死亡的概率和成本。世界各地每天都有工人为了替雇主节省开支而置身于致命风险之中。当我们评估药物开发、工作场所安全措施的成本，分配医院床位，或衡量污染减排的价值时，我们实际上是在为生命的价值定价。是的，虽然我们很可能会直接回避“为生命定价”，但是我们庞大的生产结构不会自己骗自己，将出生和死亡纳入经济计算是不可避免的。尽管对特定人类生命的价值进行评估是不可能的，但经济学家已经发展出评估‘统计生命’价值的技术；即衡量人们为了降低死亡或疾病风险愿意付出多少。在美国，定期调查发现，工人愿意接受约 1,000 美元的减薪，以将工作场所的死亡概率降低万分之一。根据经济学家的逻辑，这意味着在一个拥有 10,000 名员工的大公司中，员工们愿意支付 1,000 万美元来挽救一条生命。这就是所谓的统计生命价值（VSL）的由来。1,000 万美元的数值被美国卫生与公众服务部（HHS）、美国环境保护署和美国交通部所接受。世界银行在其成本效益分析中使用 380 万美元的 VSL。OECD则对欧洲人应用 360 万美元的VSL。在中国，我跳大神地认为VSL应该在300-700万（rmb）左右。注意，VSL存在极大的局限性，它并非任何人在拥有无限预算时愿意支付以挽救生命的金额，也不是我们实际从有限资源中支付的数额。它是一种从低成本选择中推导出的集体衡量标准。由于缺乏更好的替代方案，VSL 估算仍被使用，其优点在于简单且平等。言论谁能掌握过去的定义权，谁就能掌握现在的解释权，谁就能对未来施加影响。团结，是需要代价的我们之所以强大，并不是因为在现有规则下不存在阴影，而是我们永远不能让阴影行走于阳光之下自上而下的能力非标且难以复制，被认为是资管行业的稀缺资源，其背后常常是经年累月的经验以及不断的自我否定。沉迷于赛道之中会对世界上正在发生的变化变得迟钝，那不妨站得更高一些。可以在自己的投资框架中引入越来越多的宏观因子和慢变量，逐渐形成重行业选择的投资风格。政治的艺术在于妥协，妥协的基础在于互相威胁。成功的政策背后是成功的协商和妥协，而不是机械的命令与执行。所以理解利益冲突，理解协调和解决机制，是理解政策的基础。巴黎真的不愧是巴黎。哪怕它扒手遍地，河流大肠杆菌超标，小巷深处藏着住街的带狗猛男，桥洞中人才济济土方凶猛，但永远有一个如梦如幻的倩影潜伏在所有人的心中，能在恰当的时候给所有的瑕疵及时带上滤镜。"
  },
  {
    "title": "2024阅读计划",
    "summary": "本页面未必详尽，具体书单可参照“时歌的书库”2024.10.3：本页面已过时，具体博主年度已阅读/待阅读书单请统一参照对应Notion Page。政治经济学[X] 大停滞：新冠疫情如何撼动全球经济-亚当·图兹[ ] 崩盘：全球金融危机如何重塑世界-亚当·图兹[X] 结构性改革：中国经济的问题与对策-黄奇帆[X] 置身事内：中国政府与经济发展心理学[X] 童话中的阴影与邪恶-玛丽-路易丝·冯·法兰兹",
    "tags": [
      "阅读笔记"
    ],
    "url": "/posts/Essays/2024阅读计划/",
    "date": "2024-07-22T00:00:00.000Z",
    "content": "本页面未必详尽，具体书单可参照“时歌的书库”2024.10.3：本页面已过时，具体博主年度已阅读/待阅读书单请统一参照对应Notion Page。政治经济学[X] 大停滞：新冠疫情如何撼动全球经济-亚当·图兹[ ] 崩盘：全球金融危机如何重塑世界-亚当·图兹[X] 结构性改革：中国经济的问题与对策-黄奇帆[X] 置身事内：中国政府与经济发展心理学[X] 童话中的阴影与邪恶-玛丽-路易丝·冯·法兰兹[ ] 永恒少年：从荣格观点探讨拒绝长大-玛丽-路易丝·冯·法兰兹[ ] 心理学大师荣格文集机器学习[ ] 智力进化简史-马克思·本尼特"
  },
  {
    "title": "Weekly通讯-第六期：米哈游，萝卜快跑，AI市场出清与MMT",
    "summary": "一、米哈游的商业设计绝区零推出，当前米哈游正式形成原神时代之后的三驾马车：原神、崩坏：星穹铁道和绝区零。有点遗憾，三款游戏我都玩过一点但很快就热度消散（怪我自己电子阳痿），但不妨碍我欣赏米哈游的音乐和美术设计+赞美其高效的二次元韭菜镰刀商业模式。对于原神，进一步扩圈的压力是很明显的。参见那维莱特的角色设计，元素反应机制的搁浅，和各种游戏机制的优化。原神作为一款已经运行了四年的老游戏，可能其底层的游",
    "tags": [
      "Weekly通讯"
    ],
    "url": "/posts/ScheduledReport/Weekly通讯-第六期：米哈游，萝卜快跑，AI市场出清与MMT/",
    "date": "2024-07-20T00:00:00.000Z",
    "content": "一、米哈游的商业设计绝区零推出，当前米哈游正式形成原神时代之后的三驾马车：原神、崩坏：星穹铁道和绝区零。有点遗憾，三款游戏我都玩过一点但很快就热度消散（怪我自己电子阳痿），但不妨碍我欣赏米哈游的音乐和美术设计+赞美其高效的二次元韭菜镰刀商业模式。对于原神，进一步扩圈的压力是很明显的。参见那维莱特的角色设计，元素反应机制的搁浅，和各种游戏机制的优化。原神作为一款已经运行了四年的老游戏，可能其底层的游戏框架已经老化，他已经从迅猛增长的青年期过渡到中年期，现在正在逐步走向老年期。米哈游的三驾马车中，赛道重合的情况愈加的明显。头部游戏大世界类型的《原神》、回合制类型的《星穹铁道》、动作类型的《绝区零》看似泾渭分明，实则赛道重合度极高，因为底层逻辑都是“卖卡”且都为剧情游戏，若不扩圈，内部互分蛋糕的局面只会日益加重。“弱保软”一词的全称是“弱智保姆软件”，其主要含义是指那些为了迎合低技能或不愿意投入太多时间的玩家而设计的游戏，这些游戏通常会降低难度、简化操作，并提供明确的指引，以确保玩家能够轻松完成游戏内容《绝区零》在前期的战斗中正是贯彻了“软保弱”的思路，既未满足硬核动作游戏玩家“战斗爽”的需求，“平砍就能通关”也使得普通玩家很难从重复操作中获得成就感。我们可以从原、星和绝的模式变革和设计中窥得米哈游的出圈野望，但现在看起来仍然算不上成功。原神推出的时候在整个二游市场几乎是一枝独秋，也为后来的竞争者切切实实的探明了——二次元开放式手游+类原的免费抽卡商业模式是可行的，并且理论上割韭菜的力度比累死累活其他赛道要强不少。但二游市场从最初的原神笑傲江湖（商业实力）到现在百舸争流仅用了三四年时间，市场发展的太快了。《绝区零》上线后，米哈游将迎来至少一两年左右的新游空窗期，届时二游市场又将蜕变成何种模样，没有人能预料到。但毫无疑问，米哈游面临的竞争压力会持续增大。异环和代号无限大看测试pv是真的酷炫好伐，要是这俩出了且画的大饼全部落实，我肯定玩爆（尤其是异环）未来心理学这块知识积累的差不多了可以去剖析一下二游和乙游具体提供的情绪价值和商业模式二、萝卜快跑的相关思考上世纪60年代，斯坦福大学计算机科学家罗伊·阿玛提出了一个创新定律：人们总是高估新技术的短期效益，而低估长期影响。具体而言，当一项新技术刚刚问世时，人们总是期望其能快速落地并带来极高的效益，但当新技术进入漫长的商业化进程，人们又因为缺乏耐心看低其实际价值。详细内容参见本博客文章：中国与世界的现代化专题（一）：萝卜快跑，社会结构与国际价值链分工三、出清与兼并中的AI市场Inflection AI 成立于2022年，创始团队人才云集，自己的ai产品pi在海外也算火出了圈（产品美学设计上很独特，但中文使用体现比一坨还差），其基础模型Inflection在多项基准测试中表现也很不错。公司成立不久就融资 2.25 亿美元，一年后再度融资 13 亿美元 (当时AI领域的最高单笔融资) ，估值最高达到了 40 亿美元。2024年3月8日，公司发布最新大模型 Inflection-2.5，在仅使用 40% 计算量的前提下，就实现了与 OpenAI GPT-4 相媲美的性能，迅速成为全球科技头条。但就在十天之后，微软就和Inflection AI达成交易：微软支付6.5亿美元获取Inflection AI模型的使用授权，而  Inflection AI 公司关键人员和大部分技术员工悉数加入微软，组建新部门 Microsoft AI。无独有偶，之前的Mistral（微软系），Anthropic（亚马逊系）最近的Adept AI（亚马逊系），也是以类似的形式被巨头“收编”，加入自己的势力范围。在国内，阿里将大模型五虎（中国的五家大模型独角兽：智谱AI、零一万物、百川智能、MiniMax和月之暗面）均纳入自己的投资范围内，嫡出的通义千问表现得更是比被投企业产品还要更加出色。AI领域的独角兽们正在不断的被巨头们划分势力范围纳入麾下，而其他尚未确定归属的独角兽正在陷入“融资寒冬”。上周，The Information 透露，Character.ai 正在接触 Google、Meta、X.ai等科技巨头进行「合作」谈判，希望用自己的知识产权来交换对方的计算资源，Character.ai自身也爆出核心员工开发人员正在被挖的消息。Character.ai在2023年初快速获得融资，最近一轮融资发生在2023年3月，为1.5亿美元的A轮融资，该轮融资由知名风险投资公司Andreessen Horowitz（A16z）领投。此轮融资后，公司的估值达到了10亿美元，正式晋升为独角兽公司。2023年6月访问量达到2.8亿，用户平均每次停留28分钟，相比之下ChatGPT只有8分钟。当时的Character.ai风头无两，谁也没想到此后一年半的时间，它再没有拿到一笔融资。曾经轰轰烈烈的百模大战，一年过后真正有实力还在做的又有几家，又有多少参与者悄无声息的退出了呢？当前ai大模型的能力实际上是撑不起这么多的ai独角兽拼命制造的泡沫，例如perplexity现在的估值达到30亿美元，Notion估值甚至达到了100亿美元（蜜雪冰城估值670亿人民币，月之暗面估值30亿美刀），难道这些所谓的独角兽所做的技术创新和市场潜力真的能和其动辄几十亿上百亿刀的估值相匹配吗？不好讲的。四、大通胀与MMT你只要能接受通胀，钱就是无限的，只要你能一定程度输出通胀，钱就是更无限的。MMT或许可能是中国当前债务问题的解决途径之一。以下内容为ai生成，未来有机会可以详细聊聊MMT，就放到中国与世界的现代化专题里吧。现代货币理论（Modern Monetary Theory，MMT）是一种非主流的宏观经济学理论，主张国家发行货币以借款人的信用为标准，以满足国民的货币需求量为准，而不主要基于其他经济数据。该理论认为现代货币体系实际上是一种政府信用货币体系，即主权国家的货币并不与任何商品和其他外币挂钩，只与未来税收和债务相对应（主权货币发行国在理论上可以无限制地创造货币。）一、现代货币理论的主要观点现代货币理论认为现代货币体系实际上是一种政府信用货币体系，即主权国家的货币并不与任何商品和其他外币挂钩，只与未来税收和债务相对应。现代货币理论主张“功能财政”，即政府支出应以稳定价格、实现充分就业为目标，收支平衡不应是政府支出时要考虑的约束条件，预算收支不平衡甚至政府财政赤字才是经济发展的常态。二、现代货币理论的应用现代货币理论对于现代货币的运转虽然有着更加深刻的理解，但也受到本学派的其他人和主流经济学派的猛烈攻击。现代货币理论的最主要缺陷还在于他们沿袭了凯恩斯学派的“储蓄=投资”，并未注意到储蓄与投资的偏离过程及偏离原因，忽视了商业银行的货币创造作用，夸大了财政的作用，不受约束的过度财政扩张或实施不当势必造成通货膨胀。现代货币理论最大的意义在于破除主流经济学不必要的理论迷信，通过合理的赤字支出来实现中国特色社会主义经济。这意味着我们不应该执着于财政的结余为正、为负，或者平衡。财政的支出应该取决于我们期望达到的效果。三、现代货币理论的争议现代货币理论虽然对后世影响深远，但同时也受到了一些批评。批评者认为，现代货币理论过分强调了财政的作用，忽视了商业银行的货币创造作用，可能会导致通货膨胀。现代货币理论并不是一张空白支票，让我们随意为新项目提供资金，也不是一个扩大政府规模的阴谋。作为一个分析框架，现代货币理论旨在识别我们经济中尚未开发的潜力，即所谓的财政空间。参见[1] 投中网：王慧文，投了个中国版Character.AI[2] 对话创世伙伴周炜：下半年AI寒冬将至，去伪存真，硅谷创业者只求熬到下个周期[3] 财经十一人：阿里包揽中国估值最高的5家大模型独角兽[4] 镜像娱乐：《绝区零》失意后，该对米哈游祛魅了"
  },
  {
    "title": "中国与世界的现代化专题（一）：萝卜快跑，社会结构与国际价值链分工",
    "summary": "一、萝卜快跑成本测算分析百度做萝卜快跑（l4类）的自动驾驶其实已经积累很久了，2024年下半年应该算是一个集中的爆发期，无人驾驶正式以一个“出圈”的姿态展现到大众面前，和以前各大车企大力公关的自上而下宣传不同，本次萝卜破圈更多以基层传播为态势，人民群众之前的讨论热度广热情高。可以看到具体的舆论数据主打一个高速破圈主打一个高速破圈Untitled关注的人群构成也很有趣Untitled根据专家调研结果",
    "tags": [
      "风自东方来"
    ],
    "url": "/posts/Finance and Economics/中国与世界的现代化专题（一）：萝卜快跑，社会结构与国际价值链分工/",
    "date": "2024-07-14T00:00:00.000Z",
    "content": "一、萝卜快跑成本测算分析百度做萝卜快跑（l4类）的自动驾驶其实已经积累很久了，2024年下半年应该算是一个集中的爆发期，无人驾驶正式以一个“出圈”的姿态展现到大众面前，和以前各大车企大力公关的自上而下宣传不同，本次萝卜破圈更多以基层传播为态势，人民群众之前的讨论热度广热情高。可以看到具体的舆论数据主打一个高速破圈主打一个高速破圈Untitled关注的人群构成也很有趣Untitled根据专家调研结果，萝卜快跑单车制造成本以20万记，那么在单个城市落地3k辆的成本就是6亿；中国有4个一线城市，15个新一线城市和30个二线城市，每个城市都落地3k，那么总购买成本就是294亿，此处我们不考虑智驾中心和其他配套的费用。我们假设萝卜的预计使用年限为10年（考虑到硬件更新速度，年限肯定比这个数字要短），残值率为5%，那么单量车的预计净残值就是1万元，使用年限平均法则单辆车的折旧费用就是1.9万元，全国每年的折旧费用就是27.93亿元。由于萝卜更具体的各个软硬件数据我还没拿到也懒得算，单车具体的年维护费用就不考虑了现在路测的萝卜车群中，95%往上的车辆都是全无人的，武汉配套人员一共600人，其中近200是路测人员，通过本地云仓远程驾控的人数越70-80，地勤人员接近200人（两公里一个，车在行驶中有任何问题，两公里之内必须第一时间赶到现场，马上处理）。百度方面认为2025年可以实现盈利，我们认为抛开车辆的购买成本，后续运营成本中最重要的就是用人成本和车辆的养护成本（其中用人可能会占大头）。去年的时候，百度萝卜智驾中心内云仓人员接管的比例为1:4，现在已经升级到1:10，即一个人接管10台车。极限情况下（晚高峰或者有轿车需求比较猛增的时候），会涨到1:20。 考虑到现在各大车企的端到端智驾大模型的更新速度很快，未来一个云仓安全员接管20-40辆车是完全有可能的后续我们可以比较乐观的估计，维持1000辆自动驾驶汽车的总团队成员可以压缩到100-300人这个数量（需要考虑白夜班），维持单城市3000辆自动驾驶汽车的总团队成员数量大概在400-800这个数量级，按照人均月薪6k-8k，单人总支出7k-10k算，那么总年度用人成本大概在三千三百六十到九千六百万这个区间（取5500万），按照落地49座城市算，则维护团队的年支出为26.95亿。这是一个很粗略的估算，有许多因素都没有考虑进去（例如各地政府的公关费用，汽车汽修可以外包给途虎，地勤可以外包到代驾，成本可以压缩的空间也是有的），但我们仍然可以看出l4级智驾是一项重资产的投入。是的，我的意思是，百度未必真的会如各种媒体所渲染的那样在全国主要大城市都落地成千上万量萝卜快跑——因为这玩意纯纯重资产，不只是百度，全国乃至全世界的互联网公司都不敢把自己的重资产搞到这种天文数字。阿波罗的L4的萝卜智驾模式更像一个“偏政府规划友好型模式”，而非市场经济推进模式。因为让l4级无人驾驶车辆上路必须要经过地方政府各级部门的层层审批和同意，地方政府也要承担大量的责任和舆情的考量（就业的蓄水池被打破），智驾的推进会和各地政府规划的智慧交通耦合，和低空、车路云相似，有些地方政府是愿意补贴给L4做运营的，从补贴角度有可能会扭曲这个产业实际发展的进度。因此，相较于百度花费大量的人力财力物力去全国各地一家家的去公关，去推进，可能直接选择和各地的地头蛇合作，走华为智驾模式会更加顺利一点。我能想到的可能：1.华为模式：百度阿波罗作为中国第一个成功较大规模落地的l4级自动驾驶服务商，和其他整车主机厂合作，百度出售智驾方案，由地方地头蛇开展运营；2.资产剥离模式：百度阿波罗从百度集团剥离，作为控股/大股东模式展开落地，隔绝风险；3.我们不排除百度真的打算完全自己运营全自主可控的可能，如德拉曼故事；只是这样从财务和战略的角度都比较冒险，推进难度也不小；当然做成之后好处还是很明显的。重视轻资产运行的外包模式虽然在财务报表上相对好看，但高度依赖精密的社会分工，面对突发事件的超预期冲击抵抗力较弱。互联网世界中许多公司表面上是高新技术服务业，但实际上干的就是“二房东”和中介的活，纯粹靠着资本的故事去放泡沫。将视角扩大到整个智驾产业，可以落地的方向大概有哪些？首先就是萝卜快跑这种“德拉曼”模式，充当出租车巡游车网约车的替代品；然后，对于雄安新区这类高标准规划的新城城区，可以充当公共交通的替代品（无人驾驶公交车、城区间快速通勤）；可能社会方面影响更大的，是在近封闭环境点对点的高速公路上逐渐取代有人货车。目前我知道国内有好几家在做l4级无人货车的科技初创公司，一旦政策上的口子放开，路测加快，货车无人驾驶大规模实现后，对我国高速公路安全与运输成本现状的改变将是根本性的，由此引发的社会冲击也不是出租车行业能比，货车司机是更有组织性有行动力的群体。在部分港口（如宁波舟山港）已经实现了无人装卸与无人运输，杭州也是工信部的智能网联汽车“车路云一体化”首批试点城市之一。对于交通运输业，被替代的压力是实打实且好比是屠刀已经放到了脖子上，虽然这么说很残酷，但我认为从业者们对社会呼喊“留口饭吃”是徒劳的，更像是一种绝望般的行为艺术。在大模型替代的大浪潮下，喊了也不会有人听，从业者的未来要么卷死同行要么尽早转型，岗位的空间会被ai迅速挤压（不是替代，我也很讨厌替代这个词，太绝对了）。二、社会结构的扁平化之前和群友聊天的时候提到过小米，我认为米家家居生态链可以做到便宜皮实好用不仅仅得益于其优秀的供应链管理和小米长期在产业链上下游的战略投资，还得益于整个米家家居销售的“扁平化”。小米通过自建电商平台（小米商城）、官方旗舰店以及第三方电商平台等方式直接面向消费者销售产品，减少中间环节降低渠道成本。消费电子终端大厂的经典供应链管理能力也显著强于传统厂商（此处点名雷总耍猴:D），库存积压较少，供应链效率可以进一步提高（库存信息差异对线上零售商利润的影响更大）。而像格力、美的这种传统厂商用的则是多层的分销体系，产品从工厂出来之后需要经过一级代理商、二级代理商，甚至更多层级的经销商，才能最终到达消费者手中。是的，这种模式在电商时代之前可以打造极强的基层统治力，产品覆盖广深度渗透，但同时也养了一大批附属经销商和县乡镇级维护工程师，最终导致公司资产尾大不掉，大量的利润空间被电商时代产业链条上不必要的附属品消耗吸收。针对这种情况，传统巨头当然不会坐视不管（虽然仍然反应缓慢步履蹒跚）。董明珠早早就跟进直播带货，巨头们无视自己曾经搭建的经销体系，不光放任经销商串货，更是自己下场在网店和直播中给出底价。到这一步，传统实体经销的生意基本就到头了。本质上，是电商，尤其直播电商的触达率已经让厂家在最大程度上不再依赖复杂沉重的实体销售体系。对于各种巨头企业来说，降本增效当然是好事。但这同时也意味着大量的“中间层”会因此丢失就业机会，即社会结构的扁平化会消灭掉“中间岗位”和所谓的“蓄水池”。中国是当前世界社会结构扁平化速度最快的大国，各种社会中间件与管道设施的大规模演化与淘汰快到大众舆论经常来不及多关注一眼。这个过程中往往没有多少G点，没有很多可供操弄情绪的叙事，不光大众，这种替代甚至从业者自身也往往觉得理所当然。对于社会治理，各种社会中间件和管道设施的转换越快，整体的就业环境也就愈发的动荡，各类就业的蓄水池有效期缩短的进程也就越快。传统行业因为技术进步迅速萎缩，但新兴行业则需要时间来成熟并形成稳定的就业机会。相互磨合过程中会产生技能的错配问题，即现有劳动力的技能与市场需求之间存在差距，进一步加剧了就业市场的波动性和不确定性。曾经，农村是中国缓解就业危机的总蓄水池，后来农村基层逐渐凋敝，工厂、工地和城市基础服务业乃至于外卖出租又成了新的城市底层蓄水池。社会结构中各个阶层也有各自的蓄水池，各行各业庞大的销售类岗位和文员岗位是所有基础文凭以上人员的蓄水池，游戏公司，灰产行业与曾经的P2P是互联网高收入阶层的蓄水池。中小餐饮业是个体户的蓄水池，快递外卖和网约车则成了中底层城市居民共用的蓄水池。2023年之后大模型进步的飞快，在我自己心目中最容易被大模型积压就业岗位的专业榜单里，第一是法学，第二就是计算机，各行各业的销售类岗位和文员岗位被大模型替代也是大势所趋。我们所说的蓄水池虽然不稳定、上限不高，基本没有人想在里面长期停留，但确实中短期内可以大量的吸纳就业人口。因为市场经济的非计划性和周期性，经济指标的发展经常与稳定就业规模不充分匹配，蓄水池的存在对缓解就业危机，维持社会稳定有关键性作用。然而社会结构越扁平，信息均等化程度越高，市场经济中的蓄水池就越容易快速失去作用。在AI替代的浪潮下，我们必须要去了解、分析和努力去解决蓄水池无效化的问题。当然，我们的思维也可以简单一点——ai高速发展，就业供给不足最后的结果很有可能会导向一场局部热战。只要通胀可控，热战胜利，眼下的问题都是可解的三、悲观一点的推导从最简单的数学，和根本上来说，全人类的高薪高附加值的产业和就业岗位是很有限的，这个破烂世界当前就只能容纳得下这么大的发达社会结构。我们现在处于跨国公司主导的全球化时代，与传统的帝国主义时代有诸多不同。跨国公司作为全球生产链的核心，利用其在全球范围内的资源配置能力和技术创新优势，主导了全球总剩余产品的分割方式，在具体的操作中，跨国公司在研发设计、品牌管理、市场销售等高附加值环节占据主导地位，而将生产制造等低附加值环节外包给发展中国家的企业。而全球价值链各部门的不均匀分布实际上又代表着一种交换关系，发达国家国民能在国际贸易当中，以很少的劳动力和平均劳动时间换取发展中国家国民以大量劳动力和高平均劳动时间堆积出的巨大劳动。这实际上是垄断或寡头垄断阻碍了部门间利润率的平均化，将生产价格进一步扭曲为垄断价格。全球总剩余产品的分割也就不由价值——劳动时间决定，甚至不按各个资本的资本量分配平均利润，而是以跨国公司为媒介，发达国家获得大部分增加值，发展中国家获得小部分增加值，再依各国劳资关系分配增加值。国际贸易中的不平等只是世界经济体系中不平等的一部分，反映在各国国际收支经常项上，而国际收支资本项所代表的跨国资本（及其所得利润）流动带来了更大的问题。发展中国家的企业，往往是因发达国家资本输出而建立起来的，这就使得其很大一部分利润要归属于发达国家的食利者。从这个角度，发达经济体的高福利和廉价商品实际上是一种针对国民的群体贿赂。发达国家国民通过养老金和社会保障体系获得股票市场和债券市场上的收益，通过国内各种高产业附加值的就业岗位和其衍生的服务业岗位分享着跨国公司的赃物。发达国家在国内分配上越是公平，跨国公司利润率越高，实际上越能说明国际间分配越不公平。在中国加入世贸并快速进行产业升级之前，新自由主义模式下的跨国公司殖民体系是可以运转的很好的，但以中国的体量和执行力，在进入任何边际收益仍较高的领域或者原先被垄断的领域，都能迅速降低整个领域的边际收益。说人话就是，发达经济体躺着拿不到钱了。我们认为市场经济和资本主义模式的优势之一就在于其自发的会产生一套激励模式，但这并非是鸟语花香的和平竞争，而是一旦失败就万劫不复的生死竞速。尤其是在当前世界增量严重不足，而存量的争夺也愈发急切的情况下，和平共存的空间越来越少，你死我活的竞争越来越多。我们假设央行和宏观政府不进行大放水，对于就业方面改善没有特别大的动作，在大模型轰轰烈烈发展的大背景下，最终的结局大概率是会导向一场东南方向的局部热战的。what can i say？天佑吾国。下一篇可能会写一点关于财政改革与坏账处理的内容参见[1] 调研纪要：Robotaxi的深夜思考[2] 新潮沉思录：现在哪轮得到担心萝卜快跑？[3]刘龙.基于电商平台的供应商竞争和分销模式研究[D].合肥工业大学,2019.[4]李海,崔南方,徐贤浩.存在制造商竞争下的双渠道供应链模型研究[J].系统工程学报,2017,32(04):535-546.DOI:10.13383/j.cnki.jse.2017.04.010.[5]范冬雪,曾能民,张朝辉.考虑零售商公平偏好的代销直供供应链决策研究[J].软科学,2020,34(05):88-93.DOI:10.13956/j.ss.1001-8409.2020.05.14.[6]王剑.零售企业的全渠道演变及供应链优化研究[J].商业经济研究,2018,(04):93-95.[7]凌永辉,刘志彪.全球价值链发展悖论：研究进展、述评与化解[J].经济体制改革,2021,(03):100-107.[8]樊茂清,黄薇.基于全球价值链分解的中国贸易产业结构演进研究[J].世界经济,2014,37(02):50-70.DOI:10.19985/j.cnki.cassjwe.2014.02.004.[9]刘洪钟.经济全球化、金融危机与东亚转型: 基于制度与结构的视角.亚洲问题研究论丛"
  },
  {
    "title": "Weekly通讯-第五期：耐心资本、鸿蒙Next、科大讯飞、信息成瘾与柔不监国",
    "summary": "一、耐心资本与长期主义不谋全局者，不足谋一域；不谋万世者，不足谋一时。20世纪30年代，本杰明·格雷厄姆在其《证券分析》中奠定了价值投资的基础，即投资者应当基于企业内在价值而非市场情绪做出投资决策。20世纪60-90年代，沃伦·巴菲特和查理·芒格将格雷厄姆的价值投资原则进一步发扬光大，通过伯克希尔·哈撒韦公司开展长期主义投资。1978年，美国劳工部在《雇员退休收入安全法案》中正式明确，允许养老金和",
    "tags": [
      "Weekly通讯"
    ],
    "url": "/posts/ScheduledReport/Weekly通讯-第五期：耐心资本、鸿蒙Next、科大讯飞、信息成瘾与柔不监国/",
    "date": "2024-07-06T00:00:00.000Z",
    "content": "一、耐心资本与长期主义不谋全局者，不足谋一域；不谋万世者，不足谋一时。20世纪30年代，本杰明·格雷厄姆在其《证券分析》中奠定了价值投资的基础，即投资者应当基于企业内在价值而非市场情绪做出投资决策。20世纪60-90年代，沃伦·巴菲特和查理·芒格将格雷厄姆的价值投资原则进一步发扬光大，通过伯克希尔·哈撒韦公司开展长期主义投资。1978年，美国劳工部在《雇员退休收入安全法案》中正式明确，允许养老金和企业年金投资私募股权基金。此后，**机构投资者成为了美国私募股权基金的主要资金来源。机构资金推动风险投资基金募资额高速增长，从1978年的4.27亿美元提升至1980年的12.45亿美元。其中养老金贡献巨大，其占比从1978年的15%提升至1980年的30%，个人资金占比从1978年的32%降至1980年的16%。自此，美国风投市场的私募股权获得了更为稳定且规模庞大的资金池。中国目前股权投资市场的现状是，长期股权资金供给偏少，股权投资基金持有期偏短。2022年，**人民币股权投资基金出资中，只有8.32%来源于养老金、社保基金、保险资金等长期资金。**如果把国内政府引导基金列入长期资本，也仅为10%-20%之间。同比，美国的长期资本占比在70%-80%之间。并且中国股权投资基金的持有期大致在3.3年，低于国际上5年左右的平均水平。这种LP结构性的差异对VC/PE行业的发展产生了非常重大的影响。在任何一个市场中，投资和回报永远成正比，一个完善的市场中需要有人愿意承担低风险，获得低回报，也需要有人愿意承担高风险，博取高回报；需要有人短线投资进行套利，也同样需要“耐心投资者”去进行长期的，跨周期的资产配置。后者很难直接通过个人投资者来实现，毕竟中国改革开放尚且只有四十多年，资本市场仍然很年轻。自ChatGPT大模型时代到来之后，我们抛开那些成天赛博亡国的鬼扯言论不谈，中国本土的企业擅长从1到100，但确实缺乏从0到1的原始创新能力。 由于缺少耐心资本支持，中国企业在创新过程中时时刻刻担忧生存问题，如果初创企业的CEO从拿到融资款的第二天开始就要操心什么时候AB轮，什么时候Pre-IPO，什么时候冲刺IPO，那整个企业的风气实际上也是难以做到沉下去搞研发的，理想主义的光辉必然要向现实的沉重让路。微软和谷歌之于OpenAI的例子实际上已经很清楚了，很多时候巨头由于自身组织架构和决策链路的臃肿，在许多尖端层面的可研突破是不如更灵活的小公司的，而小公司想要活下去多半需要各类VCPE来注资——真正的尖端科技的创新创业孵化器，应当由政府和巨头联手打造（参见DARPA-美国国防高级研究计划局）当然实际上现在中美两家的传统风投都不太好做，中美头部风投都开始转型二级市场，裁撤一级团队。“国进民退”是结果而不是原因，国家尚且还愿意去拉动罢了。2023 年，美国风险投资公司的融资额创下六年来的新低，投资额下跌 30% 至 1700 亿美元，即便在对人工智能初创企业进行大量投资的情况下也是如此。PitchBook 的数据显示，2023 年，美国活跃风险投资者的数量下降了 38%。二、鸿蒙Next上的Agent在HDC 鸿蒙Next的大模型演示中，小艺可以通过“模拟触控”的方式完成用户指令的遵循。比如用户要求“给xx发短信，内容为xx”，小艺会打开电话，点击搜索栏，然后搜索xx……有的人可能会说，国内米OV也能做到啊，小艺这次展现出来的只不过是更像人操作了，有什么新鲜的地方吗？在测试中，云飞测试了好几次，每一次的操作路径都不一样，这代表背后是华为在用一套完整的大模型Moblie Agent系统来执行用户的指令。Untitled这对我来说才是真正革命性的地方。原来所有的Moblie Agent操作手机的框架都还停留在实验室开源社区自娱自乐的阶段，有新进展顶多发个视频大家乐呵惊叹一下——但这次，华为是要率先在C端大规模商用了。我们都知道大模型强在泛化和迁移上，既然华为盘古大模型可以实现自主搜索打电话发邮件，那代表距离跨多个第三方应用执行较为复杂的任务也必定不远，至少不存在太大的技术瓶颈。真正的自感知自操作agent智能体，是否也很快就要到来了呢？AI要成为能每个人身边的生产娱乐工具，人的可用之器，必须达成物理世界（输入）->数字世界（输入）->数字世界（输出）->物理世界（输出）的闭环，而各家的手机助手，未必不能是这最后一块补天石。三、科大讯飞掉队了吗科大讯飞在上个月发布了星火大模型V4.0，在纸面上宣称“全面对标GPT-4 Turbo”，发布会后讯飞股票直接大跌，不管是资本市场还是技术层，大家都不太认可讯飞在大模型面的作为。Untitled发布会后从近期的最高点一直跌到现在这不正常。科大讯飞是曾经的ai四小龙，也是国内自ChatGPT发布后最开始搞大模型的那一批，国内第一梯队（阿里的通义千问 百度的文心 月之暗面等）在2023年末或多或少都能在部分能力上追平甚至超越gpt4，讯飞这次相当于落后国内一线模型近半年。讯飞的模型更新速度和质量，都是不正常的。哪怕因为讯飞不是大厂，没有阿里那种超高质量数据，模型的更新速度也比不上国内的ai独角兽和大厂（除了百度的文心）。我猜测，可能是因为讯飞现在是全面昇腾集群，所有的训练和推理任务都放到飞星一号昇腾集群中进行，导致训练进度远不及预期。昇腾910b单卡基本上可以达到80%的A100，但多卡集群就效率差问题多，生态亟待完善。其他大厂虽然也都有万卡昇腾集群，但一般不会将自家主流大模型放到昇腾集群训练，仅作为推理用途；讯飞的失利是否就代表华为昇腾的失利呢？不是这样的。昇腾在2024年处于一个大爆发的状态，美国的制裁使得各大厂商几乎不可能大批量的去采购先进N卡进行下一代模型的训练，国内同类竞品海光、摩尔线程都支棱不起来——大模型厂商必须要捏着鼻子去买华为昇腾，不仅要买，还要跟华为乃至全国的其他大模型工程师一起为昇腾写算子搞适配。这也是一种举国体制。我们都知道实际上全世界正儿八经有做大模型的资本和产业基础的只有中美两家，其他玩家根本上不了台面（法、日、英、韩），当中国的所有大模型厂商都去给华为昇腾贡献生态的时候，华为想输都难，起码一定不会落后英伟达太多。四、信息成瘾信息革命之后，人类可以像生产糖一样大量的生产信息，不仅生产成本，传播成本更低，可以接近零成本地到达消费者。生产商发现，那些最刺激多巴胺的信息，有最多的阅读量，可以赚到更多的钱。于是，垃圾信息就被大量生产，变得无处不在。网页和手机app经常采用无限滚动、推送通知、自动播放视频并自动跳转连播等设计，这些设计可以有效地吸引大多数用户的注意力，下拉滚动以斯金纳箱的经典方式带来虚假的掌控感。现有的数字平台，尤其是社交媒体，会加剧人们的错失恐惧——人们或多或少地相信其他人有可能在平台上分享有用的经验、错过这些可能给自己造成实质上的损失，这导致人们花大量时间反复检查别人有没有更新、更新了些什么。世界范围内，人们经常在社交媒体上夸大自己的外表与生活水平。这有概率让观看者与不切实际的对象进行比较，加剧观看者的自卑、不满、孤独、焦虑。五、柔不监国其实我一直都觉得，在人类社会的管理岗，尤其是政府公共部门的、可以做出重大决策的管理岗位，要做的事都很残酷。权利无非 生 杀 予 夺这四个字。我们假设你必须要做出一个决策，你手下某部门几千人必须失业，否则集团现金流会在几个月内支撑不住，走破产程序，怎么办？几千人的失业，可能代表几千个对应的嗷嗷待哺的家庭失去了他们的主要经济来源——这实际上是在杀人。破产？集团中高层估计还可以凭借着自己的人脉手段去另谋出路，现在就业形势不好，基层员工呢？当然，我们可以说这是壮士断腕，这是迫不得已，这是我作为决策者必须要承担的职能。但你实际上就是间接杀了人。或者，我直白一点。对于民选政体的最佳范例美利坚，疫情爆发初期总统和官僚机构的不作为是不是杀人？上百万人直接死于新冠疫情，遑论未来数量更加庞大的超额死亡人数和病毒对于人体器官的持续侵害。东大也是，虽然国内素有团结一致向前看的传统，放开也是迫不得已，但无论如何放开一定会导致百万人口直接死于冠病，超额死亡数据也可以证实这一点。还有未来医保系统因为冠病带来的额外庞大资金压力……当然，我们也不能忽视在全世界范围内新冠消灭老年人对于减缓人口老龄化，间接缓解养老基金压力的贡献决策者，或者说我们，实际上是在无意识的，以自由、民主等崇高的名义，满怀热泪的，永远年轻的，集体不负责的将百万同胞送进了火葬场。南京大屠杀三十万人就已经是人间阿鼻地狱，中华民族可以铭记几十年乃至上百年，将永远成为人类文明史上的一大污点难道新冠就可以堂而皇之的讲，“我们没有办法，天命如此，我们不可能将公民囚禁在室内，这是他们/我们的自由，谁偷走了我的青春，我只是想出去……”，可以这样讲吗？我觉得这样很无赖。这是全人类的治理体系的失能，是全人类当前政治体制运行下的固有缺陷。所以，慈不掌兵，柔不监国。言论你们都想要发起一场战争，你们却不知道怎么停止一场战争。会发而不会收，那不如一开始就不要发。很多人都觉得，当英雄结束了传奇的冒险生涯，戴上王冠的那一条起，就到了故事结束的时候了。理想主义的冒险传奇，却必须要让位于现实主义的政治，故事当然也就没什么可读的了。所以，我才说你们这些年轻人是真的天真。艾梅塔·帕梅廷夫人受到谁的指示重要吗？背后有谁又重要吗？她的话既然会有那么多人愿意坐下聆听，本身便表明了一种思潮。如果你把心思放在所谓的幕后黑手上，格局就会限定在黑白分明的视野中哦。贝尔蒙特准将，这是游击士和政坛的思路，不应该是你的。说白了，在现代的政治体制中，大众总是希望自己的领导者是一个完美无缺的领袖，但越是完美的领袖，越是英明果决的决策者，身上的人味儿就越少。十几个世纪以来，银河帝国的龙王们，蒂芮罗人的武勋贵族和异种贵族，以及公民、国民和奴隶构成的帝国社会体系，早已经被另外半边宇宙的共和派社会政治学者们扒了个干净。 可是，那又怎么样呢？ 自古以来，辨经是辨不死人的。如果你过于悲观，就意味着你会做出不必要的牺牲，试图减轻实际上不存在的风险。 ——《极端的假设可能导致更极端的结果》参考[1] 赵泠的回答：明明手机很无聊，却还是忍不住刷来刷去，这是为什么？[2] 大模型个性化时代到来！讯飞星火V4.0打造个人专属AI助手[3] 讯飞星火V3.5正式发布，基于全国产算力平台“飞星一号”训练[4] 极客湾的视频：华为HDC大会现场直击：鸿蒙的新篇章"
  },
  {
    "title": "使用ResNet训练一个图片分类模型",
    "summary": "项目文件已上传至Github和我自己的公开仓库。一、背景介绍2024.10.22:本篇博文的展示代码已经落后于GitHub库代码，但我懒得写一篇新的博客来解析对应GitHub库了，实际上主要的实现方式路径都差不多，如果你想训练自己的分类模型而不想究其原理，直接fork库即可事情的起因是这样的：我看到喜欢的图都会直接保存到手机里（猫猫狗狗、各种群友分享的网上搜集的蔚蓝档案图、壁纸等），但是这些图片又",
    "tags": [],
    "url": "/posts/AI and Deep Learning/使用ResNet训练一个图片分类模型/",
    "date": "2024-07-04T00:00:00.000Z",
    "content": "项目文件已上传至Github和我自己的公开仓库。一、背景介绍2024.10.22:本篇博文的展示代码已经落后于GitHub库代码，但我懒得写一篇新的博客来解析对应GitHub库了，实际上主要的实现方式路径都差不多，如果你想训练自己的分类模型而不想究其原理，直接fork库即可事情的起因是这样的：我看到喜欢的图都会直接保存到手机里（猫猫狗狗、各种群友分享的网上搜集的蔚蓝档案图、壁纸等），但是这些图片又会和我繁杂的各种随手截图，拍照留下的笔记等混到一块，每次整理上传到云端都需要我一张一张的分类判别，挺烦人的。——为什么不直接用ai来识别呢？经过一番广泛的调查与试错之后，我选择了ResNet。ResNet，全称Residual Network（残差网络），是由何凯明（Kaiming He）、张祥雨（Xiangyu Zhang）、任少卿（Shaoqing Ren）和孙剑（Jian Sun）在2015年提出的深度学习架构。他们在同一年的ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 中取得了多项任务的第一名，包括图像分类和物体检测。ResNet的主要创新点在于它引入了一种特殊的网络结构——残差块（Residual Block），这使得深度神经网络能够有效训练更多的层而不遭受性能退化的问题。在传统深度网络中，随着网络深度的增加，训练变得越来越困难，可能会遇到梯度消失或梯度爆炸问题，以及所谓的“退化”现象，即更深的网络表现反而不如较浅的网络。中译中：好用皮实效果好。考虑到手上MacBook air的羸弱性能，我预训练的模型用的是ResNet-18，训练数据集一共分了四类：'a.美少女', 'b.截图与杂图', 'c.动物', 'd.漫画’，一共大概六百张图片。训练跑了10个epoch，训练用时差不多10min（没有用Apple自己的mps加速框架），实际效果非常不错，准确率在95%左右。Untitled二、完整代码1.模型训练import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.models import resnet18\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nImage.MAX_IMAGE_PIXELS = None\n\n# 数据预处理\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# 加载数据集\ndataset = ImageFolder(root='xxx/dataset', transform=transform)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# 使用本地的预训练ResNet模型\nmodel = resnet18()\nstate_dict = torch.load('models/resnet18-f37072fd.pth')\nmodel.load_state_dict(state_dict)\n\n# 获取类别数量\nnum_classes = len(dataset.classes)\n\n# 修改最后一层以适应新的分类任务\nnum_ftrs = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_ftrs, num_classes)\n\n# 训练模型\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\nnum_epochs = 10  # 根据需要调整\n\n# 记录每个epoch的loss值\nloss_values = []\n\nfor epoch in range(num_epochs):\n    epoch_loss = 0.0\n    with tqdm(total=len(dataloader), desc=f'Epoch {epoch+1}/{num_epochs}') as pbar:\n        for inputs, labels in dataloader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n            pbar.set_postfix({'loss': epoch_loss / (pbar.n + 1)})\n            pbar.update(1)\n\n    avg_loss = epoch_loss / len(dataloader)\n    loss_values.append(avg_loss)\n    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}')\n\n# 保存模型\ntorch.save(model.state_dict(), 'model.pth')\n\n# 绘制并保存loss值图表\nplt.figure()\nplt.plot(range(1, num_epochs + 1), loss_values, label='Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss over Epochs')\nplt.legend()\nplt.savefig('training_loss.png')\nplt.show()2.执行分类任务import os\nimport shutil\nimport torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom torchvision.models import resnet18\n\n# 定义类别标签\nclasses = ['a.美少女', 'b.截图与杂图', 'c.动物', 'd.漫画']  # 根据你的实际类别名称修改\n\n# 创建对应的类别文件夹\noutput_folder = '分类结果'  # 保存分类结果的主文件夹\nos.makedirs(output_folder, exist_ok=True)\nfor class_name in classes:\n    os.makedirs(os.path.join(output_folder, class_name), exist_ok=True)\n\n# 加载模型\nmodel = resnet18()\nnum_ftrs = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_ftrs, len(classes))\nmodel.load_state_dict(torch.load('model.pth'))\nmodel.eval()\n\n# 图像预处理\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# 批量分类并保存到对应文件夹函数\ndef classify_and_save_images(folder_path, model, transform, classes, output_folder):\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.jpg', '.jpeg', '.png')):  # 支持的图像格式\n            image_path = os.path.join(folder_path, filename)\n            image = Image.open(image_path).convert('RGB')\n            image = transform(image)\n            image = image.unsqueeze(0)  # 添加批次维度\n\n            # 进行预测\n            with torch.no_grad():\n                outputs = model(image)\n                _, predicted = torch.max(outputs, 1)\n\n            # 获取预测类别\n            predicted_class = classes[predicted.item()]\n\n            # 保存图片到对应类别文件夹\n            destination_folder = os.path.join(output_folder, predicted_class)\n            shutil.copy(image_path, destination_folder)\n            print(f'Image: {filename}, Predicted: {predicted_class}, Saved to: {destination_folder}')\n\n# 设置文件夹路径\ntest_folder = 'xxx/需要分类的图片'  # 替换为你的“测试”文件夹路径\n\n# 调用分类并保存函数\nclassify_and_save_images(test_folder, model, transform, classes, output_folder)\n\nprint('Classification and saving complete.')三、代码解析1.训练模型代码解析我使用的是PyTorch框架，结合torchvision库中的功能，来训练一个基于ResNet18的图片分类模型。（1）导入必要的库import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.models import resnet18\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plttorch 和 torchvision：用于深度学习模型的构建和训练。transforms：用于数据预处理。DataLoader, Dataset：用于数据加载和管理。ImageFolder：一种常用的数据集加载方式，可以从文件夹结构读取分类图像数据。PIL.Image：用于图像处理。tqdm：进度条显示。matplotlib.pyplot：用于绘制图表。（2）数据预处理# 数据预处理\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])将所有图像调整为224x224像素。转换为张量。标准化图像数据。（3）加载数据集# 加载数据集\ndataset = ImageFolder(root='xxx/dataset', transform=transform)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)使用 ImageFolder从指定目录加载数据，该目录下应按照类别分文件夹存放图像。数据集被封装为 DataLoader，便于批量训练。（4）加载预训练的ResNet18模型# 使用本地的预训练ResNet模型\nmodel = resnet18()\nstate_dict = torch.load('models/resnet18-f37072fd.pth')\nmodel.load_state_dict(state_dict)加载模型架构。加载预训练权重。（5）修改模型以适应新的分类任务# 获取类别数量\nnum_classes = len(dataset.classes)\n\n# 修改最后一层以适应新的分类任务\nnum_ftrs = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_ftrs, num_classes)确定输出类别数。替换模型的最后一层，以匹配新任务的输出需求。（6）定义训练过程：# 训练模型\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\nnum_epochs = 10  # 根据需要调整\n\n# 记录每个epoch的loss值\nloss_values = []\n\nfor epoch in range(num_epochs):\n    epoch_loss = 0.0\n    with tqdm(total=len(dataloader), desc=f'Epoch {epoch+1}/{num_epochs}') as pbar:\n        for inputs, labels in dataloader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n            pbar.set_postfix({'loss': epoch_loss / (pbar.n + 1)})\n            pbar.update(1)\n\n    avg_loss = epoch_loss / len(dataloader)\n    loss_values.append(avg_loss)\n    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}')选择损失函数：交叉熵损失。选择优化器：随机梯度下降(SGD)，设置学习率为0.001，动量为0.9。设置迭代轮数。进行模型训练，记录每个epoch的平均损失。（7）保存模型# 保存模型\ntorch.save(model.state_dict(), 'model.pth')保存训练后的模型权重至本地。（8）绘制训练损失变化图# 绘制并保存loss值图表\nplt.figure()\nplt.plot(range(1, num_epochs + 1), loss_values, label='Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss over Epochs')\nplt.legend()\nplt.savefig('training_loss.png')\nplt.show()使用 matplotlib绘制训练过程中每个epoch的损失变化曲线。保存和显示图表。2.执行分类任务代码解析（1）定义类别标签和创建分类结果的文件夹# 定义类别标签\nclasses = ['a.美少女', 'b.截图与杂图', 'c.动物', 'd.漫画']  # 根据你的实际类别名称修改\n\n# 创建对应的类别文件夹\noutput_folder = '分类结果'  # 保存分类结果的主文件夹\nos.makedirs(output_folder, exist_ok=True)\nfor class_name in classes:\n    os.makedirs(os.path.join(output_folder, class_name), exist_ok=True)classes列表包含了所有可能的类别名称。这些名称需要与你的数据集类别相对应。在指定的 output_folder目录下创建与 classes列表中相同名称的子文件夹，用于保存分类后的图片。（2）加载模型# 加载模型\nmodel = resnet18()\nnum_ftrs = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_ftrs, len(classes))\nmodel.load_state_dict(torch.load('model.pth'))\nmodel.eval()加载ResNet18模型架构。修改模型的最后一层全连接层，使其输出节点数等于类别数。从之前训练好的 model.pth文件加载模型权重。设置模型为评估模式（model.eval()），这是在进行预测时必要的步骤。（3）定义图像预处理：# 图像预处理\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])使用 torchvision.transforms定义了一系列的图像预处理操作，包括缩放、转换为张量以及标准化。（4）批量分类并保存图片到对应文件夹的函数：# 批量分类并保存到对应文件夹函数\ndef classify_and_save_images(folder_path, model, transform, classes, output_folder):\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.jpg', '.jpeg', '.png')):  # 支持的图像格式\n            image_path = os.path.join(folder_path, filename)\n            image = Image.open(image_path).convert('RGB')\n            image = transform(image)\n            image = image.unsqueeze(0)  # 添加批次维度\n\n            # 进行预测\n            with torch.no_grad():\n                outputs = model(image)\n                _, predicted = torch.max(outputs, 1)\n\n            # 获取预测类别\n            predicted_class = classes[predicted.item()]\n\n            # 保存图片到对应类别文件夹\n            destination_folder = os.path.join(output_folder, predicted_class)\n            shutil.copy(image_path, destination_folder)\n            print(f'Image: {filename}, Predicted: {predicted_class}, Saved to: {destination_folder}')\n函数 classify_and_save_images接收文件夹路径、模型、预处理方法、类别列表和输出文件夹路径作为参数。遍历指定文件夹下的所有图片文件，只处理常见的图像格式（如.jpg、.jpeg、.png）。对每张图片进行预处理，并添加批次维度，准备送入模型。使用模型进行预测，获取预测的类别。将图片复制到对应的类别文件夹中，并打印出分类结果和保存位置。（5 ）执行分类与保存操作：# 设置文件夹路径\ntest_folder = 'xxx/需要分类的图片'  # 替换为你的“测试”文件夹路径\n\n# 调用分类并保存函数\nclassify_and_save_images(test_folder, model, transform, classes, output_folder)\n\nprint('Classification and saving complete.')指定需要分类的图片所在的文件夹路径。调用 classify_and_save_images函数，开始分类并保存图片。四、总结在大模型时代，传统的机器学习当然还有其重要的使用价值，毕竟不可能所有的任务都要上昂贵的大模型，很多简单、廉价的任务传统的机器学习模型完全可以胜任我希望着手开始构建一个蔚蓝档案角色的数据集，训练出一个专门用于ba角色分类的ResNet模型。能否实现抓取、分类、筛选、放大全自动化流程，实现美图自由？不知道模型是否有“审美”的概念，可以自动剔除掉低质量（指绘画质量）的插画。理论上讲我觉得是没问题的，等未来视觉大模型进一步降价还可以考虑使用视觉大模型来筛选。"
  },
  {
    "title": "2024年度下半年个人OKR",
    "summary": "OKR1：考研—法学Objective目标在五个月内完成非法本法学研究生考试的准备，并进行至少三轮复习Key Results关键结果学科知识掌握：完成刑法、宪法、民法、法理学和法制史五大核心课程的系统学习，每门课程至少完成三轮复习，并通过模拟测试验证，确保平均得分达到80%以上。考研英语提升：完成考研英语词汇量积累至8000词，通过历年真题练习，使得阅读理解正确率达到75%，作文模板熟练掌握并能灵",
    "tags": [],
    "url": "/posts/Essays/2024年度下半年个人OKR/",
    "date": "2024-06-25T00:00:00.000Z",
    "content": "OKR1：考研—法学Objective目标在五个月内完成非法本法学研究生考试的准备，并进行至少三轮复习Key Results关键结果学科知识掌握：完成刑法、宪法、民法、法理学和法制史五大核心课程的系统学习，每门课程至少完成三轮复习，并通过模拟测试验证，确保平均得分达到80%以上。考研英语提升：完成考研英语词汇量积累至8000词，通过历年真题练习，使得阅读理解正确率达到75%，作文模板熟练掌握并能灵活运用，至少完成20篇高质量作文练习，每篇作文经过批改后得分不低于18分（满分20分）。考研政治备考：完成考研政治全部科目的学习，包括马克思主义基本原理、毛泽东思想和中国特色社会主义理论体系概论、中国近现代史纲要、思想道德修养与法律基础、形势与政策以及当代世界经济与政治，通过三次模拟考试，平均分达到70分以上。综合能力提升：参加至少两次全真模拟考试，包括所有科目，总分达到目标院校过去三年录取分数线的平均值之上10分。时间管理与复习规划：制定并严格遵守个人学习计划，确保每天至少8小时高效学习时间，每周进行一次学习进度复盘，根据实际情况调整学习策略。OKR2：自我成长—博客专题更新Objective目标在2024年下半年，真对三大专题：机器学习、中国与世界的现代化和情报科学入门分别至少各产出3篇深度文章。Key Results关键结果机器学习专题: 完成并发表3篇深度文章中国与世界的现代化专题: 完成并发表3篇深度文章情报科学入门专题: 完成并发表3篇深度文章行动计划主题研究与资料搜集（1-2周/专题）机器学习专题: 阅读最新研究报告、论文，关注行业动态，如深度学习、神经网络进展。中国与世界的现代化专题: 研究经济、社会、科技发展报告，关注政策变动，收集历史与现状对比资料。情报科学入门专题: 学习基础理论，收集案例研究，了解最新技术应用。文章大纲与初稿撰写（2-3周/文章）制定大纲: 根据专题内容，为每篇文章制定详细的大纲，明确论点、论据、结构。撰写初稿: 结合收集的资料，开始撰写，确保内容有深度、有见解，引用数据准确。内容审核与修订（1-2周/文章）自我审查: 完成初稿后，进行自我审核，确保逻辑严密，语言流畅。OKR3：私募行业Objective目标在2024年下半年，作为私募基金行业的入门者，深入理解私募基金行业，熟悉地方政府招商与国资部门的诉求，精通私募基金募投管退流程，并对企业IPO流程有全面了解。Key Results关键结果完成至少3份深度研究报告，每份报告涵盖一个专题：私募基金行业洞察、地方政府招商策略分析、国资部门投资偏好。参与至少1项实际的私募基金募投管退流程项目（考虑到基金一般是5-7年，仅募和投即可）准备并完成一份企业IPO流程的详细指南，包括关键环节、法规要求和案例分析。建立与至少5位私募基金行业专家、地方政府招商负责人或国资部门代表的联系，并进行深度访谈。OKR4：毕业论文Objective目标为2025年的毕业论文作准备。论文可能会涉及到机器学习、影子银行和私募投资等领域Key Results关键结果文献综述：收集并阅读至少50篇相关领域的高质量学术文献，撰写一篇详尽的文献综述报告。选题与开题报告：在2024年底之前，明确研究课题，完成开题报告，通过导师及评审组的审批。数据收集与预处理：获取至少两组相关数据集，完成数据清洗和预处理工作，确保数据质量。模型开发与实验：基于机器学习算法，开发至少两种模型来解决选定的研究问题，进行实验并比较性能。论文撰写：在2025年初完成论文初稿，经过至少三轮修订，确保内容完整、逻辑严谨、论述清晰。论文答辩准备：制作答辩PPT，准备答辩材料，进行至少两次模拟答辩，确保答辩流畅、回答问题准确。行动计划2024年（基础准备阶段）:Q1-Q2: 深入学习机器学习基础理论与常用算法（如监督学习、无监督学习、强化学习等），同时，对影子银行和私募投资的基本概念、运作机制进行系统学习。Q3: 开始初步的文献调研，重点关注机器学习在金融领域的应用案例，特别是涉及影子银行和私募投资的研究。Q4: 完成初步的文献综述报告，同时尝试提出几个潜在的研究问题和方向。2024年（深化研究与开题阶段）:Q1: 确定研究课题，细化研究问题，与导师讨论并获得初步认可。Q2: 完善开题报告，包括研究背景、目的、方法、预期成果等，提交并准备开题答辩。Q3: 开题报告通过后，开始正式的数据搜集工作，利用公开数据库、政府报告、行业报告等多渠道获取数据。Q4: 完成数据预处理，开始构建模型框架，进行初步的模型训练与评估。2025年（论文撰写与答辩准备阶段）:Q1: 根据研究结果撰写论文初稿，包括摘要、引言、文献综述、方法论、结果分析、结论与建议等部分。Q2: 进行论文的多次修订，邀请导师和同行进行审阅，根据反馈进行修改。Q3: 完成最终论文定稿，提交论文并通过格式审查。Q4: 准备论文答辩，包括制作答辩PPT，进行模拟答辩，确保对论文内容和可能的提问了然于胸。"
  },
  {
    "title": "Weekly通讯-第四期：偏见、投资人的傲慢与不要人格化组织",
    "summary": "一、大模型的偏见—人类互联网的偏见大模型的所谓“观点”和“意识”是如何形成的？大模型的基础是Transformer架构的神经网络，本质上是在庞大的数据集上进行训练，学习语言的统计规律和模式，实际上是“人类社会的共识与偏见在数字空间的映射”。当被提问或给予某个任务时，它会基于训练过程中学到的知识和模式，通过算法生成最有可能符合语言规则和上下文逻辑的响应。这种响应看似表达了某种“观点”，实则是模型根据",
    "tags": [
      "Weekly通讯"
    ],
    "url": "/posts/ScheduledReport/Weekly通讯-第四期：偏见、投资人的傲慢与不要人格化组织/",
    "date": "2024-06-18T00:00:00.000Z",
    "content": "一、大模型的偏见—人类互联网的偏见大模型的所谓“观点”和“意识”是如何形成的？大模型的基础是Transformer架构的神经网络，本质上是在庞大的数据集上进行训练，学习语言的统计规律和模式，实际上是“人类社会的共识与偏见在数字空间的映射”。当被提问或给予某个任务时，它会基于训练过程中学到的知识和模式，通过算法生成最有可能符合语言规则和上下文逻辑的响应。这种响应看似表达了某种“观点”，实则是模型根据输入信息重组已学习到的语言片段，以高度相关性和连贯性的方式输出结果。它所做的是对输入数据统计概率的反馈，而非什么狗屁自媒体营销号所说的自我意识、情感与世界模型巴拉巴拉。既然大模型是“人类社会的共识与偏见在数字空间的映射”，那么大模型输出的内容很大程度上就是人类的意识形态、人类这个族群的观点，只不过我们用后天对齐的手段将那些不符合监管要求和主流价值观的“输出”给抹去了而已。认识到这一点后，提高数据集的包容性成为了改进大模型输出质量的首要步骤。这意味着在构建训练数据集时，需要有意识地纳入多元化的视角、文化和背景信息，确保各种声音都能得到充分代表。这不仅仅是为了政治正确，更是为了提升模型的理解广度和适应能力，使其能够更加公平、准确地服务于全球用户。 ——By 通义千问但是，如果你的数据集已经尽可能具有包容性——比如说，囊括了几乎所有书面语言，几千亿个词汇——而这个世界本身就有偏见，你该怎么做？大多数的、被纳入数据集的互联网内容，实际上很大程度上都是白人创造的，即使我们都把他们想象成白莲花，但无形的、天然地偏见是无法从数据集中消除的（例如黑人、女性等内容占比一定会更小）。我不知道，只能凑合着用吧，反正对我来讲好像所谓的平等与风险也不是那么的急迫，让通义千问更好的念经才是我最大的需求 : D“即我们也许能够以这样的语言模型为基础构建我们的系统，这些模型不仅捕捉到了现实世界，也是更美好世界的模型，一个我们想要的世界的模型。”对齐的目的不仅仅是遵循我们现在的价值观，还应当导向那个“我们想要的”世界。“不难想象，用这个方法不仅可以回顾过去，还能展望未来：比如说，根据过去6个月的数据，某种偏见是变好还是变糟了？甚至可以想象用某种实时仪表板来展示社会本身——或者至少是公共话语——的偏见是在增加还是减少，作为正在发生的转变的风向标，以及对未来世界的一瞥。”我很期待大模型加持下的社会舆论分析工具，或许可以给我们提供一个新的研究视角二、投资人的傲慢我之前的思维方式偏向于寻找“漏洞”和坐忘道，会去下意识的论证项目的可行性与盈利性。在面对被投标的时，我不太相信他们对于“未来”的设想，而是更倾向于“现实”的考量。如果我是风控官，或者是所谓的以色列的“第十人”类似的角色，那么这样想当然是合理的；但假如我是一位VC投资人，这样无疑是一种傲慢——我自以为看透了别人在干什么，看透了他们的商业模式与逻辑，不再相信未来与增量。这种思维很现实，但同时也会限制我未来的发展上限，还是要对被投标的存有敬畏之心。厌恶风险就会没有办法进步，投资的本质就是与不确定性，与未来共舞。投资人应当与被投标的建立基于相互尊重和开放沟通的关系，理解创业者的愿景并相信他们的执行能力，同时提供自己的行业洞察和资源支持，这样的合作关系往往能激发出超越预期的价值。风控官是“批判者”，而投资人是“建设者”，应当将寻找“漏洞”的能力转变为帮助创业者加固其商业模型的砖石，在指出潜在问题的同时提出建设性意见，帮助项目更好地适应市场、规避风险，共同探索成长的可能路径。三、不要人格化一个群体/组织“骂政府总有人叫好，政府监管与金融创新百年来一直在博弈，反复螺旋上升构建了现代金融史。站一边骂一边把一切矛盾看成阶级斗争固然卖座，可也在脱离现实，浮皮潦草的思考，如作者的论点。任何一个实体、公司、部门甚至个体都有做大做强的潜能与愿望，组织越大利益越难以协调，部门之间个人与个人会有利益冲突是常理，难道这是各国政府尊崇凯恩斯学派的原因？政府官员是既得利益者所以凯恩斯学派大行其道？思维漏洞百出，简单归因忽略现实博弈制衡关系。答者上来就假定政府目标不可协调，直接得出个人利益大于政府大目标的结论。按作者逻辑，难道所有政府职员都是凯恩斯学派？立法与部门之间毫无分权与制衡，大家制定政策以渔私利？1930年代经济大萧条时期自由市场学派大行其道，崩溃后不得已才转向监管，一战后和会政治秩序重建凯恩斯便写书预言秩序即将崩溃，二战后终于遵从凯恩斯的构想重建秩序，换来了近80年和平发展，08年危机金融衍生品的自由创新导致了世界级的经济危机。这些事实资料唾手可得。凯恩斯主义当然不完美充满缺陷，张嘴就喷当然简单，然后呢？出题者问凯恩斯学派实证有缺陷，为什么政府政策偏保守，愿意偏向凯恩斯学派，与其摆事实列数据逻辑推演与解答，答者上来就站队，假定凯恩斯主义完全失败了，政府一帮猪只吃饭不干活，好像他比老百姓知道更多政府内幕秘密一样，那他连自由学派站队都配不上，只是个没常识经济学学歪了的喷子，给的答案本来就不新颖，论证又东拼西凑偷换概念，答者只是换了一个角度人格化政府”切忌习惯性的把复杂问题简单化，将群体组织一体化、拟人化固然符合直觉和易于接受，但这样会忽视大量的且极为重要的细节。每个群体或组织都是由众多具有不同思想、背景、需求及动机的个体组成的庞大系统，更科学的思路应当是研究个体行为如何汇聚成集体行动，不同利益诉求如何交织影响决策过程，以及外部环境变化如何被系统内部感知并作出响应。言论“投资具备不确定性，所以反而基本面分析和逻辑分析更有用，建模分析只是工具之一，而且是比较垃圾的工具。”“无人问津也好 技不如人也罢 你都要试着安静下来 去做自己该做的事 而不是让内心的烦躁 焦虑 毁掉你本就不多的热情和定力。”“知乎中，提问对议事的导向性远强于回答。以小见大可以看到舆论与政治中，设置议题、编辑议题的重要性。”“提炼输出观点第一位的好处是磨砺自己，而不是说服对面。年轻时候我觉得要说服对面，大了一点我只想气死对面，现在我认为保持一个稳定的思维方式是对自己负责。其二是公共平台发言，第三方看了自然有个高下定论。其三，不少时候摆事实讲道理真能说服对面，有时候对面达成共识，有时候碍于面子不想承认，有时候自己删了评论私信道歉，我都遇见过。能坚持走正道，如果就是年轻人了，一如既往，这种朝气和理想主义我不觉得有什么不好的。”"
  },
  {
    "title": "博客下半年更新计划",
    "summary": "计划下半年主要围绕两个专题进行写作：专题：金融与机器学习主要探讨lstm、transformer等机器学习框架如何同金融相结合，更多会分享一些我在金融量化领域的感悟可能的选题：[ ] 从零开始的深度学习[ ] Transformer与金融量化[X] 想法：训练一个图片分类模型，将我搜集的壁纸和日常截图分类整理后上传到云盘中。如果是那种清晰度比较低的图片，可以送过去超分之后再上传（图片分类模型已经训",
    "tags": [],
    "url": "/posts/Essays/博客下半年更新计划/",
    "date": "2024-06-18T00:00:00.000Z",
    "content": "计划下半年主要围绕两个专题进行写作：专题：金融与机器学习主要探讨lstm、transformer等机器学习框架如何同金融相结合，更多会分享一些我在金融量化领域的感悟可能的选题：[ ] 从零开始的深度学习[ ] Transformer与金融量化[X] 想法：训练一个图片分类模型，将我搜集的壁纸和日常截图分类整理后上传到云盘中。如果是那种清晰度比较低的图片，可以送过去超分之后再上传（图片分类模型已经训练完成）Agent与FinTech相关还可能会涉及到大模型领域一些热点的分析专题：中国与世界的现代化主要围绕地方债务、中国特色的现代化、国资LP、后现代文化等议题展开讨论。可能的选题：[X] 世界价值体系[X] 货币的本质与中国的税收体系[ ] 城投与地方债：从分税制改革到房地产经济的逻辑解读[ ] 国资LP：当前一级市场的现状与未来改革展望马克斯韦伯、科层制与官僚制度东亚三国现代化道路分析：汉江奇迹、中国奇迹与日本的现代化附加专题：浅议文化霸权和文化输出计划经济时代的教训：从苏联模式到中国道路—央地关系变革（这个倒是可以放到新专题：从苏联模式到中国道路—社会主义新体制）专题：情报科学入门（未定）主要针对我感兴趣的开源情报和传媒工程（自造词）方面展开探讨。\n但情报科学离不开统计学与传媒学基础的支撑，在探讨这个议题之前相应的学科基础要扎实。"
  },
  {
    "title": "使用LSTM模型对Apple股票进行简单预测",
    "summary": "一、技术基础1.RNNRNN，即循环神经网络（Recurrent Neural Network），是一种专为处理序列数据而设计的神经网络架构。与传统的前馈神经网络不同，RNN具有循环的内部状态，能够在处理序列中的每个元素时保留和更新关于过去信息的记忆。这种机制使得RNN能够捕捉到数据中的时间依赖性和顺序性，非常适合诸如自然语言处理（NLP）、语音识别、音乐生成、时间序列预测等任务。RNN的核心特性",
    "tags": [],
    "url": "/posts/AI and Deep Learning/使用LSTM模型对Apple股票进行简单预测/",
    "date": "2024-06-17T00:00:00.000Z",
    "content": "一、技术基础1.RNNRNN，即循环神经网络（Recurrent Neural Network），是一种专为处理序列数据而设计的神经网络架构。与传统的前馈神经网络不同，RNN具有循环的内部状态，能够在处理序列中的每个元素时保留和更新关于过去信息的记忆。这种机制使得RNN能够捕捉到数据中的时间依赖性和顺序性，非常适合诸如自然语言处理（NLP）、语音识别、音乐生成、时间序列预测等任务。RNN的核心特性在于其循环单元，这个单元会在每个时间步（time step）对输入数据和前一时间步的隐藏状态进行处理，产生新的隐藏状态，然后将这个新状态传递到下一个时间步，形成一个信息流的循环。这个过程可以形象地描述为网络拥有“短期记忆”，能够在一定程度上模拟人类对序列数据处理时的“记忆”功能。我们可以这样理解：想象一下你正在和一个非常聪明但有点健忘的朋友聊天，他能根据你刚刚说的话回应你，但很快就会忘记早些时候的对话内容。循环神经网络（RNN）就像是那个朋友，但它有一个小本子可以记笔记。在RNN中，这个“小本子”就是隐藏状态，它会在每次聊天（或者说，每个时间点）时更新。每当有新的话（新的输入数据）进来，RNN不仅会看这个新信息，还会参考它之前的“笔记”（前一时间步的隐藏状态），然后决定怎么更新它的“笔记”，以及如何回应你（产生输出）。这样，即使聊了很多内容，RNN也能基于整个对话的上下文给出合理的回答，因为它一直在用这个“小本子”记录重要的信息。所以简单来说，RNN是一种特别擅长处理像句子这样有顺序信息的任务的AI模型，它能记住并利用过去的信息来帮助理解现在，就像你在阅读时会根据前面的句子理解当前句子的意思一样。2.LSTM模型LSTM 是一种特殊的循环神经网络 (RNN)，设计用于处理序列数据，如时间序列、自然语言文本等。传统的RNN在处理长序列时容易出现梯度消失或爆炸问题，而LSTM通过引入门控机制（输入门、遗忘门、输出门）来控制信息的流入、保存和流出，允许网络有选择地记住或忘记信息，算是RNN的有效改良。简单理解：LSTM就是RNN Plus，它不仅拥有一个记事本，还有精细的控制按钮来决定哪些事情该牢牢记住，哪些可以适时忘记。在LSTM中，这个“记事本”被称为细胞状态，它能够存储长时间序列中的重要信息。不同于一般的记事本，LSTM给这个记事本配备了三个智能“控制门”：遗忘门：决定哪些旧信息不再重要，可以擦除。就像翻看旧笔记时，有意识地划掉已经不相关的内容。输入门：控制哪些新信息值得加入到记事本中。就像在笔记本上挑选精华部分仔细记录下来。输出门：决定哪些存储的信息现在应该拿出来用，用于生成当前时刻的输出。好比根据当前谈话内容，选择性地分享之前记得的事情。这样，LSTM能够非常聪明地管理信息流，既不会因为记住太多杂乱信息而混乱，也不会轻易忘记关键细节，特别适合处理那些需要长时间依赖关系的任务，比如语言翻译、情感分析或复杂的时序预测。正是因为LSTM模型在时间序列预测中表现良好，而股价数据就是典型的时间序列数据（过去价格变动的信息可能对预测未来股价有帮助），所以我们在此将LSTM模型运用到量化之中。二、完整代码import numpy as np\nimport pandas as pd\nimport yfinance as yf\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\n\n# 设置使用MPS加速\nphysical_devices = tf.config.list_physical_devices('GPU')\nif physical_devices:\n    try:\n        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    except:\n        # 无法设置内存增长，忽略\n        pass\n    tf.config.set_visible_devices(physical_devices[0], 'GPU')\n\n# 定义数据文件路径\ndata_file = 'AAPL_data.csv'\n\n# 下载或读取股票历史数据\nif os.path.exists(data_file):\n    data = pd.read_csv(data_file, index_col='Date', parse_dates=True)\nelse:\n    data = yf.download('AAPL', start='2010-01-01', end='2022-01-01')\n    data.to_csv(data_file)\n\ndata = data[['Close']]\n\n# 数据预处理\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaled_data = scaler.fit_transform(data)\n\n# 创建数据集\ntrain_size = int(len(scaled_data) * 0.8)\ntrain_data = scaled_data[:train_size]\ntest_data = scaled_data[train_size:]\n\ndef create_dataset(data, time_step=1):\n    X, Y = [], []\n    for i in range(len(data) - time_step - 1):\n        X.append(data[i:(i + time_step), 0])\n        Y.append(data[i + time_step, 0])\n    return np.array(X), np.array(Y)\n\ntime_step = 60\nX_train, y_train = create_dataset(train_data, time_step)\nX_test, y_test = create_dataset(test_data, time_step)\n\n# 调整输入数据形状为 [samples, time_steps, features]\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n\n# 构建LSTM模型\nmodel = Sequential()\nmodel.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\nmodel.add(LSTM(50, return_sequences=False))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(25))\nmodel.add(Dense(1))\n\n# 编译模型\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# 训练模型\nmodel.fit(X_train, y_train, batch_size=64, epochs=20)\n\n# 预测\ntrain_predict = model.predict(X_train)\ntest_predict = model.predict(X_test)\n\n# 反归一化\ntrain_predict = scaler.inverse_transform(train_predict)\ntest_predict = scaler.inverse_transform(test_predict)\n\n# 创建空数组以存储预测结果，并调整它们的位置\ntrain_plot = np.empty_like(scaled_data)\ntrain_plot[:, :] = np.nan\ntrain_plot[time_step:len(train_predict) + time_step, :] = train_predict\n\ntest_plot = np.empty_like(scaled_data)\ntest_plot[:, :] = np.nan\ntest_plot[len(train_predict) + (time_step * 2) + 1:len(scaled_data) - 1, :] = test_predict\n\n# 绘制结果\nplt.figure(figsize=(14, 5))\nplt.plot(data.index, scaler.inverse_transform(scaled_data)[:,0], label='Actual Prices')\nplt.plot(data.index, train_plot[:,0], label='Train Predict')\nplt.plot(data.index, test_plot[:,0], label='Test Predict')\nplt.legend()\nplt.show()\n三、代码分析1.导入所需库import numpy as np\nimport pandas as pd\nimport yfinance as yf\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tfnumpy主要用于数学运算pandas则是数据分析的老朋友了，可以用来读取、处理数据集yifinance 是雅虎财经数据的api库，用来获取股票价格、期权、指数等金融数据sklearn.preprocessing.MinMaxScaler: 这是Scikit-Learn库中的一个预处理模块，用于数据的标准化。MinMaxScaler将数据缩放到[0, 1]区间内，有利于神经网络的训练tensorflow.keras.models.Sequential: Keras是TensorFlow的一个高级API，用于快速构建和训练深度学习模型。Sequential模型是Keras中的一种线性堆叠模型，用于创建具有顺序层的神经网络tensorflow.keras.layers.LSTM, Dense, Dropout:LSTM: 长短期记忆层，专门用于处理时间序列数据，是循环神经网络的一种变体，能有效学习长期依赖关系。Dense: 全连接层，用于网络中各神经元的全面连接，常用于网络的最后一层进行最终输出。Dropout: 正则化技术，随机关闭网络中的一些神经元以防止过拟合，提高模型的泛化能力。matplotlib.pyplot (plt): Matplotlib是Python中最常用的绘图库，pyplot是其面向对象接口，用于绘制静态、动态、交互式的图形。在股价预测中，常用于绘制实际股价与预测股价的对比图os: 操作系统接口模块，提供了许多与操作系统交互的功能，如文件和目录操作。在这个项目中，可能用于检查或创建文件路径等2.设置TensorFlow使用GPUphysical_devices = tf.config.list_physical_devices('GPU')\nif physical_devices:\n    try:\n        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    except:\n        pass\n    tf.config.set_visible_devices(physical_devices[0], 'GPU')检查系统是否有可用的GPU，并尝试设置内存增长以提高训练效率3.下载/读取AAPL股票历史数据data_file = 'AAPL_data.csv'\nif os.path.exists(data_file):\n    data = pd.read_csv(data_file, index_col='Date', parse_dates=True)\nelse:\n    data = yf.download('AAPL', start='2010-01-01', end='2022-01-01')\n    data.to_csv(data_file)\ndata = data[['Close']]检查本地是否有数据文件，如果没有则从Yahoo Finance下载AAPL的历史数据，并保存为CSV文件4.数据预处理scaler = MinMaxScaler(feature_range=(0, 1))\nscaled_data = scaler.fit_transform(data)使用MinMaxScaler将数据缩放到0到1之间（归一化处理）在代码中使用 MinMaxScaler进行数据预处理，并将特征范围设定为(0, 1)，这是非常常见的做法，尤其是在准备数据用于机器学习和深度学习模型训练时。以下是这么做的几个主要原因：归一化：通过缩放，将所有特征的值映射到0到1之间，这个过程称为归一化或标准化。这样做可以确保所有的输入特征都在同一尺度上，避免了因某些特征原始数值范围过大或过小而主导模型学习过程的问题。提升模型性能：大多数机器学习算法（包括神经网络）在特征尺度统一时表现更好。归一化可以加快模型收敛速度，因为梯度下降等优化算法在特征尺度相近时更容易找到最优解。减轻权重不均衡问题：在未标准化的数据上训练模型，特别是使用像梯度下降这样的优化算法时，可能会导致权重更新时偏向于大数值特征，而忽视小数值特征。归一化有助于平衡各特征的重要性。简化学习率选择：归一化后，选择合适的 learning rate 变得更加直接，因为特征值都被约束在了一个合理的范围内。数值稳定性：某些算法或激活函数（如sigmoid）在处理极端数值时可能会遇到梯度消失或爆炸的问题，归一化数据可以减少这类问题的发生。scaler.fit_transform(data)首先通过 fit方法计算数据的最大值和最小值，然后通过 transform方法基于这些统计量将原始数据转换到0到1的范围内。这样一来，scaled_data就变成了适合用于训练模型的格式。5.创建训练和测试数据集train_size = int(len(scaled_data) * 0.8)\ntrain_data = scaled_data[:train_size]\ntest_data = scaled_data[train_size:]将数据集按80%和20%的比例分为训练集和测试集然后定义创建数据集的函数：def create_dataset(data, time_step=1):\n    X, Y = [], []\n    for i in range(len(data) - time_step - 1):\n        X.append(data[i:(i + time_step), 0])\n        Y.append(data[i + time_step, 0])\n    return np.array(X), np.array(Y)函数签名：def create_dataset(data, time_step=1):data: 是一个二维数组（通常是从DataFrame转换而来），其中每一行代表一个时间点的观测值，本例中主要关注第一列（索引为0）的数据，即假设我们只用一个特征（如股价）进行预测。time_step=1: 表示用于预测未来值的时间窗口大小，默认为1，意味着考虑前一个时间点的数据来预测下一个时间点的值。可以根据需求调整此参数来考虑更长的历史序列。函数体：X, Y = [], [] 初始化两个空列表，X用于存放输入数据（特征），Y用于存放目标变量（标签），也就是我们要预测的值f or i in range(len(data) - time_step - 1): 遍历原始数据集的索引，但不包括最后一个时间点以及不足以构成一个完整时间窗口的点在每次循环中，从 data中提取一个长度为 time_step的时间窗口数据，将其添加到 X列表中作为训练样本的输入特征。同时，将该时间窗口之后的一个时间点的数据（即 data[i + time_step, 0]）添加到 Y列表中作为对应的标签或目标值。X.append(data[i:(i + time_step), 0])\nY.append(data[i + time_step, 0])\n返回值：return np.array(X), np.array(Y) 最后，将列表 X和 Y转换为NumPy数组并返回。这样得到的 X是形状为 (样本数, 时间窗口大小)的数组，而 Y是形状为 (样本数,)的一维数组，分别对应模型训练所需的输入特征和输出标签。这个函数将数据集转换为适合LSTM模型输入的格式，作用是从连续的时间序列数据中生成一系列的输入-输出对，每个输入是一个固定长度的历史数据窗口，输出是紧随该窗口之后的单个数据点6.生成训练和测试数据集time_step = 60\nX_train, y_train = create_dataset(train_data, time_step)\nX_test, y_test = create_dataset(test_data, time_step)\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)将数据集转换为形状为 [samples, time_steps, features] 的格式。设置时间窗口大小 (time_step=60): 这里设置 time_step参数为60，意味着在构造数据集时，会使用过去60个时间点的数据来预测第61个时间点的值。这对于捕捉数据中的长期依赖关系特别有用，比如在金融市场预测、天气预报等领域。创建训练集 (X_train, y_train): 调用 create_dataset函数，传入训练数据 train_data和时间窗口大小 time_step=60，生成训练集的特征 X_train和目标变量 y_train。X_train包含多个长度为60的时间序列窗口，y_train则包含这些窗口之后对应的单一目标值。创建测试集 (X_test, y_test): 同样地，使用测试数据 test_data和相同的时间窗口大小 time_step=60来生成测试集的特征 X_test和目标变量 y_test。这用于评估模型在未见过的数据上的表现。数据重塑: 由于LSTM等循环神经网络通常要求输入数据具有特定的形状——(样本数量, 时间步长, 特征数量)，这里的特征数量为1（因为我们只关注一个变量）。因此，执行以下重塑操作：X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)这两行代码将原本为二维的 X_train和 X_test（形状分别为 (样本数, 时间窗口大小)）重塑为三维数组，增加了特征维度，使之成为 (样本数, 时间窗口大小, 1)，符合大多数基于时间序列的深度学习模型的输入要求。这样，每个样本就明确地表示了时间序列的一个窗口，且指明了该窗口含有单个特征。7.构建与训练LSTM模型model = Sequential()\nmodel.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\nmodel.add(LSTM(50, return_sequences=False))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(25))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mean_squared_error')使用Sequential搭建LSTM网络，包括两层LSTM层和两层全连接层。model = Sequential()：初始化一个空的Sequential模型。Sequential模型是一个线性堆叠的网络，其中每一层都有唯一一个输入和输出。model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))：向模型中添加第一个LSTM（长短时记忆）层。LSTM是一种特殊的循环神经网络（RNN），特别适合于处理序列数据，能够学习长期依赖关系。50 表示这一层LSTM单元的数量，即输出维度。return_sequences=True 表示这一层的输出会作为下一个RNN层的输入，所以它会返回整个序列的输出。input_shape=(time_step, 1) 指定了模型的输入形状，其中 time_step是输入序列的时间步长，1表示每个时间步的特征数量。例如，在处理单变量时间序列数据时，1可能代表一个单独的数据点。model.add(LSTM(50, return_sequences=False))：添加第二个LSTM层。与第一层不同的是，这里 return_sequences=False，意味着这层LSTM只返回序列的最后一个时间步的输出，而不是整个序列的输出，通常用于将序列信息压缩为一个固定长度的向量，以供后续全连接层使用。model.add(Dropout(0.3))：添加Dropout层，这是一种正则化技术，随机“丢弃”（设置为0）输入神经元的比例为0.3，以防止过拟合。这有助于模型泛化能力的提升。model.add(Dense(25))：添加一个全连接（Dense）层，拥有25个神经元。这层将前面LSTM层的输出作为输入，并进行进一步的学习和特征提取。model.add(Dense(1))：最后添加另一个全连接层，仅有一个神经元。对于回归问题（比如预测一个连续值），这是很常见的配置，输出单一预测值。model.compile(optimizer='adam', loss='mean_squared_error')：编译模型，指定优化器为Adam（一种常用的高效优化算法），损失函数为均方误差（Mean Squared Error, MSE）。MSE常用于回归问题，衡量预测值与真实值之间的差距。使用Sequential搭建LSTM网络，包括两层LSTM层和两层全连接层。开始训练：model.fit(X_train, y_train, batch_size=64, epochs=20)model.fit(X_train, y_train, ...)：这是开始模型训练的命令。fit函数用于通过输入数据 (X_train) 和目标数据 (y_train) 来训练模型。X_train 是训练集中的特征数据，而 y_train 是相应的目标或标签数据。batch_size=64：指定了每次迭代（一个前向传播和反向传播的过程）中使用的样本数。较大的批次大小可以加速训练过程，因为可以利用矩阵运算的高效性，但需要更多的内存。较小的批次则提供了更好的泛化能力，因为模型在每次更新时都会看到更多不同的数据子集。在这个例子中，选择了一个相对适中的批次大小64。epochs=20：表示整个训练数据集将被用来训练模型的完整遍历次数。一个epoch意味着所有训练样本都被模型学习过一次。增加epoch数量可以让模型更深入地学习数据，但也可能导致过拟合。在这里，模型将训练20次遍历数据集。8.预测和反归一化train_predict = model.predict(X_train)\ntest_predict = model.predict(X_test)\ntrain_predict = scaler.inverse_transform(train_predict)\ntest_predict = scaler.inverse_transform(test_predict)模型预测:train_predict = model.predict(X_train): 使用训练数据集 X_train对已经训练好的模型进行预测。这一步是为了评估模型在训练数据上的表现，虽然实际应用中更关注测试数据上的性能，但在调试和模型选择阶段，查看训练数据上的预测结果也很重要。test_predict = model.predict(X_test): 接着，使用测试数据集 X_test进行预测。这是评估模型泛化能力的关键步骤，即看模型在未见过的数据上的表现如何。反归一化:在进行预测之前，如果原始数据进行了归一化处理（如使用MinMaxScaler或StandardScaler等），那么预测结果也需要通过相同的逆操作转换回原始尺度，以便结果具有实际意义。train_predict = scaler.inverse_transform(train_predict): 这行代码对训练集的预测结果进行反归一化。scaler是之前用于对训练数据进行归一化的实例，inverse_transform方法将预测值转换回原始尺度。test_predict = scaler.inverse_transform(test_predict): 同样，对测试集的预测结果也进行反归一化处理，以便我们能够直接理解和比较这些预测值与原始数据集中的实际目标值。9.绘图train_plot = np.empty_like(scaled_data)\ntrain_plot[:, :] = np.nan\ntrain_plot[time_step:len(train_predict) + time_step, :] = train_predict\ntest_plot = np.empty_like(scaled_data)\ntest_plot[:, :] = np.nan\ntest_plot[len(train_predict) + (time_step * 2) + 1:len(scaled_data) - 1, :] = test_predict\nplt.figure(figsize=(14, 5))\nplt.plot(data.index, scaler.inverse_transform(scaled_data)[:,0], label='Actual Prices')\nplt.plot(data.index, train_plot[:,0], label='Train Predict')\nplt.plot(data.index, test_plot[:,0], label='Test Predict')\nplt.legend()\nplt.show()初始化绘图数组:首先创建两个与原始归一化数据形状相同的空数组 train_plot和 test_plot，并用 np.nan填充，这样做的目的是为了之后能在这两个数组中插入预测结果，同时保持时间序列的完整性。np.empty_like(scaled_data)确保新数组与原始数据在形状上一致。填充预测数据到绘图数组:对于 train_plot，从 time_step索引开始，用训练集的预测结果填充（考虑到LSTM模型可能需要一定的时间步作为输入来开始预测，因此从 time_step之后的位置开始填充）。这表示训练集预测是从原始数据序列的某一点开始覆盖的。对于 test_plot，根据训练集预测的结束位置和测试集预测的起始位置计算，从训练预测结束后的某个时间点开始，用测试集的预测结果填充数组。注意，这里的偏移量考虑了 time_step和额外的间距，确保了预测结果在时间轴上的正确对齐。绘制图形:使用 matplotlib库绘制三条曲线：实际价格、训练集预测价格、测试集预测价格。plt.figure(figsize=(14, 5))设置图形大小。plt.plot(data.index, scaler.inverse_transform(scaled_data)[:,0], label='Actual Prices')绘制原始实际价格曲线，先对 scaled_data进行反归一化以得到实际价格，并用索引 data.index作为x轴，展示实际的价格变化。分别绘制训练集和测试集的预测价格曲线，使用 train_plot[:,0]和 test_plot[:,0]作为y值，对应于预测的价格数据。plt.legend()显示图例，区分三条曲线。plt.show()展示图形。三、总结训练结果：Untitled在训练时间内我重拳出击，预测未来我唯唯诺诺毕竟选用的数据也只是简单的收盘价，太简单了股票市场瞬息万变，是一个复杂的混沌模型，妄图简单的使用LSTM模型是不行的"
  },
  {
    "title": "股票指数投资组合VaR（在险价值）的计算",
    "summary": "作为风险评估的核心工具，Value at Risk (VaR) 能有效量化投资组合在未来特定时间内可能遭受的最大损失概率，为投资者提供了决策的“安全边际”。本文假设有一个投资者使用10000美刀来投资道琼斯工业指数、上证、深证和日经225，来计算该投资组合的VaR。一、完整代码import yfinance as yf\nimport pandas as pd\nimport numpy as np\n",
    "tags": [],
    "url": "/posts/Finance and Economics/股票指数投资组合VaR（在险价值）的计算/",
    "date": "2024-06-15T00:00:00.000Z",
    "content": "作为风险评估的核心工具，Value at Risk (VaR) 能有效量化投资组合在未来特定时间内可能遭受的最大损失概率，为投资者提供了决策的“安全边际”。本文假设有一个投资者使用10000美刀来投资道琼斯工业指数、上证、深证和日经225，来计算该投资组合的VaR。一、完整代码import yfinance as yf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n# 定义股票指数和时间段\nindices = {\n    'DJIA': '^DJI',\n    'SSE Composite': '000001.SS',\n    'Shenzhen Component': '399001.SZ',\n    'Nikkei 225': '^N225'\n}\nstart_date = '2020-01-01'\nend_date = '2020-03-01'\n\n# 获取数据\ndata = yf.download(list(indices.values()), start=start_date, end=end_date)['Adj Close']\ndata.columns = indices.keys()\n\n# 手动设置2020年1月1日的汇率\nexchange_rates = {\n    'SSE Composite': 0.143,  # 2020年1月1日1 CNY = 0.143 USD\n    'Shenzhen Component': 0.143,  # 2020年1月1日1 CNY = 0.143 USD\n    'Nikkei 225': 0.0093  # 2020年1月1日1 JPY = 0.0093 USD\n}\n\n# 转换非美元指数为美元\nfor index in exchange_rates.keys():\n    data[index] = data[index] * exchange_rates[index]\n\n# 计算每日收益率\nreturns = data.pct_change().dropna()\n\n# 计算投资组合每日收益率\nweights = np.array([0.4, 0.3, 0.2, 0.1])  # 根据新指数调整权重\nportfolio_returns = returns.dot(weights)\n\n# 计算VaR\nconfidence_level = 0.95\nvar = np.percentile(portfolio_returns, (1 - confidence_level) * 100)\n\nprint(f\"投资组合的VaR为: {var}\")\n\n# 可视化投资组合每日收益率分布\nplt.hist(portfolio_returns, bins=50, alpha=0.75, edgecolor='black')\nplt.title('Portfolio Daily Returns Distribution')\nplt.xlabel('Daily Returns')\nplt.ylabel('Frequency')\nplt.axvline(var, color='r', linestyle='dashed', linewidth=2, label=f'VaR at {confidence_level*100}% confidence level: {var:.4f}')\nplt.legend()\nplt.show()二、代码解析1.导入所需库import yfinance as yf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime•\tyfinance: 用于从Yahoo Finance获取金融数据。 •\tpandas: 数据处理和分析库。 •\tnumpy: 数值计算库。 •\tmatplotlib.pyplot: 绘图库。 •\tdatetime: 处理日期和时间。需要你自行安装相应的python库（记得在终端安装，直接用Python不行的）2.定义股票指数和时间段indices = {\n    'DJIA': '^DJI',\n    'SSE Composite': '000001.SS',\n    'Shenzhen Component': '399001.SZ',\n    'Nikkei 225': '^N225'\n}\nstart_date = '2020-01-01'\nend_date = '2020-03-01'四个股票指数分别是道琼斯、上证、深证和日经，可以根据需要自己修改。我选取的开始时间和结束时间分别为2020-01-01到2020-03-01，这个根据自己情况另行选择3.获取数据data = yf.download(list(indices.values()), start=start_date, end=end_date)['Adj Close']\ndata.columns = indices.keys()•\t使用yfinance库下载指定时间段内的股票指数数据。 •\t提取调整收盘价（Adj Close）数据，并将列名替换为指数名称。4.手动设置汇率exchange_rates = {\n    'SSE Composite': 0.143,  # 2020年1月1日1 CNY = 0.143 USD\n    'Shenzhen Component': 0.143,  # 2020年1月1日1 CNY = 0.143 USD\n    'Nikkei 225': 0.0093  # 2020年1月1日1 JPY = 0.0093 USD\n}•\t定义每个非美元指数的初始汇率，具体需要自己查询（我没找到对应的自动化接口）5.转换非美元指数为美元for index in exchange_rates.keys():\n    data[index] = data[index] * exchange_rates[index]将非美元指数转化为美元，方便统一计算6.计算每日收益率returns = data.pct_change().dropna()计算每日收益率，并删除缺失值。7.计算投资组合每日收益率weights = np.array([0.4, 0.3, 0.2, 0.1])  # 根据新指数调整权重\nportfolio_returns = returns.dot(weights)定义投资组合的权重计算投资组合每日收益率在10000美刀的投资组合中，四个指数分别占比40%、30%、20%和10%，可以按照需要自己调整。8.计算VaRconfidence_level = 0.95\nvar = np.percentile(portfolio_returns, (1 - confidence_level) * 100)\nprint(f\"投资组合的VaR为: {var}\")计算95%置信水平下的VaR值。9.可视化投资组合每日收益率分布plt.hist(portfolio_returns, bins=50, alpha=0.75, edgecolor='black')\nplt.title('Portfolio Daily Returns Distribution')\nplt.xlabel('Daily Returns')\nplt.ylabel('Frequency')\nplt.axvline(var, color='r', linestyle='dashed', linewidth=2, label=f'VaR at {confidence_level*100}% confidence level: {var:.4f}')\nplt.legend()\nplt.show()绘制投资组合每日收益率的分布直方图。 在图上标注VaR值，并显示图例。如果一切正常的话，这段代码的运行结果应该是：image-cauo.png即这份投资组合在限定时间内，VaR应该为-0.0240，在95%的置信水平下，该投资组合在一天内的最大可能损失为240美元（这意味着有95%的概率，该投资组合在一天内的损失不会超过240美元。相应地，也意味着有5%的概率损失会超过240美元）"
  },
  {
    "title": "Weekly通讯-第三期：回旋镖、AI就业、阴谋论与摘录",
    "summary": "一、回旋镖二年今晚考古23年9月前的一个探讨国产化芯片的议题，回旋镖来的实在是有些快。从2023年开始，不论哪一方我们都看过了太多太多的回旋镖，这是否也是网络生态下的一种必然？1.屏蔽掉一切阴阳怪气，不论立场阴阳怪气者有什么伟大而正义的原因所以要阴阳怪气，这不需要我担心，总之生活环境中不断被这些阴阳怪气的东西挤占是不健康的。 环境中的危险不需要通过阴阳怪气者来提供；客观的建设性答案自然也无法从阴阳",
    "tags": [
      "Weekly通讯"
    ],
    "url": "/posts/ScheduledReport/Weekly通讯-第三期：回旋镖、AI就业、阴谋论与摘录/",
    "date": "2024-06-07T00:00:00.000Z",
    "content": "一、回旋镖二年今晚考古23年9月前的一个探讨国产化芯片的议题，回旋镖来的实在是有些快。从2023年开始，不论哪一方我们都看过了太多太多的回旋镖，这是否也是网络生态下的一种必然？1.屏蔽掉一切阴阳怪气，不论立场阴阳怪气者有什么伟大而正义的原因所以要阴阳怪气，这不需要我担心，总之生活环境中不断被这些阴阳怪气的东西挤占是不健康的。 环境中的危险不需要通过阴阳怪气者来提供；客观的建设性答案自然也无法从阴阳怪气者的口中得出。很多人尝试不使用阴阳怪气的手段来解决问题，也就是 “我好好说”，但却总是失败，根本的问题在哪？在于首先这个 “好好说” 本身往往成色不足，只是相对于 “直接开骂” 好一些而已，但实际上仍然是一种强加掩饰的愤怒表达。对方根本不认为自己有罪，或者至少不接受自己不经合法合理的程序而被人私自认定有罪，而我们的的 “好好说” 本质上只是 “你无疑有罪，但我减轻 / 免除惩罚，还不谢恩”。谁会觉得这样的“好好说”是可以被接受的吗？如果我们从第一步就确立了敌我关系，那么对方还可以受积极影响的概率当然要大打折扣。假如我们还想要解决问题，就需要把“审判心”给收起来。人不能判断人，这不是你的权利。 父母、师长、领导、配偶能判断我，要么是经过我自己、要么是经过命运授权的，这不是一个普遍存在的当然权利。影响力能超出自己的职权范围之外，能影响素不相识、没有利害关系的陌生人，这是很重要的门槛。这个力量是源源不绝的，是没有天花板的，绝对值得花巨大的功夫去争取和积淀。世界是什么样，在极大程度上取决于我们自己。 这还不是指要如何如何努力来改变山川河流、社会秩序…… 这类豪言壮语， 而是首先指社会本身像 XX 一样，能够毫无破绽的见人说人话、见鬼说鬼话，瞬息万变的 “此面向敌”。 我们的满含怨恨的瞟它一眼，在看清之前，它就会瞬间把通向绞肉机的传送带给我们装饰的金光闪闪，祥云缭绕。 以最快的速度送我们上路。 这事不公平的地方在于 —— 谁抱怨，世界就会安排一堆人来给谁附和，伺候得ta舒舒服服，赞颂ta光荣正确，敲锣打鼓给ta风光大葬。 我们努力，世界却要安排一群人出来说 “都没用”，嘲笑我们、讽刺我们、咒骂甚至打击我们。 不过若非如此，努力又有什么可贵的呢？在不摘下眼罩的前提下，你可能想问怎么能让屋子亮起来，你说何解？“那我怎么判断是我没摘眼罩，还是摘掉了眼罩而天真的是黑的？”很简单，后者看得见点亮的灯。2.长期主义与习惯性质疑股市几乎就是一个巨大无比的混沌系统；可以影响股价的因素和噪声太多。因此任何人几乎不可能持续地准确预测股市的走向，就别提精确到具体的数字了。 对于长线投资者而言，预测股市的短期走势毫无意义。我只需要知道：10年以后的大盘指数，大概率要比今天高很多。 我是一个珍惜自己羽毛的人。每公布一次自己的预测，就有50%的概率被现实打脸。我丢不起这个人。而相对于整个世界波谲云诡的变动，股市几条点、线和面的变动都会显得无比的可爱与简单。在我这个年龄段不应当轻易的下结论，随便的给某一方、某一集团下注，而是不断提高自己的能力和手中的筹码，争取在未来可以给自己卖一个更好的价钱。同时，对于各种议题论点也应当抱有习惯性的质疑，不管这个议题的立场是符合我还是忤逆我。忤逆我的议题到最后未必有害，符合我立场的议题最后却也有可能带来损失大于收益——而盲从几乎不论什么时候都只会亏损。3.信息过载这件事从高中就开始困扰着我，直到现在我实际上也没有什么很好的办法。Reedly每天要给我推送400-700条信息，按单条信息1000字算、600条推送，那么在这条渠道上我每天需要接受60万字的信息；我每天会看差不多30-60分钟的视频我每天可能会花费1-2小时在各种社交媒体上（且用处不大）我每天几乎一定要花1-2个小时在阅读上庞大的、低质量的信息真的未必有助于我进行高质量的思考判断，过载的信息量只会堵塞真正有价值的信息被传递到我的大脑中。二、AI与就业岗位我们简单的建立这样一个模型：今年是2024年，我们假设现在有一个100万程序员的人口单位（单位内人口素质呈金字塔形，60万低级程序员+30万中级程序员+10万高级程序员），他们对应的GDP为100个单位；假设GDP增量为6%每年。那么到2027年这个人口单位对应的GDP总量就是119.1016单位。我想我们都不怀疑，到2027年这60万程序员可以被ai全部替换，维持该人口单位所需要的119单位的GDP完全可以由30万中级程序员+10万高级程序员来完成（甚至30万中级的都不需要）。6%的GDP增量已经是我们对这个世界相对乐观的预计，而2027年ai浩浩荡荡的替代浪潮却也是大概率降临的达摩克利斯之剑——增量有限，但降本增效却是实打实的，我们该怎么办？这100万人里不被需要的60-90万人该怎么办？我不知道。更可怕的是已经进入就业市场的失业人口尚且无法消化，还有一批批初出象牙塔的大学生们呢？巨量的就业需求该用什么手段方式来填满？有人可能会问，ai不能背锅坐牢啊？简单。我们假设在券商咨询领域，一个小组原来需要10个人：6个实习生+3个中层+一个最终的把关审核签字的，他们加起来可以每周出具1-5份报告分析。那么2027年可以ai自主出具一份研报，简化成2个实习生做审核检验，1个中层2审，一个最终3审，最终责任人就在这两个审核上，没准效率会更快，质量会更高（ai可比某些一本实习生拟人多了）。二者的变化就是把被拼命压榨的实习生换成了ai而已，最终仍然有人担责，还可以裁掉6个人，难道很难吗？难道不可实现吗？大批量的低端、初级入门岗位，没理由二本大学实习生能干，26、27年的ai不能干。在基础的处理环节，二本大学生真的会比ai好吗？三、登月、阴谋论与市场经济在真正的舆论场里，我国整体氛围对自然科学是高度尊重的， 但是这不是天然而成的，是来自于近代史以来的种种屈辱，把自然科学提到了极高的位置。但是这样的思路是存在一个缺陷的，那就是如此的叙事，把自然科学的进步性与西方国家绑定在了一起，如果在西方国家依然有足够大优势的情况下，这样的叙事倒还糊弄得下去，但是在如今都要吹什么决战兵器的当下，还要用这套叙事来规训别人，是会有反噬的。这种叙事的崩溃，可能会动摇国人普遍对于自然科学的信任，这方面的倒下与重建，恐怕是难以逃避的问题。毕竟，自然科学这东西是广泛存在的规律，它从来没有什么白皮肤蓝眼睛，有的幻觉总是要有打破的那一天（我们在23年初ChatGPT刚发布时各种评论区下已经品鉴的够多了，投降主义果然是人类的通病）。至于美国产的登月阴谋论被大量进口也是正常，在美国这些人被美国主流社会开除了出去，所以他们的理论很大程度是反对美国叙事的，自然会很对一些人的胃口，可以说是非常市场经济了。人类的未来当然应该走向星空，只不过这个时间很可能是以百年千年为单位的，在我们有生之年，能看到月球和火星维持南极式的常驻科考站而不中断，已经是很不错了。 只不过在硅谷式的营销之下，无论是移民火星，还是超级人工智能，或是包治百病与长生不老，都是只要投钱就能在三十年内实现的事情。物理规律从不在乎股价高低，有的社会问题也不是技术能解决的。要承认，某些伟大的工程，可能无法在我们有生之年实现。只有这种最为残忍的实事求是，才能破而后立，让阴谋论的空间降到最低。言论摘录今天的一切都能从过去找到原因。知道此地的历史，你才能理解此地的“政治”。政治哪里是这么简单的事情？历史、积怨、深层矛盾、当事者的性格，每一个环节都会影响政治的走向。把政治斗争简单化，简化为男女分家这种比喻，简直是大错特错！你不考虑一百年之后的事情，那就连十年之后的事情也无法保证。如果你不考虑整张棋盘，那就连棋盘的一角也无法占住。用剑夺走性命是杀人，用饥荒和战乱夺走人命就不是杀人？亚当斯将军的手干净，我的手上是血，所以他比我高尚？是呀，要是亚当斯将军肯做戏，还有人要称颂他悲天悯人呢！上校拍了拍温特斯的肩膀，一语双关：“活着本身就是一种恩赐。” “前提是随时能夺走性命。”温特斯的声音在宁静的夜里听起来很通透：“在直面死亡前，人不会将生存视为一种恩赐，只会将生存视为理所应当。这不是傲慢，而是天性使然。”“情报永远都是残缺不全、真真假假、纷繁复杂。老元帅说过——指挥者的职责就是通过有限的、真假不知的信息，做出正确的判断。”正统的经院神学的基础是严密的逻辑学，而且在接受其给定前提的情况下，经院神学在逻辑上能够形成自洽。“一个人是什么样，取决于他的内心被激发出什么样的情感。”因为谁能掌握过去的定义权，谁就能掌握现在的解释权，谁就能对未来施加影响。"
  },
  {
    "title": "我们到底需要什么样的AI？",
    "summary": "一、从信息处理和复杂度开始谈起首先，我们认为从广义信息处理的角度来讲，一个系统想要实现某些功能特性，基础是一定水平的必要复杂度。暴论：香农的信道编码指出，存在一种编码方法使得在给定的信道噪声水平下，信息传输速率不超过信道容量时，可以实现几乎无误的通信。信息熵是衡量信息不确定性的度量，复杂任务的输入信息通常包含高熵（如给我分析拼多多的年报），具有较大的不确定性或变异性。那么对于复杂任务处理而言，此系",
    "tags": [],
    "url": "/posts/AI and Deep Learning/我们到底需要什么样的AI？/",
    "date": "2024-05-29T00:00:00.000Z",
    "content": "一、从信息处理和复杂度开始谈起首先，我们认为从广义信息处理的角度来讲，一个系统想要实现某些功能特性，基础是一定水平的必要复杂度。暴论：香农的信道编码指出，存在一种编码方法使得在给定的信道噪声水平下，信息传输速率不超过信道容量时，可以实现几乎无误的通信。信息熵是衡量信息不确定性的度量，复杂任务的输入信息通常包含高熵（如给我分析拼多多的年报），具有较大的不确定性或变异性。那么对于复杂任务处理而言，此系统相当于一个“智能信道”，其处理能力和准确性受限于其内部的“信道容量”。提高这个“信道容量”（即处理能力）通常意味着增加系统的复杂度，以更有效地编码和解码复杂信息，减少错误和提升效率。要处理一个领域的信息，很可能需要系统已经存储了这领域的知识并能够使用；要对于一个场景能够给出预测，那么需要系统已经记住之前各种场景下的经验。类比之下就是：师傅之前教过这个，所以我会干xx计算的本质就是对事物的求解——我问，我算，我求解。y=F（x），输入问题自变量x，得出答案因变量y。F（x）或许就可以抽象为这个“系统”，将用户输入的信息接收、处理，最终得出答案y。So，what can i say？从这个角度看，古人龟甲占卜，观天象来决定军国大事，和我们现在用计算机求解是不存在根本性的差异的，只是问询的对象从虚幻的神变成了更为精确的超大规模集成电路加持下的数学与代码，中间的处理过程从先辈的冥冥经验变成了更为精确可信的逻辑推理与运算。文明发展的程度不一样，但大家的追求都是一样的——算出一个更接近真实的答案。各种计算的发展史就是在寻找一个更高效、准确的求解方法，我们现在开炉炼丹大模型也得烧个香求收敛不是，这就是历史的传承.jpg1.生成式AI之前在AI浪潮之前，我们人类是如何完成复杂任务的？专 业 分 工大家问道：“为了将瓦良格号完工，工厂究竟需要什么？”马卡洛夫回答道：“苏联、党中央、国家计划委员会、军事工业委员会和九个国防工业部、600个相关专业、8000家配套厂家，总之需要一个伟大的国家才能完成他。”从原始社会末期开始的农业与畜牧业分离，到手工业与农业的独立，再到脱产士兵、官僚与各种细化阶级，整个社会分工构建在层级管理与网络化协作上，层级结构提供清晰的指挥链和责任分配，而网络结构则促进信息流通和灵活合作，多条管线相互独立以保证集中资源和专业知识处理特定任务，最终完成一个复杂的社会工程。我们处理复杂度的方式就是人工处理，每个部分至少确保有人可以充分理解这个局部的复杂度，组合在一起形成了一个可以处理该问题的“系统”。这个时期，不依赖人工处理复杂度的方式是极少的，主要分为两种：机器学习算法与运筹优化算法。（有监督）机器学习算法的主要功能是从数据中自动的学习出其中的相关性，获得在给定模型约束下的最好（或比较好的）的相关性拟合结果。而使用该算法的人并不需要充分理解数据中到底有哪些具体的相关性规律。在训练过程中，算法自我优化调整参数，以最小化预测误差或其他目标函数，从而在新的数据上做出准确的预测或决策（之后的大模型就将这条路子发扬光大了）。但是在cuda等方案还没有提出的时代，算力紧张限制了机器学习算法的发挥，只能做一些小细节上的修修补补，自数据和算力快速增长之后，深度学习等方案才做到了相对不依赖于算法使用者输入太多的先验知识就能求解的程度。运筹优化算法则指在给定约束条件下寻找最优或近似最优解（从简单的线性规划到工业界常用的混合整数线性规划乃至更困难的非线性规划等等问题），与机器学习不同，运筹优化更多关注于确定性或风险可量化的情况，力求在有限资源下最大化效益或最小化成本。机器学习擅长处理不确定性、非结构化数据和模式识别，而运筹优化则在处理结构化决策问题、优化目标和约束条件方面更为高效2.生成式AI之后我不敢也没能力妄下定论（某工程师：现在是个搞科研的都想对大模型导一发.jpg），直接引用大佬的观点吧：在我来看，GenAI时代的大模型并没有涌现能力，它们仍然是在学习原始数据中的规律，只是某些规律在很抽象的层面，让大多数人觉得很难理解。这一轮大模型范式给机器学习领域带来了一个重要的启发：不必非要直接一次性的去学习目标问题，可以将困难的问题分解为小的“片段”去学习，再在使用中完整的生成最终结果。以物理的角度来说就是不必直接学习完整的复杂曲线的形状，而是去学习所有位置的偏微分方程的系数。以stable diffusion来说就是学习每次如何从图像中去除一点噪声，以LLM来说就是学习每次只预测下一个token。事实证明这种方式是有效的，人类解锁了一大类数据/问题的可学习性。毫无疑问，近期的各类大模型是人类操控复杂度能力的重大进步。但目前大模型的能力仍然是有限的，它们生成不了一些具有复杂信息和内部结构的对象。例如SD模型无法生成可用的建筑设计图纸，LLM模型也很难生成合法的复杂网页HTML。作为完全仅靠自回归方式生成整体内容的方案，这个结果已经算不错了。By 孔某人现在来看估计单Model能独立完成遥遥无期，或许Multi—Agent系统是未来的方向之一。我们从始至终对于AI的定义就是——工具，帮助我们解决复杂度的工具系统。这个复杂度可以是工作内容，可以是十万个为什么，可以是虚拟对象，可以是具身智能……Whatever，它是工具，而且我们希望它最终可以成为完全替代人的工具。二、多样性与对齐共识1.何为对齐？既然我们对于AI的定义就是一个尽量趁手的工具，那么就不得不谈“对齐”。密歇根州的北点公司（Northpointe）开发了名为“替代制裁矫正罪犯管理分析”（COMPAS）的风险评估系统，COMPAS能对各种风险给出1到10的评分，包括一般累犯风险、暴力累犯风险和审前不当行为风险。但ProPublica组织在调查后认为该系统在针对不同种群、肤色的人群进行量刑时存在系统性差异（尤其对黑人存在偏见）。不仅是COMPAS，也不仅是更广泛的风险评估算法，还有公平的概念本身。确切地说，我们如何——用统计学和计算的术语——定义法律阐明的原则、权利和理想？这个世界正逐渐以各种方式依赖于机器学习领域给出的数学和计算模型（尤其是2023年之后的大模型时代）：在科技和商业领域，ai在工程中产出大量的代码，辅助各投资员做出决策；司法体系中也越来越广泛地使用“风险评估”软件来确定保释和假释；2023年末华为问界和24年初的特斯拉率先开启无图NOA，L3级自动驾驶已经触手可及；我们的贷款申请、简历和体检结果逐渐不再由人类负责评估。大模型时代，越来越多的人在致力于让世界（在象征意义上和字面意义上）——自动驾驶。那么，随着用于解决复杂度的系统越来越“非人化”，越来越能灵活、实时、自动地做决策，我们越来越发现自己正处于一个尴尬的境地：我们召唤出一种力量，给它一组指令，希望它自主但又完全顺从，然后一旦我们意识到指令不准确或不完整，又手忙脚乱地阻止，以免用我们的智慧召唤出某种可怕的东西。如何防止这种灾难性的背离——如何确保这些模型捕捉到我们的规范和价值观，理解我们的意思或意图，最重要的是，以我们想要的方式行事——已成为计算机科学领域最核心、最紧迫的问题之一。这个问题被称为对齐问题（the alignment problem）不管怎样，我们未来一整个世纪很可能都在致力于建立、启动和维护各种智能系统。机器学习是技术问题，但越来越多地涉及到人类问题；人类、社会问题是政治的议题，但逐渐同技术密不可分。技术问题正在变得人性化、社会化和公众化。2.谁来给AI立规矩？基本上对科幻略有耳闻的人应该都知道著名的阿西莫夫机器人三大定律：机器人不得伤害人类或因不作为而使人类受到伤害。机器人必须服从人类的命令，除非这些命令与第一定律相冲突。机器人必须保护自己的存在，只要这不违反第一定律或第二定律。但靠这些显然不够，框架性的协议顶多可以稍微凝聚一些共识，为未来更细致的协议、法规奠定基础，但作用也就仅限于此了。Q：谁有权利给AI立规矩\nA：废话，当然是人了。\nQ：谁能代表人？\nA：Well，actually……🤓在大模型造成真正的混乱之前，先出现问题的总会是与之多少有关联的人。如果给AI制定规则的人都是混乱的，又何来好的、完整的AI规则？算法霸权、媒体霸权等词早已不再新鲜，算法霸权意味着算法系统不仅控制着大量数据处理和决策过程，还因其复杂性和技术性而具有高度的不透明性，算法的决策过程如同黑箱，其内在逻辑和偏见不易被发现和纠正——至少不易被使用其的人纠正。大模型时代，算法霸权的影响只会更加的严重和潜移默化。过去我们认为殖民主义者通过算法推送来达到控制新闻传播的目的，固然我们可以通过大量的推送来制造一个信息茧房，**但是这些信息最终的接受方式依旧离不开被动地灌输。**只要获取信息的渠道是顺畅的，那么稍微掌握一点点大脑和技术能力的用户就可以主动去接触其他信息而不被困住。但是，大模型对于我们来说就很容易被认为是“独立来源”，由我们用户主动调用、主动提问并传播信息。如果大模型自我标榜为道德的、中立的、理性的（当然他们在多大多数时间看来确实是如此），那么想要准确判别是模型的输出是否存在道德与价值观风险（即是否塞了私货），其所需要的成本就大幅提高了，核验一条信息的难度也会随之增加。这么想，美帝的出口管制法案和愈演愈烈的对于先进技术出口的限制导致的OpenAI和Google等巨头对于中国的主动封锁，反而对于中国培养自己的大模型体系算重大利好（毕竟Gemini大搞四色冰激淋的丑闻犹在眼前）。3.谁来坐牢？刘教授认为，无论是走“灌输”还是“学习”路线，自动驾驶汽车均可以随机方案或直接刹车加以解决。重要的是承担事故责任，而不是纠结于自动驾驶如何解决“电车难题”。当AI系统出现问题或造成伤害时，需要有明确的责任归属，这是在模型脱离了可解释层级之后要进行的底线式思考。尤其对于深度学习大模型这种高级ai系统，由于其复杂性和黑盒特性，其决策过程往往对非专业人员来说是不透明的，即“脱离了可解释层级”。在这种情况下即使AI系统做出了错误的决定，人们也可能难以追溯原因或进行干预。面对复杂度高的工程问题，面对高度复杂、难以直接解释的模型时，我们必须预先设定一套基本的原则和框架，确保能够明确责任归属，保护用户和社会的利益（这就是法学和社会学的科研范畴了）。考虑到大模型未来对全世界的庞大潜在增量贡献，模型本身造成的责任应当通过某种保险机制由社会承担（因为模型所带来的也是社会的进步），而所需要的资金则可以由既有模型获益者与国家共同出资筹措。4.对齐共识在2023年大模型元年为节点之后，全世界对于大模型在对齐方面我觉得共识是比较小的。虽然大家表面上都在讲什么“不作恶”、“科技向善”之类的鬼话，但实际上各家都在构建自己的技术数据商业护城河，对齐表现上也各自有各自的花活。大模型领域是一个变化发展极快的，有大量未知待发现的领域，我们不知道scaling law什么时候过时，我们也不太能搞清楚所谓的具身智能到底什么时候可以代替人类。AI要成为能每个人身边的生产娱乐工具，人的可用之器，必须达成物理世界（输入）->数字世界（输入）->数字世界（输出）->物理世界（输出）的闭环，我们在计科方面的进步要远快于社科方面的研究积累，人类又真的做好了面对AGI的准备了吗？"
  },
  {
    "title": "Weekly通讯-第二期：B站的运作、GPT-4o与胖猫",
    "summary": "一、进入瓶颈期的B站B站有在2024年实现盈利的承诺，但涉及到具体的增长空间从何处来？假如后续B站业务不发生重大调整，在保证平台生态正常运转（UP多少可以分一点钱）的情况下，B站支出端的优化已经到尾声了。一年170亿的成本，其中大部分（90亿的收入分成，35亿的内容成本以及20亿的带宽成本）都相对“刚性”，此外100亿的费用支出也很难有大规模优化的空间，那么要达到盈亏平衡，至少要实现270亿元的年",
    "tags": [
      "Weekly通讯"
    ],
    "url": "/posts/ScheduledReport/Weekly通讯-第二期：B站的运作、GPT-4o与胖猫/",
    "date": "2024-05-20T00:00:00.000Z",
    "content": "一、进入瓶颈期的B站B站有在2024年实现盈利的承诺，但涉及到具体的增长空间从何处来？假如后续B站业务不发生重大调整，在保证平台生态正常运转（UP多少可以分一点钱）的情况下，B站支出端的优化已经到尾声了。一年170亿的成本，其中大部分（90亿的收入分成，35亿的内容成本以及20亿的带宽成本）都相对“刚性”，此外100亿的费用支出也很难有大规模优化的空间，那么要达到盈亏平衡，至少要实现270亿元的年收入，相对于今年的225亿要增长20%。但在营收端，B站仍然依赖游戏，新游优俊少女跟似了无异，营收仍然在吃FGO和碧蓝航线的老本，新游能打的几乎没有，短期内流水翻身几乎没有希望。电商里B战的核心up主（百万粉丝级别）在关键的几个活动（双十一）这些 还是选择去抖音等更成熟的平台卖货，优质UP主放不下身段去卖东西，对于选品会更谨慎（自身要求、怕被粉丝嘲），以及直播间也会更多的去倡导理性消费。B如何让市场让投资人相信他24年会实现盈利承诺？B站的主要用户有着深入骨髓的白嫖风和性价比风，使得商业化的过程都带着又当又立的色彩，表现实在是难看（男二次元能爆多少米.avi）二、谈一谈GPT-4o不仅在传统的文本能力上GPT-4 Turbo的性能相当，还在 API 方面更快速，价格还更便宜 50%。总结来说，与 GPT-4 Turbo 相比，GPT-4o 速度提高了 2 倍，价格减半，限制速率提高了 5 倍。还是那个OpenAI味，基础的先放出来用，好的公布但是普通用户用不了，最受欢迎的语音对话功能估计还得再等一个月。还可以预见的是，大模型价格战从Deepseek开始，OpenAI来进一步推动。假如OpenAI吹的都是真的，响应速度和智能程度属实的话，那确实挺令人振奋的。但这些进步尚处于工程学上的雕花，都在预期之内。既然免费用户都能用上 gpt4o ，确实代表他们的成本已经可以压缩到一个很好看的程度了。目前有两种构建人工智能的策略：一种是假设模型不会改进，然后在现有的能力上建设一堆小东西；另一种是假设 OpenAI 将保持相同的增长轨迹（继续疯狂迭代）。我认为，95% 的人应该押注在第二种策略上。我们有改进模型的使命，不是我不喜欢你们，但我们将碾压你。‍——Sam Altman，2023年4月17日三、胖猫事件与舆论1.公信力是否对于现代社会来讲，公信力其实是一个伪命题？我们对公信力的定义是：一个个体、组织或机构在社会中所拥有的权威和信任。但现代性的演进、信息传播方式的变革天然要对传统的权威结构提出挑战，信息来源的多元化、传播速度加快和“自媒体”的泛滥削弱了传统权威机构（政府和主流媒体）对于信息的垄断地位，我们过去所熟知的“权威”确实是在不断的被消解和解构（如经典的专家，和现在确实有很大一部分人看到警情通告不会选择直接相信了）有没有可能，这十年十五年，其实是一种“反常”，是一种充满着对未来希望的、特殊的、难以复现的黄金时期，随着社会治理成本的不断增加和当前增量动力不足、存量有限情况的不断挤压，可能熵增、无序和混乱才是常态。2.思维工具其二：质疑引擎触发条件：假如一件事情从发生到后续的走向都符合舆论的预期，符合人们朴素的情感，且涉及到争议性公共议题存在难以解释的、含糊不清的疑点，逻辑链不清晰不完整陈述的内容里存在相互矛盾或与既定事实不符若满足任意一点，则质疑引擎触发，先质疑 再质疑 最后质疑 所有细节没盘出来之前不轻易判断。"
  },
  {
    "title": "Pake打包Web APP记录",
    "summary": "一、Pake是什么？Pake是一项使用Rust Tauri作为底层框架的、实现了快捷键的透传、沉浸式的窗口、拖动、样式改写、去广告、产品的极简风格定制的web app打包开源项目。原本的网页打包成应用要么是PWA，要么就是electron塞一个chromium，Pake则是用Tauri 替代之前套壳网页打包的老思路，相比传统的 Electron 套壳打包，软件要小将近 20 倍，约 5M 上下。开",
    "tags": [],
    "url": "/posts/TechnicalTutorials/Pake打包Web APP记录/",
    "date": "2024-05-13T00:00:00.000Z",
    "content": "一、Pake是什么？Pake是一项使用Rust Tauri作为底层框架的、实现了快捷键的透传、沉浸式的窗口、拖动、样式改写、去广告、产品的极简风格定制的web app打包开源项目。原本的网页打包成应用要么是PWA，要么就是electron塞一个chromium，Pake则是用Tauri 替代之前套壳网页打包的老思路，相比传统的 Electron 套壳打包，软件要小将近 20 倍，约 5M 上下。开源地址二、如何使用Pake呢？有两种方法，一是直接在线使用Github Action（小白推荐），二是本地运行Pake。1.Github Action 执行打包（1）Fork本项目这一步我觉得不用多说了（2）前往Actions点击前往Actions界面，选择 Build App with Pake-Cli，填写表单信息，点击 Run Workflow即可。表单参数与填写要求基本和pake-cli参数保持一致，具体可以参考下面的pake-cli变量内容Untitled（3）下载附件出现绿色小图标则代表打包成功，可以点击 Build App with Pake-Cli查看打包详情和附件。Untitled可以看到这里的 Artfacts出现了一个1,也就代表有一个附件可供下载。Untitled点击 Artfacts，自动跳转到最下方，可以看到最终的附件信息，点击该附件名即可正式下载。Untitled（4）运行时间第一次运行会比较慢，大概10-15分钟左右，后续有了缓存后，就会快很多。尽量保证第一次完整运行，这样生成的缓存可以节省很多时间，如果运行失败，则生成的缓存不完整，后续就无法实现加速的效果。可以在Actions左下角的页面查看缓存，一般命名为 [打包平台]-cargo-xxxx，一般在400M-600M之间，如果缓存生成较小，只有几十M，可以通过右边的删除按钮删除缓存，那么下次构建会自动生成新缓存来代替。\ntitle2.MacOS 环境配置（1）安装Node.jsMacOS里可以直接通过Homebrew安装。打开终端用以下命令安装Node.js：brew install node安装完成后，同样可以使用 node -v 和 npm -v 命令验证安装。（2）安装Pake确保 Node.js 版本为 18 或更高版本（例如 18.7），避免使用 sudo 进行安装npm install pake-cli -g若下载速度较慢 请给终端设置代理实测安装之后无法在当前终端进行打包，需要重启终端开一个新的窗口2.Windows/Linux 环境配置（稍微麻烦一点）对于 Windows 用户，请确保至少安装了 Win10 SDK(10.0.19041.0) 和 Visual Studio Build Tools 2022（版本 17.2 或更高），此外还需要安装以下组件：Microsoft Visual C++ 2015-2022 Redistributable (x64)Microsoft Visual C++ 2015-2022 Redistributable (x86)Microsoft Visual C++ 2012 Redistributable (x86)（可选）Microsoft Visual C++ 2013 Redistributable (x86)（可选）Microsoft Visual C++ 2008 Redistributable (x86)（可选）对于 Ubuntu 用户，在开始之前，建议运行以下命令以安装所需的依赖项：sudo apt install libdbus-1-dev \\\n    libsoup2.4-dev \\\n    libjavascriptcoregtk-4.0-dev \\\n    libwebkit2gtk-4.0-dev \\\n    build-essential \\\n    curl \\\n    wget \\\n    libssl-dev \\\n    libgtk-3-dev \\\n    libayatana-appindicator3-dev \\\n    librsvg2-dev \\\n    gnome-video-effects \\\n    gnome-video-effects-extra之后，命令行安装pake即可npm install pake-cli -g3.正式打包网页（pake-cli）pake [url] [options]举个例子：pake https://weekly.tw93.fun --name Weekly --hide-title-bar变量解释：[url]url 是您需要打包的网页链接 🔗 或本地 HTML 文件的路径，此参数为必填。[options]您可以通过传递以下选项来定制打包过程：[name]指定应用程序的名称，如果在输入时未指定，系统会提示您输入，建议使用单个英文名称，不要出现下划线或者中文。--name <string>\n[icon]指定应用程序的图标，支持本地或远程文件。默认使用 Pake 的内置图标。您可以访问 icon-icons\n或 macOSicons 下载自定义图标。macOS 要求使用 .icns 格式。Windows 要求使用 .ico 格式。Linux 要求使用 .png 格式。--icon <path>\n[height]设置应用窗口的高度，默认为 780px。--height <number>\n[width]设置应用窗口的宽度，默认为 1200px。--width <number>\n[hide-title-bar]设置是否启用沉浸式头部，默认为 false（不启用）。当前只对 macOS 上有效。--hide-title-bar\n[fullscreen]设置应用程序是否在启动时自动全屏，默认为 false。使用以下命令可以设置应用程序启动时自动全屏。--fullscreen\n[activation-shortcut]设置应用程序的激活快捷键。默认为空，不生效，可以使用以下命令自定义激活快捷键，例如 CmdOrControl+Shift+P，使用可参考 available-modifiers。--activation-shortcut <string>\n[always-on-top]设置是否窗口一直在最顶层，默认为 false。--always-on-top\n[disabled-web-shortcuts]设置是否禁用原有 Pake 容器里面的网页操作快捷键，默认为 false。--disabled-web-shortcuts\n[multi-arch]设置打包结果同时支持 Intel 和 M1 芯片，仅适用于 macOS，默认为 false。准备工作注意：启用此选项后，需要使用 rust 官网的 rustup 安装 rust，不支持通过 brew 安装。对于 Intel 芯片用户，需要安装 arm64 跨平台包，以使安装包支持 M1 芯片。使用以下命令安装：rustup target add aarch64-apple-darwin对于 M1 芯片用户，需要安装 x86 跨平台包，以使安装包支持 Intel 芯片。使用以下命令安装：rustup target add x86_64-apple-darwin使用方法：--multi-arch[targets]选择输出的包格式，支持 deb、appimage 或 all。如果选择 all，则会同时打包 deb 和 appimage。此选项仅适用于 Linux，默认为 all。--targets <string>[user-agent]自定义浏览器的用户代理请求头，默认为空。--user-agent <string>[show-system-tray]设置是否显示通知栏托盘，默认不显示。--show-system-tray[system-tray-icon]设置通知栏托盘图标，仅在启用通知栏托盘时有效。图标必须为 .ico 或 .png 格式，分辨率为 32x32 到 256x256 像素。--system-tray-icon <path>[use-local-file]当 url 为本地文件路径时，如果启用此选项，则会递归地将 url 路径文件所在的文件夹及其所有子文件复制到 Pake 的静态文件夹。默认不启用。--use-local-file[inject]使用 inject 可以通过本地的绝对、相对路径的 css js 文件注入到你所指定 url 的页面中，从而为其做定制化改造。举个例子：一段可以通用到任何网页的广告屏蔽脚本，或者是优化页面 UI 展的 css，你只需要书写一次可以将其通用到任何其他网页打包的 app。--inject ./tools/style.css --inject ./tools/hotkey.js[safe-domain]这个安全域名是除你当前配置的 url 之外可能会出现重定向或跳转到的其他域名，只有在已配置为安全的域名中，才能够使用 tauri 暴露到浏览器的 api ，保证 pake 内置增强功能的正确运行。PS: 安全域名不需要携带协议。--safe-domain weread.qq.com,google.com[debug]打出来的包具备 deb-tools 的调试模式，此外还会输出更多的日志信息用于调试。--debug"
  },
  {
    "title": "广汽埃安IPO受阻分析",
    "summary": "一、广汽埃安历史沿革与战略地位2011年，整个国内新能源汽车行业方兴未艾，广汽集团开始探索新能源汽车市场的发展机会。四年后，随着新能源汽车行业加速发展，广汽集团正式成立新能源分公司，对外宣布进军新能源汽车市场。2017年7月，广汽新能源汽车有限公司正式注册成立，在当时普遍还是“油改电”时，广汽新能源就已经有了自己的汽车纯电平台，推出“GE3”等纯电平台专属车型（虽然一直都不温不火）。广汽新能源的转",
    "tags": [],
    "url": "/posts/Finance and Economics/广汽埃安IPO受阻分析/",
    "date": "2024-05-10T00:00:00.000Z",
    "content": "一、广汽埃安历史沿革与战略地位2011年，整个国内新能源汽车行业方兴未艾，广汽集团开始探索新能源汽车市场的发展机会。四年后，随着新能源汽车行业加速发展，广汽集团正式成立新能源分公司，对外宣布进军新能源汽车市场。2017年7月，广汽新能源汽车有限公司正式注册成立，在当时普遍还是“油改电”时，广汽新能源就已经有了自己的汽车纯电平台，推出“GE3”等纯电平台专属车型（虽然一直都不温不火）。广汽新能源的转机出现在了2018年，当年的11月，广汽新能源发布“AION（埃安）”系列，一个月之后，广汽新能源的智能生态工厂正式竣工。随着“AION（埃安）”系列的发布，广汽新能源正式走上了正轨，其在次年4月发布的“AION S”，由于续航里程长、售价偏低、性价比高等优势，在发布后便受到了消费者的关注，2019年全年销量超过了3万台。随着“AION S”的走红，广汽新能源在6个月后又发布了国内首款L3级智能驾驶量产车型“AION LX”，同样的高性价比“打法”，也让“AION LX”也迅速出圈；随着埃安系列的大卖，2020年广汽新能源更名为广汽埃安新能源汽车有限公司，广汽埃安品牌正式独立。注：AION LX的那个L3级自动驾驶还是依赖高精度地图，跟华为、特斯拉乃至大疆的都不太好比二、融资历程与资本市场野心2022年3月，广汽埃安完成了Pre-A轮融资，交易金额达到了25.66亿元，估值达到了390亿元。2022年10月，广汽埃安完成A轮融资，本次融资由人保资本、南网能创、国调基金、深创投、中信金石、广州产投集团或其旗下基金或机构联合领投，共计引入53名战略投资者，金额高达182.94亿元，释放17.72%股份，创下国内新能源整车行业最大单笔私募融资，远超此前造车新势力在pre-IPO轮的融资规模，成为未上市新能源车企中最大的独角兽企业。此轮估值后广汽埃安整体估值达到1032.39亿元，已经超过港交所小鹏汽车、零跑汽车的市值。随后，广汽埃安方面表示，计划在2023年底或者2024年初完成科创板上市，上市前不会再进行B轮融资。到了2023年，这个口径又变了好几次。2023年初的上海国际车展上，广汽集团总经理冯兴亚表示，广汽埃安力争在今年实现IPO；在2023年3月举办的广汽集团2022年业绩发布会上，广汽集团党委书记、董事长曾庆洪表示，在当前的资本模式下，埃安若不拆分上市，资本运作空间将十分有限。通过机制创新、资本运营，埃安才能跟其他的造车新势力去竞争，包括比亚迪。作为国有的几大汽车集团之一，广汽集团每年汽车销量在200万辆以上，但市值却不到2000亿元，远不及利润低于广汽集团的其他企业。因此，从埃安独立的那天开始，广汽就把自己最核心的资产都打包进了埃安，做局推动埃安上市。因此可以说埃安上市，不仅是为了自己，更是为了整个广汽。2023年7月的中国新能源汽车第2000万辆下线活动上，广汽埃安总经理古惠南则表示，公司IPO按计划进行，但预计最快也要到2024年。到了9月的2023年半年度业绩会上，曾庆洪回应广汽埃安IPO时的回应，就变成了“具体上市时间将取决于审核进展和资本市场状况”。三、IPO被否原因分析目前来看，广汽埃安的科创板IPO进程是没有实质性的突破的。创板在创新性、盈利能力等方面的审核标准或许是新能源车企面临的最大难题，即使是“根正苗红”的埃安也无法通过。今年本就IPO渠道缩紧，我认为最大的问题可能还是市场对于埃安业务的可持续性、盈利前景还有增长潜力存在质疑。1.广汽埃安销售结构问题最初，广汽埃安瞄准的是B端网约车市场，目前国内网约车市场上运营着超过30万辆广汽埃安的车型，大约占据了网约车市场的25%。在广东地区的网约车市场，广汽埃安几乎占据了半壁江山，成为了当地网约车之首。2023年初，广汽埃安计划全年销售额达到50万辆，甚至要冲刺60万辆，但最终2023年埃安全年累计销量达到48万辆，同比增长77%。2023年下半年埃安的销量出现了明显下滑。随着国内网约车市场逐渐接近饱和，埃安倚重的B端市场正在出现瓶颈。而承载着埃安进军高端市场希望的子品牌昊铂，并未能及时补位。数据显示，定位在20万元以上的昊铂GT上市后销量逐月下降，仅能维持在月均千台左右的水平。昊铂HT上市月的销量仅有1910台。昊铂还需要更多时间来证明自己。\nimage.png销售曲线已经陷入了瓶颈2024年，广汽埃安的表现更差，2月广汽埃安实现销量为10006辆，与去年同期的30086辆相比，同比大幅下滑66.74%；而在今年前两个月，广汽埃安的累计销量仅为21011辆，销量大幅下滑了45.13%。3月稍好，销量达到32530辆，4月则是21350辆，这个成绩和广汽埃安去年年末相比要拉跨不少。低端市场（8-15万）是广汽埃安当前的核心市场，但竞争在2023-2024年变得愈发激烈。比亚迪2023年末开始率先打价格战，五菱星光、长安启源、吉利银河、奇瑞icar等纷纷加入战场，埃安Y、埃安S正逐渐失去声音，甚至被打的毫无还手之力。高端市场一直都是埃安的弱势，它在这一领域表现如何呢？2023年7月，广汽埃安的高端品牌昊铂的第一辆车型昊铂GT发售，新品牌昊铂正式加入市场竞争，并接连发布昊铂SSR、昊铂HT等车型，但销售数据同样难看。目前国内40万元以上的高端市场基本被蔚来所垄断，而且像理想、小鹏、极氪甚至比亚迪都在不断向上开拓高端市场，广汽埃安能否成功开拓高端市场，背后的不确定性显然非常的大。相较于国内核心车企，广汽埃安在三电技术、智驾上都有不足，甚至广汽旗下的传祺也跳到华为智驾阵营里了。广汽埃安2024年目标销量为70万辆，当前前四个月销量为74891辆，即后续八个月每个月需要完成近8万辆的销售成绩，基于埃安当前的成绩，这基本上是不太能做到的。2.持续亏损从广汽埃安公示的财务报表来看，其在2019年-2022年5月31日期间，亏损额逐年增加，累计净亏损超37亿元，负债总额高达98.5亿元。进入2023和2024年后，市场竞争和价格战的加剧，新品牌的投入都只会让埃安的资金压力更大，若从经营状况来看，目前广汽埃安的情况，显然还比不上当年已经顺利盈利的北汽新能源。时间拖得越久，对埃安的估值和发展恐怕会越不利。亏损原因之一就有供应链里电池价格过高，即时2022年10月份开始布局自研电池厂，2023年末正式投产，但此时新能源电池周期已过，动力锂电池材料价格的全面下降也使电池成本快速下降，广汽埃安的百亿投资现在来看未必是明智的选择。2024年年初埃安接手广汽三菱工厂扩张的产能又真的是一件好事吗？当前广汽埃安本就陷入产能过度扩张的泥潭，三菱工厂更像是IPO路上的拖油瓶。一方面，广汽埃安现在面临持续亏损；另一方面在国产其他新势力的围攻下，广汽埃安盈利可能的空间也在不断被压缩，什么时候可以取得盈利仍有较大的不确定性。"
  },
  {
    "title": "Weekly通讯-第一期：Agent、New Money的投资逻辑与时代的孤独",
    "summary": "一、2024年大模型领域的热点：Agent1.Agent基础Agent（代理）一概念起源于哲学，描述了一种拥有欲望、信念、意图以及采取行动能力的实体。在大模型中，agent的含义为：具有自主性、反应性、交互性等特征的智能“代理”。LLM给AI Agent底层提供了一个突破性技术方案：LLM带来了深度学习新范式，思维链和强大的自然语言理解能力有望让Agent 具备强大的学习能力和迁移能力，从而让创建",
    "tags": [
      "Weekly通讯"
    ],
    "url": "/posts/ScheduledReport/Weekly通讯-第一期：Agent、New Money的投资逻辑与时代的孤独/",
    "date": "2024-05-06T00:00:00.000Z",
    "content": "一、2024年大模型领域的热点：Agent1.Agent基础Agent（代理）一概念起源于哲学，描述了一种拥有欲望、信念、意图以及采取行动能力的实体。在大模型中，agent的含义为：具有自主性、反应性、交互性等特征的智能“代理”。LLM给AI Agent底层提供了一个突破性技术方案：LLM带来了深度学习新范式，思维链和强大的自然语言理解能力有望让Agent 具备强大的学习能力和迁移能力，从而让创建广泛应用且实用的Agent成为可能。scaling law让ai拥有了“泛化”能力，通过few shot（GPT）或者像Gemini 1.5 Pro那样给出足够的范例，大模型可以掌握一门新的技能。LLM的框架优势：过去等强化学习基于深度学习框架可让Agent学到技能，但Agent的泛化性较差，往往用于非常窄的特定领域，例如用在游戏或低维层面的控制或计划，标志性应用是围棋领域的AlphaGo。AI Agent = LLM x （规划（Planning）+记忆（Memory）+工具（Tools）+行动（Action））我们希望最终的Agent系统具有自感知自推理自规划自决策的能力。可以由一个强大的对话大模型+若干个特化的小模型组成的一个Multi-Agent系统，其中各个模块应当解耦，容易被替换。当前大模型迭代速度快，一个不能快速更新的框架是没有意义的2.如何看待AI Agent——LLM技术下提示词工程的进化image.png其中字节的COZE就是agent平台的佼佼者。第二周的任务之一就是完成Agent系统的概述吧二、New Money的投资逻辑很多新锐的投资人想去投出能够跨越周期的事，有新一代的理想主义。这种理想主义我们可以理解为，我们想真的参与到世界的“构建”中来。这种构建是新时代的技术浪潮中，有我的参与感，而不是沉迷于老一辈的叙事风格。美国著名文化人类学家玛格丽特·米德在她的《代沟》对于代际沟通有过更为详尽的描述：“整个世界处于一个前所未有的局面之中，年轻人和年老人――青少年和所有比他们年长的人――隔着一条深沟在互相望着……因此，人们可以问：’代沟在变窄吗？代沟在弥合吗？’但是一条深深的、人工的沟壑是人类亲手所挖，它发明了一种技术把四十年代中期以前成长起来的人与此后成长起来的人分开了；这样的沟是不会弥合、不会变窄的。”古典主义投资人说，我要留在牌桌上。是对自己过往原始积累的保护，新锐主义投资人说，我要构建这个世界，是因为我们拥有的不够多。三、终结与孤独 By 姬轩亦在不太遥远的至正七年，黑死病正在这个世界上横行无忌，西北诸国的内讧和衰弱让大都的皇帝不寒而栗，一无所有的瘸子开始觊觎小亚细亚，东欧和中东的病夫，那流不出眼泪的和尚正在淮西的尸坑旁郁郁独行。基督教的思想铁幕被瘟疫无情地撕成了碎片，不列颠，高卢和日耳曼等罗马时代的边缘之地即将在佛罗伦萨的吵闹中觉醒——旧日的世界不复存在一开始只是我们少数人的十年前的惊悚话题，而现在将随着瘟疫的暴政扩散到每一个人心里，蒙古人缔造的这个世界秩序已经终结，无论大汗的功业多么前无古人，都已经在瘟疫的铁蹄下化为灰烬，诡异的是，黑死病的起因和蒙古人脱离不了干系，秩序的缔造者往往拥有自杀的美德，而这种美德是他们自己所意识不到的。十年前的我们是孤独的。能够安慰我们自己的只有夜航船上的话题，只有已经逝去的，三国时代的一切，只有建安二十四年的那个庚子年，只有在荒原上的夜行本身。我们当时也不知道这样的混沌会持续多长时间，抵抗这种混沌只是一种本能，我们甚至不知道这种本能是从哪里继承而来的，在《前进，达瓦里希》让北方帝国的遗老唏嘘不已的时候，我们只是凭借本能知道，这个东西讲的并不是什么苏联。十年后的我们依然孤独。但是这种孤独和十年前最终是不一样的。这是一种自己选择的孤独，是黑夜中不断加快的脚步，是许多年后，再一次登楼长啸的这个夜晚，而在这个夜晚我已经明确知道了自己拾级而上的理由：许多年后的春天，许多年后的荒原和夜晚。穿越荒原的例行越野，拾阶而上的脚步声通向废墟的顶端， 那一瞬间我看到北方的天幕涌动着异样的光晕——绯红天幕上的大熊座清晰可辨，大熊座中间有一颗青绿色的彗星。"
  },
  {
    "title": "智能驾驶全景分析其二-决策篇",
    "summary": "智能驾驶全景分析其二-决策篇0.内容概述https://prod-files-secure.s3.us-west-2.amazonaws.com/ef94828e-afdb-4350-867b-0be70b1374bc/a8be34e2-f781-4561-b3e2-3a2cf9f446b3/image1.png2.决策篇拆分决策层（Decision-making Layer）是智能驾驶系统中的关",
    "tags": [],
    "url": "/posts/Finance and Economics/智能驾驶全景分析其二-决策篇/",
    "date": "2023-10-12T00:00:00.000Z",
    "content": "智能驾驶全景分析其二-决策篇0.内容概述https://prod-files-secure.s3.us-west-2.amazonaws.com/ef94828e-afdb-4350-867b-0be70b1374bc/a8be34e2-f781-4561-b3e2-3a2cf9f446b3/image1.png2.决策篇拆分决策层（Decision-making Layer）是智能驾驶系统中的关键组成部分，负责根据感知层提供的环境信息，为车辆制定安全、可行和高效的行驶策略。决策层的核心就是车载计算平台。车载计算平台产业链从硬件到软件主要包括硬件平台，系统软件与功能软件。异构计算平台：CPU 计算单元、AI 单元、MCU 控制单元、存储、ISP 等其他硬件组成 的自动驾驶域控制器系统软件：硬件抽象层、操作系统内核、中间件组件等；功能软件：自动驾驶通用框架、功能软件通用框架。2.1 硬件部分2.1.1 概念与名词解释CPU 计算单元：CPU 是中央处理器的缩写，是计算机的核心部件，负责执行指令和处理数据。CPU 计算单元是指 CPU 中用于进行算术和逻辑运算的部分，通常包括 ALU（算术逻辑单元）和 FPU（浮点运算单元）。CPU 计算单元在自动驾驶域控制器中主要用于执行系统软件和功能软件，以及处理一些复杂的控制逻辑和决策策略。AI 单元：AI 单元是指用于加速人工智能或机器学习的计算速度的硬件部件，通常有 GPU、ASIC、FPGA 三种类型。GPU：GPU 是图形处理器的缩写，最初是用于处理图形数据和复杂算法的硬件部件，具有高并行结构和高速度。后来，GPU 也被用于加速人工智能或机器学习的计算速度，特别适合用在深度学习训练方面，因为深度学习需要大量的矩阵运算和数据并行处理。GPU 在自动驾驶域控制器中主要用于执行深度神经网络和图像识别等任务。ASIC：ASIC 是专用集成电路的缩写，是针对某一特定应用而设计和制造的硬件部件，具有高效率和低功耗的特点。ASIC 可以更有针对性地进行硬件层次的优化，从而获得更好的性能、功耗比。但是 ASIC 的设计和制造需要大量的资金、较长的研发周期和工程周期，而且深度学习算法仍在快速发展，若深度学习算法发生大的变化，ASIC 类芯片一旦定制则难于进行修改。ASIC 在自动驾驶域控制器中主要用于执行一些固定且高频的人工智能或机器学习任务，例如目标检测、语音识别等。FPGA：FPGA 是现场可编程门阵列的缩写，是一种可编程的硬件部件，具有低能耗、高性能以及可编程等特性，相对于 CPU 和 GPU 有明显的性能或者能耗优势。FPGA 可以通过编程重组电路，直接生成专用电路，仅消耗少量甚至一次时钟周期就可完成运算。此外，由于 FPGA 的灵活性，很多使用通用处理器或 ASIC 难以实现的底层硬件控制操作技术，利用 FPGA 可以很方便地实现。这个特性为算法的功能实现和优化留出了更大空间。FPGA 在自动驾驶域控制器中主要用于执行一些可变且低频的人工智能或机器学习任务，例如路径规划、定位等。https://prod-files-secure.s3.us-west-2.amazonaws.com/ef94828e-afdb-4350-867b-0be70b1374bc/a4a512a1-3c4a-4b13-808e-4166d6d7b5ec/image2.pngMCU 控制单元：MCU 是微控制器的缩写，是一种集成了 CPU、存储器和外围接口的单片机，通常用于执行一些简单的控制功能。MCU 控制单元是指 MCU 中用于控制外围设备和通信总线的部分，通常包括 GPIO（通用输入输出端口）、UART（通用异步收发器）、SPI（串行外设接口）、I2C（双向串行总线）等。MCU 控制单元在自动驾驶域控制器中主要用于与传感器、执行器、显示器等外围设备进行数据交换和控制指令的发送和接收。存储：存储是指用于存储数据和程序的硬件部件，通常有 ROM（只读存储器）、RAM（随机存取存储器）、Flash（闪存）等类型。存储在自动驾驶域控制器中主要用于存储系统软件和功能软件，以及缓存一些中间数据和结果数据。ISP：ISP 是图像信号处理器的缩写，是一种专门用于处理图像信号的硬件部件，通常包括图像采集、预处理、增强、压缩、编码等功能。ISP 在自动驾驶域控制器中主要用于对来自摄像头的图像信号进行处理，以提高图像质量和降低数据量。2.1.2 发展趋势（1） EEA架构集中化；走向DCU传统EEA架构的问题：控制器数量过多：各级别汽车 ECU 数量都在逐年递增，每台汽车搭载的 ECU 平均 25 个，一些高端车型通常会超过 100 个；线束布置过于复杂：ECU 数量越多，总线数量必将更长，2000 年奔驰 S 级轿车的电子系统已经拥有 80 个 ECU， 1,900 条总长达 4km 的通信总线。2007 年奥迪 Q7 和保时捷卡宴的总线长度突破 6km，重量超过 70kg，基本成为位列发动机之后的全车第二重部件；“跨域”信号传输需求增加：智能驾驶需要大量的“跨域”信号传输，环境传感器（雷达，视频和激光雷达）产生了大量数据传输的需求，这也对传统分散式ECU基础架构提出了挑战。因此，为了适应智能化需求，催生了以DCU为主的域集中架构（2） 算力需求快速提高；单车传感器数量倍增2.1.3 硬件平台：芯片（1） 概念解释MCU是微控制器（Microcontroller Unit）的缩写，是将计算机的 CPU、RAM、ROM、定 时计数器和多种 I/O 接口集成在一片芯片上，形成芯片级的芯片；它是一种集成了处理器、存储器、输入/输出接口和外设控制器等功能的单片电路。MCU通常用于嵌入式系统，如智能家居、工业控制、物联网等领域，可以实现对硬件设备的控制和通信。SoC是系统芯片（System on Chip）的缩写，它是一种将多个电子系统的功能集成在一个芯片上的技术。SoC通常包括处理器、存储器、图形处理器、音频处理器、网络接口、安全模块等组件，可以提供更高的性能和更低的功耗。SoC通常用于移动设备、智能电视、游戏机等领域，可以实现多媒体处理、人工智能、云计算等功能。与 MCU 不同的是，SoC 是系统级的芯 片，它既像 MCU 那样有内置 RAM、ROM，同时又可以运行操作系统。（手机常用）（2）技术路径当前，CPU+XPU是自动驾驶SoC芯片设计的主流趋势。 根据XPU选择不同，可以分为三种技术路线：CPU+GPU+ASIC、CPU+ASIC 以及 CPU+FPGA 三类“CPU+GPU+ASIC”，主要代表英伟达、特斯拉 FSD 以及高通 Ride好像是最主要的技术路径？这种方案的优点是可以利用 GPU 的强大并行计算能力来处理数据密集型的应用，如卷积神经网络等，同时 ASIC 可以针对特定的算法需求进行定制化设计，提高性能、降低功耗和成本。这种方案的缺点是 ASIC 的开发周期较长，且不易适应算法的变化，而 GPU 的功耗也较高。“CPU+ASIC”，主要代表 Mobileye EyeQ5 系列和地平线征程系列这种方案的优点是可以充分发挥 ASIC 的优势，实现高效、低功耗、低成本的专用芯片，同时减少了 GPU 的冗余和功耗。这种方案的缺点是 ASIC 的开发难度较大，且需要与算法开发同步进行，而 CPU 的计算能力相对有限。”CPU+FPGA“，主要代表 Waymo这种方案的优点是 FPGA 具有硬件可编程的能力，可以灵活地适应不同的算法需求，同时 FPGA 也适合处理顺序相关的机器学习算法，如循环神经网络等。这种方案的缺点是 FPGA 的性能、功耗和成本都不如 ASIC，而且 FPGA 的编程难度也较高。目前各家发布的最新芯片平台均可以支持 L3 或 L4 级的算力需求，英伟达当前 处于领先位置。英伟达单颗 Orin 的算力可以达到 254TOPS，而 2022 年落地 的车型中搭载 4 颗 Orin 的蔚来 ET7 和威马 M7 其巅峰算力将超过 1000TOPS， 高通骁龙 Ride 平台的巅峰算力预计在 700-760TOPS，Mobileye 也推出了面向 高阶自动驾驶的 EyeQ6 Ultra，算力达到 176 TOPS，当前各家最先进的算力平 台均可以支持 L3 或 L4 级的算力需求。从相关量产车型来看，英伟达 Orin 成为 当下的主流选择，Mobileye 正在逐渐掉队。（3）关键参数和关键指标TOPS（Tera Operation Per Second）SoC的TOPS算力是指每秒钟可以进行的万亿次操作（Tera Operations Per Second），用于衡量SoC的运算能力。不同的SoC可能有不同的运算精度，例如int8，int16等，影响TOPS算力的计算方法。一般来说，TOPS算力可以通过以下公式计算：https://prod-files-secure.s3.us-west-2.amazonaws.com/ef94828e-afdb-4350-867b-0be70b1374bc/086c23df-a628-4214-bdff-a4caae4b3920/image3.png其中，F是SoC的工作频率（Hz），C是输入通道数，H和W是输入特征图的高度和宽度（像素），M是输出通道数，N是卷积核大小（像素），2是每次乘加操作的运算次数。例如，如果一个SoC的工作频率是1GHz，输入通道数是3，输入特征图的大小是224x224，输出通道数是64，卷积核大小是3x3，那么它的TOPS算力可以计算为：https://prod-files-secure.s3.us-west-2.amazonaws.com/ef94828e-afdb-4350-867b-0be70b1374bc/2b73effb-976b-479e-a1af-62b8b861c8ea/image4.png也就是说，这个SoC每秒钟可以进行0.173万亿次操作。TOPS 峰值算力反映的都是 GPU 理论上的乘积累加矩阵运算算力， 而非在实际 AI 应用场景中的处理能力，具有很大的局限性。以英伟达的芯片为 例，Orin、Xavier 的利用率基本上是 30%左右，而采用 ASIC 路线，ASIC 芯片 针对不同的神经网络模型去优化，基本上可以做到 60%~80%之间FLOPS（Floating-Point Operations Per Second）每秒可执行的浮点 运算次数的字母缩写，它用于衡量计算机浮点运算处理能力。浮点运算， 包括了所有涉及小数的运算。MFLOPS（MegaFLOPS）等于每秒 1 百万 次的浮点运算；GFLOPS（GigaFLOPS）等于每秒 10 亿（=10^9）次的 浮点运算；TFLOPS（teraFLOPS）等于每秒 1 万亿次的浮点运算。DMIPS（Dhrystone Million Instructions Per Second）是测量处理器 运算能力的最常见基准程序之一，常用于处理器的整型运算性能的测量。 MIPS：每秒执行百万条指令，用来计算同一秒内系统的处理能力，即每秒 执行了多少百万条指令。不同的 CPU 指令集不同、硬件加速器不同、CPU 架构不同， 导致不能简单的用核心数和 CPU 主频来评估性能，Dhrystone 作为统一的跑分算法，DMIPS 比 MIPS 的数值更具有意义。2.1.4 硬件平台：域控制器**上面提到的SoC是域控制器的一部分。**车载计算平台需采用异构多核芯片硬件架构。自动驾驶的域控制器，要具备多传感器融合、定位、路径规划、决策控制、无线通讯、高速通讯的能力。通常需要外接多个摄像头、毫米波雷达、激光雷达，以及 IMU 等设备，完成的功能 包含图像识别、数据处理等。面向 L3 及以上高阶自动驾驶，单一芯片无法满足诸多接口和算力需求，计算基础平台需采用异构芯片的硬件方案，具有芯片选型灵活、可配置拓展、算力可堆砌等优点。计算平台的异构分布硬件架构主要 包括 CPU 计算单元、AI 单元和控制单元。AI芯片：负责执行深度学习、图像处理、数据融合等复杂的AI计算和智能控制，通常包括GPU、CPU、DLA、PVA、ISP等不同类型的处理器，如NVIDIA Xavier、华为昇腾310等。MCU：负责功能安全和车辆控制，不要求很高的算力，但是可靠性必须要有保障，ISO26262等级要求达到ASIL-D，如Infineon的TC297或TC397等。传感器接口：负责连接摄像头、激光雷达、毫米波雷达、超声波雷达等感知传感器，用于采集车辆周围的环境信息，如道路状况、障碍物位置、交通信号等。定位模块：负责接收GPS信号和IMU数据，用于确定车辆的位置和姿态，以及与地图的匹配。车联网模块：负责与其他车辆或基站进行通信，用于交换路况信息、协同控制、远程监控等。底盘线控：负责与车辆的执行器进行通信，用于控制车辆的加速、刹车、转向等动作。2.1.5 域控制器主要玩家自动驾驶域控制器玩家主要分为系统集成商、软件平台厂商以及 OEM 厂商三大类。OEM整车厂家特斯拉以及国内的造车新势力如蔚来、小鹏、威马、理想、上汽智己等都已实现或宣布将自研自动驾驶域控制器，以掌握未来软件定义汽车下底层的硬件自主权；系统集成商和Tier1如博世、大陆、采埃孚等国际 Tier1 和系统集成商,德赛西威、经纬恒润、华为等一批本土 Tier1 和系统集成商；软件平台厂商如映驰科技、东软睿驰、TTech、中科创达等公司（1）智能座舱域控制器目前，主要有两类芯片厂商参与智能座舱域控制器的市场，一类是传统的汽车芯片厂商，如NXP、德州仪器、瑞萨电子等，他们主要面向中低端市场，提供成熟和稳定的解决方案；另一类是手机领域的厂商，如联发科、三星、高通等，他们主要面向高端市场，提供高性能和创新的解决方案。全球主要的智能座舱域控制器厂商有以下几家：https://blog-1302893975.cos.ap-beijing.myqcloud.com/pic/202310121456782.png?imageSlim（此图存疑，主要在于计算平台存在一些疑似失误）我查到的造车新势力使用的控制器：蔚来：英伟达Orin理想：高通8155小鹏：英伟达Xavier威马：高通8155特斯拉：自己的FSD（2）自动驾驶域控制器全球范围内，全球 Tier1 基本都已布局自动驾驶域控制器产品，典型产品如伟世通 DriveCore、博世 DASy、大陆集团 ADCU、采埃 孚 ProAI、Veoneer Zeus、麦格纳 MAX4 等，国内方面，如德赛西威 IPU 系列、 经纬恒润 ADC、东软睿驰 CPDC、华为 MDC 等。此外，在域控制器市场还有一类重要的玩家，就是从主机厂孵化成立的智能驾驶软件平台型公司，如长城汽车的毫末知行，吉利汽 车的亿咖通等。2.2 软件部分2.2.1 操作系统（1） 介绍在智能网联时代，车机操作系统OS按照下游应用划分，可以分为车控OS和座舱OS两大类。车控OS：底盘控制，动力系统和自动驾驶，与汽车的行驶决策直接相关车控OS的操作系统有两种：嵌入式实时操作系统 RTOS 和基于 POSIX 标准的操作系统，RTOS 和 POSIX 在汽车领域的应用主要分为三个方面：安全车载操作系统、智能驾驶操作系统和智能座舱操作系统。安全车载操作系统主要是实时操作系统 RTOS，主要应用对象是 ECU。ECU 对安全车载操作系统最基本的要求是高实时性，系统需要在规定时间内完成资源分配、任务同步等指定动作。嵌入式实时操作系统具有高可靠性、实时性、交互性以及多路性的优势，系统响应极高，通常在毫秒或者微秒级别，满足了高实时性的要求。目前，主流的安全车载操作系统都兼容 OSEK/VDX 和 Classic AUTOSAR 这两类汽车电子软件标准。智能驾驶操作系统主要面向智能驾驶领域，应用于智能驾驶域控制器，该类操作系统对安全性和可靠性要求较高，同时对性能和运算能力的要求也较高。该类操作系统目前在全世界范围内日趋成熟，但生态尚未完备。智能驾驶操作系统主要是基于 POSIX 标准的操作系统，可以为支持 POSIX 标准的操作系统及不同的应用需求提供标准化的平台接口和应用服务，主要是为了适应汽车智能化的发展需求。智能座舱操作系统主要为汽车信息娱乐服务以及车内人机交互提供控制平台，是汽车实现座舱智能化与多源信息融合的运行环境，对操作系统的实时性与可靠性要求并不严苛。主流车型的智能座舱操作主要包括 QNX、Linux、Android 等，传统智能座舱操作系统中 QNX 占据了绝大部分份额，近年来，智能座舱的娱乐与信息服务属性越发凸显，开源的 Linux 以及在手机端拥有大量成熟信息服务资源的 Android 被众多主机厂青睐，成为后起之秀。一般来说，RTOS 更适合对实时性和可靠性要求极高的安全车载领域，而 POSIX 更适合对通用性和兼容性要求较高的智能驾驶和智能座舱领域。座舱OS：车载信息娱乐服务+人机交互平台，不直接参与汽车的行驶决策智能座舱OS多用linux或者Android（2）底层内核QNX、Linux、VxWorks 是主要的底层内核（狭义 OS 仅包含内核（如 QNX、Linux），广义 OS 从下至上包括从BSP、操作系统内核、中间件及库组件等硬件和上层应用之间的所有程序。）QNX、Linux 是目前常见内核 OS，VxWorks 也有一定应用。随着 WinCE 停止更新逐渐退出，OS 内核的格局较为稳定，主要玩家为 QNX（Blackberry）、Linux（开源基金会）、VxWorks（风河）。其中 Linux 属于非实时操作系统，而 QNX 和 VxWorks 属于实时操作系统，WinCE 是微软开发的嵌入式操作系统，正在逐步退出汽车操作系统市场。实时操作系统和非实时操作系统的区别在于实时操作系统必须在规定的时间内完成任务，而非实时操作系统则没有这样的要求。实时操作系统通常用于对时间敏感的场合，比如导弹控制、汽车电子、工业控制等，而非实时操作系统则适用于一般的娱乐办公用途。\n实时操作系统和非实时操作系统的另一个区别是任务调度方式不同。实时操作系统一般采用基于优先级的调度方式，也就是说，当高优先级的任务就绪时，它可以抢占低优先级的任务而立即得到执行，无论低优先级的任务是否已经进入内核调度。这样可以保证高优先级的任务能够及时响应外部事件。非实时操作系统一般采用基于时间片的调度方式，也就是说，当一个任务的时间片用完后，内核会停止它而切换到下一个任务执行，即使这个任务没有执行完也没有主动挂起。这样可以保证所有任务都能公平地获得CPU资源。黑莓QNX遵从POSIX规范的类UNIX实时操作系统，是全球第一款达到ASIL D级别的车载操作系统。ASIL D级别是指汽车安全完整性等级的最高等级，也是对功能安全要求最严苛的等级。ASIL D级别是通过对危害事件进行严重程度、暴露率和可控性三个维度的评估而确定的，代表了危害事件导致的伤害或损失的潜在风险最高。ASIL D级别的安全目标需要在系统设计、硬件、软件等方面进行严格的设计和实施，验证，以保证功能安全 。一般来说，安全气囊、防抱死制动系统和动力转向系统等对时间敏感和安全攸关的功能需要达到ASIL D级别。优点是稳定性和安全性非常高，内核小，代码小，故障影响小，驱动等错误不会导致整个系统都崩溃。缺点是它作为非开源系统，兼容性较差，开发难度大，在娱乐系统开发中应用不多，开放性不够，生态缺乏Linux（Android）linux是基于POSIX和UNIX的开源操作系统，定制开发灵活性强，接口多，主要运用在车载信息娱乐场景，但基于linux开发的难度大，开发周期长，限制了车机系统进入门槛VxWorksWind River设计开发的嵌入式实时操作系统，具有良好的可靠性和卓越的实时性，被广泛的应用在通信，军事，航空航天等领域；但是需要收取高昂的授权费，开发定制成本较高。https://blog-1302893975.cos.ap-beijing.myqcloud.com/pic/202310121458155.png?imageSlim在当前市场中，QNX和Linux是车机OS内核的首选。2021年QNX市占率达到43%；Linux（含Android）版本丰富，经过改造linux内核也具有实时性功能，21年市占率35%；WinCE市占率8%，并且仍在快速下滑；VxWorks由于其业务重点在复杂工业领域，对于汽车产业投入较少，售价和维护费用极其昂贵，目前仅在部分高端品牌车型上有所尝试。（4）当前主流的车机OS分类定制型车机OS在基础OS上进行深度开发和定制（包括系统内核修改），与 Tier1 和主机厂一起实现座舱系统平台或自动驾驶系统平台。例如百度车载 OS、大众 VW.OS、特斯拉 Version；ROM型车机OS基于 Android 或 Linux 定制开发，无需更改系统内核。海外主机厂多选择基于 Linux 开发 ROM 型车机 OS，国内自主品牌则主要选择应用生态更好的 Android。例如奔驰、宝马、蔚来、小鹏等整车厂的车机系统都属于 ROM 型车机 OS；超级汽车APP手机映射系统，是指集地图，音乐，语音，社交等功能于一体的超级APP。例如苹果的CarPlay，华为HiCar，百度CarLife，谷歌AndroidAuto等。（这种方式更像是把算力外包给了手机）https://blog-1302893975.cos.ap-beijing.myqcloud.com/pic/202310121458168.png?imageSlimQNX+Linux 或者是 QNX+Android 是当前智能驾驶 OS+智能座舱 OS 的主要选择。以ONX为代表的实时操作系统主要用在驾驶OS上，座舱OS主流是Android和基于Linux的定制型及ROM型系统。2.2.2 硬件抽象层与中间件层硬件抽象层（HAL）是位于操作系统内核与硬件电路之间的接口层，其目的在于将硬件抽象化，隐藏了特定平台的硬件接口细节，为操作系统提供虚拟硬件平台，使其具有硬件无关性，可在多种平台上进行移植。（1） BSP：操作系统和硬件之间的桥梁BSP是板级支持包（Board Support Package）的缩写，是嵌入式系统中介于操作系统和硬件之间的软件层次，主要目的是为了支持操作系统，使之能够更好地运行于硬件主板。BSP的内容和形式可能因不同的操作系统而有所差异，但一般来说，BSP包括以下几个方面：硬件初始化：BSP负责在系统启动时对硬件进行初始化，如设置栈指针、中断向量、内存映射、时钟源等，为操作系统的加载和运行做好准备。启动加载程序：BSP提供一个启动加载程序（Bootloader），用于将操作系统的映像文件从存储介质（如Flash、SD卡等）加载到内存中，并传递一些硬件参数给操作系统。设备驱动程序：BSP包含特定硬件平台的设备驱动程序，这些驱动程序是为了使操作系统与硬件之间进行通信，实现对硬件的控制和访问。常见的设备驱动程序有串口、网卡、LCD、触摸屏、键盘、鼠标等。文档和示例代码：BSP通常会提供详细的文档和示例代码，帮助开发人员更好地理解硬件平台和BSP的工作方式，并提供一些开发指南和最佳实践。BSP 的功能分为两部分，一方面为 OS 及上层应用程序提供一个与硬件无关的软件平台，另一方面 OS可以通过 BSP 来完成对指定硬件的配置和管理。（2）Hypervisor：虚拟化平台提供平台虚拟化的层称为Hypervisor，Hypervisor是一种用于创建和运行虚拟机（VM）的计算机软件、固件或硬件，也称为虚拟机监控器（VMM）或虚拟化器。Hypervisor可以让一台主机计算机支持多个客户机虚拟机，通过虚拟地共享其资源，如内存和处理能力。每个虚拟机都被称为一个客户机机器。Hypervisor向客户机操作系统提供一个虚拟的操作平台，并管理客户机操作系统的执行。与模拟器不同的是，客户机大多数指令是在原生硬件上执行的。车载领域的 Hypervisor 负责管理并虚拟化异构硬件资源，以提供给运行在 Hypervisor 之上的多个操作系统内核。Hypervisor 支持异构硬件单元（包括控制单元、计算单元、AI 单元）的隔离，在同一个异构硬件平台上支持不同的操作系统内核，从而支持不同种类的应用。Hypervisor的作用是实现硬件和软件的解耦，提高软件的可移植性和可复用性，降低开发难度和成本，加快开发进度。Hypervisor也可以根据不同的需求进行定制和优化，以适应不同的应用场景。QNX Hypervisor 是当前市场的主流。目前常见的 Hypervisor 包括黑莓的 QNX、英特尔与 Linux 主导的 ACRN、Mobica 为代表的 XEN、松下收购的 OpenSynergy 的 COQOS、德国大陆汽车的 L4RE，法国 VOSyS 的 VOSySmonitor等，其中最主流的是黑莓的 QNX与英特尔与 Linux 主导的 ACRN，其中黑莓的QNX 是目前唯一被大规模商用且安全等级达到 ASIL D 级的虚拟化操作系统。https://blog-1302893975.cos.ap-beijing.myqcloud.com/pic/202310121459763.png?imageSlim基于 QNX Hypervisor 虚拟技术运行的多操作系统架构https://blog-1302893975.cos.ap-beijing.myqcloud.com/pic/202310121459827.png?imageSlim（3）中间件层：软硬件解耦中间件隔离了应用层与底层硬件，助力软硬件解耦。中间件位于操作系统、网络和数据库之上，应用软件的下层，作用是为处于自己上层的应用软件提供运行与开发的环境，帮助用户灵活、高效地开发和集成复杂的应用软件，实现软硬件的解耦分离。所有的中间件方案中，最著名的就是CP AUTOSAR的RTE。AUTOSAR 标准发展了十多年，已经形成非 常复杂的技术体系。各工具厂商开发了相应的支撑软件，以助力主机厂加速实现 AUTOSAR 的落地。目前全球知名的 AUTOSAR 解决方案厂商包括 ETAS（博世）、EB（大陆）、Mentor Graphics（西门子）、Wind River、Vector、KPIT等，国内主要是东软睿驰、经纬恒润等。2.2.3 功能软件，工具链及应用程序（1）功能软件https://blog-1302893975.cos.ap-beijing.myqcloud.com/pic/202310121500930.png?imageSlim智能驾驶通用模型对应于自动驾驶中环境感知，决策与规划，控制与执行三大部分，通用模型也可以分为环境模型，规划模型和控制模型等功能软件通用框架功能软件通用框架是承载智能驾驶通用模型的基础，是功能软件的核心和驱动部分，可以分为数据流框架和基础服务两部分。数据流框架向下封装不同的智能驾驶系统软件和中间件服务，向智能驾驶通用模型中的算法提供与底层系统软件解耦的算法框架。基础服务是功能软件层共用的基本服务，包括可靠冗余组件、信息安全基本服务以及网联云控服务等。数据抽象数据抽象可以为上层各模型提供数据源。通过对传感器、执行器、自车状态、地图以及来自云端的接口等数据进行标准化处理，数据抽象的过程可以为智能驾驶通用模型提供各种不同的数据源进而建立异构硬件数据抽象，达到功能和应用开发与底层硬件的解耦和依赖。这段话的意思是，数据抽象是一种让上层的模型不用关心数据是从哪里来的，怎么来的，格式是什么样的，而只需要按照统一的方式使用数据的方法。数据抽象可以把各种不同的数据，比如传感器的信号，执行器的动作，自己车辆的状态，地图的信息，云端的接口等等，都转换成一种标准化的形式，让上层的模型可以方便地获取和处理。这样做的好处是，上层的模型就不用管底层的硬件是什么样的，有什么特点和限制，只要数据抽象层能够提供所需的数据就行。这样就可以让功能和应用开发更加灵活和通用，不受底层硬件的影响。（2）工具链车载计算平台开发的软硬件环境以及全栈工具链成为提升开发效率的重要途径之一。高阶自动驾驶技术不断迭代，车载计算平台的研发更需要对产品进行整体持续的迭代，而不只是针对单一的模块，或者其中几个功能。全栈式工具链主要包括开发工具、集成工具、仿真工具、调试工具、测试工具等。https://blog-1302893975.cos.ap-beijing.myqcloud.com/pic/202310121501793.png?imageSlim（3）应用软件应用软件是在系统和功能软件之上独立开发的软件程序，主要包括面向自动驾驶算法，地图导航类，车载语音，OTA与云服务，信息娱乐等。自动驾驶算法自动驾驶算法是指用于实现自动驾驶汽车的各种功能和任务的计算机程序。自动驾驶算法通常可以分为四大类：定位、感知、规划和控制。定位算法是指用于估计自动驾驶汽车相对于地图或道路的位置和方向的算法。定位算法通常利用车载传感器，如激光雷达、雷达、摄像机、GPS、IMU等，以及离线或在线的地图数据，来进行数据融合和状态估计。定位算法有基于激光雷达的、基于激光雷达加相机的和基于相机的等不同的方法。感知算法是指用于检测和识别自动驾驶汽车周围环境中的各种对象和事件的算法。感知算法通常利用车载传感器，如激光雷达、雷达、摄像机等，以及深度学习、计算机视觉、模式识别等技术，来进行数据处理和信息提取。感知算法有静态障碍物测绘、移动障碍物检测与跟踪、道路测绘、交通信号检测与识别等不同的任务。规划算法是指用于生成自动驾驶汽车从当前位置到目标位置的最优或可行的路径或轨迹的算法。规划算法通常利用车辆状态和环境信息，如位置、速度、加速度、地图、障碍物、交通规则等，以及优化理论、人工智能、运筹学等技术，来进行数据分析和决策生成。规划算法有路径规划、行为选择、运动规划等不同的层次。控制算法是指用于控制自动驾驶汽车沿着规划好的路径或轨迹运行的算法。控制算法通常利用车辆状态和轨迹信息，如位置、速度、加速度、曲率等，以及控制理论、反馈控制、预测控制等技术，来进行数据计算和信号输出。控制算法有纵向控制（速度和加速度）、横向控制（方向盘转角）等不同的方面。其中，感知类算法，SLAM（ Simultaneous localization and mapping，同步定位与建图）算法是一个重要分支，SLAM 算法根据点云数据传感器的不同又可分为视觉 SLAM 算法、激光 SLAM 算法以及多传感器融合算法；决策类算法包括自动驾驶规划算法、自动驾驶决策算法；执行类算法主要为自动驾驶控制算法。https://prod-files-secure.s3.us-west-2.amazonaws.com/ef94828e-afdb-4350-867b-0be70b1374bc/deeb967d-a2e2-477b-8037-b095ca437102/image12.png高精度地图高 精 度 地 图 ， 即 HD Map（ High Definition Map）或 HAD Map（ Highly Automated Driving Map），是指绝对精度和相对精度均在 1 米以内的高精度、高新鲜度、高丰富度的电子地图。其信息包括道路类型、曲率、车道线位置等道路信息，路边基础设施、障碍物、交通标志等环境对象信息，以及交通流量、红绿灯状态信息等实时动态信息。高精度地图是实现高度自动化驾驶的必要条件，是L3及以上级别的自动驾驶汽车的必备选项。https://prod-files-secure.s3.us-west-2.amazonaws.com/ef94828e-afdb-4350-867b-0be70b1374bc/b3d67ba2-3d98-4047-8960-dacbef28c425/image13.png目前国内的高精度地图市场呈现三足鼎立的态势，百度，四维图新，高德占据主要份额。https://prod-files-secure.s3.us-west-2.amazonaws.com/ef94828e-afdb-4350-867b-0be70b1374bc/5435178a-fbc9-4c12-9c99-39e42c5243e2/image14.png车载语音车载语音是车内最简洁、最人性化、最安全的交互方式，也是未来最主要的车内交互方式。随着 AI 和硬件性能的增强，语音交互是未来汽车的绝对主流。语音交互主要是依靠 NLP 算法对语音进行解析，使得自动驾驶系统更容易理解驾驶员的指令。当前，科大讯飞与Cerence领先中国车载语音市场，互联网企业以及车厂纷纷入局。https://blog-1302893975.cos.ap-beijing.myqcloud.com/pic/202310121503479.png?imageSlim"
  },
  {
    "title": "思维工具",
    "summary": "思维工具1.作恶史观如果一个人做了看上去很蠢，即正常逻辑说不通，和他一如既往打造的人设相反的事情，那么就说明有我没有盘出来的逻辑。假如每一个对他的恶意揣测都有证据支撑，那么作恶史观就生效了。从最坏的角度出发，基于发生的事实和最终的效果，而不是当事人的叙述和情绪态度进行推理。搞有罪推定，选择那个最简单，需要假设最少的解释（奥卡姆剃刀原则，如无必要勿增实体），会得出一套完整的，可以说得通的恶毒的逻辑，",
    "tags": [],
    "url": "/posts/Essays/思维工具/",
    "date": "2023-10-12T00:00:00.000Z",
    "content": "思维工具1.作恶史观如果一个人做了看上去很蠢，即正常逻辑说不通，和他一如既往打造的人设相反的事情，那么就说明有我没有盘出来的逻辑。假如每一个对他的恶意揣测都有证据支撑，那么作恶史观就生效了。从最坏的角度出发，基于发生的事实和最终的效果，而不是当事人的叙述和情绪态度进行推理。搞有罪推定，选择那个最简单，需要假设最少的解释（奥卡姆剃刀原则，如无必要勿增实体），会得出一套完整的，可以说得通的恶毒的逻辑，我们会选择相信这一套逻辑，做好最坏的应对打算。也可以解释为：有罪推定，把这个人说的话做的事都带有恶意的中译中，过滤掉所有带有迷惑性的信息，用现实逻辑替代他构建的一切脱罪逻辑，把这个人底裤扒干净，有时候甚至他本人主观不这样想，也要这样定罪，至少是动机有问题。需要注意的是，这种史观类似于抓特务的斗争思维，现实生活中大多数不适用。2.工程土狗在成长中，我们或许有段时间会很恐慌身边同龄人竞争者可以很轻易的学会我们所掌握的技术，然后轻而易举的取代我，但他们会的那些工程经验我却不能快速掌握。后来才发现这个问题不太需要思考，有很多书论文我看得进去，他们就是看不进去。这里的“我”不是博主3.质疑引擎在遇到Q/微群里的各种无头新闻，聊天记录，或者生活中一些人时，我会开启“质疑引擎”。这种思维工具强调洞察和逻辑，尽量去盘出整个事件的逻辑链，运用自己的常识和相关专业知识分别找出信息中的疑点和漏洞提出质疑，假如存在难以弥补的逻辑缺陷，那么就基本可以断定是谣言/蓄意造假了。质疑引擎屡试不爽，我现在还没碰到过质疑失败的场合，鉴别谣言一看一个准3.1 舆论核检例如昨晚（9.24），微信群内有消息称陕西师范大学于9.15日晚发生连环杀人案，当晚断电断网，救护车警车来学校，但是没开声音，学校把热度压下去了。就这两天微博才有相关的讨论 看记录里真正事发的15,16号微博几乎没有太大动静微博中都在24号发消息 说“昨晚断网”；但是上一个聊天记录说明是15号晚上事发，信息相互矛盾国内外平台 都没有除了这个聊天记录之外的其他可信信源（陕师有通天的本事 能如此全方位的压制热度？）除此之外，微博中散布这些信息的，除了吃瓜群众之外都是三无新注册的小号依据舆论核验，热度极不正常，造假的可能性极大因此，我当晚就可以基本断定这是一则谣言，后来被证实确实是以谣传谣。3.2 逻辑核验还是以上面这件事为例，假如学校宿舍内发生连环杀人案，有哪些元素是必不可少的？学生的哭声（尤其是这件事发生在女生宿舍）整栋宿舍楼的暴动恐慌如此大规模的恶性事件，警察和救护车怎么可能“无声”到来，校领导哪来的通天手段？家长对于学校的围攻图片之类的，可以使用yandex等网站来查看图片出现的历史还可以分析整个事件的传播链，假如多为轮媒/谣棍/以煽动情绪为业的自媒体，那真实性可靠性就要大打折扣。3.3 专业知识核验之前QQ群看到有人发动态说原号主已经自杀，警察给出自杀死亡证明，自己是弟弟来发布公告。直觉上，自杀时间和他宣称的自杀证明出示时间间隔太短了（应该是只间隔一两个小时）。后来通过查阅相关刑侦知识，确认这是一场经典青少年自导自演的闹剧。（几个月后确实装不下去了，自己承认是演的）3.4 总结自己不熟悉的领域不要讲的太详细，会被相关专家一眼丁真分析舆论热度和传播链逐步核查每一条信息，再整合起来看看逻辑是否成立多运用自己的常识4.传播学辩证法工具（引用自X岛）4.1 归纳推理法看到一个新闻后，比如“某人在二楼一脚踏破楼板，建筑质量堪忧”，附照片“一支从楼上踏破板的腿，穿着棉袜”查看新闻时间:6-8月，气温普遍升高新闻预设地点:中国国内推论:棉袜表示气温很低，与当前时间不符，如果照片时间确定为当时，与国内情况不符答:新闻编造或不实4.2 人物查询法标题:“陈丹青谈教育，这帮老混蛋，为了自己的权利，培养了一群考试机器”推论:陈丹青其人，中央美院毕业，是文学评论家。答:不具备专业知识，审慎接受该观点，不要以单专业专家就认同他的其他专业知识，隔行如隔山。另:标题利用情绪认同，制造焦虑和逆反情绪4.3 标题推论法还是和2一样的新闻标题“这帮老混蛋，为了自己的权利，培养了一群考试机器”新闻标题希望引起你的:学生身份认同，逆反情绪，对政策和现状的不满情绪等，“老混蛋”没有明确代指，但是新闻会将你引导向:资本家、教育局掌权、国家掌权者等并不是在标题就告诉你，而是通过暗示让你想到新闻想让你思考的东西。答:控制情绪，避免身份认同，关心事实，多看合订本，多关注深度逻辑性内容，避免渲染焦虑内容占领你的视线和舆论阵地。4.4 时间确认法任意新闻，时间是否过时。例如某某博览会，某某改革政策，某某民事纠纷 ，先看视频/新闻发布时间，紧接着贴去网上，查找最新进展，查看时间你会发现大多数事件都已经结案。4.5 追根溯源，防止前提植入有时候，不实的数据也会造成误判和过判。比如，cpi和ppi只上升或下降了几个百分点，并不能作为宏观经济整体通缩或通胀的论据美债的上升和下降，也不能只关注国防开支，要搜集完整的信息见信息论据(M2)余额281.46万亿元，同比增长12.7%，增速比上月末低0.2个百分点，比上年同期高3个百分点；狭义货币(M1)余额67.81万亿元，同比增长5.1%，增速比上月末低0.7个百分点，比上年同期高0.4个百分点；流通中货币(M0)余额10.56万亿元，同比增长11%。一季度净投放现金961亿元。结合cpi来看：以下新闻来自新京报贝壳财经讯5.16网页链接未来几个月受高基数等影响，CPI将低位窄幅波动。今年5-7月CPI还将阶段性保持低位，主要受去年同期CPI涨幅基本在2.5%左右的高基数影响。但要看到，随着基数降低，特别是政策效应将进一步显现，市场机制发挥充分作用，经济内生动力也在增强，供需缺口有望趋于弥合，预计下半年CPI中枢可能温和抬升，年末可能回升至近年均值水平附近。当前我国经济没有出现通缩。通缩主要指价格持续负增长，货币供应量也具有下降趋势，且通常伴随经济衰退。我国物价仍在温和上涨，特别是核心CPI同比稳定在0.7%左右，M2和社融增长相对较快，经济运行持续好转，不符合通缩的特征。中长期看，我国经济总供求基本平衡，货币条件合理适度，居民预期稳定，不存在长期通缩或通胀的基础。结论所以新闻的标题是预设了一个前提的，而这个前提会变成一种潜意识植入，让你在不经意间保存这个理论，当现实需要使用这个相关理论时，虚荣心或潜意识就会提醒你“大环境”是“通缩”这是一种非常高明的舆论战方法。4.6 标题定性现象“解构某某主播，一场虚伪的伪下沉表演”标题本身对观点进行了定性，无论它的内容如何不切题，”伪下沉“标题本身，就将对目标主播进行舆论上的打击这种情况就类似，《让子弹飞》中的名场面，六子吃了几碗粉都无法反驳扣帽子的真相。4.7 颜色革命相关防止美国颜色革命类似的国内二元对立情况，防止对号入座。我们以人为本，我们应该是国家的公民、整体中的个体，团结的民族和执政的合法性应该是安稳和必要的，这有助于我们个人美好生活的实现。有些时候间接原因并非主要原因，不要被引导到非必要和非重要议题上去，保持关注重点。"
  },
  {
    "title": "十八岁-未济与求索",
    "summary": "小时候囫囵吞枣看易经，到现在内容忘个精光，每一卦的名称倒是还依稀记得。易经以乾坤两卦开始，最后一卦却是 “未济”。何为 “未济”？孔夫子作的《序卦传》说，“物不可穷也，故受之以未济终焉。” 易经六十四卦到了既济这一卦，乾坤或几乎息矣。矛盾似乎消失，斗争已然停止 —— 但是唯物辩证法告诉我们，矛盾永远不会消失，“物不可穷”，因此既济之后还会有未济，事物矛盾的变化没有穷尽。今晚十二点的钟声一旦敲响，就",
    "tags": [],
    "url": "/posts/Essays/十八岁-未济与求索/",
    "date": "2023-10-12T00:00:00.000Z",
    "content": "小时候囫囵吞枣看易经，到现在内容忘个精光，每一卦的名称倒是还依稀记得。易经以乾坤两卦开始，最后一卦却是 “未济”。何为 “未济”？孔夫子作的《序卦传》说，“物不可穷也，故受之以未济终焉。” 易经六十四卦到了既济这一卦，乾坤或几乎息矣。矛盾似乎消失，斗争已然停止 —— 但是唯物辩证法告诉我们，矛盾永远不会消失，“物不可穷”，因此既济之后还会有未济，事物矛盾的变化没有穷尽。今晚十二点的钟声一旦敲响，就代表着我如果根据中国的阴阳合历来计算，就要正式加入到成年人的世界里了。是的，我十八岁了，成年了。成年意味着我正式结束了青少年的青涩与惶恐，哪怕心中仍有戚戚；成年意味着我要正式承担一位公民应尽的责任，哪怕我还没有自立；成年意味着我好像已经不再是个孩子，那个小时候梦寐以求的 “我已经长大了” 现在似乎正在呼啸而来，硬拉着我向前走，去面对这个世界。逝者如斯夫，不舍昼夜。幸至此世，今日恰逢十八载。我在阅读时经常会想：我们作为一个 “现代人”，又该如何面对现代性危机？何为现代性危机？何为现代性？现代性就是 “长江后浪推前浪，一代新人换旧人”，是革故鼎新。现在，太多的生活方式不是被颠覆，就是在被颠覆中。当然，乐观者称之为 “迭代”。在频繁的迭代声中，似乎一切的行业都会迅速变成传统行业，跟不上时代是这个时代最致命的挑战，多少坚固如长城的东西已迅速销声匿迹。似乎转眼间自己所熟知的老梗已经变成了时代的眼泪，最新的爆炸新闻和知识正在由大数据和互联网抢着向我的大脑里灌。“乱花渐欲迷人眼” 是对这个高速发展的社会最真实的写照。随着现代性的价值观深入人心，自由主义和平等主义也在逐渐浸入我们的意识。可是自由主义和平等主义要求多元主义，多元主义又何相对主义是一对孪生子 —— 相对主义正是现代性危机潜伏的精神土壤。一切都是流变的，一切都是可以被肆意解构的。标准已经不再是标准，美德也不再是美德。一切都是相对的，真理，价值，美丑，好坏，对错……这种思维模式未必错误，但是它绝非完全正确。艾伦・布鲁姆就敏锐地指出：“这样一来，人之间、文化之间的差异似乎消除了，反对歧视获得了更为充分的根据。然而在另一方面，推动人类追寻高尚、优秀品质的动力也消失了。即便这些品质找到了，也无须加以推崇。”无论是微观叙事中身边之事的变化，还是宏大叙事中国家时代的改变，时代的车轮都在滚滚向前。在快与变之中，在速生和速朽之间，我坚信这个社会中始终会有一个坚定稳固的内核，历经时间的淬炼，依然散发出不变的灼灼光芒。这个内核表现为学弟学妹们为了未来而努力奋斗，表现为支教教师深入山村送入光明，表现为身边中每一个不放弃的你我他。这个内核是我们对公平正义的追求，对仁与义的期许，对更符合人性与人类发展方向的道德律的坚持。已经走过的十七年里，时间流逝和自身的成长是变，我对于阅读和计算机的喜欢，对于那些美好事物的追求是不变。高考之后有段时间，我特别焦虑 —— 大数据算法实在太强了，各种我已经喜欢和可能喜欢的视频，文章争相出现在各类 APP 和网站的首页推荐里。拇指在手机屏幕方寸间游走的距离，也许会超过双脚走过的路程。我每天要花费大量的时间在这些事物上，结果不仅对我的成长帮助不大，还可能会形成信息茧房，反倒让我更加狭隘。理解以真实为本，但是真实不总是会自动呈现。认识到这一点之后，我开始逐步的收窄自己的信息获取渠道，严格控制大数据的作用，将绝大多数的信息源都合并到一处，拒绝算法的推荐。专注于在自己的领域内精进，在面对各类事件时多问一句 “真的吗” 和 “为什么”。在网上冲浪越久，我越是想要重新翻开书本，不为寻求真理，只为内心的平静。互联网带给我的信息已经严重过载，严肃阅读才是心之所向。作为时代的一粒沙，我有时有力，更多时候无力，但别无选择，除了阅读，思考，然后尽最大的努力过好这一生。在这变与不变之中，我跌跌撞撞的走过了十七年，并且即将开启新一段历程。正如我经常和好朋友说的一句话：“落子无悔，抉择本身就是向前。” 一路走来，纵使有很多遗憾，但是更多的是乐趣，是很多很多我所爱的人和爱我的人。人之抉择，难以处处顺滑，但求不违内心。总结十七年的经验，改掉自己的缺点，保持自己的优点，绝不放弃，乐观的继续向下走。絮絮叨叨了很多，十七年那么长，未来也那么长，一条朋友圈很难写的完；十七年很短，人生似乎也很短，一条朋友圈好像绰绰有余。不管怎样，祝自己 18 岁生日快乐！"
  },
  {
    "title": "分析问题的框架",
    "summary": "分析问题的框架一、判定信息的类型#信息可以被分成事实，立场，信仰和观点。事实，是独立于人的判断客观存在的，是可以被证明或观察到的真实情况和事件。观点，是人们针对事实得出的看法，带有主观意味。立场，是被位置和利益影响的观点；通常一件社会事件可以基于利益划分出多种立场。信仰，是内部完全自洽的逻辑体系。很重要却经常被人忽视的一点是：事实，不一定就是真相。“真相” 是一个很有趣，经常（或者说总是）被滥用。",
    "tags": [],
    "url": "/posts/Essays/分析问题的框架/",
    "date": "2023-10-12T00:00:00.000Z",
    "content": "分析问题的框架一、判定信息的类型#信息可以被分成事实，立场，信仰和观点。事实，是独立于人的判断客观存在的，是可以被证明或观察到的真实情况和事件。观点，是人们针对事实得出的看法，带有主观意味。立场，是被位置和利益影响的观点；通常一件社会事件可以基于利益划分出多种立场。信仰，是内部完全自洽的逻辑体系。很重要却经常被人忽视的一点是：事实，不一定就是真相。“真相” 是一个很有趣，经常（或者说总是）被滥用。假如一个人 / 组织在不断的宣称自己掌握了 “真相”，那这个人 / 组织大多有所图谋并且不怀好意。常见的场景：不使用全面的事实，有意无意地忽略事实，不顾事实，选择性地接受自己喜欢的事实。2. 故意利用只给部分事实的方法误导别人 3. 以为是真的，其实是假的 4. 以为是确定的，其实是不确定的因此，在接收到新的信息时，一定要先去判断这份信息到底属于什么类型，信源可信度如何，能否交叉验证，此信息的逻辑链是否完整，是否同已知的知识相抵触・・・・・・二、认识准则#没有人是永远对的，只要是根据事实证据来做理性的逻辑推演，我们就应该给予尊重。如果有相反的意见，既然作者已经把推理过程详细解释了，那么尽可以就事论事指出逻辑错误之处。这是一个相互切磋的过程。个人初始结论的对错不要紧，重要的是论证必须遵循严谨的逻辑。但如果不做逻辑推演，直接下结论，那就是空喊口号，浪费大家的时间。如果连结论都懒得叙述，直接做人身攻击，这种人更是无需理会，其言论当垃圾过滤掉即可。假如不同意某个结论，需要自带完整而严密的事实和逻辑推理，只通过文辞用感情来惑乱理性，让读者无暇思考直接接受他人的结论，这通常是骗子的障眼法"
  }
]